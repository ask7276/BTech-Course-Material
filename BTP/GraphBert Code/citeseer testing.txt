0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8017 acc_train: 0.1083 loss_val: 1.8005 acc_val: 0.1800 loss_test: 1.7062 acc_test: 0.4560 time: 0.1435s
Epoch: 0051 loss_train: 0.0156 acc_train: 1.0000 loss_val: 1.7533 acc_val: 0.3800 loss_test: 1.1200 acc_test: 0.6610 time: 0.0970s
Epoch: 0101 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7212 acc_val: 0.4167 loss_test: 1.1122 acc_test: 0.6760 time: 0.0970s
Epoch: 0151 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7719 acc_val: 0.4367 loss_test: 1.1465 acc_test: 0.6830 time: 0.0768s
Epoch: 0201 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8585 acc_val: 0.4433 loss_test: 1.2000 acc_test: 0.6800 time: 0.0900s
Epoch: 0251 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9142 acc_val: 0.4600 loss_test: 1.2561 acc_test: 0.6900 time: 0.0644s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9769 acc_val: 0.4900 loss_test: 1.3030 acc_test: 0.6920 time: 0.0734s
Epoch: 0351 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0294 acc_val: 0.4933 loss_test: 1.3440 acc_test: 0.6970 time: 0.0977s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0699 acc_val: 0.5067 loss_test: 1.3850 acc_test: 0.7000 time: 0.0578s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1183 acc_val: 0.5133 loss_test: 1.4210 acc_test: 0.7010 time: 0.0602s
Optimization Finished!
Total time elapsed: 37.6906s, best testing performance  0.706000, minimun loss  1.047450
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7757 acc_train: 0.2500 loss_val: 1.7974 acc_val: 0.1533 loss_test: 1.6851 acc_test: 0.4910 time: 0.1089s
Epoch: 0051 loss_train: 0.0157 acc_train: 1.0000 loss_val: 1.7241 acc_val: 0.3900 loss_test: 1.1167 acc_test: 0.6600 time: 0.0831s
Epoch: 0101 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.6659 acc_val: 0.4467 loss_test: 1.1033 acc_test: 0.6760 time: 0.0869s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7082 acc_val: 0.4633 loss_test: 1.1409 acc_test: 0.6840 time: 0.0957s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.7908 acc_val: 0.4667 loss_test: 1.1949 acc_test: 0.6870 time: 0.0694s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.8141 acc_val: 0.4867 loss_test: 1.2435 acc_test: 0.6970 time: 0.0778s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9032 acc_val: 0.5000 loss_test: 1.2987 acc_test: 0.7040 time: 0.0927s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0230 acc_val: 0.5067 loss_test: 1.3717 acc_test: 0.7010 time: 0.1136s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0220 acc_val: 0.5100 loss_test: 1.4041 acc_test: 0.7070 time: 0.0826s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0747 acc_val: 0.5067 loss_test: 1.4599 acc_test: 0.7050 time: 0.0664s
Optimization Finished!
Total time elapsed: 40.9706s, best testing performance  0.711000, minimun loss  1.054468
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8112 acc_train: 0.1167 loss_val: 1.8109 acc_val: 0.1800 loss_test: 1.7116 acc_test: 0.4700 time: 0.0841s
Epoch: 0051 loss_train: 0.0155 acc_train: 1.0000 loss_val: 1.7819 acc_val: 0.3533 loss_test: 1.1289 acc_test: 0.6580 time: 0.0695s
Epoch: 0101 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7706 acc_val: 0.4233 loss_test: 1.1282 acc_test: 0.6740 time: 0.0858s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8277 acc_val: 0.4167 loss_test: 1.1735 acc_test: 0.6720 time: 0.0867s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8921 acc_val: 0.4233 loss_test: 1.2181 acc_test: 0.6750 time: 0.0946s
Epoch: 0251 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9155 acc_val: 0.4467 loss_test: 1.2522 acc_test: 0.6850 time: 0.0816s
Epoch: 0301 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9702 acc_val: 0.4600 loss_test: 1.3034 acc_test: 0.6870 time: 0.0978s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0247 acc_val: 0.4700 loss_test: 1.3506 acc_test: 0.6890 time: 0.0818s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1019 acc_val: 0.4933 loss_test: 1.4033 acc_test: 0.6930 time: 0.0764s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1172 acc_val: 0.5000 loss_test: 1.4369 acc_test: 0.7010 time: 0.0584s
Optimization Finished!
Total time elapsed: 38.6899s, best testing performance  0.702000, minimun loss  1.045956
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7910 acc_train: 0.1750 loss_val: 1.7936 acc_val: 0.1500 loss_test: 1.7004 acc_test: 0.4810 time: 0.0892s
Epoch: 0051 loss_train: 0.0156 acc_train: 1.0000 loss_val: 1.7338 acc_val: 0.3800 loss_test: 1.1362 acc_test: 0.6600 time: 0.0597s
Epoch: 0101 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.6588 acc_val: 0.4433 loss_test: 1.1152 acc_test: 0.6770 time: 0.0810s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7223 acc_val: 0.4800 loss_test: 1.1457 acc_test: 0.6830 time: 0.0815s
Epoch: 0201 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.7718 acc_val: 0.4533 loss_test: 1.1812 acc_test: 0.6800 time: 0.0739s
Epoch: 0251 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8564 acc_val: 0.4700 loss_test: 1.2315 acc_test: 0.6850 time: 0.0898s
Epoch: 0301 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9309 acc_val: 0.4833 loss_test: 1.2852 acc_test: 0.6930 time: 0.0657s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0441 acc_val: 0.4867 loss_test: 1.3497 acc_test: 0.6930 time: 0.0776s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1131 acc_val: 0.4967 loss_test: 1.3929 acc_test: 0.6940 time: 0.0860s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1732 acc_val: 0.5000 loss_test: 1.4427 acc_test: 0.6920 time: 0.0858s
Optimization Finished!
Total time elapsed: 39.2429s, best testing performance  0.698000, minimun loss  1.061365
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7951 acc_train: 0.1667 loss_val: 1.7959 acc_val: 0.1167 loss_test: 1.7138 acc_test: 0.4660 time: 0.0980s
Epoch: 0051 loss_train: 0.0151 acc_train: 1.0000 loss_val: 1.7868 acc_val: 0.3733 loss_test: 1.1445 acc_test: 0.6600 time: 0.0828s
Epoch: 0101 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7608 acc_val: 0.4067 loss_test: 1.1361 acc_test: 0.6760 time: 0.0892s
Epoch: 0151 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8294 acc_val: 0.4367 loss_test: 1.1739 acc_test: 0.6780 time: 0.0815s
Epoch: 0201 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8837 acc_val: 0.4400 loss_test: 1.2178 acc_test: 0.6790 time: 0.0916s
Epoch: 0251 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9181 acc_val: 0.4633 loss_test: 1.2618 acc_test: 0.6840 time: 0.0843s
Epoch: 0301 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9720 acc_val: 0.4700 loss_test: 1.3082 acc_test: 0.6880 time: 0.1062s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9874 acc_val: 0.4833 loss_test: 1.3442 acc_test: 0.6920 time: 0.0897s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0316 acc_val: 0.4967 loss_test: 1.3889 acc_test: 0.6990 time: 0.1160s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0626 acc_val: 0.5067 loss_test: 1.4265 acc_test: 0.6970 time: 0.0762s
Optimization Finished!
Total time elapsed: 40.5113s, best testing performance  0.702000, minimun loss  1.066909
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8002 acc_train: 0.1333 loss_val: 1.8012 acc_val: 0.1533 loss_test: 1.7144 acc_test: 0.4750 time: 0.0863s
Epoch: 0051 loss_train: 0.0165 acc_train: 1.0000 loss_val: 1.8865 acc_val: 0.3433 loss_test: 1.1634 acc_test: 0.6510 time: 0.0589s
Epoch: 0101 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8248 acc_val: 0.4000 loss_test: 1.1449 acc_test: 0.6710 time: 0.0589s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.4233 loss_test: 1.1790 acc_test: 0.6780 time: 0.0886s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8705 acc_val: 0.4533 loss_test: 1.2198 acc_test: 0.6810 time: 0.0808s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8820 acc_val: 0.4733 loss_test: 1.2541 acc_test: 0.6860 time: 0.0805s
Epoch: 0301 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9093 acc_val: 0.4800 loss_test: 1.2983 acc_test: 0.6910 time: 0.0864s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9580 acc_val: 0.5000 loss_test: 1.3362 acc_test: 0.6970 time: 0.0860s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0081 acc_val: 0.5100 loss_test: 1.3816 acc_test: 0.6970 time: 0.0774s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0480 acc_val: 0.5200 loss_test: 1.4246 acc_test: 0.6950 time: 0.0861s
Optimization Finished!
Total time elapsed: 37.6569s, best testing performance  0.704000, minimun loss  1.073043
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.1667 loss_val: 1.7926 acc_val: 0.1600 loss_test: 1.7027 acc_test: 0.5000 time: 0.0797s
Epoch: 0051 loss_train: 0.0163 acc_train: 1.0000 loss_val: 1.8406 acc_val: 0.3867 loss_test: 1.1425 acc_test: 0.6530 time: 0.0714s
Epoch: 0101 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8271 acc_val: 0.4100 loss_test: 1.1430 acc_test: 0.6730 time: 0.0762s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8557 acc_val: 0.4200 loss_test: 1.1760 acc_test: 0.6810 time: 0.0743s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9082 acc_val: 0.4367 loss_test: 1.2161 acc_test: 0.6810 time: 0.0865s
Epoch: 0251 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9514 acc_val: 0.4500 loss_test: 1.2549 acc_test: 0.6860 time: 0.0697s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0020 acc_val: 0.4633 loss_test: 1.2996 acc_test: 0.6860 time: 0.0740s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0539 acc_val: 0.4767 loss_test: 1.3353 acc_test: 0.6860 time: 0.0723s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1190 acc_val: 0.4867 loss_test: 1.3830 acc_test: 0.6930 time: 0.0830s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1737 acc_val: 0.4867 loss_test: 1.4198 acc_test: 0.6930 time: 0.0871s
Optimization Finished!
Total time elapsed: 40.7332s, best testing performance  0.700000, minimun loss  1.066604
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7921 acc_train: 0.1750 loss_val: 1.7784 acc_val: 0.1833 loss_test: 1.7062 acc_test: 0.5420 time: 0.0933s
Epoch: 0051 loss_train: 0.0164 acc_train: 1.0000 loss_val: 1.8256 acc_val: 0.3467 loss_test: 1.1371 acc_test: 0.6510 time: 0.0606s
Epoch: 0101 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7744 acc_val: 0.4033 loss_test: 1.1217 acc_test: 0.6720 time: 0.0585s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8048 acc_val: 0.4200 loss_test: 1.1542 acc_test: 0.6830 time: 0.0633s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8387 acc_val: 0.4300 loss_test: 1.1942 acc_test: 0.6900 time: 0.0801s
Epoch: 0251 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8697 acc_val: 0.4600 loss_test: 1.2315 acc_test: 0.6920 time: 0.0878s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9169 acc_val: 0.4800 loss_test: 1.2732 acc_test: 0.6950 time: 0.0876s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9428 acc_val: 0.4833 loss_test: 1.3140 acc_test: 0.6970 time: 0.0734s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0272 acc_val: 0.5000 loss_test: 1.3633 acc_test: 0.7000 time: 0.0901s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0789 acc_val: 0.4933 loss_test: 1.4073 acc_test: 0.7010 time: 0.0819s
Optimization Finished!
Total time elapsed: 37.0254s, best testing performance  0.703000, minimun loss  1.044438
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7702 acc_train: 0.2750 loss_val: 1.8058 acc_val: 0.1667 loss_test: 1.6943 acc_test: 0.5170 time: 0.0960s
Epoch: 0051 loss_train: 0.0160 acc_train: 1.0000 loss_val: 1.8184 acc_val: 0.3800 loss_test: 1.1421 acc_test: 0.6540 time: 0.0936s
Epoch: 0101 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7947 acc_val: 0.4067 loss_test: 1.1346 acc_test: 0.6770 time: 0.0964s
Epoch: 0151 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8373 acc_val: 0.4333 loss_test: 1.1692 acc_test: 0.6810 time: 0.0851s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8715 acc_val: 0.4267 loss_test: 1.2086 acc_test: 0.6830 time: 0.0664s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9426 acc_val: 0.4433 loss_test: 1.2623 acc_test: 0.6850 time: 0.0846s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9801 acc_val: 0.4633 loss_test: 1.3158 acc_test: 0.6910 time: 0.0825s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1025 acc_val: 0.4667 loss_test: 1.3947 acc_test: 0.6940 time: 0.1163s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1773 acc_val: 0.4767 loss_test: 1.4595 acc_test: 0.6980 time: 0.0818s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2326 acc_val: 0.5000 loss_test: 1.5173 acc_test: 0.7030 time: 0.0955s
Optimization Finished!
Total time elapsed: 40.7500s, best testing performance  0.705000, minimun loss  1.058836
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7864 acc_train: 0.2417 loss_val: 1.7880 acc_val: 0.1900 loss_test: 1.6999 acc_test: 0.5490 time: 0.0986s
Epoch: 0051 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.7945 acc_val: 0.3833 loss_test: 1.1366 acc_test: 0.6640 time: 0.0592s
Epoch: 0101 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.8152 acc_val: 0.4033 loss_test: 1.1406 acc_test: 0.6710 time: 0.0587s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8677 acc_val: 0.4333 loss_test: 1.1760 acc_test: 0.6790 time: 0.0588s
Epoch: 0201 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8966 acc_val: 0.4467 loss_test: 1.2163 acc_test: 0.6870 time: 0.0602s
Epoch: 0251 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9458 acc_val: 0.4600 loss_test: 1.2609 acc_test: 0.6850 time: 0.0799s
Epoch: 0301 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0146 acc_val: 0.4700 loss_test: 1.3114 acc_test: 0.6830 time: 0.0878s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0871 acc_val: 0.4800 loss_test: 1.3669 acc_test: 0.6910 time: 0.0810s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1428 acc_val: 0.4900 loss_test: 1.4172 acc_test: 0.6930 time: 0.0825s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2170 acc_val: 0.4867 loss_test: 1.4609 acc_test: 0.6950 time: 0.0908s
Optimization Finished!
Total time elapsed: 36.0388s, best testing performance  0.700000, minimun loss  1.078055
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8108 acc_train: 0.1500 loss_val: 1.7841 acc_val: 0.2133 loss_test: 1.7296 acc_test: 0.4230 time: 0.0937s
Epoch: 0051 loss_train: 0.0181 acc_train: 1.0000 loss_val: 1.8740 acc_val: 0.3567 loss_test: 1.1532 acc_test: 0.6560 time: 0.0698s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8496 acc_val: 0.3900 loss_test: 1.1497 acc_test: 0.6670 time: 0.0868s
Epoch: 0151 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8998 acc_val: 0.4200 loss_test: 1.1889 acc_test: 0.6820 time: 0.0864s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9191 acc_val: 0.4400 loss_test: 1.2293 acc_test: 0.6840 time: 0.0800s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9550 acc_val: 0.4533 loss_test: 1.2699 acc_test: 0.6860 time: 0.0809s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9838 acc_val: 0.4667 loss_test: 1.3085 acc_test: 0.6860 time: 0.0809s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0447 acc_val: 0.4733 loss_test: 1.3594 acc_test: 0.6910 time: 0.0863s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1023 acc_val: 0.4833 loss_test: 1.4011 acc_test: 0.6980 time: 0.0853s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1375 acc_val: 0.4833 loss_test: 1.4396 acc_test: 0.7000 time: 0.0764s
Optimization Finished!
Total time elapsed: 41.3382s, best testing performance  0.705000, minimun loss  1.073442
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8054 acc_train: 0.1333 loss_val: 1.7804 acc_val: 0.2100 loss_test: 1.7219 acc_test: 0.4700 time: 0.0801s
Epoch: 0051 loss_train: 0.0175 acc_train: 1.0000 loss_val: 1.8974 acc_val: 0.3400 loss_test: 1.1483 acc_test: 0.6450 time: 0.0592s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8552 acc_val: 0.4033 loss_test: 1.1452 acc_test: 0.6570 time: 0.0588s
Epoch: 0151 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8748 acc_val: 0.4133 loss_test: 1.1791 acc_test: 0.6690 time: 0.0587s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8910 acc_val: 0.4433 loss_test: 1.2132 acc_test: 0.6820 time: 0.0589s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9497 acc_val: 0.4533 loss_test: 1.2647 acc_test: 0.6850 time: 0.0941s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9964 acc_val: 0.4733 loss_test: 1.3138 acc_test: 0.6920 time: 0.0776s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0372 acc_val: 0.4800 loss_test: 1.3580 acc_test: 0.6930 time: 0.0879s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0769 acc_val: 0.5000 loss_test: 1.4058 acc_test: 0.6970 time: 0.0716s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1484 acc_val: 0.5000 loss_test: 1.4520 acc_test: 0.7000 time: 0.0901s
Optimization Finished!
Total time elapsed: 35.3788s, best testing performance  0.703000, minimun loss  1.054049
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1333 loss_val: 1.7719 acc_val: 0.2233 loss_test: 1.7092 acc_test: 0.5010 time: 0.0811s
Epoch: 0051 loss_train: 0.0175 acc_train: 1.0000 loss_val: 1.8261 acc_val: 0.3600 loss_test: 1.1475 acc_test: 0.6550 time: 0.0724s
Epoch: 0101 loss_train: 0.0134 acc_train: 1.0000 loss_val: 1.8247 acc_val: 0.4033 loss_test: 1.1441 acc_test: 0.6630 time: 0.0806s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8441 acc_val: 0.4133 loss_test: 1.1787 acc_test: 0.6830 time: 0.0848s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8572 acc_val: 0.4400 loss_test: 1.2121 acc_test: 0.6820 time: 0.0926s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8819 acc_val: 0.4600 loss_test: 1.2518 acc_test: 0.6860 time: 0.0719s
Epoch: 0301 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9351 acc_val: 0.4700 loss_test: 1.3073 acc_test: 0.6850 time: 0.0919s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0043 acc_val: 0.4767 loss_test: 1.3683 acc_test: 0.6920 time: 0.0823s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0557 acc_val: 0.4867 loss_test: 1.4234 acc_test: 0.6920 time: 0.0809s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1521 acc_val: 0.4867 loss_test: 1.4798 acc_test: 0.6920 time: 0.0628s
Optimization Finished!
Total time elapsed: 40.8161s, best testing performance  0.701000, minimun loss  1.083597
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7882 acc_train: 0.2250 loss_val: 1.7929 acc_val: 0.1833 loss_test: 1.7092 acc_test: 0.5110 time: 0.0929s
Epoch: 0051 loss_train: 0.0172 acc_train: 1.0000 loss_val: 1.8851 acc_val: 0.3333 loss_test: 1.1519 acc_test: 0.6430 time: 0.0578s
Epoch: 0101 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8363 acc_val: 0.4033 loss_test: 1.1389 acc_test: 0.6650 time: 0.0587s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8298 acc_val: 0.4200 loss_test: 1.1643 acc_test: 0.6810 time: 0.0615s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8347 acc_val: 0.4433 loss_test: 1.1978 acc_test: 0.6850 time: 0.0602s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8736 acc_val: 0.4567 loss_test: 1.2422 acc_test: 0.6880 time: 0.0602s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9116 acc_val: 0.4733 loss_test: 1.2889 acc_test: 0.6920 time: 0.0752s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9831 acc_val: 0.4933 loss_test: 1.3421 acc_test: 0.6930 time: 0.0943s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0219 acc_val: 0.4900 loss_test: 1.3839 acc_test: 0.7010 time: 0.0755s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4867 loss_test: 1.4345 acc_test: 0.7040 time: 0.0775s
Optimization Finished!
Total time elapsed: 34.9581s, best testing performance  0.707000, minimun loss  1.075047
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7998 acc_train: 0.1250 loss_val: 1.7946 acc_val: 0.1733 loss_test: 1.7199 acc_test: 0.4550 time: 0.1043s
Epoch: 0051 loss_train: 0.0165 acc_train: 1.0000 loss_val: 1.9021 acc_val: 0.3400 loss_test: 1.1723 acc_test: 0.6440 time: 0.0879s
Epoch: 0101 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8274 acc_val: 0.3933 loss_test: 1.1474 acc_test: 0.6620 time: 0.0808s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8438 acc_val: 0.4133 loss_test: 1.1767 acc_test: 0.6780 time: 0.0686s
Epoch: 0201 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8607 acc_val: 0.4467 loss_test: 1.2029 acc_test: 0.6780 time: 0.0722s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8871 acc_val: 0.4633 loss_test: 1.2349 acc_test: 0.6860 time: 0.0631s
Epoch: 0301 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9103 acc_val: 0.4833 loss_test: 1.2670 acc_test: 0.6940 time: 0.0880s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9455 acc_val: 0.4867 loss_test: 1.3047 acc_test: 0.6940 time: 0.0703s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 1.9910 acc_val: 0.4800 loss_test: 1.3404 acc_test: 0.7000 time: 0.0641s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0414 acc_val: 0.4900 loss_test: 1.3799 acc_test: 0.7000 time: 0.0740s
Optimization Finished!
Total time elapsed: 40.7165s, best testing performance  0.705000, minimun loss  1.089354
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7772 acc_train: 0.1750 loss_val: 1.7936 acc_val: 0.1933 loss_test: 1.6935 acc_test: 0.4570 time: 0.0952s
Epoch: 0051 loss_train: 0.0155 acc_train: 1.0000 loss_val: 1.7897 acc_val: 0.3767 loss_test: 1.1304 acc_test: 0.6620 time: 0.0575s
Epoch: 0101 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7901 acc_val: 0.4000 loss_test: 1.1277 acc_test: 0.6780 time: 0.0604s
Epoch: 0151 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8063 acc_val: 0.4267 loss_test: 1.1595 acc_test: 0.6830 time: 0.0608s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8126 acc_val: 0.4433 loss_test: 1.1984 acc_test: 0.6840 time: 0.0587s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8556 acc_val: 0.4633 loss_test: 1.2415 acc_test: 0.6870 time: 0.0590s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.8864 acc_val: 0.4733 loss_test: 1.2812 acc_test: 0.6880 time: 0.0747s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9653 acc_val: 0.4833 loss_test: 1.3263 acc_test: 0.6900 time: 0.0735s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0058 acc_val: 0.4833 loss_test: 1.3614 acc_test: 0.6940 time: 0.0739s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0571 acc_val: 0.5000 loss_test: 1.4036 acc_test: 0.6940 time: 0.0739s
Optimization Finished!
Total time elapsed: 34.4409s, best testing performance  0.698000, minimun loss  1.048513
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.2000 loss_val: 1.7895 acc_val: 0.1600 loss_test: 1.7028 acc_test: 0.4920 time: 0.0896s
Epoch: 0051 loss_train: 0.0164 acc_train: 1.0000 loss_val: 1.8339 acc_val: 0.3667 loss_test: 1.1500 acc_test: 0.6520 time: 0.0680s
Epoch: 0101 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8038 acc_val: 0.3900 loss_test: 1.1457 acc_test: 0.6680 time: 0.0742s
Epoch: 0151 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8229 acc_val: 0.4200 loss_test: 1.1744 acc_test: 0.6800 time: 0.0860s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8156 acc_val: 0.4600 loss_test: 1.2016 acc_test: 0.6870 time: 0.0885s
Epoch: 0251 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.8454 acc_val: 0.4600 loss_test: 1.2458 acc_test: 0.6900 time: 0.0634s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9030 acc_val: 0.4767 loss_test: 1.3021 acc_test: 0.6960 time: 0.0816s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 1.9623 acc_val: 0.4933 loss_test: 1.3665 acc_test: 0.6960 time: 0.0703s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0712 acc_val: 0.4867 loss_test: 1.4361 acc_test: 0.6960 time: 0.0912s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1647 acc_val: 0.4800 loss_test: 1.4990 acc_test: 0.6950 time: 0.1202s
Optimization Finished!
Total time elapsed: 40.6819s, best testing performance  0.701000, minimun loss  1.066932
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.1667 loss_val: 1.7991 acc_val: 0.1933 loss_test: 1.7160 acc_test: 0.4540 time: 0.0975s
Epoch: 0051 loss_train: 0.0166 acc_train: 1.0000 loss_val: 1.8757 acc_val: 0.3533 loss_test: 1.1450 acc_test: 0.6490 time: 0.0586s
Epoch: 0101 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.8535 acc_val: 0.3900 loss_test: 1.1430 acc_test: 0.6670 time: 0.0572s
Epoch: 0151 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8803 acc_val: 0.4267 loss_test: 1.1797 acc_test: 0.6750 time: 0.0583s
Epoch: 0201 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9130 acc_val: 0.4300 loss_test: 1.2226 acc_test: 0.6800 time: 0.0590s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9431 acc_val: 0.4533 loss_test: 1.2586 acc_test: 0.6870 time: 0.0603s
Epoch: 0301 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9899 acc_val: 0.4567 loss_test: 1.3043 acc_test: 0.6900 time: 0.0594s
Epoch: 0351 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0365 acc_val: 0.4633 loss_test: 1.3418 acc_test: 0.6910 time: 0.0677s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0854 acc_val: 0.4733 loss_test: 1.3802 acc_test: 0.6950 time: 0.0887s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1087 acc_val: 0.4833 loss_test: 1.4077 acc_test: 0.6970 time: 0.0795s
Optimization Finished!
Total time elapsed: 33.5509s, best testing performance  0.703000, minimun loss  1.057835
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8115 acc_train: 0.0917 loss_val: 1.7806 acc_val: 0.1767 loss_test: 1.7203 acc_test: 0.4570 time: 0.1076s
Epoch: 0051 loss_train: 0.0158 acc_train: 1.0000 loss_val: 1.8073 acc_val: 0.3767 loss_test: 1.1476 acc_test: 0.6610 time: 0.0813s
Epoch: 0101 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7845 acc_val: 0.4033 loss_test: 1.1405 acc_test: 0.6690 time: 0.0896s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8238 acc_val: 0.4233 loss_test: 1.1723 acc_test: 0.6730 time: 0.0926s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8263 acc_val: 0.4500 loss_test: 1.2056 acc_test: 0.6800 time: 0.0700s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8732 acc_val: 0.4700 loss_test: 1.2472 acc_test: 0.6850 time: 0.0702s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9051 acc_val: 0.4833 loss_test: 1.2824 acc_test: 0.6940 time: 0.0675s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9232 acc_val: 0.4867 loss_test: 1.3190 acc_test: 0.6980 time: 0.0679s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 1.9416 acc_val: 0.4967 loss_test: 1.3507 acc_test: 0.7020 time: 0.0725s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 1.9727 acc_val: 0.5167 loss_test: 1.3760 acc_test: 0.7030 time: 0.0955s
Optimization Finished!
Total time elapsed: 40.6225s, best testing performance  0.709000, minimun loss  1.060031
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8015 acc_train: 0.1417 loss_val: 1.8010 acc_val: 0.1500 loss_test: 1.7247 acc_test: 0.4510 time: 0.0688s
Epoch: 0051 loss_train: 0.0162 acc_train: 1.0000 loss_val: 1.8105 acc_val: 0.3833 loss_test: 1.1306 acc_test: 0.6590 time: 0.0575s
Epoch: 0101 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7854 acc_val: 0.4033 loss_test: 1.1332 acc_test: 0.6720 time: 0.0575s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8088 acc_val: 0.4267 loss_test: 1.1699 acc_test: 0.6750 time: 0.0574s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8509 acc_val: 0.4433 loss_test: 1.2160 acc_test: 0.6800 time: 0.0600s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8831 acc_val: 0.4667 loss_test: 1.2541 acc_test: 0.6860 time: 0.0591s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9478 acc_val: 0.4700 loss_test: 1.3020 acc_test: 0.6890 time: 0.0592s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0039 acc_val: 0.4800 loss_test: 1.3484 acc_test: 0.6920 time: 0.0597s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0414 acc_val: 0.4900 loss_test: 1.3856 acc_test: 0.6990 time: 0.0851s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0907 acc_val: 0.4933 loss_test: 1.4217 acc_test: 0.6980 time: 0.0901s
Optimization Finished!
Total time elapsed: 32.0811s, best testing performance  0.703000, minimun loss  1.063621
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7930 acc_train: 0.1833 loss_val: 1.8046 acc_val: 0.2000 loss_test: 1.7061 acc_test: 0.4000 time: 0.0777s
Epoch: 0051 loss_train: 0.0142 acc_train: 1.0000 loss_val: 1.8697 acc_val: 0.3667 loss_test: 1.1609 acc_test: 0.6650 time: 0.0691s
Epoch: 0101 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8941 acc_val: 0.3967 loss_test: 1.1713 acc_test: 0.6760 time: 0.0789s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9230 acc_val: 0.4300 loss_test: 1.2148 acc_test: 0.6780 time: 0.0738s
Epoch: 0201 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0175 acc_val: 0.4333 loss_test: 1.2813 acc_test: 0.6760 time: 0.0800s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0708 acc_val: 0.4533 loss_test: 1.3244 acc_test: 0.6750 time: 0.0694s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0817 acc_val: 0.4733 loss_test: 1.3564 acc_test: 0.6870 time: 0.0807s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1165 acc_val: 0.4900 loss_test: 1.3945 acc_test: 0.6920 time: 0.0694s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1620 acc_val: 0.5000 loss_test: 1.4383 acc_test: 0.6950 time: 0.0738s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2027 acc_val: 0.5033 loss_test: 1.4718 acc_test: 0.7020 time: 0.0789s
Optimization Finished!
Total time elapsed: 40.7367s, best testing performance  0.705000, minimun loss  1.029670
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8043 acc_train: 0.1167 loss_val: 1.7805 acc_val: 0.1700 loss_test: 1.7233 acc_test: 0.4350 time: 0.0851s
Epoch: 0051 loss_train: 0.0142 acc_train: 1.0000 loss_val: 1.9035 acc_val: 0.3600 loss_test: 1.1635 acc_test: 0.6530 time: 0.0579s
Epoch: 0101 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9518 acc_val: 0.3800 loss_test: 1.1922 acc_test: 0.6580 time: 0.0570s
Epoch: 0151 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9917 acc_val: 0.3867 loss_test: 1.2307 acc_test: 0.6660 time: 0.0572s
Epoch: 0201 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0254 acc_val: 0.4300 loss_test: 1.2611 acc_test: 0.6800 time: 0.0578s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0864 acc_val: 0.4633 loss_test: 1.3041 acc_test: 0.6850 time: 0.0610s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1127 acc_val: 0.4833 loss_test: 1.3385 acc_test: 0.6900 time: 0.0590s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1396 acc_val: 0.4900 loss_test: 1.3705 acc_test: 0.6940 time: 0.0589s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1790 acc_val: 0.5067 loss_test: 1.4069 acc_test: 0.6960 time: 0.0600s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2048 acc_val: 0.5133 loss_test: 1.4357 acc_test: 0.6990 time: 0.0925s
Optimization Finished!
Total time elapsed: 31.5933s, best testing performance  0.702000, minimun loss  1.041823
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7896 acc_train: 0.1750 loss_val: 1.8049 acc_val: 0.1600 loss_test: 1.6844 acc_test: 0.5280 time: 0.0849s
Epoch: 0051 loss_train: 0.0151 acc_train: 1.0000 loss_val: 1.8019 acc_val: 0.3800 loss_test: 1.1577 acc_test: 0.6610 time: 0.1175s
Epoch: 0101 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8775 acc_val: 0.4133 loss_test: 1.1831 acc_test: 0.6700 time: 0.0833s
Epoch: 0151 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.9170 acc_val: 0.4333 loss_test: 1.2190 acc_test: 0.6760 time: 0.0856s
Epoch: 0201 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9411 acc_val: 0.4300 loss_test: 1.2554 acc_test: 0.6730 time: 0.0717s
Epoch: 0251 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0273 acc_val: 0.4500 loss_test: 1.3014 acc_test: 0.6820 time: 0.0694s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0477 acc_val: 0.4767 loss_test: 1.3194 acc_test: 0.6920 time: 0.0820s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0799 acc_val: 0.4900 loss_test: 1.3482 acc_test: 0.6930 time: 0.0951s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1367 acc_val: 0.5000 loss_test: 1.3827 acc_test: 0.6970 time: 0.0865s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1474 acc_val: 0.5067 loss_test: 1.4116 acc_test: 0.7020 time: 0.1050s
Optimization Finished!
Total time elapsed: 40.8414s, best testing performance  0.704000, minimun loss  1.046583
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7907 acc_train: 0.1667 loss_val: 1.7745 acc_val: 0.2433 loss_test: 1.6967 acc_test: 0.5320 time: 0.0759s
Epoch: 0051 loss_train: 0.0143 acc_train: 1.0000 loss_val: 1.9141 acc_val: 0.3767 loss_test: 1.1638 acc_test: 0.6570 time: 0.0765s
Epoch: 0101 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9922 acc_val: 0.3867 loss_test: 1.1998 acc_test: 0.6630 time: 0.0571s
Epoch: 0151 loss_train: 0.0079 acc_train: 1.0000 loss_val: 2.0436 acc_val: 0.3900 loss_test: 1.2473 acc_test: 0.6620 time: 0.0573s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0017 acc_val: 0.4200 loss_test: 1.2624 acc_test: 0.6830 time: 0.0594s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0027 acc_val: 0.4400 loss_test: 1.2843 acc_test: 0.6880 time: 0.0574s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0614 acc_val: 0.4733 loss_test: 1.3255 acc_test: 0.6940 time: 0.0582s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1008 acc_val: 0.5000 loss_test: 1.3625 acc_test: 0.6960 time: 0.0609s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1062 acc_val: 0.5067 loss_test: 1.3912 acc_test: 0.7020 time: 0.0588s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.5033 loss_test: 1.4251 acc_test: 0.7070 time: 0.0595s
Optimization Finished!
Total time elapsed: 31.5111s, best testing performance  0.707000, minimun loss  1.026903
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8073 acc_train: 0.0917 loss_val: 1.8000 acc_val: 0.1133 loss_test: 1.7198 acc_test: 0.4460 time: 0.0612s
Epoch: 0051 loss_train: 0.0140 acc_train: 1.0000 loss_val: 1.9278 acc_val: 0.3633 loss_test: 1.1891 acc_test: 0.6630 time: 0.0862s
Epoch: 0101 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9277 acc_val: 0.3867 loss_test: 1.1881 acc_test: 0.6690 time: 0.0816s
Epoch: 0151 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9590 acc_val: 0.4100 loss_test: 1.2301 acc_test: 0.6790 time: 0.0927s
Epoch: 0201 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9923 acc_val: 0.4133 loss_test: 1.2729 acc_test: 0.6780 time: 0.0796s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0252 acc_val: 0.4467 loss_test: 1.3057 acc_test: 0.6850 time: 0.0711s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0186 acc_val: 0.4500 loss_test: 1.3343 acc_test: 0.6880 time: 0.0661s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0603 acc_val: 0.4700 loss_test: 1.3729 acc_test: 0.6910 time: 0.0683s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0692 acc_val: 0.4933 loss_test: 1.3907 acc_test: 0.6970 time: 0.0702s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0936 acc_val: 0.4967 loss_test: 1.4246 acc_test: 0.6980 time: 0.0861s
Optimization Finished!
Total time elapsed: 41.1099s, best testing performance  0.705000, minimun loss  1.054730
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8163 acc_train: 0.1083 loss_val: 1.7891 acc_val: 0.2067 loss_test: 1.7356 acc_test: 0.4170 time: 0.1038s
Epoch: 0051 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.8779 acc_val: 0.3500 loss_test: 1.1519 acc_test: 0.6490 time: 0.0718s
Epoch: 0101 loss_train: 0.0134 acc_train: 1.0000 loss_val: 1.8490 acc_val: 0.4000 loss_test: 1.1463 acc_test: 0.6650 time: 0.0934s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8439 acc_val: 0.4233 loss_test: 1.1748 acc_test: 0.6830 time: 0.0573s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8536 acc_val: 0.4800 loss_test: 1.2082 acc_test: 0.6930 time: 0.0576s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8960 acc_val: 0.4600 loss_test: 1.2541 acc_test: 0.6960 time: 0.0589s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9457 acc_val: 0.4700 loss_test: 1.2993 acc_test: 0.6980 time: 0.0576s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0058 acc_val: 0.4667 loss_test: 1.3418 acc_test: 0.6980 time: 0.0593s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0579 acc_val: 0.4800 loss_test: 1.3839 acc_test: 0.7020 time: 0.0620s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1268 acc_val: 0.4733 loss_test: 1.4364 acc_test: 0.7050 time: 0.0600s
Optimization Finished!
Total time elapsed: 33.4897s, best testing performance  0.711000, minimun loss  1.077596
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8044 acc_train: 0.1167 loss_val: 1.7951 acc_val: 0.2100 loss_test: 1.7225 acc_test: 0.4660 time: 0.0733s
Epoch: 0051 loss_train: 0.0182 acc_train: 1.0000 loss_val: 1.8986 acc_val: 0.3467 loss_test: 1.1808 acc_test: 0.6440 time: 0.0702s
Epoch: 0101 loss_train: 0.0138 acc_train: 1.0000 loss_val: 1.8484 acc_val: 0.3967 loss_test: 1.1685 acc_test: 0.6620 time: 0.0685s
Epoch: 0151 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8598 acc_val: 0.4367 loss_test: 1.1986 acc_test: 0.6760 time: 0.0738s
Epoch: 0201 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8937 acc_val: 0.4467 loss_test: 1.2358 acc_test: 0.6840 time: 0.1030s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9264 acc_val: 0.4667 loss_test: 1.2811 acc_test: 0.6820 time: 0.0711s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9978 acc_val: 0.4667 loss_test: 1.3318 acc_test: 0.6870 time: 0.0729s
Epoch: 0351 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0516 acc_val: 0.4633 loss_test: 1.3774 acc_test: 0.6850 time: 0.0756s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1351 acc_val: 0.4667 loss_test: 1.4307 acc_test: 0.6920 time: 0.0733s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.4700 loss_test: 1.4811 acc_test: 0.6900 time: 0.0669s
Optimization Finished!
Total time elapsed: 40.7553s, best testing performance  0.696000, minimun loss  1.112201
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7881 acc_train: 0.1500 loss_val: 1.7767 acc_val: 0.2167 loss_test: 1.7074 acc_test: 0.4920 time: 0.0613s
Epoch: 0051 loss_train: 0.0174 acc_train: 1.0000 loss_val: 1.8529 acc_val: 0.3633 loss_test: 1.1383 acc_test: 0.6560 time: 0.0790s
Epoch: 0101 loss_train: 0.0134 acc_train: 1.0000 loss_val: 1.8325 acc_val: 0.4100 loss_test: 1.1391 acc_test: 0.6630 time: 0.0678s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8353 acc_val: 0.4367 loss_test: 1.1669 acc_test: 0.6820 time: 0.0850s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8837 acc_val: 0.4567 loss_test: 1.2115 acc_test: 0.6820 time: 0.0578s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9270 acc_val: 0.4600 loss_test: 1.2545 acc_test: 0.6920 time: 0.0570s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9705 acc_val: 0.4800 loss_test: 1.2978 acc_test: 0.6960 time: 0.0587s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0061 acc_val: 0.4867 loss_test: 1.3405 acc_test: 0.6980 time: 0.0577s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0549 acc_val: 0.4833 loss_test: 1.3800 acc_test: 0.6980 time: 0.0634s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1117 acc_val: 0.4900 loss_test: 1.4228 acc_test: 0.7020 time: 0.0597s
Optimization Finished!
Total time elapsed: 33.6400s, best testing performance  0.712000, minimun loss  1.061199
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.1500 loss_val: 1.8012 acc_val: 0.1467 loss_test: 1.7181 acc_test: 0.4740 time: 0.0872s
Epoch: 0051 loss_train: 0.0174 acc_train: 1.0000 loss_val: 1.8740 acc_val: 0.3467 loss_test: 1.1358 acc_test: 0.6510 time: 0.0713s
Epoch: 0101 loss_train: 0.0137 acc_train: 1.0000 loss_val: 1.8554 acc_val: 0.4067 loss_test: 1.1372 acc_test: 0.6620 time: 0.0691s
Epoch: 0151 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8611 acc_val: 0.4167 loss_test: 1.1694 acc_test: 0.6750 time: 0.0712s
Epoch: 0201 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8663 acc_val: 0.4400 loss_test: 1.2027 acc_test: 0.6860 time: 0.0720s
Epoch: 0251 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4500 loss_test: 1.2422 acc_test: 0.6910 time: 0.0867s
Epoch: 0301 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9372 acc_val: 0.4767 loss_test: 1.2805 acc_test: 0.6960 time: 0.0739s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9987 acc_val: 0.4700 loss_test: 1.3318 acc_test: 0.6940 time: 0.0693s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.4833 loss_test: 1.3820 acc_test: 0.7040 time: 0.0775s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0785 acc_val: 0.5033 loss_test: 1.4213 acc_test: 0.7020 time: 0.0767s
Optimization Finished!
Total time elapsed: 40.9593s, best testing performance  0.704000, minimun loss  1.068353
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7882 acc_train: 0.1667 loss_val: 1.7843 acc_val: 0.2133 loss_test: 1.7138 acc_test: 0.4590 time: 0.0819s
Epoch: 0051 loss_train: 0.0177 acc_train: 1.0000 loss_val: 1.8749 acc_val: 0.3433 loss_test: 1.1585 acc_test: 0.6510 time: 0.0841s
Epoch: 0101 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8274 acc_val: 0.4033 loss_test: 1.1459 acc_test: 0.6650 time: 0.0768s
Epoch: 0151 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8327 acc_val: 0.4333 loss_test: 1.1724 acc_test: 0.6830 time: 0.0847s
Epoch: 0201 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8685 acc_val: 0.4533 loss_test: 1.2077 acc_test: 0.6940 time: 0.0862s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9243 acc_val: 0.4600 loss_test: 1.2529 acc_test: 0.6930 time: 0.0881s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0099 acc_val: 0.4633 loss_test: 1.3043 acc_test: 0.6920 time: 0.0574s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1032 acc_val: 0.4700 loss_test: 1.3605 acc_test: 0.6950 time: 0.0584s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1823 acc_val: 0.4833 loss_test: 1.4236 acc_test: 0.6930 time: 0.0626s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2553 acc_val: 0.4800 loss_test: 1.4716 acc_test: 0.6950 time: 0.0602s
Optimization Finished!
Total time elapsed: 35.4699s, best testing performance  0.701000, minimun loss  1.087655
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8040 acc_train: 0.1500 loss_val: 1.7965 acc_val: 0.1433 loss_test: 1.7373 acc_test: 0.3940 time: 0.0998s
Epoch: 0051 loss_train: 0.0136 acc_train: 1.0000 loss_val: 1.9546 acc_val: 0.3467 loss_test: 1.2038 acc_test: 0.6480 time: 0.0827s
Epoch: 0101 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9807 acc_val: 0.3733 loss_test: 1.2071 acc_test: 0.6630 time: 0.0930s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9914 acc_val: 0.4100 loss_test: 1.2378 acc_test: 0.6690 time: 0.1041s
Epoch: 0201 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0237 acc_val: 0.4333 loss_test: 1.2743 acc_test: 0.6830 time: 0.0804s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0417 acc_val: 0.4500 loss_test: 1.3010 acc_test: 0.6890 time: 0.0875s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0655 acc_val: 0.4633 loss_test: 1.3386 acc_test: 0.6910 time: 0.0687s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0488 acc_val: 0.4800 loss_test: 1.3560 acc_test: 0.6980 time: 0.0652s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0866 acc_val: 0.4833 loss_test: 1.3857 acc_test: 0.7010 time: 0.0892s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1206 acc_val: 0.4933 loss_test: 1.4205 acc_test: 0.6980 time: 0.0929s
Optimization Finished!
Total time elapsed: 41.0936s, best testing performance  0.702000, minimun loss  1.074082
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7956 acc_train: 0.1917 loss_val: 1.8095 acc_val: 0.1400 loss_test: 1.6995 acc_test: 0.5120 time: 0.0769s
Epoch: 0051 loss_train: 0.0138 acc_train: 1.0000 loss_val: 1.9288 acc_val: 0.3467 loss_test: 1.2002 acc_test: 0.6490 time: 0.0908s
Epoch: 0101 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.9022 acc_val: 0.3967 loss_test: 1.1908 acc_test: 0.6670 time: 0.0797s
Epoch: 0151 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9182 acc_val: 0.4167 loss_test: 1.2184 acc_test: 0.6780 time: 0.0861s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9693 acc_val: 0.4500 loss_test: 1.2708 acc_test: 0.6820 time: 0.0737s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9899 acc_val: 0.4700 loss_test: 1.3036 acc_test: 0.6860 time: 0.0696s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0102 acc_val: 0.4767 loss_test: 1.3391 acc_test: 0.6950 time: 0.0951s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0741 acc_val: 0.4867 loss_test: 1.3805 acc_test: 0.6970 time: 0.0578s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0933 acc_val: 0.5067 loss_test: 1.4112 acc_test: 0.7010 time: 0.0577s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1603 acc_val: 0.5167 loss_test: 1.4564 acc_test: 0.6990 time: 0.0587s
Optimization Finished!
Total time elapsed: 36.5452s, best testing performance  0.709000, minimun loss  1.059300
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7949 acc_train: 0.1417 loss_val: 1.7928 acc_val: 0.2000 loss_test: 1.7069 acc_test: 0.5050 time: 0.0728s
Epoch: 0051 loss_train: 0.0147 acc_train: 1.0000 loss_val: 1.9137 acc_val: 0.3433 loss_test: 1.1639 acc_test: 0.6480 time: 0.0854s
Epoch: 0101 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8862 acc_val: 0.3900 loss_test: 1.1579 acc_test: 0.6730 time: 0.0863s
Epoch: 0151 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8929 acc_val: 0.4200 loss_test: 1.1884 acc_test: 0.6820 time: 0.0942s
Epoch: 0201 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8934 acc_val: 0.4333 loss_test: 1.2270 acc_test: 0.6910 time: 0.0797s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9454 acc_val: 0.4600 loss_test: 1.2751 acc_test: 0.6880 time: 0.0835s
Epoch: 0301 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9739 acc_val: 0.4833 loss_test: 1.3162 acc_test: 0.6910 time: 0.0989s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9959 acc_val: 0.5033 loss_test: 1.3490 acc_test: 0.7000 time: 0.0730s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0314 acc_val: 0.5033 loss_test: 1.3830 acc_test: 0.7000 time: 0.0721s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0807 acc_val: 0.5167 loss_test: 1.4210 acc_test: 0.7040 time: 0.0809s
Optimization Finished!
Total time elapsed: 40.4824s, best testing performance  0.706000, minimun loss  1.030652
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7806 acc_train: 0.2250 loss_val: 1.7941 acc_val: 0.2067 loss_test: 1.7020 acc_test: 0.4870 time: 0.1086s
Epoch: 0051 loss_train: 0.0138 acc_train: 1.0000 loss_val: 1.9391 acc_val: 0.3667 loss_test: 1.1911 acc_test: 0.6530 time: 0.0690s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.9114 acc_val: 0.4067 loss_test: 1.1876 acc_test: 0.6620 time: 0.0874s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8976 acc_val: 0.4100 loss_test: 1.2171 acc_test: 0.6790 time: 0.0694s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9319 acc_val: 0.4233 loss_test: 1.2556 acc_test: 0.6810 time: 0.0944s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9121 acc_val: 0.4400 loss_test: 1.2885 acc_test: 0.6800 time: 0.1197s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9855 acc_val: 0.4700 loss_test: 1.3247 acc_test: 0.6960 time: 0.0826s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0652 acc_val: 0.4867 loss_test: 1.3652 acc_test: 0.6990 time: 0.0778s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1047 acc_val: 0.4967 loss_test: 1.3977 acc_test: 0.7000 time: 0.0575s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1365 acc_val: 0.5033 loss_test: 1.4286 acc_test: 0.7000 time: 0.0584s
Optimization Finished!
Total time elapsed: 38.2915s, best testing performance  0.702000, minimun loss  1.041673
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8000 acc_train: 0.0917 loss_val: 1.8010 acc_val: 0.1833 loss_test: 1.7061 acc_test: 0.4880 time: 0.0810s
Epoch: 0051 loss_train: 0.0150 acc_train: 1.0000 loss_val: 1.8632 acc_val: 0.3667 loss_test: 1.1808 acc_test: 0.6530 time: 0.0898s
Epoch: 0101 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8954 acc_val: 0.3933 loss_test: 1.1944 acc_test: 0.6640 time: 0.0827s
Epoch: 0151 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8938 acc_val: 0.4233 loss_test: 1.2189 acc_test: 0.6730 time: 0.0899s
Epoch: 0201 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9244 acc_val: 0.4333 loss_test: 1.2560 acc_test: 0.6790 time: 0.0839s
Epoch: 0251 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9696 acc_val: 0.4667 loss_test: 1.2847 acc_test: 0.6890 time: 0.0701s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0455 acc_val: 0.4667 loss_test: 1.3245 acc_test: 0.6900 time: 0.0875s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0942 acc_val: 0.4933 loss_test: 1.3628 acc_test: 0.7000 time: 0.0720s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1314 acc_val: 0.4967 loss_test: 1.3953 acc_test: 0.6970 time: 0.0757s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1592 acc_val: 0.5000 loss_test: 1.4269 acc_test: 0.6960 time: 0.0723s
Optimization Finished!
Total time elapsed: 39.7505s, best testing performance  0.700000, minimun loss  1.059899
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7816 acc_train: 0.2583 loss_val: 1.8003 acc_val: 0.1900 loss_test: 1.7219 acc_test: 0.4810 time: 0.0732s
Epoch: 0051 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.8280 acc_val: 0.3467 loss_test: 1.1252 acc_test: 0.6520 time: 0.0828s
Epoch: 0101 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8188 acc_val: 0.4000 loss_test: 1.1276 acc_test: 0.6710 time: 0.0784s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8367 acc_val: 0.4300 loss_test: 1.1625 acc_test: 0.6800 time: 0.0720s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8807 acc_val: 0.4533 loss_test: 1.2034 acc_test: 0.6840 time: 0.0900s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9333 acc_val: 0.4633 loss_test: 1.2500 acc_test: 0.6900 time: 0.0842s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9925 acc_val: 0.4633 loss_test: 1.2943 acc_test: 0.6930 time: 0.0780s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0336 acc_val: 0.4833 loss_test: 1.3369 acc_test: 0.6990 time: 0.0741s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0842 acc_val: 0.4933 loss_test: 1.3796 acc_test: 0.7000 time: 0.0681s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1611 acc_val: 0.4867 loss_test: 1.4282 acc_test: 0.6990 time: 0.1181s
Optimization Finished!
Total time elapsed: 40.0385s, best testing performance  0.704000, minimun loss  1.060383
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7920 acc_train: 0.2250 loss_val: 1.7863 acc_val: 0.1767 loss_test: 1.7119 acc_test: 0.5030 time: 0.0811s
Epoch: 0051 loss_train: 0.0165 acc_train: 1.0000 loss_val: 1.8196 acc_val: 0.3600 loss_test: 1.1380 acc_test: 0.6540 time: 0.0583s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8206 acc_val: 0.4133 loss_test: 1.1380 acc_test: 0.6690 time: 0.0602s
Epoch: 0151 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8345 acc_val: 0.4300 loss_test: 1.1683 acc_test: 0.6830 time: 0.0772s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8640 acc_val: 0.4533 loss_test: 1.2111 acc_test: 0.6840 time: 0.0891s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9143 acc_val: 0.4700 loss_test: 1.2545 acc_test: 0.6890 time: 0.0713s
Epoch: 0301 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9414 acc_val: 0.4733 loss_test: 1.2970 acc_test: 0.6910 time: 0.1007s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0062 acc_val: 0.4867 loss_test: 1.3418 acc_test: 0.6960 time: 0.0713s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0570 acc_val: 0.4967 loss_test: 1.3874 acc_test: 0.6980 time: 0.0975s
Epoch: 0451 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0856 acc_val: 0.4900 loss_test: 1.4222 acc_test: 0.7020 time: 0.0921s
Optimization Finished!
Total time elapsed: 38.6451s, best testing performance  0.706000, minimun loss  1.058842
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8040 acc_train: 0.0667 loss_val: 1.7933 acc_val: 0.1600 loss_test: 1.7243 acc_test: 0.4350 time: 0.0799s
Epoch: 0051 loss_train: 0.0178 acc_train: 1.0000 loss_val: 1.8994 acc_val: 0.3333 loss_test: 1.1649 acc_test: 0.6500 time: 0.0713s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8503 acc_val: 0.3933 loss_test: 1.1512 acc_test: 0.6590 time: 0.0723s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8307 acc_val: 0.4400 loss_test: 1.1782 acc_test: 0.6760 time: 0.0897s
Epoch: 0201 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8619 acc_val: 0.4533 loss_test: 1.2102 acc_test: 0.6840 time: 0.0771s
Epoch: 0251 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9141 acc_val: 0.4567 loss_test: 1.2518 acc_test: 0.6850 time: 0.0923s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9258 acc_val: 0.4733 loss_test: 1.2805 acc_test: 0.6940 time: 0.0704s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9862 acc_val: 0.4667 loss_test: 1.3186 acc_test: 0.6960 time: 0.0831s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0338 acc_val: 0.4733 loss_test: 1.3545 acc_test: 0.6990 time: 0.0893s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0641 acc_val: 0.4733 loss_test: 1.3940 acc_test: 0.6960 time: 0.0946s
Optimization Finished!
Total time elapsed: 40.4828s, best testing performance  0.704000, minimun loss  1.087059
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8058 acc_train: 0.1000 loss_val: 1.8007 acc_val: 0.1367 loss_test: 1.7342 acc_test: 0.3780 time: 0.0975s
Epoch: 0051 loss_train: 0.0171 acc_train: 1.0000 loss_val: 1.8766 acc_val: 0.3667 loss_test: 1.1541 acc_test: 0.6570 time: 0.0609s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8559 acc_val: 0.3933 loss_test: 1.1495 acc_test: 0.6670 time: 0.0603s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8643 acc_val: 0.4300 loss_test: 1.1824 acc_test: 0.6820 time: 0.0610s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8764 acc_val: 0.4567 loss_test: 1.2184 acc_test: 0.6850 time: 0.0787s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8965 acc_val: 0.4600 loss_test: 1.2507 acc_test: 0.6910 time: 0.0862s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9545 acc_val: 0.4700 loss_test: 1.2915 acc_test: 0.6910 time: 0.0778s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9742 acc_val: 0.4733 loss_test: 1.3288 acc_test: 0.6950 time: 0.0848s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0731 acc_val: 0.4633 loss_test: 1.3722 acc_test: 0.6970 time: 0.0740s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1040 acc_val: 0.4700 loss_test: 1.4044 acc_test: 0.7010 time: 0.0801s
Optimization Finished!
Total time elapsed: 37.5887s, best testing performance  0.704000, minimun loss  1.084151
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7821 acc_train: 0.1917 loss_val: 1.7813 acc_val: 0.1700 loss_test: 1.7050 acc_test: 0.5390 time: 0.0876s
Epoch: 0051 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.8706 acc_val: 0.3567 loss_test: 1.1469 acc_test: 0.6480 time: 0.0900s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8357 acc_val: 0.3967 loss_test: 1.1390 acc_test: 0.6570 time: 0.0861s
Epoch: 0151 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8188 acc_val: 0.4333 loss_test: 1.1715 acc_test: 0.6710 time: 0.0835s
Epoch: 0201 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8446 acc_val: 0.4500 loss_test: 1.2170 acc_test: 0.6820 time: 0.0801s
Epoch: 0251 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9091 acc_val: 0.4633 loss_test: 1.2730 acc_test: 0.6910 time: 0.0857s
Epoch: 0301 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9377 acc_val: 0.4800 loss_test: 1.3267 acc_test: 0.6980 time: 0.0777s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0163 acc_val: 0.5000 loss_test: 1.3870 acc_test: 0.7010 time: 0.1045s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0733 acc_val: 0.5067 loss_test: 1.4497 acc_test: 0.7020 time: 0.0711s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1241 acc_val: 0.5100 loss_test: 1.4992 acc_test: 0.7040 time: 0.0834s
Optimization Finished!
Total time elapsed: 40.9441s, best testing performance  0.706000, minimun loss  1.067929
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8083 acc_train: 0.1167 loss_val: 1.7867 acc_val: 0.1467 loss_test: 1.7160 acc_test: 0.4170 time: 0.0964s
Epoch: 0051 loss_train: 0.0159 acc_train: 1.0000 loss_val: 1.7926 acc_val: 0.3700 loss_test: 1.1419 acc_test: 0.6550 time: 0.0608s
Epoch: 0101 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.8065 acc_val: 0.4033 loss_test: 1.1422 acc_test: 0.6650 time: 0.0584s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8818 acc_val: 0.4067 loss_test: 1.1807 acc_test: 0.6680 time: 0.0588s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9020 acc_val: 0.4167 loss_test: 1.2090 acc_test: 0.6780 time: 0.0603s
Epoch: 0251 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9117 acc_val: 0.4567 loss_test: 1.2408 acc_test: 0.6860 time: 0.0749s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9423 acc_val: 0.4667 loss_test: 1.2812 acc_test: 0.6880 time: 0.0695s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9742 acc_val: 0.4867 loss_test: 1.3210 acc_test: 0.6940 time: 0.0676s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0194 acc_val: 0.4900 loss_test: 1.3692 acc_test: 0.6970 time: 0.0763s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0846 acc_val: 0.4967 loss_test: 1.4127 acc_test: 0.7000 time: 0.0858s
Optimization Finished!
Total time elapsed: 36.4462s, best testing performance  0.702000, minimun loss  1.068818
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7847 acc_train: 0.1917 loss_val: 1.8225 acc_val: 0.1167 loss_test: 1.7093 acc_test: 0.4790 time: 0.0717s
Epoch: 0051 loss_train: 0.0152 acc_train: 1.0000 loss_val: 1.8117 acc_val: 0.3733 loss_test: 1.1459 acc_test: 0.6570 time: 0.0948s
Epoch: 0101 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7692 acc_val: 0.4133 loss_test: 1.1326 acc_test: 0.6720 time: 0.0673s
Epoch: 0151 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8664 acc_val: 0.4200 loss_test: 1.1829 acc_test: 0.6800 time: 0.0933s
Epoch: 0201 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9376 acc_val: 0.4367 loss_test: 1.2430 acc_test: 0.6800 time: 0.0796s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9659 acc_val: 0.4400 loss_test: 1.2818 acc_test: 0.6800 time: 0.0677s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9891 acc_val: 0.4633 loss_test: 1.3208 acc_test: 0.6920 time: 0.0717s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0139 acc_val: 0.4633 loss_test: 1.3545 acc_test: 0.6960 time: 0.0814s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0291 acc_val: 0.4800 loss_test: 1.3856 acc_test: 0.6970 time: 0.0684s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0690 acc_val: 0.4967 loss_test: 1.4223 acc_test: 0.7010 time: 0.0697s
Optimization Finished!
Total time elapsed: 40.7636s, best testing performance  0.705000, minimun loss  1.050756
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7893 acc_train: 0.1583 loss_val: 1.7958 acc_val: 0.1833 loss_test: 1.6999 acc_test: 0.5050 time: 0.0800s
Epoch: 0051 loss_train: 0.0155 acc_train: 1.0000 loss_val: 1.8333 acc_val: 0.3633 loss_test: 1.1405 acc_test: 0.6560 time: 0.0591s
Epoch: 0101 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.7709 acc_val: 0.4233 loss_test: 1.1196 acc_test: 0.6730 time: 0.0609s
Epoch: 0151 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8338 acc_val: 0.4300 loss_test: 1.1612 acc_test: 0.6790 time: 0.0585s
Epoch: 0201 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9064 acc_val: 0.4300 loss_test: 1.2147 acc_test: 0.6840 time: 0.0593s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9503 acc_val: 0.4600 loss_test: 1.2592 acc_test: 0.6860 time: 0.0923s
Epoch: 0301 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9729 acc_val: 0.4733 loss_test: 1.2999 acc_test: 0.6920 time: 0.0715s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0208 acc_val: 0.4867 loss_test: 1.3443 acc_test: 0.6970 time: 0.0953s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0696 acc_val: 0.5033 loss_test: 1.3876 acc_test: 0.7030 time: 0.0816s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1205 acc_val: 0.5033 loss_test: 1.4263 acc_test: 0.7010 time: 0.0644s
Optimization Finished!
Total time elapsed: 35.6150s, best testing performance  0.706000, minimun loss  1.056186
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8163 acc_train: 0.1000 loss_val: 1.7854 acc_val: 0.1867 loss_test: 1.7157 acc_test: 0.4510 time: 0.1125s
Epoch: 0051 loss_train: 0.0161 acc_train: 1.0000 loss_val: 1.8436 acc_val: 0.3467 loss_test: 1.1577 acc_test: 0.6490 time: 0.0663s
Epoch: 0101 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7470 acc_val: 0.4100 loss_test: 1.1241 acc_test: 0.6710 time: 0.0963s
Epoch: 0151 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8139 acc_val: 0.4067 loss_test: 1.1668 acc_test: 0.6770 time: 0.0829s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8459 acc_val: 0.4300 loss_test: 1.2065 acc_test: 0.6810 time: 0.0861s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8746 acc_val: 0.4500 loss_test: 1.2462 acc_test: 0.6840 time: 0.0937s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.8978 acc_val: 0.4800 loss_test: 1.2837 acc_test: 0.6920 time: 0.0719s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9560 acc_val: 0.4933 loss_test: 1.3270 acc_test: 0.6970 time: 0.0802s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0136 acc_val: 0.4833 loss_test: 1.3671 acc_test: 0.7020 time: 0.0801s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.4900 loss_test: 1.4004 acc_test: 0.7060 time: 0.0773s
Optimization Finished!
Total time elapsed: 40.7324s, best testing performance  0.710000, minimun loss  1.056595
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7999 acc_train: 0.1500 loss_val: 1.7801 acc_val: 0.2033 loss_test: 1.7136 acc_test: 0.4810 time: 0.0995s
Epoch: 0051 loss_train: 0.0157 acc_train: 1.0000 loss_val: 1.7877 acc_val: 0.3833 loss_test: 1.1543 acc_test: 0.6500 time: 0.0569s
Epoch: 0101 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7882 acc_val: 0.4133 loss_test: 1.1474 acc_test: 0.6730 time: 0.0594s
Epoch: 0151 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8409 acc_val: 0.4233 loss_test: 1.1836 acc_test: 0.6760 time: 0.0592s
Epoch: 0201 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8394 acc_val: 0.4467 loss_test: 1.2111 acc_test: 0.6870 time: 0.0598s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8794 acc_val: 0.4667 loss_test: 1.2502 acc_test: 0.6950 time: 0.0595s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9342 acc_val: 0.4800 loss_test: 1.2916 acc_test: 0.6970 time: 0.0756s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9931 acc_val: 0.4867 loss_test: 1.3400 acc_test: 0.7060 time: 0.0717s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0145 acc_val: 0.4900 loss_test: 1.3636 acc_test: 0.7030 time: 0.0704s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0585 acc_val: 0.4933 loss_test: 1.4051 acc_test: 0.7030 time: 0.0909s
Optimization Finished!
Total time elapsed: 34.4835s, best testing performance  0.707000, minimun loss  1.066329
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7709 acc_train: 0.2083 loss_val: 1.8074 acc_val: 0.1167 loss_test: 1.6945 acc_test: 0.4330 time: 0.0916s
Epoch: 0051 loss_train: 0.0166 acc_train: 1.0000 loss_val: 1.8373 acc_val: 0.3467 loss_test: 1.1396 acc_test: 0.6530 time: 0.0861s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8741 acc_val: 0.3900 loss_test: 1.1541 acc_test: 0.6630 time: 0.0908s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8970 acc_val: 0.4233 loss_test: 1.1817 acc_test: 0.6730 time: 0.0889s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9125 acc_val: 0.4333 loss_test: 1.2184 acc_test: 0.6820 time: 0.0687s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9341 acc_val: 0.4400 loss_test: 1.2535 acc_test: 0.6890 time: 0.0803s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9712 acc_val: 0.4567 loss_test: 1.2932 acc_test: 0.6960 time: 0.0771s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9875 acc_val: 0.4700 loss_test: 1.3322 acc_test: 0.6950 time: 0.0850s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0436 acc_val: 0.4700 loss_test: 1.3723 acc_test: 0.6970 time: 0.0695s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.4800 loss_test: 1.4092 acc_test: 0.6970 time: 0.0826s
Optimization Finished!
Total time elapsed: 40.4769s, best testing performance  0.701000, minimun loss  1.063981
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7973 acc_train: 0.1667 loss_val: 1.8039 acc_val: 0.1433 loss_test: 1.7141 acc_test: 0.4590 time: 0.0897s
Epoch: 0051 loss_train: 0.0171 acc_train: 1.0000 loss_val: 1.8618 acc_val: 0.3567 loss_test: 1.1525 acc_test: 0.6570 time: 0.0576s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8446 acc_val: 0.4100 loss_test: 1.1425 acc_test: 0.6650 time: 0.0575s
Epoch: 0151 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8730 acc_val: 0.4367 loss_test: 1.1770 acc_test: 0.6750 time: 0.0590s
Epoch: 0201 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9412 acc_val: 0.4433 loss_test: 1.2287 acc_test: 0.6780 time: 0.0588s
Epoch: 0251 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0112 acc_val: 0.4500 loss_test: 1.2852 acc_test: 0.6820 time: 0.0579s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1033 acc_val: 0.4500 loss_test: 1.3481 acc_test: 0.6910 time: 0.0618s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1811 acc_val: 0.4467 loss_test: 1.4184 acc_test: 0.6900 time: 0.0775s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2340 acc_val: 0.4533 loss_test: 1.4667 acc_test: 0.7040 time: 0.0958s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3532 acc_val: 0.4600 loss_test: 1.5280 acc_test: 0.7020 time: 0.0846s
Optimization Finished!
Total time elapsed: 33.4866s, best testing performance  0.711000, minimun loss  1.071095
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7772 acc_train: 0.2500 loss_val: 1.7934 acc_val: 0.1633 loss_test: 1.6910 acc_test: 0.5280 time: 0.0726s
Epoch: 0051 loss_train: 0.0171 acc_train: 1.0000 loss_val: 1.8690 acc_val: 0.3567 loss_test: 1.1464 acc_test: 0.6510 time: 0.0697s
Epoch: 0101 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8113 acc_val: 0.4033 loss_test: 1.1283 acc_test: 0.6690 time: 0.0823s
Epoch: 0151 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8462 acc_val: 0.4300 loss_test: 1.1676 acc_test: 0.6730 time: 0.0713s
Epoch: 0201 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8767 acc_val: 0.4367 loss_test: 1.2092 acc_test: 0.6830 time: 0.0867s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9134 acc_val: 0.4433 loss_test: 1.2529 acc_test: 0.6880 time: 0.0756s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9795 acc_val: 0.4533 loss_test: 1.3047 acc_test: 0.6870 time: 0.0921s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0085 acc_val: 0.4733 loss_test: 1.3463 acc_test: 0.6900 time: 0.0771s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0547 acc_val: 0.4767 loss_test: 1.3889 acc_test: 0.6970 time: 0.0854s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0859 acc_val: 0.4933 loss_test: 1.4318 acc_test: 0.6970 time: 0.0879s
Optimization Finished!
Total time elapsed: 40.8253s, best testing performance  0.703000, minimun loss  1.059748
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1833 loss_val: 1.7957 acc_val: 0.1233 loss_test: 1.7187 acc_test: 0.4350 time: 0.0706s
Epoch: 0051 loss_train: 0.0171 acc_train: 1.0000 loss_val: 1.9051 acc_val: 0.3400 loss_test: 1.1764 acc_test: 0.6500 time: 0.0575s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8479 acc_val: 0.3900 loss_test: 1.1549 acc_test: 0.6640 time: 0.0580s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8560 acc_val: 0.4200 loss_test: 1.1805 acc_test: 0.6780 time: 0.0575s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8939 acc_val: 0.4500 loss_test: 1.2218 acc_test: 0.6820 time: 0.0590s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9374 acc_val: 0.4600 loss_test: 1.2630 acc_test: 0.6880 time: 0.0586s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9857 acc_val: 0.4667 loss_test: 1.3075 acc_test: 0.6900 time: 0.0592s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0279 acc_val: 0.4700 loss_test: 1.3430 acc_test: 0.6950 time: 0.0606s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0789 acc_val: 0.4833 loss_test: 1.3866 acc_test: 0.6990 time: 0.0717s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1308 acc_val: 0.4867 loss_test: 1.4240 acc_test: 0.7030 time: 0.0929s
Optimization Finished!
Total time elapsed: 32.1861s, best testing performance  0.705000, minimun loss  1.091485
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7797 acc_train: 0.1333 loss_val: 1.7798 acc_val: 0.1767 loss_test: 1.7058 acc_test: 0.4880 time: 0.0730s
Epoch: 0051 loss_train: 0.0169 acc_train: 1.0000 loss_val: 1.8838 acc_val: 0.3533 loss_test: 1.1625 acc_test: 0.6530 time: 0.0707s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8453 acc_val: 0.3867 loss_test: 1.1505 acc_test: 0.6670 time: 0.0925s
Epoch: 0151 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8662 acc_val: 0.4333 loss_test: 1.1786 acc_test: 0.6780 time: 0.0682s
Epoch: 0201 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9233 acc_val: 0.4433 loss_test: 1.2266 acc_test: 0.6760 time: 0.0714s
Epoch: 0251 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9566 acc_val: 0.4433 loss_test: 1.2660 acc_test: 0.6870 time: 0.0849s
Epoch: 0301 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9978 acc_val: 0.4633 loss_test: 1.3055 acc_test: 0.6890 time: 0.0734s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4667 loss_test: 1.3451 acc_test: 0.6940 time: 0.0706s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0425 acc_val: 0.4833 loss_test: 1.3829 acc_test: 0.6980 time: 0.0743s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1019 acc_val: 0.4767 loss_test: 1.4254 acc_test: 0.7000 time: 0.0894s
Optimization Finished!
Total time elapsed: 41.0933s, best testing performance  0.705000, minimun loss  1.074498
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8165 acc_train: 0.0833 loss_val: 1.7922 acc_val: 0.1600 loss_test: 1.7154 acc_test: 0.4650 time: 0.1000s
Epoch: 0051 loss_train: 0.0152 acc_train: 1.0000 loss_val: 1.8233 acc_val: 0.3800 loss_test: 1.1517 acc_test: 0.6600 time: 0.0578s
Epoch: 0101 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8079 acc_val: 0.4033 loss_test: 1.1505 acc_test: 0.6680 time: 0.0576s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8751 acc_val: 0.4100 loss_test: 1.1940 acc_test: 0.6700 time: 0.0591s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4300 loss_test: 1.2220 acc_test: 0.6810 time: 0.0571s
Epoch: 0251 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9036 acc_val: 0.4800 loss_test: 1.2534 acc_test: 0.6890 time: 0.0587s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9571 acc_val: 0.4667 loss_test: 1.3025 acc_test: 0.6940 time: 0.0586s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0062 acc_val: 0.4800 loss_test: 1.3517 acc_test: 0.6970 time: 0.0593s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0488 acc_val: 0.4833 loss_test: 1.3880 acc_test: 0.6980 time: 0.0603s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0819 acc_val: 0.4967 loss_test: 1.4268 acc_test: 0.6970 time: 0.1014s
Optimization Finished!
Total time elapsed: 31.4379s, best testing performance  0.706000, minimun loss  1.052861
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7950 acc_train: 0.2167 loss_val: 1.8007 acc_val: 0.1433 loss_test: 1.7024 acc_test: 0.4450 time: 0.0882s
Epoch: 0051 loss_train: 0.0155 acc_train: 1.0000 loss_val: 1.8379 acc_val: 0.3500 loss_test: 1.1502 acc_test: 0.6470 time: 0.0847s
Epoch: 0101 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8258 acc_val: 0.3967 loss_test: 1.1560 acc_test: 0.6640 time: 0.0711s
Epoch: 0151 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8773 acc_val: 0.4000 loss_test: 1.1942 acc_test: 0.6690 time: 0.1006s
Epoch: 0201 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8950 acc_val: 0.4300 loss_test: 1.2192 acc_test: 0.6800 time: 0.0898s
Epoch: 0251 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9498 acc_val: 0.4600 loss_test: 1.2656 acc_test: 0.6890 time: 0.0947s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0212 acc_val: 0.4733 loss_test: 1.3184 acc_test: 0.6920 time: 0.0812s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0748 acc_val: 0.4833 loss_test: 1.3715 acc_test: 0.6900 time: 0.0750s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1206 acc_val: 0.4867 loss_test: 1.4101 acc_test: 0.6950 time: 0.1098s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1760 acc_val: 0.4900 loss_test: 1.4555 acc_test: 0.6980 time: 0.0778s
Optimization Finished!
Total time elapsed: 40.7635s, best testing performance  0.703000, minimun loss  1.054659
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1333 loss_val: 1.7913 acc_val: 0.1367 loss_test: 1.7115 acc_test: 0.4760 time: 0.0806s
Epoch: 0051 loss_train: 0.0153 acc_train: 1.0000 loss_val: 1.8126 acc_val: 0.3767 loss_test: 1.1423 acc_test: 0.6510 time: 0.0707s
Epoch: 0101 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7626 acc_val: 0.4033 loss_test: 1.1345 acc_test: 0.6680 time: 0.0575s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8045 acc_val: 0.4167 loss_test: 1.1761 acc_test: 0.6700 time: 0.0576s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8241 acc_val: 0.4300 loss_test: 1.2067 acc_test: 0.6770 time: 0.0574s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.8861 acc_val: 0.4500 loss_test: 1.2575 acc_test: 0.6870 time: 0.0572s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9597 acc_val: 0.4600 loss_test: 1.3022 acc_test: 0.6940 time: 0.0593s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0277 acc_val: 0.4833 loss_test: 1.3546 acc_test: 0.6940 time: 0.0594s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0758 acc_val: 0.4867 loss_test: 1.3931 acc_test: 0.6970 time: 0.0610s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1037 acc_val: 0.4967 loss_test: 1.4285 acc_test: 0.6990 time: 0.0609s
Optimization Finished!
Total time elapsed: 31.3356s, best testing performance  0.705000, minimun loss  1.050835
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7912 acc_train: 0.1917 loss_val: 1.8066 acc_val: 0.1900 loss_test: 1.6986 acc_test: 0.5020 time: 0.0626s
Epoch: 0051 loss_train: 0.0160 acc_train: 1.0000 loss_val: 1.7820 acc_val: 0.3733 loss_test: 1.1441 acc_test: 0.6640 time: 0.0734s
Epoch: 0101 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.7473 acc_val: 0.4300 loss_test: 1.1349 acc_test: 0.6730 time: 0.0997s
Epoch: 0151 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7818 acc_val: 0.4300 loss_test: 1.1685 acc_test: 0.6770 time: 0.0704s
Epoch: 0201 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8667 acc_val: 0.4333 loss_test: 1.2199 acc_test: 0.6840 time: 0.0689s
Epoch: 0251 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9083 acc_val: 0.4500 loss_test: 1.2590 acc_test: 0.6870 time: 0.0696s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9592 acc_val: 0.4733 loss_test: 1.2970 acc_test: 0.6880 time: 0.0890s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0193 acc_val: 0.4900 loss_test: 1.3383 acc_test: 0.6930 time: 0.0741s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0482 acc_val: 0.4967 loss_test: 1.3738 acc_test: 0.6940 time: 0.0907s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1287 acc_val: 0.5033 loss_test: 1.4149 acc_test: 0.6950 time: 0.0744s
Optimization Finished!
Total time elapsed: 41.2807s, best testing performance  0.699000, minimun loss  1.064717
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 1, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1583 loss_val: 1.8000 acc_val: 0.1700 loss_test: 1.7122 acc_test: 0.4560 time: 0.0767s
Epoch: 0051 loss_train: 0.0151 acc_train: 1.0000 loss_val: 1.8059 acc_val: 0.3767 loss_test: 1.1503 acc_test: 0.6570 time: 0.0934s
Epoch: 0101 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7602 acc_val: 0.4267 loss_test: 1.1341 acc_test: 0.6730 time: 0.0702s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8377 acc_val: 0.4367 loss_test: 1.1745 acc_test: 0.6790 time: 0.0571s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9016 acc_val: 0.4467 loss_test: 1.2184 acc_test: 0.6820 time: 0.0574s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9376 acc_val: 0.4733 loss_test: 1.2615 acc_test: 0.6870 time: 0.0588s
Epoch: 0301 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0169 acc_val: 0.4700 loss_test: 1.3124 acc_test: 0.6930 time: 0.0584s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0777 acc_val: 0.4800 loss_test: 1.3532 acc_test: 0.7000 time: 0.0590s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1289 acc_val: 0.4867 loss_test: 1.3940 acc_test: 0.7000 time: 0.0610s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2162 acc_val: 0.4867 loss_test: 1.4427 acc_test: 0.7060 time: 0.0596s
Optimization Finished!
Total time elapsed: 31.6299s, best testing performance  0.708000, minimun loss  1.064842
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7930 acc_train: 0.1500 loss_val: 1.7798 acc_val: 0.2033 loss_test: 1.7190 acc_test: 0.4850 time: 0.1219s
Epoch: 0051 loss_train: 0.0164 acc_train: 1.0000 loss_val: 1.8471 acc_val: 0.3567 loss_test: 1.1473 acc_test: 0.6540 time: 0.0891s
Epoch: 0101 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7819 acc_val: 0.4167 loss_test: 1.1295 acc_test: 0.6680 time: 0.0965s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8333 acc_val: 0.4167 loss_test: 1.1593 acc_test: 0.6840 time: 0.0795s
Epoch: 0201 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8808 acc_val: 0.4367 loss_test: 1.1997 acc_test: 0.6860 time: 0.1011s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9178 acc_val: 0.4467 loss_test: 1.2386 acc_test: 0.6910 time: 0.0939s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9620 acc_val: 0.4533 loss_test: 1.2766 acc_test: 0.6940 time: 0.1063s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0161 acc_val: 0.4600 loss_test: 1.3191 acc_test: 0.6920 time: 0.0725s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0791 acc_val: 0.4600 loss_test: 1.3660 acc_test: 0.6990 time: 0.0878s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1273 acc_val: 0.4633 loss_test: 1.4120 acc_test: 0.6970 time: 0.1185s
Optimization Finished!
Total time elapsed: 48.7399s, best testing performance  0.702000, minimun loss  1.056055
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7737 acc_train: 0.1833 loss_val: 1.7795 acc_val: 0.1700 loss_test: 1.6983 acc_test: 0.5140 time: 0.1318s
Epoch: 0051 loss_train: 0.0173 acc_train: 1.0000 loss_val: 1.8341 acc_val: 0.3600 loss_test: 1.1286 acc_test: 0.6550 time: 0.0646s
Epoch: 0101 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.7902 acc_val: 0.4200 loss_test: 1.1175 acc_test: 0.6650 time: 0.0641s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8333 acc_val: 0.4467 loss_test: 1.1525 acc_test: 0.6790 time: 0.0640s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8799 acc_val: 0.4600 loss_test: 1.1963 acc_test: 0.6840 time: 0.0647s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9481 acc_val: 0.4600 loss_test: 1.2434 acc_test: 0.6930 time: 0.0652s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0048 acc_val: 0.4833 loss_test: 1.2954 acc_test: 0.6970 time: 0.0687s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0251 acc_val: 0.5000 loss_test: 1.3330 acc_test: 0.7000 time: 0.0700s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1000 acc_val: 0.5067 loss_test: 1.3841 acc_test: 0.7040 time: 0.0689s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1253 acc_val: 0.5167 loss_test: 1.4238 acc_test: 0.7030 time: 0.1060s
Optimization Finished!
Total time elapsed: 37.2801s, best testing performance  0.707000, minimun loss  1.057656
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7843 acc_train: 0.2583 loss_val: 1.8007 acc_val: 0.1800 loss_test: 1.7179 acc_test: 0.4800 time: 0.0805s
Epoch: 0051 loss_train: 0.0168 acc_train: 1.0000 loss_val: 1.8300 acc_val: 0.3567 loss_test: 1.1378 acc_test: 0.6470 time: 0.1013s
Epoch: 0101 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8050 acc_val: 0.4267 loss_test: 1.1283 acc_test: 0.6670 time: 0.1140s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8085 acc_val: 0.4467 loss_test: 1.1511 acc_test: 0.6810 time: 0.1109s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8428 acc_val: 0.4567 loss_test: 1.1910 acc_test: 0.6870 time: 0.0850s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8944 acc_val: 0.4533 loss_test: 1.2348 acc_test: 0.6890 time: 0.0846s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9247 acc_val: 0.4633 loss_test: 1.2709 acc_test: 0.6950 time: 0.1147s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9481 acc_val: 0.4833 loss_test: 1.3077 acc_test: 0.6990 time: 0.1076s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0098 acc_val: 0.4900 loss_test: 1.3560 acc_test: 0.6990 time: 0.0993s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0501 acc_val: 0.4967 loss_test: 1.3975 acc_test: 0.7030 time: 0.1038s
Optimization Finished!
Total time elapsed: 48.5599s, best testing performance  0.707000, minimun loss  1.070351
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8001 acc_train: 0.0917 loss_val: 1.7895 acc_val: 0.1900 loss_test: 1.7182 acc_test: 0.4890 time: 0.0968s
Epoch: 0051 loss_train: 0.0174 acc_train: 1.0000 loss_val: 1.8540 acc_val: 0.3667 loss_test: 1.1441 acc_test: 0.6510 time: 0.0641s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8145 acc_val: 0.4000 loss_test: 1.1294 acc_test: 0.6630 time: 0.0650s
Epoch: 0151 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8422 acc_val: 0.4300 loss_test: 1.1594 acc_test: 0.6790 time: 0.0671s
Epoch: 0201 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8786 acc_val: 0.4433 loss_test: 1.2031 acc_test: 0.6850 time: 0.0676s
Epoch: 0251 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9204 acc_val: 0.4567 loss_test: 1.2513 acc_test: 0.6890 time: 0.0675s
Epoch: 0301 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0004 acc_val: 0.4633 loss_test: 1.3095 acc_test: 0.6910 time: 0.1003s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0656 acc_val: 0.4867 loss_test: 1.3568 acc_test: 0.6950 time: 0.0895s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1345 acc_val: 0.4867 loss_test: 1.4170 acc_test: 0.6930 time: 0.0957s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2232 acc_val: 0.4967 loss_test: 1.4674 acc_test: 0.6940 time: 0.1006s
Optimization Finished!
Total time elapsed: 40.5221s, best testing performance  0.699000, minimun loss  1.059497
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8016 acc_train: 0.1833 loss_val: 1.8051 acc_val: 0.1433 loss_test: 1.7192 acc_test: 0.4410 time: 0.1051s
Epoch: 0051 loss_train: 0.0168 acc_train: 1.0000 loss_val: 1.8863 acc_val: 0.3567 loss_test: 1.1497 acc_test: 0.6510 time: 0.1021s
Epoch: 0101 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8576 acc_val: 0.4167 loss_test: 1.1382 acc_test: 0.6670 time: 0.1279s
Epoch: 0151 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8820 acc_val: 0.4500 loss_test: 1.1650 acc_test: 0.6780 time: 0.0851s
Epoch: 0201 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9227 acc_val: 0.4533 loss_test: 1.2068 acc_test: 0.6810 time: 0.0926s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9710 acc_val: 0.4533 loss_test: 1.2484 acc_test: 0.6840 time: 0.1007s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0222 acc_val: 0.4667 loss_test: 1.2901 acc_test: 0.6910 time: 0.1039s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0768 acc_val: 0.4667 loss_test: 1.3334 acc_test: 0.6970 time: 0.0961s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1471 acc_val: 0.4767 loss_test: 1.3791 acc_test: 0.6950 time: 0.0808s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1588 acc_val: 0.4767 loss_test: 1.4123 acc_test: 0.6990 time: 0.0796s
Optimization Finished!
Total time elapsed: 48.8424s, best testing performance  0.708000, minimun loss  1.064128
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7903 acc_train: 0.2500 loss_val: 1.8110 acc_val: 0.1533 loss_test: 1.7096 acc_test: 0.4530 time: 0.1016s
Epoch: 0051 loss_train: 0.0152 acc_train: 1.0000 loss_val: 1.8156 acc_val: 0.3767 loss_test: 1.1521 acc_test: 0.6530 time: 0.0653s
Epoch: 0101 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7981 acc_val: 0.4133 loss_test: 1.1516 acc_test: 0.6760 time: 0.0660s
Epoch: 0151 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8482 acc_val: 0.4433 loss_test: 1.1834 acc_test: 0.6800 time: 0.0830s
Epoch: 0201 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8823 acc_val: 0.4567 loss_test: 1.2222 acc_test: 0.6900 time: 0.1078s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9251 acc_val: 0.4700 loss_test: 1.2624 acc_test: 0.6920 time: 0.1085s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9706 acc_val: 0.4900 loss_test: 1.3064 acc_test: 0.6980 time: 0.1112s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0255 acc_val: 0.4900 loss_test: 1.3500 acc_test: 0.6950 time: 0.1166s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0742 acc_val: 0.5033 loss_test: 1.3945 acc_test: 0.6950 time: 0.0867s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1333 acc_val: 0.5133 loss_test: 1.4378 acc_test: 0.6980 time: 0.0994s
Optimization Finished!
Total time elapsed: 44.2665s, best testing performance  0.701000, minimun loss  1.054349
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7755 acc_train: 0.2417 loss_val: 1.7892 acc_val: 0.1567 loss_test: 1.6794 acc_test: 0.5550 time: 0.0924s
Epoch: 0051 loss_train: 0.0143 acc_train: 1.0000 loss_val: 1.8207 acc_val: 0.3633 loss_test: 1.1660 acc_test: 0.6450 time: 0.0806s
Epoch: 0101 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8212 acc_val: 0.3967 loss_test: 1.1717 acc_test: 0.6650 time: 0.0774s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8608 acc_val: 0.4267 loss_test: 1.2021 acc_test: 0.6790 time: 0.0957s
Epoch: 0201 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8870 acc_val: 0.4533 loss_test: 1.2414 acc_test: 0.6890 time: 0.0967s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9489 acc_val: 0.4833 loss_test: 1.2929 acc_test: 0.6960 time: 0.1136s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0108 acc_val: 0.4967 loss_test: 1.3351 acc_test: 0.6960 time: 0.1167s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0478 acc_val: 0.5133 loss_test: 1.3732 acc_test: 0.7010 time: 0.0769s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0791 acc_val: 0.5167 loss_test: 1.4055 acc_test: 0.6990 time: 0.0715s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1144 acc_val: 0.5200 loss_test: 1.4402 acc_test: 0.6990 time: 0.0657s
Optimization Finished!
Total time elapsed: 45.2333s, best testing performance  0.703000, minimun loss  1.062576
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7990 acc_train: 0.1500 loss_val: 1.7975 acc_val: 0.1433 loss_test: 1.7086 acc_test: 0.4840 time: 0.0974s
Epoch: 0051 loss_train: 0.0159 acc_train: 1.0000 loss_val: 1.7716 acc_val: 0.3633 loss_test: 1.1335 acc_test: 0.6540 time: 0.1009s
Epoch: 0101 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7851 acc_val: 0.3900 loss_test: 1.1397 acc_test: 0.6710 time: 0.1034s
Epoch: 0151 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8479 acc_val: 0.4200 loss_test: 1.1770 acc_test: 0.6840 time: 0.0995s
Epoch: 0201 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8620 acc_val: 0.4433 loss_test: 1.2089 acc_test: 0.6880 time: 0.1010s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9001 acc_val: 0.4733 loss_test: 1.2550 acc_test: 0.6920 time: 0.0926s
Epoch: 0301 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9666 acc_val: 0.4800 loss_test: 1.3088 acc_test: 0.6940 time: 0.0977s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0188 acc_val: 0.4933 loss_test: 1.3511 acc_test: 0.6960 time: 0.0811s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0720 acc_val: 0.4933 loss_test: 1.3907 acc_test: 0.6970 time: 0.1065s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1148 acc_val: 0.4900 loss_test: 1.4336 acc_test: 0.7000 time: 0.1049s
Optimization Finished!
Total time elapsed: 47.7305s, best testing performance  0.704000, minimun loss  1.033727
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7762 acc_train: 0.3000 loss_val: 1.7849 acc_val: 0.1867 loss_test: 1.7007 acc_test: 0.4950 time: 0.1005s
Epoch: 0051 loss_train: 0.0153 acc_train: 1.0000 loss_val: 1.8979 acc_val: 0.3667 loss_test: 1.1862 acc_test: 0.6470 time: 0.1105s
Epoch: 0101 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8824 acc_val: 0.4000 loss_test: 1.1860 acc_test: 0.6620 time: 0.0780s
Epoch: 0151 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9137 acc_val: 0.4333 loss_test: 1.2124 acc_test: 0.6720 time: 0.0816s
Epoch: 0201 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9484 acc_val: 0.4467 loss_test: 1.2466 acc_test: 0.6810 time: 0.0917s
Epoch: 0251 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9801 acc_val: 0.4733 loss_test: 1.2845 acc_test: 0.6900 time: 0.0963s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0009 acc_val: 0.4967 loss_test: 1.3246 acc_test: 0.6920 time: 0.0648s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0452 acc_val: 0.5000 loss_test: 1.3652 acc_test: 0.7000 time: 0.0644s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0802 acc_val: 0.5133 loss_test: 1.4024 acc_test: 0.6990 time: 0.0643s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1329 acc_val: 0.5100 loss_test: 1.4401 acc_test: 0.7020 time: 0.0650s
Optimization Finished!
Total time elapsed: 41.9556s, best testing performance  0.703000, minimun loss  1.067833
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8130 acc_train: 0.1083 loss_val: 1.7960 acc_val: 0.1733 loss_test: 1.7236 acc_test: 0.4790 time: 0.0767s
Epoch: 0051 loss_train: 0.0141 acc_train: 1.0000 loss_val: 1.8262 acc_val: 0.3967 loss_test: 1.1683 acc_test: 0.6570 time: 0.0757s
Epoch: 0101 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7883 acc_val: 0.4267 loss_test: 1.1548 acc_test: 0.6700 time: 0.0863s
Epoch: 0151 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8285 acc_val: 0.4367 loss_test: 1.1891 acc_test: 0.6790 time: 0.0913s
Epoch: 0201 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8774 acc_val: 0.4400 loss_test: 1.2335 acc_test: 0.6850 time: 0.0996s
Epoch: 0251 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9320 acc_val: 0.4600 loss_test: 1.2784 acc_test: 0.6870 time: 0.1133s
Epoch: 0301 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.4867 loss_test: 1.3206 acc_test: 0.6920 time: 0.0819s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0464 acc_val: 0.4967 loss_test: 1.3704 acc_test: 0.6950 time: 0.0787s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0953 acc_val: 0.4967 loss_test: 1.4098 acc_test: 0.6970 time: 0.0818s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1513 acc_val: 0.5000 loss_test: 1.4535 acc_test: 0.6980 time: 0.1091s
Optimization Finished!
Total time elapsed: 49.1999s, best testing performance  0.703000, minimun loss  1.059961
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1417 loss_val: 1.8039 acc_val: 0.0833 loss_test: 1.7138 acc_test: 0.3740 time: 0.0868s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.3567 loss_test: 1.2214 acc_test: 0.6500 time: 0.1016s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8947 acc_val: 0.3933 loss_test: 1.2092 acc_test: 0.6730 time: 0.0804s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9497 acc_val: 0.4267 loss_test: 1.2471 acc_test: 0.6760 time: 0.0879s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9204 acc_val: 0.4667 loss_test: 1.2674 acc_test: 0.6880 time: 0.0660s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9466 acc_val: 0.4733 loss_test: 1.3029 acc_test: 0.6870 time: 0.0641s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9700 acc_val: 0.4833 loss_test: 1.3333 acc_test: 0.6920 time: 0.0658s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 1.9960 acc_val: 0.4967 loss_test: 1.3632 acc_test: 0.6950 time: 0.0674s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 1.9997 acc_val: 0.5100 loss_test: 1.3859 acc_test: 0.6970 time: 0.0681s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0450 acc_val: 0.5200 loss_test: 1.4168 acc_test: 0.6990 time: 0.0660s
Optimization Finished!
Total time elapsed: 38.0002s, best testing performance  0.705000, minimun loss  1.047652
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7900 acc_train: 0.1917 loss_val: 1.7884 acc_val: 0.1833 loss_test: 1.7195 acc_test: 0.4500 time: 0.1233s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 2.0066 acc_val: 0.3467 loss_test: 1.2262 acc_test: 0.6480 time: 0.0935s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8967 acc_val: 0.4233 loss_test: 1.2033 acc_test: 0.6680 time: 0.0909s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9011 acc_val: 0.4367 loss_test: 1.2299 acc_test: 0.6810 time: 0.1026s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9551 acc_val: 0.4700 loss_test: 1.2753 acc_test: 0.6890 time: 0.1034s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9686 acc_val: 0.4800 loss_test: 1.3101 acc_test: 0.6930 time: 0.1118s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0147 acc_val: 0.4933 loss_test: 1.3525 acc_test: 0.6940 time: 0.0937s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0457 acc_val: 0.4900 loss_test: 1.3916 acc_test: 0.6940 time: 0.0869s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0632 acc_val: 0.5000 loss_test: 1.4179 acc_test: 0.7000 time: 0.0825s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1040 acc_val: 0.5067 loss_test: 1.4514 acc_test: 0.7010 time: 0.0816s
Optimization Finished!
Total time elapsed: 48.5175s, best testing performance  0.704000, minimun loss  1.048436
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7757 acc_train: 0.2667 loss_val: 1.7928 acc_val: 0.1833 loss_test: 1.6890 acc_test: 0.5000 time: 0.0974s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.9611 acc_val: 0.3567 loss_test: 1.2118 acc_test: 0.6450 time: 0.0884s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8752 acc_val: 0.4167 loss_test: 1.2032 acc_test: 0.6650 time: 0.0645s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8880 acc_val: 0.4333 loss_test: 1.2317 acc_test: 0.6780 time: 0.0650s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9321 acc_val: 0.4533 loss_test: 1.2710 acc_test: 0.6850 time: 0.0642s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9547 acc_val: 0.4833 loss_test: 1.3007 acc_test: 0.6910 time: 0.0657s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0221 acc_val: 0.4900 loss_test: 1.3438 acc_test: 0.6940 time: 0.0686s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0724 acc_val: 0.4967 loss_test: 1.3792 acc_test: 0.6980 time: 0.0660s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1141 acc_val: 0.4933 loss_test: 1.4123 acc_test: 0.6970 time: 0.0693s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1504 acc_val: 0.5000 loss_test: 1.4436 acc_test: 0.6960 time: 0.1134s
Optimization Finished!
Total time elapsed: 37.0285s, best testing performance  0.705000, minimun loss  1.030933
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7833 acc_train: 0.2750 loss_val: 1.7936 acc_val: 0.2167 loss_test: 1.7039 acc_test: 0.4920 time: 0.1183s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.9484 acc_val: 0.3433 loss_test: 1.1929 acc_test: 0.6540 time: 0.1008s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.9310 acc_val: 0.3900 loss_test: 1.1986 acc_test: 0.6680 time: 0.0763s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9498 acc_val: 0.4267 loss_test: 1.2303 acc_test: 0.6830 time: 0.1211s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9575 acc_val: 0.4433 loss_test: 1.2650 acc_test: 0.6860 time: 0.1120s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9584 acc_val: 0.4733 loss_test: 1.2968 acc_test: 0.6930 time: 0.1069s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0045 acc_val: 0.4767 loss_test: 1.3340 acc_test: 0.6920 time: 0.1123s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0275 acc_val: 0.5000 loss_test: 1.3654 acc_test: 0.6950 time: 0.0890s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0679 acc_val: 0.5000 loss_test: 1.4001 acc_test: 0.6930 time: 0.0829s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1001 acc_val: 0.5167 loss_test: 1.4285 acc_test: 0.6950 time: 0.1167s
Optimization Finished!
Total time elapsed: 48.9142s, best testing performance  0.698000, minimun loss  1.029822
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7903 acc_train: 0.1417 loss_val: 1.8059 acc_val: 0.1733 loss_test: 1.7077 acc_test: 0.4470 time: 0.0863s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 2.0143 acc_val: 0.3667 loss_test: 1.2266 acc_test: 0.6440 time: 0.0664s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.9083 acc_val: 0.4133 loss_test: 1.2083 acc_test: 0.6650 time: 0.0640s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9269 acc_val: 0.4400 loss_test: 1.2347 acc_test: 0.6770 time: 0.0652s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9368 acc_val: 0.4567 loss_test: 1.2635 acc_test: 0.6860 time: 0.0679s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9292 acc_val: 0.4867 loss_test: 1.2926 acc_test: 0.6980 time: 0.0659s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9114 acc_val: 0.5000 loss_test: 1.3131 acc_test: 0.7010 time: 0.0800s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 1.9242 acc_val: 0.5167 loss_test: 1.3401 acc_test: 0.7040 time: 0.0839s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 1.9466 acc_val: 0.5267 loss_test: 1.3744 acc_test: 0.7030 time: 0.1136s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 1.9734 acc_val: 0.5233 loss_test: 1.4033 acc_test: 0.7060 time: 0.1147s
Optimization Finished!
Total time elapsed: 39.4273s, best testing performance  0.709000, minimun loss  1.049365
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7769 acc_train: 0.2000 loss_val: 1.7843 acc_val: 0.1933 loss_test: 1.7216 acc_test: 0.4750 time: 0.0815s
Epoch: 0051 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.8665 acc_val: 0.3467 loss_test: 1.1429 acc_test: 0.6520 time: 0.0944s
Epoch: 0101 loss_train: 0.0134 acc_train: 1.0000 loss_val: 1.8090 acc_val: 0.4067 loss_test: 1.1336 acc_test: 0.6710 time: 0.0813s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8125 acc_val: 0.4333 loss_test: 1.1636 acc_test: 0.6870 time: 0.0867s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8534 acc_val: 0.4367 loss_test: 1.2090 acc_test: 0.6870 time: 0.0876s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8963 acc_val: 0.4767 loss_test: 1.2493 acc_test: 0.6930 time: 0.0891s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9450 acc_val: 0.4733 loss_test: 1.2973 acc_test: 0.6910 time: 0.0854s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0068 acc_val: 0.4833 loss_test: 1.3457 acc_test: 0.6920 time: 0.1086s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0448 acc_val: 0.4967 loss_test: 1.3847 acc_test: 0.6960 time: 0.1260s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1679 acc_val: 0.4900 loss_test: 1.4491 acc_test: 0.6980 time: 0.1072s
Optimization Finished!
Total time elapsed: 48.7122s, best testing performance  0.701000, minimun loss  1.056675
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7772 acc_train: 0.3000 loss_val: 1.7874 acc_val: 0.2267 loss_test: 1.7120 acc_test: 0.5110 time: 0.0992s
Epoch: 0051 loss_train: 0.0173 acc_train: 1.0000 loss_val: 1.8878 acc_val: 0.3533 loss_test: 1.1650 acc_test: 0.6470 time: 0.0654s
Epoch: 0101 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8415 acc_val: 0.3867 loss_test: 1.1507 acc_test: 0.6640 time: 0.0707s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8613 acc_val: 0.4200 loss_test: 1.1807 acc_test: 0.6750 time: 0.0677s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8917 acc_val: 0.4200 loss_test: 1.2191 acc_test: 0.6870 time: 0.1108s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9561 acc_val: 0.4433 loss_test: 1.2605 acc_test: 0.6870 time: 0.0810s
Epoch: 0301 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0043 acc_val: 0.4433 loss_test: 1.3003 acc_test: 0.6880 time: 0.1010s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0356 acc_val: 0.4700 loss_test: 1.3360 acc_test: 0.6960 time: 0.0870s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0675 acc_val: 0.4700 loss_test: 1.3706 acc_test: 0.6930 time: 0.0935s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0807 acc_val: 0.4833 loss_test: 1.4033 acc_test: 0.6940 time: 0.0879s
Optimization Finished!
Total time elapsed: 44.0033s, best testing performance  0.700000, minimun loss  1.082399
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7971 acc_train: 0.1500 loss_val: 1.8041 acc_val: 0.1567 loss_test: 1.7185 acc_test: 0.4510 time: 0.1365s
Epoch: 0051 loss_train: 0.0174 acc_train: 1.0000 loss_val: 1.8978 acc_val: 0.3467 loss_test: 1.1596 acc_test: 0.6490 time: 0.0907s
Epoch: 0101 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8518 acc_val: 0.3967 loss_test: 1.1491 acc_test: 0.6650 time: 0.0771s
Epoch: 0151 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8591 acc_val: 0.4200 loss_test: 1.1785 acc_test: 0.6770 time: 0.0951s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8960 acc_val: 0.4433 loss_test: 1.2197 acc_test: 0.6780 time: 0.0877s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9274 acc_val: 0.4500 loss_test: 1.2530 acc_test: 0.6830 time: 0.0798s
Epoch: 0301 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9395 acc_val: 0.4667 loss_test: 1.2881 acc_test: 0.6870 time: 0.1166s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0159 acc_val: 0.4767 loss_test: 1.3354 acc_test: 0.6920 time: 0.1117s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0905 acc_val: 0.4700 loss_test: 1.3669 acc_test: 0.6930 time: 0.1132s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1786 acc_val: 0.4800 loss_test: 1.4105 acc_test: 0.6910 time: 0.0661s
Optimization Finished!
Total time elapsed: 45.8143s, best testing performance  0.699000, minimun loss  1.069650
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7951 acc_train: 0.1667 loss_val: 1.7927 acc_val: 0.1400 loss_test: 1.7157 acc_test: 0.4840 time: 0.1039s
Epoch: 0051 loss_train: 0.0178 acc_train: 1.0000 loss_val: 1.8274 acc_val: 0.3600 loss_test: 1.1455 acc_test: 0.6480 time: 0.0983s
Epoch: 0101 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.7794 acc_val: 0.4067 loss_test: 1.1346 acc_test: 0.6690 time: 0.0896s
Epoch: 0151 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7933 acc_val: 0.4400 loss_test: 1.1666 acc_test: 0.6830 time: 0.1044s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8123 acc_val: 0.4567 loss_test: 1.1990 acc_test: 0.6840 time: 0.0942s
Epoch: 0251 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8471 acc_val: 0.4700 loss_test: 1.2375 acc_test: 0.6910 time: 0.0889s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9136 acc_val: 0.4767 loss_test: 1.2872 acc_test: 0.6920 time: 0.1018s
Epoch: 0351 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9672 acc_val: 0.4767 loss_test: 1.3309 acc_test: 0.6980 time: 0.1040s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0166 acc_val: 0.4667 loss_test: 1.3794 acc_test: 0.7000 time: 0.1016s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1030 acc_val: 0.4667 loss_test: 1.4342 acc_test: 0.6960 time: 0.0863s
Optimization Finished!
Total time elapsed: 47.8076s, best testing performance  0.703000, minimun loss  1.074769
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7961 acc_train: 0.1417 loss_val: 1.7989 acc_val: 0.1600 loss_test: 1.7151 acc_test: 0.4890 time: 0.0934s
Epoch: 0051 loss_train: 0.0167 acc_train: 1.0000 loss_val: 1.8851 acc_val: 0.3400 loss_test: 1.1599 acc_test: 0.6510 time: 0.1007s
Epoch: 0101 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8248 acc_val: 0.4067 loss_test: 1.1481 acc_test: 0.6680 time: 0.1040s
Epoch: 0151 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8348 acc_val: 0.4333 loss_test: 1.1834 acc_test: 0.6820 time: 0.1147s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8700 acc_val: 0.4400 loss_test: 1.2270 acc_test: 0.6830 time: 0.1256s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9083 acc_val: 0.4733 loss_test: 1.2693 acc_test: 0.6850 time: 0.1178s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0004 acc_val: 0.4667 loss_test: 1.3266 acc_test: 0.6900 time: 0.0645s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0557 acc_val: 0.4700 loss_test: 1.3775 acc_test: 0.6920 time: 0.0652s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1525 acc_val: 0.4633 loss_test: 1.4344 acc_test: 0.6930 time: 0.0646s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2216 acc_val: 0.4667 loss_test: 1.4863 acc_test: 0.6980 time: 0.0657s
Optimization Finished!
Total time elapsed: 42.2863s, best testing performance  0.702000, minimun loss  1.071851
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8137 acc_train: 0.1167 loss_val: 1.7877 acc_val: 0.2200 loss_test: 1.7284 acc_test: 0.4770 time: 0.1109s
Epoch: 0051 loss_train: 0.0169 acc_train: 1.0000 loss_val: 1.8264 acc_val: 0.3600 loss_test: 1.1486 acc_test: 0.6530 time: 0.1046s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.7914 acc_val: 0.4067 loss_test: 1.1363 acc_test: 0.6700 time: 0.1176s
Epoch: 0151 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8122 acc_val: 0.4433 loss_test: 1.1699 acc_test: 0.6870 time: 0.0777s
Epoch: 0201 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8399 acc_val: 0.4533 loss_test: 1.2038 acc_test: 0.6900 time: 0.1157s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8713 acc_val: 0.4767 loss_test: 1.2405 acc_test: 0.6910 time: 0.0971s
Epoch: 0301 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9569 acc_val: 0.4767 loss_test: 1.2959 acc_test: 0.6930 time: 0.0993s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0049 acc_val: 0.4833 loss_test: 1.3427 acc_test: 0.6910 time: 0.0981s
Epoch: 0401 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0821 acc_val: 0.4700 loss_test: 1.3956 acc_test: 0.6920 time: 0.0981s
Epoch: 0451 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1982 acc_val: 0.4733 loss_test: 1.4575 acc_test: 0.6920 time: 0.1097s
Optimization Finished!
Total time elapsed: 48.6559s, best testing performance  0.698000, minimun loss  1.062620
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8146 acc_train: 0.0833 loss_val: 1.8092 acc_val: 0.1667 loss_test: 1.7365 acc_test: 0.4420 time: 0.0952s
Epoch: 0051 loss_train: 0.0176 acc_train: 1.0000 loss_val: 1.8992 acc_val: 0.3433 loss_test: 1.1496 acc_test: 0.6430 time: 0.0820s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8557 acc_val: 0.4033 loss_test: 1.1480 acc_test: 0.6690 time: 0.0888s
Epoch: 0151 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8786 acc_val: 0.4200 loss_test: 1.1869 acc_test: 0.6830 time: 0.1080s
Epoch: 0201 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9009 acc_val: 0.4433 loss_test: 1.2247 acc_test: 0.6860 time: 0.0653s
Epoch: 0251 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9693 acc_val: 0.4667 loss_test: 1.2847 acc_test: 0.6920 time: 0.0643s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0113 acc_val: 0.4700 loss_test: 1.3360 acc_test: 0.6970 time: 0.0654s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0714 acc_val: 0.4800 loss_test: 1.3948 acc_test: 0.6930 time: 0.0647s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1241 acc_val: 0.4900 loss_test: 1.4476 acc_test: 0.6910 time: 0.0670s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2385 acc_val: 0.4833 loss_test: 1.5166 acc_test: 0.6970 time: 0.0688s
Optimization Finished!
Total time elapsed: 38.4213s, best testing performance  0.699000, minimun loss  1.052594
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7857 acc_train: 0.2083 loss_val: 1.7849 acc_val: 0.2200 loss_test: 1.7060 acc_test: 0.5000 time: 0.0775s
Epoch: 0051 loss_train: 0.0165 acc_train: 1.0000 loss_val: 1.8426 acc_val: 0.3700 loss_test: 1.1394 acc_test: 0.6560 time: 0.1000s
Epoch: 0101 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8052 acc_val: 0.4167 loss_test: 1.1338 acc_test: 0.6760 time: 0.1134s
Epoch: 0151 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8337 acc_val: 0.4533 loss_test: 1.1731 acc_test: 0.6890 time: 0.1101s
Epoch: 0201 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8657 acc_val: 0.4633 loss_test: 1.2114 acc_test: 0.6900 time: 0.1016s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9042 acc_val: 0.4733 loss_test: 1.2527 acc_test: 0.6920 time: 0.1006s
Epoch: 0301 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9609 acc_val: 0.4767 loss_test: 1.2921 acc_test: 0.6970 time: 0.0904s
Epoch: 0351 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0261 acc_val: 0.4800 loss_test: 1.3388 acc_test: 0.6950 time: 0.1222s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0775 acc_val: 0.4867 loss_test: 1.3791 acc_test: 0.6950 time: 0.0769s
Epoch: 0451 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1428 acc_val: 0.4867 loss_test: 1.4249 acc_test: 0.6980 time: 0.0977s
Optimization Finished!
Total time elapsed: 48.3628s, best testing performance  0.701000, minimun loss  1.048537
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8044 acc_train: 0.1583 loss_val: 1.7820 acc_val: 0.1200 loss_test: 1.7088 acc_test: 0.4900 time: 0.0971s
Epoch: 0051 loss_train: 0.0167 acc_train: 1.0000 loss_val: 1.8315 acc_val: 0.3433 loss_test: 1.1712 acc_test: 0.6480 time: 0.0817s
Epoch: 0101 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7960 acc_val: 0.4100 loss_test: 1.1535 acc_test: 0.6660 time: 0.0638s
Epoch: 0151 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7912 acc_val: 0.4300 loss_test: 1.1797 acc_test: 0.6840 time: 0.0642s
Epoch: 0201 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8449 acc_val: 0.4433 loss_test: 1.2235 acc_test: 0.6860 time: 0.0665s
Epoch: 0251 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9061 acc_val: 0.4467 loss_test: 1.2677 acc_test: 0.6880 time: 0.0645s
Epoch: 0301 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9969 acc_val: 0.4600 loss_test: 1.3243 acc_test: 0.6890 time: 0.0658s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0821 acc_val: 0.4700 loss_test: 1.3747 acc_test: 0.6890 time: 0.0691s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1662 acc_val: 0.4667 loss_test: 1.4255 acc_test: 0.6920 time: 0.0677s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2225 acc_val: 0.4800 loss_test: 1.4672 acc_test: 0.6970 time: 0.0971s
Optimization Finished!
Total time elapsed: 37.2636s, best testing performance  0.702000, minimun loss  1.087177
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8074 acc_train: 0.1167 loss_val: 1.7920 acc_val: 0.2167 loss_test: 1.7205 acc_test: 0.5030 time: 0.1083s
Epoch: 0051 loss_train: 0.0170 acc_train: 1.0000 loss_val: 1.9037 acc_val: 0.3467 loss_test: 1.1689 acc_test: 0.6380 time: 0.1040s
Epoch: 0101 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8649 acc_val: 0.4133 loss_test: 1.1678 acc_test: 0.6680 time: 0.0954s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8568 acc_val: 0.4333 loss_test: 1.1965 acc_test: 0.6770 time: 0.0879s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8980 acc_val: 0.4500 loss_test: 1.2337 acc_test: 0.6870 time: 0.1108s
Epoch: 0251 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9178 acc_val: 0.4633 loss_test: 1.2661 acc_test: 0.6900 time: 0.1020s
Epoch: 0301 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9968 acc_val: 0.4700 loss_test: 1.3119 acc_test: 0.6910 time: 0.1103s
Epoch: 0351 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0402 acc_val: 0.4800 loss_test: 1.3540 acc_test: 0.6920 time: 0.0920s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0567 acc_val: 0.5000 loss_test: 1.3825 acc_test: 0.6960 time: 0.1124s
Epoch: 0451 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1303 acc_val: 0.5000 loss_test: 1.4210 acc_test: 0.7000 time: 0.0982s
Optimization Finished!
Total time elapsed: 49.2228s, best testing performance  0.704000, minimun loss  1.066327
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7899 acc_train: 0.1583 loss_val: 1.7794 acc_val: 0.1967 loss_test: 1.7134 acc_test: 0.4430 time: 0.0939s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9695 acc_val: 0.3467 loss_test: 1.2207 acc_test: 0.6590 time: 0.0664s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8629 acc_val: 0.4000 loss_test: 1.2120 acc_test: 0.6730 time: 0.0643s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8686 acc_val: 0.4433 loss_test: 1.2476 acc_test: 0.6810 time: 0.0687s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9050 acc_val: 0.4767 loss_test: 1.2787 acc_test: 0.6910 time: 0.0657s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9516 acc_val: 0.4933 loss_test: 1.3101 acc_test: 0.6960 time: 0.0663s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9909 acc_val: 0.4900 loss_test: 1.3438 acc_test: 0.6960 time: 0.0768s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0351 acc_val: 0.5067 loss_test: 1.3762 acc_test: 0.7010 time: 0.0859s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0750 acc_val: 0.5133 loss_test: 1.4068 acc_test: 0.7000 time: 0.0741s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1219 acc_val: 0.5167 loss_test: 1.4364 acc_test: 0.6990 time: 0.0855s
Optimization Finished!
Total time elapsed: 39.2416s, best testing performance  0.703000, minimun loss  1.055049
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7957 acc_train: 0.1833 loss_val: 1.7916 acc_val: 0.1300 loss_test: 1.7012 acc_test: 0.4360 time: 0.0927s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.9769 acc_val: 0.3400 loss_test: 1.2194 acc_test: 0.6470 time: 0.0821s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8780 acc_val: 0.4167 loss_test: 1.2087 acc_test: 0.6680 time: 0.0995s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8918 acc_val: 0.4400 loss_test: 1.2378 acc_test: 0.6820 time: 0.1085s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9432 acc_val: 0.4533 loss_test: 1.2828 acc_test: 0.6870 time: 0.1028s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0199 acc_val: 0.4667 loss_test: 1.3243 acc_test: 0.6890 time: 0.1017s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0436 acc_val: 0.4967 loss_test: 1.3559 acc_test: 0.6980 time: 0.1009s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1178 acc_val: 0.4967 loss_test: 1.3926 acc_test: 0.6990 time: 0.0884s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1600 acc_val: 0.5000 loss_test: 1.4255 acc_test: 0.7020 time: 0.0739s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1996 acc_val: 0.5067 loss_test: 1.4536 acc_test: 0.7000 time: 0.1329s
Optimization Finished!
Total time elapsed: 49.1255s, best testing performance  0.705000, minimun loss  1.042414
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7924 acc_train: 0.1833 loss_val: 1.8121 acc_val: 0.0833 loss_test: 1.7145 acc_test: 0.4050 time: 0.1006s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.9533 acc_val: 0.3500 loss_test: 1.2131 acc_test: 0.6490 time: 0.0670s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8889 acc_val: 0.4133 loss_test: 1.2032 acc_test: 0.6730 time: 0.0654s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8518 acc_val: 0.4467 loss_test: 1.2275 acc_test: 0.6880 time: 0.0667s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9216 acc_val: 0.4667 loss_test: 1.2700 acc_test: 0.6920 time: 0.0857s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9645 acc_val: 0.4833 loss_test: 1.3023 acc_test: 0.6890 time: 0.0908s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0156 acc_val: 0.4900 loss_test: 1.3451 acc_test: 0.6910 time: 0.0782s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0466 acc_val: 0.4933 loss_test: 1.3754 acc_test: 0.6980 time: 0.0879s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0922 acc_val: 0.5000 loss_test: 1.4117 acc_test: 0.6920 time: 0.0919s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0978 acc_val: 0.5100 loss_test: 1.4382 acc_test: 0.6940 time: 0.1049s
Optimization Finished!
Total time elapsed: 43.7698s, best testing performance  0.701000, minimun loss  1.033358
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7845 acc_train: 0.2083 loss_val: 1.8058 acc_val: 0.1167 loss_test: 1.6985 acc_test: 0.4520 time: 0.1107s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8906 acc_val: 0.3467 loss_test: 1.1955 acc_test: 0.6540 time: 0.0859s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8589 acc_val: 0.3967 loss_test: 1.2025 acc_test: 0.6710 time: 0.0856s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8910 acc_val: 0.4400 loss_test: 1.2408 acc_test: 0.6840 time: 0.0918s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9175 acc_val: 0.4633 loss_test: 1.2776 acc_test: 0.6900 time: 0.0893s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9639 acc_val: 0.4900 loss_test: 1.3082 acc_test: 0.6970 time: 0.0898s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0270 acc_val: 0.4867 loss_test: 1.3518 acc_test: 0.6960 time: 0.1244s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0556 acc_val: 0.4967 loss_test: 1.3838 acc_test: 0.7000 time: 0.0885s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0760 acc_val: 0.4967 loss_test: 1.4125 acc_test: 0.6990 time: 0.0768s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1543 acc_val: 0.5067 loss_test: 1.4518 acc_test: 0.6990 time: 0.0647s
Optimization Finished!
Total time elapsed: 45.8670s, best testing performance  0.705000, minimun loss  1.031576
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7855 acc_train: 0.1750 loss_val: 1.7739 acc_val: 0.2933 loss_test: 1.7058 acc_test: 0.4970 time: 0.0969s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.9080 acc_val: 0.3633 loss_test: 1.1796 acc_test: 0.6560 time: 0.0865s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8612 acc_val: 0.4133 loss_test: 1.1834 acc_test: 0.6740 time: 0.0887s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9017 acc_val: 0.4367 loss_test: 1.2268 acc_test: 0.6860 time: 0.1044s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9314 acc_val: 0.4533 loss_test: 1.2626 acc_test: 0.6920 time: 0.1035s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9653 acc_val: 0.4567 loss_test: 1.2962 acc_test: 0.6950 time: 0.0945s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0065 acc_val: 0.4700 loss_test: 1.3350 acc_test: 0.6940 time: 0.0981s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0427 acc_val: 0.5000 loss_test: 1.3687 acc_test: 0.6990 time: 0.1018s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0725 acc_val: 0.5100 loss_test: 1.3994 acc_test: 0.7000 time: 0.0960s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0896 acc_val: 0.5100 loss_test: 1.4263 acc_test: 0.7000 time: 0.0955s
Optimization Finished!
Total time elapsed: 47.4806s, best testing performance  0.705000, minimun loss  1.033363
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7938 acc_train: 0.1083 loss_val: 1.7854 acc_val: 0.1533 loss_test: 1.7183 acc_test: 0.4040 time: 0.0985s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7833 acc_val: 0.3533 loss_test: 1.1638 acc_test: 0.6560 time: 0.1010s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7528 acc_val: 0.4233 loss_test: 1.1589 acc_test: 0.6770 time: 0.1173s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8024 acc_val: 0.4500 loss_test: 1.2046 acc_test: 0.6890 time: 0.0962s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8658 acc_val: 0.4733 loss_test: 1.2431 acc_test: 0.6920 time: 0.0919s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9089 acc_val: 0.4867 loss_test: 1.2833 acc_test: 0.6950 time: 0.1203s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9657 acc_val: 0.5000 loss_test: 1.3226 acc_test: 0.6960 time: 0.0641s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0119 acc_val: 0.5100 loss_test: 1.3586 acc_test: 0.6930 time: 0.0646s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0505 acc_val: 0.5033 loss_test: 1.3943 acc_test: 0.6970 time: 0.0647s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0786 acc_val: 0.5100 loss_test: 1.4168 acc_test: 0.6990 time: 0.0655s
Optimization Finished!
Total time elapsed: 41.9741s, best testing performance  0.702000, minimun loss  1.026632
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7943 acc_train: 0.1583 loss_val: 1.8025 acc_val: 0.1033 loss_test: 1.7101 acc_test: 0.4040 time: 0.1242s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8984 acc_val: 0.3700 loss_test: 1.1850 acc_test: 0.6610 time: 0.0761s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8545 acc_val: 0.4167 loss_test: 1.1852 acc_test: 0.6790 time: 0.0860s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8532 acc_val: 0.4600 loss_test: 1.2196 acc_test: 0.6900 time: 0.0814s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8651 acc_val: 0.4733 loss_test: 1.2564 acc_test: 0.6910 time: 0.0761s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9243 acc_val: 0.4800 loss_test: 1.2992 acc_test: 0.6930 time: 0.1184s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9833 acc_val: 0.4833 loss_test: 1.3363 acc_test: 0.6940 time: 0.1132s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0298 acc_val: 0.4967 loss_test: 1.3698 acc_test: 0.7010 time: 0.1239s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0586 acc_val: 0.5133 loss_test: 1.4005 acc_test: 0.7020 time: 0.1278s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0975 acc_val: 0.5100 loss_test: 1.4309 acc_test: 0.7020 time: 0.0911s
Optimization Finished!
Total time elapsed: 48.7894s, best testing performance  0.707000, minimun loss  1.022795
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7959 acc_train: 0.1500 loss_val: 1.8035 acc_val: 0.1067 loss_test: 1.7208 acc_test: 0.3730 time: 0.0809s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9566 acc_val: 0.3500 loss_test: 1.2129 acc_test: 0.6440 time: 0.0758s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8825 acc_val: 0.4000 loss_test: 1.1994 acc_test: 0.6680 time: 0.1082s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8262 acc_val: 0.4367 loss_test: 1.2157 acc_test: 0.6780 time: 0.0893s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9019 acc_val: 0.4400 loss_test: 1.2576 acc_test: 0.6880 time: 0.0664s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9736 acc_val: 0.4667 loss_test: 1.3000 acc_test: 0.6930 time: 0.0644s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0428 acc_val: 0.4767 loss_test: 1.3417 acc_test: 0.6940 time: 0.0638s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0636 acc_val: 0.4867 loss_test: 1.3661 acc_test: 0.6930 time: 0.0679s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1218 acc_val: 0.5033 loss_test: 1.4005 acc_test: 0.6920 time: 0.0687s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1559 acc_val: 0.5033 loss_test: 1.4301 acc_test: 0.6940 time: 0.0666s
Optimization Finished!
Total time elapsed: 38.2624s, best testing performance  0.698000, minimun loss  1.036009
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8162 acc_train: 0.0917 loss_val: 1.7900 acc_val: 0.2100 loss_test: 1.7234 acc_test: 0.4660 time: 0.1423s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.9878 acc_val: 0.3367 loss_test: 1.2226 acc_test: 0.6560 time: 0.0885s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8723 acc_val: 0.4033 loss_test: 1.2048 acc_test: 0.6730 time: 0.0958s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8972 acc_val: 0.4433 loss_test: 1.2435 acc_test: 0.6830 time: 0.0859s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9694 acc_val: 0.4500 loss_test: 1.2885 acc_test: 0.6880 time: 0.0830s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9767 acc_val: 0.4700 loss_test: 1.3164 acc_test: 0.6930 time: 0.0857s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0401 acc_val: 0.4800 loss_test: 1.3606 acc_test: 0.6930 time: 0.0885s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0700 acc_val: 0.4967 loss_test: 1.3955 acc_test: 0.6970 time: 0.1314s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1037 acc_val: 0.5033 loss_test: 1.4265 acc_test: 0.6950 time: 0.1169s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1449 acc_val: 0.5033 loss_test: 1.4611 acc_test: 0.6960 time: 0.1043s
Optimization Finished!
Total time elapsed: 49.1792s, best testing performance  0.698000, minimun loss  1.039500
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.2250 loss_val: 1.7956 acc_val: 0.2133 loss_test: 1.7279 acc_test: 0.3630 time: 0.0964s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9247 acc_val: 0.3500 loss_test: 1.1974 acc_test: 0.6490 time: 0.0640s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8284 acc_val: 0.4100 loss_test: 1.1876 acc_test: 0.6700 time: 0.0651s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9124 acc_val: 0.4433 loss_test: 1.2390 acc_test: 0.6810 time: 0.0640s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9753 acc_val: 0.4633 loss_test: 1.2849 acc_test: 0.6920 time: 0.0645s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0458 acc_val: 0.4800 loss_test: 1.3309 acc_test: 0.6910 time: 0.0659s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1007 acc_val: 0.4833 loss_test: 1.3715 acc_test: 0.6950 time: 0.0658s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1913 acc_val: 0.4767 loss_test: 1.4237 acc_test: 0.6910 time: 0.0681s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2338 acc_val: 0.4900 loss_test: 1.4562 acc_test: 0.6940 time: 0.0677s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3422 acc_val: 0.4900 loss_test: 1.5059 acc_test: 0.6970 time: 0.0886s
Optimization Finished!
Total time elapsed: 37.1472s, best testing performance  0.701000, minimun loss  1.030756
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1583 loss_val: 1.7961 acc_val: 0.2167 loss_test: 1.7102 acc_test: 0.4940 time: 0.1148s
Epoch: 0051 loss_train: 0.0166 acc_train: 1.0000 loss_val: 1.9250 acc_val: 0.3433 loss_test: 1.1697 acc_test: 0.6450 time: 0.0962s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8673 acc_val: 0.3900 loss_test: 1.1578 acc_test: 0.6600 time: 0.0928s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8895 acc_val: 0.4200 loss_test: 1.1892 acc_test: 0.6770 time: 0.0989s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9267 acc_val: 0.4367 loss_test: 1.2299 acc_test: 0.6850 time: 0.1027s
Epoch: 0251 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9587 acc_val: 0.4567 loss_test: 1.2653 acc_test: 0.6870 time: 0.1021s
Epoch: 0301 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0031 acc_val: 0.4567 loss_test: 1.3024 acc_test: 0.6950 time: 0.0928s
Epoch: 0351 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0226 acc_val: 0.4700 loss_test: 1.3313 acc_test: 0.6990 time: 0.0740s
Epoch: 0401 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0838 acc_val: 0.4700 loss_test: 1.3750 acc_test: 0.7020 time: 0.1151s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1533 acc_val: 0.4733 loss_test: 1.4126 acc_test: 0.7020 time: 0.1016s
Optimization Finished!
Total time elapsed: 48.5621s, best testing performance  0.705000, minimun loss  1.078084
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7823 acc_train: 0.1750 loss_val: 1.7926 acc_val: 0.2033 loss_test: 1.7158 acc_test: 0.4880 time: 0.0947s
Epoch: 0051 loss_train: 0.0162 acc_train: 1.0000 loss_val: 1.8822 acc_val: 0.3533 loss_test: 1.1552 acc_test: 0.6480 time: 0.0651s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8411 acc_val: 0.4100 loss_test: 1.1424 acc_test: 0.6630 time: 0.0656s
Epoch: 0151 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8475 acc_val: 0.4333 loss_test: 1.1760 acc_test: 0.6830 time: 0.0653s
Epoch: 0201 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8987 acc_val: 0.4467 loss_test: 1.2248 acc_test: 0.6860 time: 0.0655s
Epoch: 0251 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9444 acc_val: 0.4633 loss_test: 1.2667 acc_test: 0.6880 time: 0.0664s
Epoch: 0301 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9853 acc_val: 0.4700 loss_test: 1.3078 acc_test: 0.6890 time: 0.1003s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0288 acc_val: 0.4767 loss_test: 1.3564 acc_test: 0.6970 time: 0.0896s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1146 acc_val: 0.4833 loss_test: 1.4095 acc_test: 0.6970 time: 0.1143s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1746 acc_val: 0.4933 loss_test: 1.4512 acc_test: 0.6970 time: 0.0894s
Optimization Finished!
Total time elapsed: 39.5140s, best testing performance  0.702000, minimun loss  1.066251
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7865 acc_train: 0.2333 loss_val: 1.7837 acc_val: 0.1600 loss_test: 1.7181 acc_test: 0.4280 time: 0.0875s
Epoch: 0051 loss_train: 0.0171 acc_train: 1.0000 loss_val: 1.8435 acc_val: 0.3500 loss_test: 1.1535 acc_test: 0.6460 time: 0.0838s
Epoch: 0101 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.8533 acc_val: 0.3800 loss_test: 1.1538 acc_test: 0.6640 time: 0.1012s
Epoch: 0151 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8615 acc_val: 0.4167 loss_test: 1.1847 acc_test: 0.6750 time: 0.0893s
Epoch: 0201 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8942 acc_val: 0.4267 loss_test: 1.2217 acc_test: 0.6860 time: 0.1120s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9159 acc_val: 0.4300 loss_test: 1.2511 acc_test: 0.6900 time: 0.0887s
Epoch: 0301 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9470 acc_val: 0.4533 loss_test: 1.2888 acc_test: 0.6900 time: 0.0989s
Epoch: 0351 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9828 acc_val: 0.4700 loss_test: 1.3268 acc_test: 0.6900 time: 0.1147s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0467 acc_val: 0.4867 loss_test: 1.3678 acc_test: 0.6940 time: 0.1041s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0813 acc_val: 0.5000 loss_test: 1.4037 acc_test: 0.6890 time: 0.0938s
Optimization Finished!
Total time elapsed: 48.8003s, best testing performance  0.697000, minimun loss  1.078363
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8002 acc_train: 0.1500 loss_val: 1.7996 acc_val: 0.1733 loss_test: 1.7224 acc_test: 0.4820 time: 0.0993s
Epoch: 0051 loss_train: 0.0171 acc_train: 1.0000 loss_val: 1.8737 acc_val: 0.3467 loss_test: 1.1398 acc_test: 0.6430 time: 0.0652s
Epoch: 0101 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8457 acc_val: 0.3967 loss_test: 1.1367 acc_test: 0.6640 time: 0.0679s
Epoch: 0151 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8646 acc_val: 0.4233 loss_test: 1.1746 acc_test: 0.6790 time: 0.0699s
Epoch: 0201 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8930 acc_val: 0.4467 loss_test: 1.2179 acc_test: 0.6870 time: 0.0678s
Epoch: 0251 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9681 acc_val: 0.4633 loss_test: 1.2723 acc_test: 0.6860 time: 0.0946s
Epoch: 0301 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0156 acc_val: 0.4767 loss_test: 1.3167 acc_test: 0.6880 time: 0.0920s
Epoch: 0351 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0499 acc_val: 0.4767 loss_test: 1.3579 acc_test: 0.6900 time: 0.0820s
Epoch: 0401 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1192 acc_val: 0.4833 loss_test: 1.4056 acc_test: 0.6920 time: 0.1038s
Epoch: 0451 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1483 acc_val: 0.4733 loss_test: 1.4440 acc_test: 0.6920 time: 0.1036s
Optimization Finished!
Total time elapsed: 42.0054s, best testing performance  0.698000, minimun loss  1.047430
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7872 acc_train: 0.1500 loss_val: 1.7886 acc_val: 0.1767 loss_test: 1.7310 acc_test: 0.4270 time: 0.0829s
Epoch: 0051 loss_train: 0.0166 acc_train: 1.0000 loss_val: 1.8448 acc_val: 0.3700 loss_test: 1.1400 acc_test: 0.6540 time: 0.1082s
Epoch: 0101 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8358 acc_val: 0.3967 loss_test: 1.1406 acc_test: 0.6700 time: 0.1029s
Epoch: 0151 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8570 acc_val: 0.4233 loss_test: 1.1771 acc_test: 0.6800 time: 0.0879s
Epoch: 0201 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8915 acc_val: 0.4467 loss_test: 1.2140 acc_test: 0.6830 time: 0.1046s
Epoch: 0251 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9401 acc_val: 0.4533 loss_test: 1.2510 acc_test: 0.6920 time: 0.0910s
Epoch: 0301 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9767 acc_val: 0.4533 loss_test: 1.2843 acc_test: 0.6940 time: 0.0977s
Epoch: 0351 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0068 acc_val: 0.4667 loss_test: 1.3176 acc_test: 0.7000 time: 0.0993s
Epoch: 0401 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0524 acc_val: 0.4700 loss_test: 1.3519 acc_test: 0.7000 time: 0.1143s
Epoch: 0451 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0998 acc_val: 0.4767 loss_test: 1.3876 acc_test: 0.7030 time: 0.0936s
Optimization Finished!
Total time elapsed: 49.3777s, best testing performance  0.706000, minimun loss  1.068648
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8136 acc_train: 0.1083 loss_val: 1.7934 acc_val: 0.1000 loss_test: 1.6927 acc_test: 0.4520 time: 0.0834s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8338 acc_val: 0.3800 loss_test: 1.1591 acc_test: 0.6700 time: 0.0648s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8825 acc_val: 0.3933 loss_test: 1.1739 acc_test: 0.6740 time: 0.0636s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9289 acc_val: 0.4067 loss_test: 1.2180 acc_test: 0.6860 time: 0.0656s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9050 acc_val: 0.4167 loss_test: 1.2365 acc_test: 0.6890 time: 0.0657s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9424 acc_val: 0.4333 loss_test: 1.2857 acc_test: 0.6950 time: 0.0660s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0388 acc_val: 0.4700 loss_test: 1.3406 acc_test: 0.6930 time: 0.0656s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0566 acc_val: 0.4967 loss_test: 1.3688 acc_test: 0.6920 time: 0.0669s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1029 acc_val: 0.4900 loss_test: 1.3988 acc_test: 0.6920 time: 0.1150s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1375 acc_val: 0.4900 loss_test: 1.4375 acc_test: 0.6920 time: 0.0968s
Optimization Finished!
Total time elapsed: 37.5333s, best testing performance  0.699000, minimun loss  1.032124
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.1583 loss_val: 1.7929 acc_val: 0.1633 loss_test: 1.6814 acc_test: 0.5000 time: 0.0935s
Epoch: 0051 loss_train: 0.0144 acc_train: 1.0000 loss_val: 1.7647 acc_val: 0.4100 loss_test: 1.1310 acc_test: 0.6650 time: 0.1823s
Epoch: 0101 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7017 acc_val: 0.4467 loss_test: 1.1131 acc_test: 0.6820 time: 0.0754s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7550 acc_val: 0.4467 loss_test: 1.1621 acc_test: 0.6880 time: 0.0838s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8262 acc_val: 0.4567 loss_test: 1.2274 acc_test: 0.6880 time: 0.0987s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9184 acc_val: 0.4700 loss_test: 1.2795 acc_test: 0.6960 time: 0.0984s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0154 acc_val: 0.5000 loss_test: 1.3248 acc_test: 0.6960 time: 0.1090s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0342 acc_val: 0.4967 loss_test: 1.3556 acc_test: 0.6950 time: 0.0969s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1027 acc_val: 0.4933 loss_test: 1.3994 acc_test: 0.6880 time: 0.0983s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1014 acc_val: 0.5000 loss_test: 1.4257 acc_test: 0.6960 time: 0.0768s
Optimization Finished!
Total time elapsed: 49.1204s, best testing performance  0.698000, minimun loss  1.018059
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7967 acc_train: 0.1417 loss_val: 1.8164 acc_val: 0.1333 loss_test: 1.6747 acc_test: 0.5040 time: 0.0644s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8296 acc_val: 0.3933 loss_test: 1.1652 acc_test: 0.6660 time: 0.1091s
Epoch: 0101 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7761 acc_val: 0.4433 loss_test: 1.1503 acc_test: 0.6850 time: 0.0645s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8354 acc_val: 0.4500 loss_test: 1.1951 acc_test: 0.6890 time: 0.0649s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8808 acc_val: 0.4300 loss_test: 1.2433 acc_test: 0.6840 time: 0.0644s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.8895 acc_val: 0.4600 loss_test: 1.2635 acc_test: 0.6940 time: 0.0654s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9937 acc_val: 0.4667 loss_test: 1.3250 acc_test: 0.6940 time: 0.0663s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0499 acc_val: 0.4933 loss_test: 1.3702 acc_test: 0.6970 time: 0.0657s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1401 acc_val: 0.5000 loss_test: 1.4145 acc_test: 0.6980 time: 0.0663s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2046 acc_val: 0.5100 loss_test: 1.4497 acc_test: 0.6990 time: 0.0662s
Optimization Finished!
Total time elapsed: 35.7018s, best testing performance  0.701000, minimun loss  1.034599
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7824 acc_train: 0.2750 loss_val: 1.7923 acc_val: 0.1600 loss_test: 1.6662 acc_test: 0.5170 time: 0.0756s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8691 acc_val: 0.3933 loss_test: 1.1800 acc_test: 0.6670 time: 0.0793s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8265 acc_val: 0.4167 loss_test: 1.1669 acc_test: 0.6860 time: 0.0736s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8647 acc_val: 0.4400 loss_test: 1.2045 acc_test: 0.6890 time: 0.1203s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9053 acc_val: 0.4467 loss_test: 1.2476 acc_test: 0.6950 time: 0.0838s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0075 acc_val: 0.4533 loss_test: 1.3107 acc_test: 0.6940 time: 0.1019s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0688 acc_val: 0.4867 loss_test: 1.3556 acc_test: 0.6920 time: 0.0787s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1411 acc_val: 0.4900 loss_test: 1.4035 acc_test: 0.6910 time: 0.1304s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1632 acc_val: 0.4967 loss_test: 1.4329 acc_test: 0.6980 time: 0.0853s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1965 acc_val: 0.5067 loss_test: 1.4627 acc_test: 0.6990 time: 0.0990s
Optimization Finished!
Total time elapsed: 49.1703s, best testing performance  0.706000, minimun loss  1.030996
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7836 acc_train: 0.2000 loss_val: 1.7833 acc_val: 0.2033 loss_test: 1.6961 acc_test: 0.5080 time: 0.0888s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.7858 acc_val: 0.3933 loss_test: 1.1395 acc_test: 0.6650 time: 0.0838s
Epoch: 0101 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7529 acc_val: 0.4200 loss_test: 1.1381 acc_test: 0.6830 time: 0.1033s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8513 acc_val: 0.4300 loss_test: 1.2009 acc_test: 0.6790 time: 0.0810s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8355 acc_val: 0.4567 loss_test: 1.2399 acc_test: 0.6840 time: 0.0987s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9141 acc_val: 0.4700 loss_test: 1.2898 acc_test: 0.6900 time: 0.0643s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0339 acc_val: 0.4900 loss_test: 1.3393 acc_test: 0.6950 time: 0.0642s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0795 acc_val: 0.4967 loss_test: 1.3806 acc_test: 0.6950 time: 0.0641s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1263 acc_val: 0.5067 loss_test: 1.4205 acc_test: 0.6940 time: 0.0641s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2111 acc_val: 0.5033 loss_test: 1.4667 acc_test: 0.6950 time: 0.0657s
Optimization Finished!
Total time elapsed: 40.1588s, best testing performance  0.698000, minimun loss  1.016317
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8033 acc_train: 0.1750 loss_val: 1.7884 acc_val: 0.1567 loss_test: 1.6873 acc_test: 0.5020 time: 0.1138s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8461 acc_val: 0.3733 loss_test: 1.1910 acc_test: 0.6570 time: 0.1397s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7868 acc_val: 0.4100 loss_test: 1.1762 acc_test: 0.6850 time: 0.0773s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8703 acc_val: 0.4267 loss_test: 1.2244 acc_test: 0.6830 time: 0.0902s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9372 acc_val: 0.4567 loss_test: 1.2705 acc_test: 0.6840 time: 0.1086s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0370 acc_val: 0.4500 loss_test: 1.3194 acc_test: 0.6890 time: 0.0899s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0636 acc_val: 0.4767 loss_test: 1.3591 acc_test: 0.6900 time: 0.1076s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0860 acc_val: 0.4933 loss_test: 1.3859 acc_test: 0.6900 time: 0.1079s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0980 acc_val: 0.4967 loss_test: 1.4116 acc_test: 0.6950 time: 0.1192s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1788 acc_val: 0.4867 loss_test: 1.4494 acc_test: 0.6930 time: 0.0925s
Optimization Finished!
Total time elapsed: 48.6097s, best testing performance  0.699000, minimun loss  1.061452
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7943 acc_train: 0.1667 loss_val: 1.7985 acc_val: 0.2133 loss_test: 1.6900 acc_test: 0.5120 time: 0.1097s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8230 acc_val: 0.3933 loss_test: 1.1560 acc_test: 0.6610 time: 0.0883s
Epoch: 0101 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8350 acc_val: 0.4200 loss_test: 1.1607 acc_test: 0.6800 time: 0.1216s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8683 acc_val: 0.4367 loss_test: 1.1899 acc_test: 0.6760 time: 0.1287s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9018 acc_val: 0.4467 loss_test: 1.2271 acc_test: 0.6850 time: 0.1035s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9790 acc_val: 0.4500 loss_test: 1.2819 acc_test: 0.6950 time: 0.1151s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0691 acc_val: 0.4667 loss_test: 1.3388 acc_test: 0.6970 time: 0.1215s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1157 acc_val: 0.4867 loss_test: 1.3784 acc_test: 0.6940 time: 0.0814s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1207 acc_val: 0.5033 loss_test: 1.4004 acc_test: 0.6970 time: 0.0647s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1678 acc_val: 0.5000 loss_test: 1.4425 acc_test: 0.7020 time: 0.0645s
Optimization Finished!
Total time elapsed: 45.3431s, best testing performance  0.711000, minimun loss  1.034705
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7938 acc_train: 0.1500 loss_val: 1.8217 acc_val: 0.0500 loss_test: 1.6909 acc_test: 0.3380 time: 0.0985s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.7765 acc_val: 0.3867 loss_test: 1.1369 acc_test: 0.6580 time: 0.0671s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7157 acc_val: 0.4400 loss_test: 1.1187 acc_test: 0.6830 time: 0.0845s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.7505 acc_val: 0.4300 loss_test: 1.1641 acc_test: 0.6800 time: 0.1286s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.7678 acc_val: 0.4567 loss_test: 1.1989 acc_test: 0.6940 time: 0.0999s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9160 acc_val: 0.4533 loss_test: 1.2782 acc_test: 0.6960 time: 0.1100s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0296 acc_val: 0.4767 loss_test: 1.3351 acc_test: 0.6980 time: 0.0752s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0924 acc_val: 0.4900 loss_test: 1.3840 acc_test: 0.7000 time: 0.1331s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1152 acc_val: 0.5000 loss_test: 1.4108 acc_test: 0.7040 time: 0.1240s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1354 acc_val: 0.5133 loss_test: 1.4447 acc_test: 0.7040 time: 0.0950s
Optimization Finished!
Total time elapsed: 46.5343s, best testing performance  0.708000, minimun loss  1.023940
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8024 acc_train: 0.1250 loss_val: 1.7908 acc_val: 0.0700 loss_test: 1.6945 acc_test: 0.3640 time: 0.1020s
Epoch: 0051 loss_train: 0.0134 acc_train: 1.0000 loss_val: 1.8389 acc_val: 0.3733 loss_test: 1.1672 acc_test: 0.6580 time: 0.1220s
Epoch: 0101 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8008 acc_val: 0.4233 loss_test: 1.1579 acc_test: 0.6770 time: 0.0916s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8754 acc_val: 0.4133 loss_test: 1.2064 acc_test: 0.6760 time: 0.1070s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8877 acc_val: 0.4267 loss_test: 1.2460 acc_test: 0.6740 time: 0.0881s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9076 acc_val: 0.4533 loss_test: 1.2832 acc_test: 0.6930 time: 0.1328s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0240 acc_val: 0.4867 loss_test: 1.3437 acc_test: 0.6950 time: 0.1055s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0530 acc_val: 0.4933 loss_test: 1.3782 acc_test: 0.6970 time: 0.1085s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0986 acc_val: 0.5033 loss_test: 1.4213 acc_test: 0.6940 time: 0.1039s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1413 acc_val: 0.4967 loss_test: 1.4575 acc_test: 0.6940 time: 0.1013s
Optimization Finished!
Total time elapsed: 49.4432s, best testing performance  0.700000, minimun loss  1.035723
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1917 loss_val: 1.8090 acc_val: 0.1233 loss_test: 1.6822 acc_test: 0.4730 time: 0.1089s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.9141 acc_val: 0.3567 loss_test: 1.1921 acc_test: 0.6450 time: 0.0655s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8479 acc_val: 0.3767 loss_test: 1.1745 acc_test: 0.6740 time: 0.0675s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8720 acc_val: 0.4067 loss_test: 1.2083 acc_test: 0.6780 time: 0.0657s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9193 acc_val: 0.4300 loss_test: 1.2516 acc_test: 0.6860 time: 0.0695s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9858 acc_val: 0.4733 loss_test: 1.3078 acc_test: 0.6920 time: 0.0920s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0156 acc_val: 0.4900 loss_test: 1.3379 acc_test: 0.6940 time: 0.0786s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0773 acc_val: 0.4933 loss_test: 1.3824 acc_test: 0.6940 time: 0.1054s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1182 acc_val: 0.5133 loss_test: 1.4178 acc_test: 0.6940 time: 0.1383s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1514 acc_val: 0.4933 loss_test: 1.4499 acc_test: 0.6930 time: 0.0982s
Optimization Finished!
Total time elapsed: 43.0166s, best testing performance  0.697000, minimun loss  1.032396
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8017 acc_train: 0.1500 loss_val: 1.7950 acc_val: 0.1933 loss_test: 1.6936 acc_test: 0.4210 time: 0.1127s
Epoch: 0051 loss_train: 0.0139 acc_train: 1.0000 loss_val: 1.8072 acc_val: 0.3867 loss_test: 1.1705 acc_test: 0.6690 time: 0.0872s
Epoch: 0101 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7414 acc_val: 0.4100 loss_test: 1.1525 acc_test: 0.6810 time: 0.0949s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.7708 acc_val: 0.4400 loss_test: 1.1833 acc_test: 0.6860 time: 0.0888s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8227 acc_val: 0.4567 loss_test: 1.2357 acc_test: 0.6850 time: 0.0869s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9297 acc_val: 0.4633 loss_test: 1.2975 acc_test: 0.6890 time: 0.0863s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9858 acc_val: 0.4933 loss_test: 1.3386 acc_test: 0.6900 time: 0.0835s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0312 acc_val: 0.4967 loss_test: 1.3798 acc_test: 0.6940 time: 0.1121s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0550 acc_val: 0.5067 loss_test: 1.4166 acc_test: 0.6940 time: 0.1438s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1174 acc_val: 0.5067 loss_test: 1.4554 acc_test: 0.6950 time: 0.1075s
Optimization Finished!
Total time elapsed: 48.8846s, best testing performance  0.702000, minimun loss  1.069220
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8134 acc_train: 0.1167 loss_val: 1.8313 acc_val: 0.0900 loss_test: 1.7065 acc_test: 0.4490 time: 0.1144s
Epoch: 0051 loss_train: 0.0141 acc_train: 1.0000 loss_val: 1.8045 acc_val: 0.3733 loss_test: 1.1588 acc_test: 0.6530 time: 0.0641s
Epoch: 0101 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7942 acc_val: 0.3900 loss_test: 1.1671 acc_test: 0.6710 time: 0.0684s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8301 acc_val: 0.4200 loss_test: 1.2013 acc_test: 0.6740 time: 0.0653s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9088 acc_val: 0.4467 loss_test: 1.2557 acc_test: 0.6860 time: 0.0655s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9479 acc_val: 0.4600 loss_test: 1.2929 acc_test: 0.6900 time: 0.0653s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9924 acc_val: 0.4800 loss_test: 1.3299 acc_test: 0.6950 time: 0.0671s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0338 acc_val: 0.4833 loss_test: 1.3682 acc_test: 0.6960 time: 0.0990s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0882 acc_val: 0.5000 loss_test: 1.4102 acc_test: 0.6980 time: 0.0833s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1140 acc_val: 0.5033 loss_test: 1.4451 acc_test: 0.7020 time: 0.1020s
Optimization Finished!
Total time elapsed: 38.4205s, best testing performance  0.704000, minimun loss  1.051677
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7742 acc_train: 0.2667 loss_val: 1.7810 acc_val: 0.2133 loss_test: 1.6963 acc_test: 0.5190 time: 0.0976s
Epoch: 0051 loss_train: 0.0141 acc_train: 1.0000 loss_val: 1.9133 acc_val: 0.3467 loss_test: 1.1955 acc_test: 0.6370 time: 0.0954s
Epoch: 0101 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7959 acc_val: 0.3833 loss_test: 1.1665 acc_test: 0.6670 time: 0.1176s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7780 acc_val: 0.4200 loss_test: 1.1808 acc_test: 0.6890 time: 0.1054s
Epoch: 0201 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8726 acc_val: 0.4400 loss_test: 1.2404 acc_test: 0.6850 time: 0.0914s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9221 acc_val: 0.4767 loss_test: 1.2848 acc_test: 0.6890 time: 0.1043s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0067 acc_val: 0.4800 loss_test: 1.3337 acc_test: 0.6950 time: 0.0777s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0425 acc_val: 0.5100 loss_test: 1.3687 acc_test: 0.6940 time: 0.0861s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1145 acc_val: 0.5067 loss_test: 1.4155 acc_test: 0.6920 time: 0.0924s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.5033 loss_test: 1.4556 acc_test: 0.6910 time: 0.0985s
Optimization Finished!
Total time elapsed: 48.8914s, best testing performance  0.700000, minimun loss  1.045622
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7893 acc_train: 0.2000 loss_val: 1.7979 acc_val: 0.1433 loss_test: 1.6925 acc_test: 0.4750 time: 0.1415s
Epoch: 0051 loss_train: 0.0140 acc_train: 1.0000 loss_val: 1.7757 acc_val: 0.3667 loss_test: 1.1492 acc_test: 0.6500 time: 0.0887s
Epoch: 0101 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7459 acc_val: 0.4333 loss_test: 1.1437 acc_test: 0.6700 time: 0.0646s
Epoch: 0151 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.7476 acc_val: 0.4567 loss_test: 1.1663 acc_test: 0.6780 time: 0.0641s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8226 acc_val: 0.4633 loss_test: 1.2214 acc_test: 0.6910 time: 0.0658s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.8576 acc_val: 0.4767 loss_test: 1.2667 acc_test: 0.6930 time: 0.0652s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9640 acc_val: 0.4933 loss_test: 1.3223 acc_test: 0.6960 time: 0.0672s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0117 acc_val: 0.5033 loss_test: 1.3602 acc_test: 0.6930 time: 0.0663s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0726 acc_val: 0.5100 loss_test: 1.4030 acc_test: 0.6940 time: 0.0652s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0903 acc_val: 0.5167 loss_test: 1.4341 acc_test: 0.6940 time: 0.0667s
Optimization Finished!
Total time elapsed: 35.1873s, best testing performance  0.699000, minimun loss  1.043533
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 2, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7970 acc_train: 0.1917 loss_val: 1.7901 acc_val: 0.0567 loss_test: 1.6860 acc_test: 0.4000 time: 0.1227s
Epoch: 0051 loss_train: 0.0137 acc_train: 1.0000 loss_val: 1.7511 acc_val: 0.3833 loss_test: 1.1322 acc_test: 0.6570 time: 0.1223s
Epoch: 0101 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.6561 acc_val: 0.4033 loss_test: 1.1080 acc_test: 0.6730 time: 0.1139s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.6572 acc_val: 0.4233 loss_test: 1.1352 acc_test: 0.6850 time: 0.0967s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.7651 acc_val: 0.4300 loss_test: 1.1972 acc_test: 0.6820 time: 0.0800s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.8721 acc_val: 0.4467 loss_test: 1.2633 acc_test: 0.6830 time: 0.0836s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9805 acc_val: 0.4633 loss_test: 1.3250 acc_test: 0.6880 time: 0.1103s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0449 acc_val: 0.4900 loss_test: 1.3669 acc_test: 0.6930 time: 0.1099s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1079 acc_val: 0.5033 loss_test: 1.4095 acc_test: 0.6950 time: 0.0840s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.5000 loss_test: 1.4504 acc_test: 0.6870 time: 0.1096s
Optimization Finished!
Total time elapsed: 49.4585s, best testing performance  0.699000, minimun loss  1.013023
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7698 acc_train: 0.2833 loss_val: 1.7886 acc_val: 0.2067 loss_test: 1.6583 acc_test: 0.5190 time: 0.0933s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8189 acc_val: 0.3667 loss_test: 1.1378 acc_test: 0.6650 time: 0.1034s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7472 acc_val: 0.4233 loss_test: 1.1176 acc_test: 0.6760 time: 0.1079s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8192 acc_val: 0.4467 loss_test: 1.1417 acc_test: 0.6870 time: 0.1175s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8527 acc_val: 0.4500 loss_test: 1.1855 acc_test: 0.6880 time: 0.0888s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9660 acc_val: 0.4767 loss_test: 1.2735 acc_test: 0.6940 time: 0.0697s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0415 acc_val: 0.5000 loss_test: 1.3393 acc_test: 0.6960 time: 0.0702s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1637 acc_val: 0.5000 loss_test: 1.3898 acc_test: 0.6940 time: 0.0705s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1715 acc_val: 0.5033 loss_test: 1.4187 acc_test: 0.6980 time: 0.0694s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2379 acc_val: 0.5100 loss_test: 1.4578 acc_test: 0.6980 time: 0.0733s
Optimization Finished!
Total time elapsed: 41.6878s, best testing performance  0.703000, minimun loss  1.017046
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7846 acc_train: 0.2167 loss_val: 1.7715 acc_val: 0.2500 loss_test: 1.6652 acc_test: 0.5490 time: 0.1251s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7965 acc_val: 0.3733 loss_test: 1.1446 acc_test: 0.6670 time: 0.1147s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7372 acc_val: 0.4033 loss_test: 1.1247 acc_test: 0.6850 time: 0.0981s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8405 acc_val: 0.4067 loss_test: 1.1693 acc_test: 0.6850 time: 0.0761s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9012 acc_val: 0.4300 loss_test: 1.2244 acc_test: 0.6840 time: 0.1014s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9855 acc_val: 0.4567 loss_test: 1.2979 acc_test: 0.6840 time: 0.1171s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0076 acc_val: 0.5000 loss_test: 1.3370 acc_test: 0.6930 time: 0.1179s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0769 acc_val: 0.5033 loss_test: 1.3850 acc_test: 0.6970 time: 0.1031s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1404 acc_val: 0.4933 loss_test: 1.4229 acc_test: 0.6970 time: 0.1079s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1753 acc_val: 0.5033 loss_test: 1.4453 acc_test: 0.6990 time: 0.0849s
Optimization Finished!
Total time elapsed: 49.9251s, best testing performance  0.706000, minimun loss  1.018821
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7908 acc_train: 0.2000 loss_val: 1.7916 acc_val: 0.1800 loss_test: 1.6534 acc_test: 0.5410 time: 0.1267s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.6914 acc_val: 0.3867 loss_test: 1.1158 acc_test: 0.6680 time: 0.0911s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6692 acc_val: 0.4233 loss_test: 1.1106 acc_test: 0.6840 time: 0.1074s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7697 acc_val: 0.4367 loss_test: 1.1519 acc_test: 0.6860 time: 0.0907s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8308 acc_val: 0.4467 loss_test: 1.1956 acc_test: 0.6880 time: 0.0817s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9537 acc_val: 0.4667 loss_test: 1.2807 acc_test: 0.6910 time: 0.0936s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0363 acc_val: 0.4933 loss_test: 1.3474 acc_test: 0.6960 time: 0.0883s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1194 acc_val: 0.4933 loss_test: 1.4019 acc_test: 0.6960 time: 0.1056s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1515 acc_val: 0.4933 loss_test: 1.4414 acc_test: 0.6970 time: 0.0695s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1923 acc_val: 0.4900 loss_test: 1.4764 acc_test: 0.6990 time: 0.0702s
Optimization Finished!
Total time elapsed: 45.2497s, best testing performance  0.703000, minimun loss  1.015812
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7879 acc_train: 0.2000 loss_val: 1.8053 acc_val: 0.1467 loss_test: 1.6853 acc_test: 0.5230 time: 0.1077s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.8379 acc_val: 0.3667 loss_test: 1.1683 acc_test: 0.6650 time: 0.0810s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7528 acc_val: 0.4033 loss_test: 1.1425 acc_test: 0.6820 time: 0.0985s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8451 acc_val: 0.4133 loss_test: 1.1710 acc_test: 0.6760 time: 0.0913s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8901 acc_val: 0.4400 loss_test: 1.2131 acc_test: 0.6840 time: 0.1091s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0165 acc_val: 0.4700 loss_test: 1.3038 acc_test: 0.6900 time: 0.1112s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1104 acc_val: 0.4767 loss_test: 1.3603 acc_test: 0.6910 time: 0.1057s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1441 acc_val: 0.4900 loss_test: 1.3945 acc_test: 0.6970 time: 0.0833s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2208 acc_val: 0.5000 loss_test: 1.4379 acc_test: 0.7010 time: 0.1290s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2530 acc_val: 0.5000 loss_test: 1.4644 acc_test: 0.7010 time: 0.0865s
Optimization Finished!
Total time elapsed: 49.7156s, best testing performance  0.707000, minimun loss  1.036054
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7778 acc_train: 0.1667 loss_val: 1.7997 acc_val: 0.1833 loss_test: 1.6716 acc_test: 0.5100 time: 0.0877s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.8578 acc_val: 0.3567 loss_test: 1.1547 acc_test: 0.6570 time: 0.0844s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7365 acc_val: 0.4367 loss_test: 1.1294 acc_test: 0.6720 time: 0.1126s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7835 acc_val: 0.4533 loss_test: 1.1721 acc_test: 0.6880 time: 0.1114s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8448 acc_val: 0.4667 loss_test: 1.2154 acc_test: 0.6870 time: 0.0802s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9638 acc_val: 0.4800 loss_test: 1.2825 acc_test: 0.6900 time: 0.1027s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0656 acc_val: 0.4967 loss_test: 1.3490 acc_test: 0.6930 time: 0.1148s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1036 acc_val: 0.4967 loss_test: 1.3880 acc_test: 0.6970 time: 0.1036s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1233 acc_val: 0.5133 loss_test: 1.4320 acc_test: 0.6940 time: 0.0875s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1720 acc_val: 0.5100 loss_test: 1.4572 acc_test: 0.6970 time: 0.0996s
Optimization Finished!
Total time elapsed: 48.5617s, best testing performance  0.701000, minimun loss  1.023919
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7971 acc_train: 0.1750 loss_val: 1.8024 acc_val: 0.1733 loss_test: 1.6955 acc_test: 0.4930 time: 0.1110s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7602 acc_val: 0.4033 loss_test: 1.1478 acc_test: 0.6600 time: 0.0706s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6928 acc_val: 0.4233 loss_test: 1.1347 acc_test: 0.6840 time: 0.0726s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.7490 acc_val: 0.4567 loss_test: 1.1823 acc_test: 0.6870 time: 0.0937s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8555 acc_val: 0.4567 loss_test: 1.2548 acc_test: 0.6880 time: 0.0991s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.8945 acc_val: 0.4900 loss_test: 1.2891 acc_test: 0.6970 time: 0.1139s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9667 acc_val: 0.5000 loss_test: 1.3328 acc_test: 0.6980 time: 0.0945s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0336 acc_val: 0.5000 loss_test: 1.3754 acc_test: 0.7010 time: 0.1242s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0972 acc_val: 0.5000 loss_test: 1.4154 acc_test: 0.7010 time: 0.0922s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1621 acc_val: 0.5000 loss_test: 1.4578 acc_test: 0.7010 time: 0.0971s
Optimization Finished!
Total time elapsed: 46.7211s, best testing performance  0.705000, minimun loss  1.015392
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7847 acc_train: 0.2000 loss_val: 1.8142 acc_val: 0.1367 loss_test: 1.6870 acc_test: 0.4900 time: 0.0894s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7461 acc_val: 0.4200 loss_test: 1.1474 acc_test: 0.6670 time: 0.0860s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7313 acc_val: 0.4500 loss_test: 1.1547 acc_test: 0.6820 time: 0.0812s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8271 acc_val: 0.4633 loss_test: 1.2179 acc_test: 0.6840 time: 0.0755s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9229 acc_val: 0.4700 loss_test: 1.2857 acc_test: 0.6820 time: 0.0839s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9405 acc_val: 0.4933 loss_test: 1.3175 acc_test: 0.6940 time: 0.0858s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9796 acc_val: 0.5033 loss_test: 1.3512 acc_test: 0.7000 time: 0.1107s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0521 acc_val: 0.5200 loss_test: 1.3913 acc_test: 0.7020 time: 0.0876s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0647 acc_val: 0.5267 loss_test: 1.4126 acc_test: 0.7000 time: 0.1221s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1333 acc_val: 0.5167 loss_test: 1.4545 acc_test: 0.7020 time: 0.0882s
Optimization Finished!
Total time elapsed: 49.4019s, best testing performance  0.705000, minimun loss  1.033174
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8051 acc_train: 0.1250 loss_val: 1.8043 acc_val: 0.1733 loss_test: 1.6973 acc_test: 0.4680 time: 0.0896s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8547 acc_val: 0.3800 loss_test: 1.1817 acc_test: 0.6560 time: 0.0736s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8233 acc_val: 0.4133 loss_test: 1.1784 acc_test: 0.6690 time: 0.0740s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8140 acc_val: 0.4300 loss_test: 1.2018 acc_test: 0.6780 time: 0.0722s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8928 acc_val: 0.4733 loss_test: 1.2651 acc_test: 0.6820 time: 0.0733s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9737 acc_val: 0.4933 loss_test: 1.3084 acc_test: 0.6920 time: 0.1089s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0137 acc_val: 0.5000 loss_test: 1.3442 acc_test: 0.6890 time: 0.0928s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0338 acc_val: 0.5133 loss_test: 1.3792 acc_test: 0.6980 time: 0.0833s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1142 acc_val: 0.5133 loss_test: 1.4231 acc_test: 0.6970 time: 0.1044s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1361 acc_val: 0.5067 loss_test: 1.4473 acc_test: 0.6990 time: 0.0945s
Optimization Finished!
Total time elapsed: 44.1513s, best testing performance  0.700000, minimun loss  1.043076
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7977 acc_train: 0.1833 loss_val: 1.8150 acc_val: 0.2067 loss_test: 1.6749 acc_test: 0.5450 time: 0.1017s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.9069 acc_val: 0.3500 loss_test: 1.1849 acc_test: 0.6570 time: 0.1316s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8725 acc_val: 0.4033 loss_test: 1.1866 acc_test: 0.6780 time: 0.1114s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8964 acc_val: 0.4267 loss_test: 1.2304 acc_test: 0.6770 time: 0.0806s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9567 acc_val: 0.4633 loss_test: 1.2814 acc_test: 0.6870 time: 0.1011s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0437 acc_val: 0.4767 loss_test: 1.3347 acc_test: 0.6910 time: 0.1137s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1104 acc_val: 0.4733 loss_test: 1.3787 acc_test: 0.6930 time: 0.1519s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1529 acc_val: 0.4900 loss_test: 1.4218 acc_test: 0.6970 time: 0.1382s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1826 acc_val: 0.5000 loss_test: 1.4557 acc_test: 0.6970 time: 0.0901s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2621 acc_val: 0.5067 loss_test: 1.4949 acc_test: 0.6990 time: 0.0827s
Optimization Finished!
Total time elapsed: 49.9636s, best testing performance  0.702000, minimun loss  1.022647
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7770 acc_train: 0.2333 loss_val: 1.8064 acc_val: 0.1533 loss_test: 1.6756 acc_test: 0.5410 time: 0.0899s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.7999 acc_val: 0.3733 loss_test: 1.1592 acc_test: 0.6590 time: 0.0699s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7808 acc_val: 0.4233 loss_test: 1.1676 acc_test: 0.6770 time: 0.0712s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8380 acc_val: 0.4300 loss_test: 1.2064 acc_test: 0.6770 time: 0.0715s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9379 acc_val: 0.4733 loss_test: 1.2712 acc_test: 0.6800 time: 0.0718s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0207 acc_val: 0.4767 loss_test: 1.3220 acc_test: 0.6910 time: 0.0722s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0867 acc_val: 0.4867 loss_test: 1.3649 acc_test: 0.6970 time: 0.0730s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1123 acc_val: 0.4933 loss_test: 1.4052 acc_test: 0.6980 time: 0.1165s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1313 acc_val: 0.5033 loss_test: 1.4291 acc_test: 0.7010 time: 0.0697s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.5067 loss_test: 1.4706 acc_test: 0.7010 time: 0.0928s
Optimization Finished!
Total time elapsed: 41.2637s, best testing performance  0.705000, minimun loss  1.023974
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7750 acc_train: 0.2667 loss_val: 1.8271 acc_val: 0.1033 loss_test: 1.6720 acc_test: 0.4330 time: 0.0971s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7574 acc_val: 0.3733 loss_test: 1.1441 acc_test: 0.6580 time: 0.1072s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6806 acc_val: 0.4333 loss_test: 1.1231 acc_test: 0.6850 time: 0.0933s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.7706 acc_val: 0.4367 loss_test: 1.1871 acc_test: 0.6830 time: 0.1086s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9337 acc_val: 0.4400 loss_test: 1.2719 acc_test: 0.6830 time: 0.0892s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0190 acc_val: 0.4700 loss_test: 1.3236 acc_test: 0.6930 time: 0.0865s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0819 acc_val: 0.4867 loss_test: 1.3660 acc_test: 0.6950 time: 0.0933s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1518 acc_val: 0.4967 loss_test: 1.4072 acc_test: 0.6960 time: 0.0922s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1866 acc_val: 0.5067 loss_test: 1.4387 acc_test: 0.6960 time: 0.1014s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2204 acc_val: 0.5100 loss_test: 1.4728 acc_test: 0.6990 time: 0.0792s
Optimization Finished!
Total time elapsed: 49.9733s, best testing performance  0.702000, minimun loss  1.003219
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7704 acc_train: 0.2500 loss_val: 1.7934 acc_val: 0.1733 loss_test: 1.6654 acc_test: 0.5380 time: 0.0993s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8477 acc_val: 0.4033 loss_test: 1.1651 acc_test: 0.6670 time: 0.0698s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7827 acc_val: 0.4300 loss_test: 1.1482 acc_test: 0.6810 time: 0.0699s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.7837 acc_val: 0.4533 loss_test: 1.1782 acc_test: 0.6820 time: 0.0696s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8684 acc_val: 0.4600 loss_test: 1.2411 acc_test: 0.6920 time: 0.0710s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9645 acc_val: 0.4867 loss_test: 1.3094 acc_test: 0.6940 time: 0.0714s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0252 acc_val: 0.5000 loss_test: 1.3524 acc_test: 0.6950 time: 0.0754s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0280 acc_val: 0.5100 loss_test: 1.3814 acc_test: 0.6970 time: 0.0719s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0878 acc_val: 0.5100 loss_test: 1.4289 acc_test: 0.6950 time: 0.1208s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1638 acc_val: 0.5067 loss_test: 1.4639 acc_test: 0.6980 time: 0.0875s
Optimization Finished!
Total time elapsed: 38.5140s, best testing performance  0.700000, minimun loss  1.009185
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8043 acc_train: 0.1833 loss_val: 1.8015 acc_val: 0.1400 loss_test: 1.6726 acc_test: 0.4910 time: 0.1247s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8815 acc_val: 0.3700 loss_test: 1.1942 acc_test: 0.6470 time: 0.1093s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8964 acc_val: 0.3867 loss_test: 1.2131 acc_test: 0.6660 time: 0.1078s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 2.0050 acc_val: 0.4067 loss_test: 1.2730 acc_test: 0.6680 time: 0.0869s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0524 acc_val: 0.4333 loss_test: 1.3113 acc_test: 0.6790 time: 0.0864s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0996 acc_val: 0.4367 loss_test: 1.3533 acc_test: 0.6880 time: 0.0890s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1390 acc_val: 0.4733 loss_test: 1.3874 acc_test: 0.6940 time: 0.1406s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1260 acc_val: 0.4967 loss_test: 1.4029 acc_test: 0.7010 time: 0.0964s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1769 acc_val: 0.4933 loss_test: 1.4427 acc_test: 0.7000 time: 0.0933s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2128 acc_val: 0.5033 loss_test: 1.4638 acc_test: 0.7020 time: 0.0968s
Optimization Finished!
Total time elapsed: 49.6114s, best testing performance  0.704000, minimun loss  1.036025
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7877 acc_train: 0.1667 loss_val: 1.7973 acc_val: 0.1300 loss_test: 1.6521 acc_test: 0.4400 time: 0.1546s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8494 acc_val: 0.3867 loss_test: 1.1800 acc_test: 0.6620 time: 0.1277s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8485 acc_val: 0.4000 loss_test: 1.1875 acc_test: 0.6690 time: 0.1121s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8931 acc_val: 0.4167 loss_test: 1.2222 acc_test: 0.6760 time: 0.0697s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8056 acc_val: 0.4433 loss_test: 1.2276 acc_test: 0.6860 time: 0.0704s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.8208 acc_val: 0.4533 loss_test: 1.2662 acc_test: 0.6940 time: 0.0690s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9571 acc_val: 0.4867 loss_test: 1.3402 acc_test: 0.6970 time: 0.0713s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0444 acc_val: 0.4933 loss_test: 1.3876 acc_test: 0.6990 time: 0.0713s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0844 acc_val: 0.5000 loss_test: 1.4164 acc_test: 0.7000 time: 0.0717s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1623 acc_val: 0.5133 loss_test: 1.4561 acc_test: 0.6910 time: 0.0713s
Optimization Finished!
Total time elapsed: 38.8463s, best testing performance  0.702000, minimun loss  1.022887
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7898 acc_train: 0.1417 loss_val: 1.8021 acc_val: 0.2100 loss_test: 1.6632 acc_test: 0.5130 time: 0.1261s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.8423 acc_val: 0.4067 loss_test: 1.1944 acc_test: 0.6580 time: 0.0925s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7214 acc_val: 0.4500 loss_test: 1.1613 acc_test: 0.6820 time: 0.0894s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7778 acc_val: 0.4567 loss_test: 1.2035 acc_test: 0.6850 time: 0.1147s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8094 acc_val: 0.4700 loss_test: 1.2533 acc_test: 0.6920 time: 0.0883s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0063 acc_val: 0.4700 loss_test: 1.3286 acc_test: 0.6940 time: 0.0957s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1056 acc_val: 0.4833 loss_test: 1.3758 acc_test: 0.6940 time: 0.0905s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1443 acc_val: 0.4833 loss_test: 1.4122 acc_test: 0.6970 time: 0.0942s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1595 acc_val: 0.5033 loss_test: 1.4397 acc_test: 0.7030 time: 0.1031s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1834 acc_val: 0.5033 loss_test: 1.4659 acc_test: 0.7000 time: 0.1148s
Optimization Finished!
Total time elapsed: 49.9204s, best testing performance  0.707000, minimun loss  1.039267
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7781 acc_train: 0.2583 loss_val: 1.7773 acc_val: 0.2433 loss_test: 1.6888 acc_test: 0.5140 time: 0.1033s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8353 acc_val: 0.3933 loss_test: 1.1900 acc_test: 0.6480 time: 0.1000s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8295 acc_val: 0.4300 loss_test: 1.1938 acc_test: 0.6830 time: 0.0904s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8528 acc_val: 0.4367 loss_test: 1.2390 acc_test: 0.6860 time: 0.0936s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9915 acc_val: 0.4633 loss_test: 1.3149 acc_test: 0.6870 time: 0.1311s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0651 acc_val: 0.4867 loss_test: 1.3558 acc_test: 0.6890 time: 0.0696s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0979 acc_val: 0.4967 loss_test: 1.3793 acc_test: 0.6960 time: 0.0703s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1335 acc_val: 0.5000 loss_test: 1.4118 acc_test: 0.7010 time: 0.0702s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1610 acc_val: 0.5033 loss_test: 1.4377 acc_test: 0.6960 time: 0.0742s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2340 acc_val: 0.5100 loss_test: 1.4767 acc_test: 0.6980 time: 0.0746s
Optimization Finished!
Total time elapsed: 41.6154s, best testing performance  0.703000, minimun loss  1.015737
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7892 acc_train: 0.1333 loss_val: 1.8084 acc_val: 0.1500 loss_test: 1.7034 acc_test: 0.4640 time: 0.0862s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.9146 acc_val: 0.3467 loss_test: 1.2187 acc_test: 0.6410 time: 0.0816s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.9011 acc_val: 0.3900 loss_test: 1.2163 acc_test: 0.6670 time: 0.0916s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8692 acc_val: 0.4233 loss_test: 1.2464 acc_test: 0.6770 time: 0.1045s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8723 acc_val: 0.4500 loss_test: 1.2804 acc_test: 0.6870 time: 0.1146s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.8926 acc_val: 0.4867 loss_test: 1.3098 acc_test: 0.6920 time: 0.0942s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9661 acc_val: 0.4833 loss_test: 1.3663 acc_test: 0.6960 time: 0.0849s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1195 acc_val: 0.4867 loss_test: 1.4075 acc_test: 0.6960 time: 0.1020s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1481 acc_val: 0.5000 loss_test: 1.4286 acc_test: 0.6960 time: 0.0827s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1722 acc_val: 0.5133 loss_test: 1.4558 acc_test: 0.6920 time: 0.1022s
Optimization Finished!
Total time elapsed: 49.7562s, best testing performance  0.702000, minimun loss  1.028215
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8132 acc_train: 0.1167 loss_val: 1.8071 acc_val: 0.1700 loss_test: 1.6930 acc_test: 0.4800 time: 0.1148s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9084 acc_val: 0.3867 loss_test: 1.2068 acc_test: 0.6460 time: 0.1343s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8713 acc_val: 0.3967 loss_test: 1.2012 acc_test: 0.6730 time: 0.0931s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8516 acc_val: 0.4333 loss_test: 1.2229 acc_test: 0.6810 time: 0.0996s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8845 acc_val: 0.4500 loss_test: 1.2694 acc_test: 0.6870 time: 0.1064s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0362 acc_val: 0.4767 loss_test: 1.3431 acc_test: 0.6890 time: 0.0904s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0833 acc_val: 0.4900 loss_test: 1.3742 acc_test: 0.6950 time: 0.0970s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1417 acc_val: 0.4967 loss_test: 1.4080 acc_test: 0.6960 time: 0.0697s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1913 acc_val: 0.5033 loss_test: 1.4476 acc_test: 0.6930 time: 0.0698s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1949 acc_val: 0.5067 loss_test: 1.4672 acc_test: 0.6930 time: 0.0695s
Optimization Finished!
Total time elapsed: 44.6992s, best testing performance  0.707000, minimun loss  0.989222
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7871 acc_train: 0.1250 loss_val: 1.7835 acc_val: 0.2133 loss_test: 1.7080 acc_test: 0.4200 time: 0.1186s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8315 acc_val: 0.4100 loss_test: 1.1549 acc_test: 0.6730 time: 0.1029s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7926 acc_val: 0.4167 loss_test: 1.1654 acc_test: 0.6800 time: 0.1043s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.7951 acc_val: 0.4400 loss_test: 1.2058 acc_test: 0.6870 time: 0.1076s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9286 acc_val: 0.4533 loss_test: 1.2835 acc_test: 0.6870 time: 0.1211s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9713 acc_val: 0.4800 loss_test: 1.3119 acc_test: 0.6980 time: 0.0899s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0260 acc_val: 0.5033 loss_test: 1.3564 acc_test: 0.6950 time: 0.0841s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0919 acc_val: 0.4967 loss_test: 1.3908 acc_test: 0.6960 time: 0.0877s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0779 acc_val: 0.5200 loss_test: 1.4135 acc_test: 0.6970 time: 0.1513s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1046 acc_val: 0.5133 loss_test: 1.4442 acc_test: 0.7020 time: 0.1160s
Optimization Finished!
Total time elapsed: 49.5283s, best testing performance  0.705000, minimun loss  1.003173
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7950 acc_train: 0.1083 loss_val: 1.8106 acc_val: 0.1133 loss_test: 1.6920 acc_test: 0.4810 time: 0.0789s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8751 acc_val: 0.3700 loss_test: 1.1840 acc_test: 0.6570 time: 0.1308s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8751 acc_val: 0.4100 loss_test: 1.1953 acc_test: 0.6790 time: 0.1171s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8625 acc_val: 0.4167 loss_test: 1.2321 acc_test: 0.6850 time: 0.0989s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9458 acc_val: 0.4533 loss_test: 1.2901 acc_test: 0.6900 time: 0.1158s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9542 acc_val: 0.4767 loss_test: 1.3176 acc_test: 0.6940 time: 0.0857s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0250 acc_val: 0.4900 loss_test: 1.3596 acc_test: 0.6940 time: 0.1047s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0917 acc_val: 0.5000 loss_test: 1.3946 acc_test: 0.6930 time: 0.1245s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1273 acc_val: 0.5133 loss_test: 1.4190 acc_test: 0.6950 time: 0.1227s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1761 acc_val: 0.5133 loss_test: 1.4494 acc_test: 0.6960 time: 0.0927s
Optimization Finished!
Total time elapsed: 48.1020s, best testing performance  0.702000, minimun loss  1.012480
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7889 acc_train: 0.2000 loss_val: 1.7834 acc_val: 0.1733 loss_test: 1.6763 acc_test: 0.5250 time: 0.1168s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8877 acc_val: 0.3867 loss_test: 1.1984 acc_test: 0.6530 time: 0.0722s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7849 acc_val: 0.4467 loss_test: 1.1782 acc_test: 0.6830 time: 0.0727s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8326 acc_val: 0.4333 loss_test: 1.2160 acc_test: 0.6860 time: 0.0847s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8279 acc_val: 0.4767 loss_test: 1.2353 acc_test: 0.6950 time: 0.0952s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9042 acc_val: 0.4767 loss_test: 1.2896 acc_test: 0.7040 time: 0.0847s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9658 acc_val: 0.5033 loss_test: 1.3381 acc_test: 0.7020 time: 0.0931s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0832 acc_val: 0.5033 loss_test: 1.3913 acc_test: 0.6960 time: 0.0870s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1001 acc_val: 0.5000 loss_test: 1.4247 acc_test: 0.6960 time: 0.1037s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1288 acc_val: 0.5100 loss_test: 1.4464 acc_test: 0.6960 time: 0.0951s
Optimization Finished!
Total time elapsed: 46.4275s, best testing performance  0.706000, minimun loss  1.014049
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8231 acc_train: 0.0750 loss_val: 1.8011 acc_val: 0.1800 loss_test: 1.7191 acc_test: 0.4420 time: 0.1077s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8402 acc_val: 0.3967 loss_test: 1.1669 acc_test: 0.6620 time: 0.1033s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7571 acc_val: 0.4333 loss_test: 1.1467 acc_test: 0.6810 time: 0.0911s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.7881 acc_val: 0.4333 loss_test: 1.1910 acc_test: 0.6860 time: 0.1040s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8921 acc_val: 0.4467 loss_test: 1.2463 acc_test: 0.6930 time: 0.0817s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0283 acc_val: 0.4767 loss_test: 1.3074 acc_test: 0.6970 time: 0.1044s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1290 acc_val: 0.4867 loss_test: 1.3572 acc_test: 0.6940 time: 0.0961s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1711 acc_val: 0.5000 loss_test: 1.3943 acc_test: 0.6910 time: 0.0976s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2148 acc_val: 0.5000 loss_test: 1.4311 acc_test: 0.6970 time: 0.0784s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2378 acc_val: 0.5067 loss_test: 1.4584 acc_test: 0.6980 time: 0.0849s
Optimization Finished!
Total time elapsed: 49.2477s, best testing performance  0.704000, minimun loss  1.032033
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8060 acc_train: 0.1417 loss_val: 1.8182 acc_val: 0.1333 loss_test: 1.6830 acc_test: 0.4820 time: 0.0892s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8087 acc_val: 0.3867 loss_test: 1.1611 acc_test: 0.6600 time: 0.0707s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7944 acc_val: 0.4267 loss_test: 1.1687 acc_test: 0.6810 time: 0.0716s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8533 acc_val: 0.4267 loss_test: 1.2189 acc_test: 0.6820 time: 0.0722s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8769 acc_val: 0.4467 loss_test: 1.2693 acc_test: 0.6880 time: 0.0729s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9563 acc_val: 0.4800 loss_test: 1.3114 acc_test: 0.6970 time: 0.0884s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0090 acc_val: 0.4867 loss_test: 1.3497 acc_test: 0.6950 time: 0.0772s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0865 acc_val: 0.4967 loss_test: 1.3912 acc_test: 0.6970 time: 0.0897s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1694 acc_val: 0.4967 loss_test: 1.4383 acc_test: 0.6970 time: 0.0880s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1566 acc_val: 0.5067 loss_test: 1.4635 acc_test: 0.6970 time: 0.0884s
Optimization Finished!
Total time elapsed: 43.9663s, best testing performance  0.701000, minimun loss  1.017683
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7864 acc_train: 0.1583 loss_val: 1.7934 acc_val: 0.1500 loss_test: 1.6754 acc_test: 0.5380 time: 0.0873s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7668 acc_val: 0.4067 loss_test: 1.1468 acc_test: 0.6660 time: 0.0877s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7521 acc_val: 0.4367 loss_test: 1.1570 acc_test: 0.6840 time: 0.1125s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8092 acc_val: 0.4567 loss_test: 1.2041 acc_test: 0.6830 time: 0.1044s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8804 acc_val: 0.4700 loss_test: 1.2636 acc_test: 0.6850 time: 0.0959s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9568 acc_val: 0.4967 loss_test: 1.3142 acc_test: 0.6930 time: 0.0972s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0579 acc_val: 0.4967 loss_test: 1.3620 acc_test: 0.6930 time: 0.1035s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0933 acc_val: 0.5133 loss_test: 1.3965 acc_test: 0.6950 time: 0.0986s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1490 acc_val: 0.5000 loss_test: 1.4332 acc_test: 0.6940 time: 0.1056s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1676 acc_val: 0.5133 loss_test: 1.4547 acc_test: 0.7000 time: 0.0868s
Optimization Finished!
Total time elapsed: 49.8581s, best testing performance  0.702000, minimun loss  0.999783
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8094 acc_train: 0.1250 loss_val: 1.8178 acc_val: 0.1167 loss_test: 1.7077 acc_test: 0.4220 time: 0.1048s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8839 acc_val: 0.3967 loss_test: 1.1855 acc_test: 0.6520 time: 0.0712s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8338 acc_val: 0.4200 loss_test: 1.1759 acc_test: 0.6800 time: 0.0714s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8333 acc_val: 0.4400 loss_test: 1.1985 acc_test: 0.6860 time: 0.0723s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9108 acc_val: 0.4600 loss_test: 1.2591 acc_test: 0.6890 time: 0.0728s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9981 acc_val: 0.4800 loss_test: 1.3177 acc_test: 0.6980 time: 0.0717s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0451 acc_val: 0.5000 loss_test: 1.3494 acc_test: 0.6990 time: 0.0811s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.5067 loss_test: 1.3837 acc_test: 0.7040 time: 0.1100s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1098 acc_val: 0.5100 loss_test: 1.4163 acc_test: 0.7050 time: 0.0737s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1603 acc_val: 0.5133 loss_test: 1.4592 acc_test: 0.7030 time: 0.0817s
Optimization Finished!
Total time elapsed: 41.2780s, best testing performance  0.708000, minimun loss  1.029641
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7822 acc_train: 0.2250 loss_val: 1.8010 acc_val: 0.2000 loss_test: 1.6844 acc_test: 0.5290 time: 0.0977s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.7601 acc_val: 0.4100 loss_test: 1.1381 acc_test: 0.6700 time: 0.0831s
Epoch: 0101 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7014 acc_val: 0.4533 loss_test: 1.1268 acc_test: 0.6850 time: 0.1243s
Epoch: 0151 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7321 acc_val: 0.4533 loss_test: 1.1675 acc_test: 0.6910 time: 0.1104s
Epoch: 0201 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8096 acc_val: 0.4867 loss_test: 1.2227 acc_test: 0.6950 time: 0.0926s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.8901 acc_val: 0.4900 loss_test: 1.2683 acc_test: 0.6950 time: 0.1227s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9538 acc_val: 0.4933 loss_test: 1.3083 acc_test: 0.6940 time: 0.0871s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0273 acc_val: 0.4967 loss_test: 1.3517 acc_test: 0.6920 time: 0.1080s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0503 acc_val: 0.5133 loss_test: 1.3805 acc_test: 0.6970 time: 0.1051s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1128 acc_val: 0.5133 loss_test: 1.4144 acc_test: 0.7000 time: 0.1034s
Optimization Finished!
Total time elapsed: 49.5816s, best testing performance  0.701000, minimun loss  1.026453
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8078 acc_train: 0.0833 loss_val: 1.8137 acc_val: 0.0933 loss_test: 1.7115 acc_test: 0.4150 time: 0.1184s
Epoch: 0051 loss_train: 0.0137 acc_train: 1.0000 loss_val: 1.8398 acc_val: 0.3800 loss_test: 1.1622 acc_test: 0.6660 time: 0.0699s
Epoch: 0101 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7602 acc_val: 0.4267 loss_test: 1.1521 acc_test: 0.6910 time: 0.0698s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8287 acc_val: 0.4633 loss_test: 1.1995 acc_test: 0.6960 time: 0.0691s
Epoch: 0201 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9013 acc_val: 0.4767 loss_test: 1.2515 acc_test: 0.6900 time: 0.0731s
Epoch: 0251 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9489 acc_val: 0.4933 loss_test: 1.2936 acc_test: 0.6960 time: 0.0739s
Epoch: 0301 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9840 acc_val: 0.5000 loss_test: 1.3287 acc_test: 0.6980 time: 0.0720s
Epoch: 0351 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0442 acc_val: 0.5133 loss_test: 1.3714 acc_test: 0.7000 time: 0.0750s
Epoch: 0401 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0722 acc_val: 0.5067 loss_test: 1.4084 acc_test: 0.7000 time: 0.0724s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1250 acc_val: 0.5200 loss_test: 1.4517 acc_test: 0.7020 time: 0.0949s
Optimization Finished!
Total time elapsed: 38.4598s, best testing performance  0.705000, minimun loss  1.050053
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7716 acc_train: 0.3000 loss_val: 1.8138 acc_val: 0.1167 loss_test: 1.6768 acc_test: 0.4780 time: 0.1088s
Epoch: 0051 loss_train: 0.0141 acc_train: 1.0000 loss_val: 1.8406 acc_val: 0.3900 loss_test: 1.1620 acc_test: 0.6620 time: 0.0808s
Epoch: 0101 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8322 acc_val: 0.4167 loss_test: 1.1739 acc_test: 0.6810 time: 0.0811s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8424 acc_val: 0.4167 loss_test: 1.2092 acc_test: 0.6890 time: 0.0847s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9042 acc_val: 0.4467 loss_test: 1.2592 acc_test: 0.6900 time: 0.0826s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9692 acc_val: 0.4867 loss_test: 1.3099 acc_test: 0.6930 time: 0.1114s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.4967 loss_test: 1.3542 acc_test: 0.6990 time: 0.0988s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0836 acc_val: 0.5100 loss_test: 1.3972 acc_test: 0.7000 time: 0.0855s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1416 acc_val: 0.5133 loss_test: 1.4480 acc_test: 0.6990 time: 0.0778s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1957 acc_val: 0.5133 loss_test: 1.4880 acc_test: 0.6980 time: 0.0804s
Optimization Finished!
Total time elapsed: 49.3285s, best testing performance  0.703000, minimun loss  1.025439
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7725 acc_train: 0.2500 loss_val: 1.7780 acc_val: 0.2167 loss_test: 1.6701 acc_test: 0.5400 time: 0.0967s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8627 acc_val: 0.3800 loss_test: 1.1629 acc_test: 0.6590 time: 0.0823s
Epoch: 0101 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8278 acc_val: 0.4000 loss_test: 1.1623 acc_test: 0.6840 time: 0.1023s
Epoch: 0151 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8332 acc_val: 0.4133 loss_test: 1.1908 acc_test: 0.6890 time: 0.0692s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8486 acc_val: 0.4633 loss_test: 1.2269 acc_test: 0.6880 time: 0.0692s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9177 acc_val: 0.4833 loss_test: 1.2720 acc_test: 0.6930 time: 0.0698s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9728 acc_val: 0.4967 loss_test: 1.3108 acc_test: 0.6960 time: 0.0716s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0053 acc_val: 0.5000 loss_test: 1.3432 acc_test: 0.6960 time: 0.0732s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0517 acc_val: 0.5067 loss_test: 1.3825 acc_test: 0.6960 time: 0.0717s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1142 acc_val: 0.5033 loss_test: 1.4231 acc_test: 0.6960 time: 0.0725s
Optimization Finished!
Total time elapsed: 38.9989s, best testing performance  0.699000, minimun loss  1.020107
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7789 acc_train: 0.2500 loss_val: 1.8109 acc_val: 0.1200 loss_test: 1.6848 acc_test: 0.4930 time: 0.0959s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8119 acc_val: 0.3933 loss_test: 1.1366 acc_test: 0.6720 time: 0.1127s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7697 acc_val: 0.4400 loss_test: 1.1406 acc_test: 0.6900 time: 0.1051s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8209 acc_val: 0.4533 loss_test: 1.1939 acc_test: 0.6870 time: 0.1079s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8999 acc_val: 0.4733 loss_test: 1.2582 acc_test: 0.6890 time: 0.1026s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9675 acc_val: 0.4733 loss_test: 1.3060 acc_test: 0.6940 time: 0.0777s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0562 acc_val: 0.4900 loss_test: 1.3655 acc_test: 0.6930 time: 0.0884s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1265 acc_val: 0.5067 loss_test: 1.4141 acc_test: 0.6930 time: 0.1170s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2188 acc_val: 0.4967 loss_test: 1.4760 acc_test: 0.6900 time: 0.1058s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2574 acc_val: 0.4933 loss_test: 1.5180 acc_test: 0.6890 time: 0.1060s
Optimization Finished!
Total time elapsed: 49.6552s, best testing performance  0.697000, minimun loss  1.008745
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7908 acc_train: 0.1583 loss_val: 1.8072 acc_val: 0.1733 loss_test: 1.6948 acc_test: 0.5000 time: 0.1102s
Epoch: 0051 loss_train: 0.0144 acc_train: 1.0000 loss_val: 1.9373 acc_val: 0.3333 loss_test: 1.2022 acc_test: 0.6540 time: 0.0861s
Epoch: 0101 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8714 acc_val: 0.3867 loss_test: 1.1830 acc_test: 0.6650 time: 0.1082s
Epoch: 0151 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8626 acc_val: 0.4133 loss_test: 1.2040 acc_test: 0.6770 time: 0.1033s
Epoch: 0201 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9182 acc_val: 0.4367 loss_test: 1.2498 acc_test: 0.6850 time: 0.0990s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9330 acc_val: 0.4533 loss_test: 1.2807 acc_test: 0.6940 time: 0.0697s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9960 acc_val: 0.4867 loss_test: 1.3262 acc_test: 0.6940 time: 0.0698s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0204 acc_val: 0.4967 loss_test: 1.3618 acc_test: 0.6970 time: 0.0701s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.5067 loss_test: 1.4051 acc_test: 0.6960 time: 0.0715s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1372 acc_val: 0.5067 loss_test: 1.4421 acc_test: 0.6970 time: 0.0722s
Optimization Finished!
Total time elapsed: 41.5134s, best testing performance  0.700000, minimun loss  1.054296
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7868 acc_train: 0.1917 loss_val: 1.7922 acc_val: 0.1933 loss_test: 1.6844 acc_test: 0.4840 time: 0.1204s
Epoch: 0051 loss_train: 0.0138 acc_train: 1.0000 loss_val: 1.7744 acc_val: 0.4100 loss_test: 1.1387 acc_test: 0.6630 time: 0.1031s
Epoch: 0101 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8201 acc_val: 0.4133 loss_test: 1.1576 acc_test: 0.6730 time: 0.0818s
Epoch: 0151 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8826 acc_val: 0.4300 loss_test: 1.2042 acc_test: 0.6800 time: 0.1014s
Epoch: 0201 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9735 acc_val: 0.4433 loss_test: 1.2586 acc_test: 0.6820 time: 0.1015s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0269 acc_val: 0.4567 loss_test: 1.3005 acc_test: 0.6900 time: 0.1094s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0549 acc_val: 0.4767 loss_test: 1.3308 acc_test: 0.6910 time: 0.1188s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0933 acc_val: 0.4833 loss_test: 1.3670 acc_test: 0.6930 time: 0.0889s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1443 acc_val: 0.4967 loss_test: 1.4011 acc_test: 0.6970 time: 0.0847s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1497 acc_val: 0.5033 loss_test: 1.4301 acc_test: 0.6990 time: 0.1184s
Optimization Finished!
Total time elapsed: 49.6687s, best testing performance  0.700000, minimun loss  1.028166
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8110 acc_train: 0.1583 loss_val: 1.8259 acc_val: 0.1233 loss_test: 1.7084 acc_test: 0.4700 time: 0.1147s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8601 acc_val: 0.3667 loss_test: 1.1898 acc_test: 0.6540 time: 0.1032s
Epoch: 0101 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8119 acc_val: 0.4167 loss_test: 1.1755 acc_test: 0.6750 time: 0.0805s
Epoch: 0151 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8643 acc_val: 0.4233 loss_test: 1.2158 acc_test: 0.6830 time: 0.1024s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9184 acc_val: 0.4533 loss_test: 1.2574 acc_test: 0.6890 time: 0.0867s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9929 acc_val: 0.4733 loss_test: 1.3016 acc_test: 0.6930 time: 0.0922s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0469 acc_val: 0.4833 loss_test: 1.3429 acc_test: 0.6920 time: 0.0931s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1038 acc_val: 0.4933 loss_test: 1.3804 acc_test: 0.6940 time: 0.0700s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1167 acc_val: 0.4967 loss_test: 1.4045 acc_test: 0.6980 time: 0.0699s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1822 acc_val: 0.5033 loss_test: 1.4435 acc_test: 0.6990 time: 0.0711s
Optimization Finished!
Total time elapsed: 45.1324s, best testing performance  0.701000, minimun loss  1.050837
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7954 acc_train: 0.1500 loss_val: 1.7916 acc_val: 0.1600 loss_test: 1.6879 acc_test: 0.5100 time: 0.1036s
Epoch: 0051 loss_train: 0.0140 acc_train: 1.0000 loss_val: 1.7792 acc_val: 0.3767 loss_test: 1.1376 acc_test: 0.6620 time: 0.0968s
Epoch: 0101 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7806 acc_val: 0.4067 loss_test: 1.1470 acc_test: 0.6830 time: 0.1073s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8029 acc_val: 0.4400 loss_test: 1.1873 acc_test: 0.6910 time: 0.1124s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8897 acc_val: 0.4667 loss_test: 1.2427 acc_test: 0.6910 time: 0.0850s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9771 acc_val: 0.4767 loss_test: 1.3047 acc_test: 0.6920 time: 0.0852s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0317 acc_val: 0.4833 loss_test: 1.3480 acc_test: 0.6950 time: 0.1042s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0702 acc_val: 0.4900 loss_test: 1.3902 acc_test: 0.6970 time: 0.0845s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1267 acc_val: 0.5067 loss_test: 1.4327 acc_test: 0.6910 time: 0.0787s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.5033 loss_test: 1.4549 acc_test: 0.6960 time: 0.0869s
Optimization Finished!
Total time elapsed: 49.1615s, best testing performance  0.700000, minimun loss  1.017561
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7954 acc_train: 0.1917 loss_val: 1.7925 acc_val: 0.1800 loss_test: 1.7003 acc_test: 0.4880 time: 0.1166s
Epoch: 0051 loss_train: 0.0144 acc_train: 1.0000 loss_val: 1.7486 acc_val: 0.4067 loss_test: 1.1369 acc_test: 0.6720 time: 0.1270s
Epoch: 0101 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7656 acc_val: 0.4433 loss_test: 1.1477 acc_test: 0.6880 time: 0.0997s
Epoch: 0151 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8527 acc_val: 0.4400 loss_test: 1.2054 acc_test: 0.6870 time: 0.1315s
Epoch: 0201 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9126 acc_val: 0.4667 loss_test: 1.2484 acc_test: 0.6930 time: 0.1069s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9859 acc_val: 0.4767 loss_test: 1.2971 acc_test: 0.6920 time: 0.0928s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0154 acc_val: 0.4867 loss_test: 1.3350 acc_test: 0.6980 time: 0.1100s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0714 acc_val: 0.4967 loss_test: 1.3818 acc_test: 0.6950 time: 0.1145s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1094 acc_val: 0.5100 loss_test: 1.4243 acc_test: 0.7030 time: 0.1153s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1605 acc_val: 0.5067 loss_test: 1.4670 acc_test: 0.7000 time: 0.0870s
Optimization Finished!
Total time elapsed: 48.5139s, best testing performance  0.703000, minimun loss  1.031159
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7937 acc_train: 0.0750 loss_val: 1.7835 acc_val: 0.1933 loss_test: 1.6732 acc_test: 0.5400 time: 0.0966s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7783 acc_val: 0.3933 loss_test: 1.1499 acc_test: 0.6640 time: 0.0736s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7102 acc_val: 0.4467 loss_test: 1.1419 acc_test: 0.6910 time: 0.0727s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.7867 acc_val: 0.4433 loss_test: 1.2081 acc_test: 0.6880 time: 0.0901s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9032 acc_val: 0.4533 loss_test: 1.2757 acc_test: 0.6900 time: 0.1267s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9362 acc_val: 0.4600 loss_test: 1.3111 acc_test: 0.7010 time: 0.0848s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0094 acc_val: 0.4767 loss_test: 1.3586 acc_test: 0.7040 time: 0.1234s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0395 acc_val: 0.4900 loss_test: 1.3957 acc_test: 0.7020 time: 0.1124s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0815 acc_val: 0.4967 loss_test: 1.4315 acc_test: 0.7040 time: 0.0994s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1208 acc_val: 0.5167 loss_test: 1.4640 acc_test: 0.7050 time: 0.0943s
Optimization Finished!
Total time elapsed: 46.9587s, best testing performance  0.711000, minimun loss  1.027693
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8054 acc_train: 0.0917 loss_val: 1.8110 acc_val: 0.0767 loss_test: 1.6954 acc_test: 0.4600 time: 0.1053s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.7658 acc_val: 0.4000 loss_test: 1.1556 acc_test: 0.6640 time: 0.0839s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7481 acc_val: 0.4300 loss_test: 1.1633 acc_test: 0.6880 time: 0.1146s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8890 acc_val: 0.4133 loss_test: 1.2377 acc_test: 0.6830 time: 0.1099s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9658 acc_val: 0.4400 loss_test: 1.2977 acc_test: 0.6890 time: 0.0969s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0418 acc_val: 0.4667 loss_test: 1.3405 acc_test: 0.6940 time: 0.1176s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0851 acc_val: 0.4767 loss_test: 1.3752 acc_test: 0.6980 time: 0.0941s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1247 acc_val: 0.4900 loss_test: 1.4126 acc_test: 0.6980 time: 0.0891s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1614 acc_val: 0.4967 loss_test: 1.4492 acc_test: 0.6960 time: 0.0994s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1954 acc_val: 0.5067 loss_test: 1.4769 acc_test: 0.6960 time: 0.1128s
Optimization Finished!
Total time elapsed: 49.3406s, best testing performance  0.700000, minimun loss  1.012914
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8112 acc_train: 0.1000 loss_val: 1.7989 acc_val: 0.1367 loss_test: 1.6947 acc_test: 0.4600 time: 0.0955s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.6714 acc_val: 0.4300 loss_test: 1.1250 acc_test: 0.6740 time: 0.0743s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.6772 acc_val: 0.4367 loss_test: 1.1376 acc_test: 0.6830 time: 0.0732s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7624 acc_val: 0.4400 loss_test: 1.1965 acc_test: 0.6840 time: 0.0721s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9531 acc_val: 0.4400 loss_test: 1.2811 acc_test: 0.6810 time: 0.0729s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9657 acc_val: 0.4833 loss_test: 1.3157 acc_test: 0.6940 time: 0.0963s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0501 acc_val: 0.4933 loss_test: 1.3505 acc_test: 0.6930 time: 0.0963s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1051 acc_val: 0.4967 loss_test: 1.3858 acc_test: 0.6920 time: 0.0911s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1689 acc_val: 0.4967 loss_test: 1.4234 acc_test: 0.6920 time: 0.1054s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2162 acc_val: 0.5000 loss_test: 1.4563 acc_test: 0.6910 time: 0.0968s
Optimization Finished!
Total time elapsed: 44.0855s, best testing performance  0.700000, minimun loss  1.031948
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7951 acc_train: 0.1250 loss_val: 1.7814 acc_val: 0.1800 loss_test: 1.6968 acc_test: 0.4870 time: 0.0913s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8843 acc_val: 0.3733 loss_test: 1.1924 acc_test: 0.6470 time: 0.0962s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8108 acc_val: 0.4067 loss_test: 1.1804 acc_test: 0.6790 time: 0.1011s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8474 acc_val: 0.4333 loss_test: 1.2202 acc_test: 0.6830 time: 0.1115s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8475 acc_val: 0.4533 loss_test: 1.2451 acc_test: 0.6930 time: 0.0881s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9525 acc_val: 0.4833 loss_test: 1.3078 acc_test: 0.6950 time: 0.1102s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0129 acc_val: 0.5000 loss_test: 1.3460 acc_test: 0.6940 time: 0.0789s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0877 acc_val: 0.5000 loss_test: 1.3868 acc_test: 0.6950 time: 0.0820s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1027 acc_val: 0.4967 loss_test: 1.4152 acc_test: 0.6960 time: 0.1010s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1264 acc_val: 0.5067 loss_test: 1.4386 acc_test: 0.6970 time: 0.0974s
Optimization Finished!
Total time elapsed: 49.2478s, best testing performance  0.700000, minimun loss  1.021477
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7971 acc_train: 0.1500 loss_val: 1.7996 acc_val: 0.1267 loss_test: 1.6655 acc_test: 0.4910 time: 0.0839s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7827 acc_val: 0.4000 loss_test: 1.1543 acc_test: 0.6580 time: 0.0748s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7581 acc_val: 0.4167 loss_test: 1.1581 acc_test: 0.6880 time: 0.0758s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8593 acc_val: 0.4133 loss_test: 1.2185 acc_test: 0.6870 time: 0.0708s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9979 acc_val: 0.4333 loss_test: 1.2826 acc_test: 0.6880 time: 0.0718s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0464 acc_val: 0.4800 loss_test: 1.3254 acc_test: 0.6930 time: 0.0715s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0724 acc_val: 0.4967 loss_test: 1.3599 acc_test: 0.6950 time: 0.0731s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1113 acc_val: 0.5000 loss_test: 1.3974 acc_test: 0.6970 time: 0.1132s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1717 acc_val: 0.5033 loss_test: 1.4413 acc_test: 0.6990 time: 0.0814s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1884 acc_val: 0.5133 loss_test: 1.4678 acc_test: 0.6970 time: 0.0818s
Optimization Finished!
Total time elapsed: 41.1125s, best testing performance  0.703000, minimun loss  1.013425
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7896 acc_train: 0.2167 loss_val: 1.8123 acc_val: 0.1467 loss_test: 1.6759 acc_test: 0.5170 time: 0.0870s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8378 acc_val: 0.3733 loss_test: 1.1651 acc_test: 0.6560 time: 0.1190s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7978 acc_val: 0.4033 loss_test: 1.1646 acc_test: 0.6780 time: 0.0883s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8574 acc_val: 0.3733 loss_test: 1.2141 acc_test: 0.6850 time: 0.0864s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8286 acc_val: 0.4367 loss_test: 1.2442 acc_test: 0.6870 time: 0.1052s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9095 acc_val: 0.4433 loss_test: 1.2938 acc_test: 0.6890 time: 0.0920s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0172 acc_val: 0.4900 loss_test: 1.3473 acc_test: 0.6930 time: 0.0970s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0785 acc_val: 0.5100 loss_test: 1.3808 acc_test: 0.6970 time: 0.0761s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1142 acc_val: 0.5100 loss_test: 1.4099 acc_test: 0.6950 time: 0.0767s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1726 acc_val: 0.5133 loss_test: 1.4364 acc_test: 0.6990 time: 0.0825s
Optimization Finished!
Total time elapsed: 49.1874s, best testing performance  0.701000, minimun loss  1.018389
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7992 acc_train: 0.1333 loss_val: 1.8261 acc_val: 0.0933 loss_test: 1.6865 acc_test: 0.4350 time: 0.0873s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7879 acc_val: 0.4000 loss_test: 1.1661 acc_test: 0.6590 time: 0.0691s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7766 acc_val: 0.4233 loss_test: 1.1726 acc_test: 0.6840 time: 0.0706s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8241 acc_val: 0.4367 loss_test: 1.2153 acc_test: 0.6860 time: 0.0694s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8749 acc_val: 0.4633 loss_test: 1.2605 acc_test: 0.6900 time: 0.0712s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9229 acc_val: 0.4867 loss_test: 1.3027 acc_test: 0.6970 time: 0.0711s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9930 acc_val: 0.5067 loss_test: 1.3429 acc_test: 0.6980 time: 0.0709s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0595 acc_val: 0.5033 loss_test: 1.3790 acc_test: 0.6980 time: 0.0722s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1108 acc_val: 0.5133 loss_test: 1.4186 acc_test: 0.7000 time: 0.0819s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1339 acc_val: 0.5100 loss_test: 1.4425 acc_test: 0.7020 time: 0.1053s
Optimization Finished!
Total time elapsed: 38.5516s, best testing performance  0.704000, minimun loss  1.028854
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7851 acc_train: 0.2000 loss_val: 1.8047 acc_val: 0.0833 loss_test: 1.6787 acc_test: 0.4130 time: 0.1408s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7286 acc_val: 0.4100 loss_test: 1.1270 acc_test: 0.6690 time: 0.0806s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6768 acc_val: 0.4667 loss_test: 1.1191 acc_test: 0.6920 time: 0.1394s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.7788 acc_val: 0.4433 loss_test: 1.1827 acc_test: 0.6870 time: 0.1018s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8769 acc_val: 0.4600 loss_test: 1.2507 acc_test: 0.6920 time: 0.1165s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9940 acc_val: 0.4867 loss_test: 1.3099 acc_test: 0.6960 time: 0.0837s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0837 acc_val: 0.5000 loss_test: 1.3544 acc_test: 0.6950 time: 0.1119s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1452 acc_val: 0.4933 loss_test: 1.3939 acc_test: 0.6940 time: 0.0789s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1777 acc_val: 0.5067 loss_test: 1.4233 acc_test: 0.6950 time: 0.0822s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2046 acc_val: 0.5033 loss_test: 1.4523 acc_test: 0.7030 time: 0.0997s
Optimization Finished!
Total time elapsed: 49.4619s, best testing performance  0.703000, minimun loss  1.004556
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.1667 loss_val: 1.8002 acc_val: 0.1833 loss_test: 1.6814 acc_test: 0.4890 time: 0.1091s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7281 acc_val: 0.4033 loss_test: 1.1382 acc_test: 0.6700 time: 0.1136s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7546 acc_val: 0.4400 loss_test: 1.1523 acc_test: 0.6920 time: 0.1042s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8495 acc_val: 0.4300 loss_test: 1.2108 acc_test: 0.6890 time: 0.0737s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8423 acc_val: 0.4400 loss_test: 1.2528 acc_test: 0.6900 time: 0.0702s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9947 acc_val: 0.4667 loss_test: 1.3126 acc_test: 0.6910 time: 0.0690s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0360 acc_val: 0.4767 loss_test: 1.3474 acc_test: 0.6960 time: 0.0721s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1097 acc_val: 0.4867 loss_test: 1.3840 acc_test: 0.6970 time: 0.0710s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1692 acc_val: 0.5067 loss_test: 1.4173 acc_test: 0.6930 time: 0.0737s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1770 acc_val: 0.5133 loss_test: 1.4362 acc_test: 0.6980 time: 0.0722s
Optimization Finished!
Total time elapsed: 38.8218s, best testing performance  0.703000, minimun loss  1.023393
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7843 acc_train: 0.1917 loss_val: 1.8024 acc_val: 0.1033 loss_test: 1.6809 acc_test: 0.3930 time: 0.1318s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.8637 acc_val: 0.3833 loss_test: 1.1851 acc_test: 0.6490 time: 0.0785s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8421 acc_val: 0.4100 loss_test: 1.1719 acc_test: 0.6840 time: 0.0834s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8522 acc_val: 0.4400 loss_test: 1.2018 acc_test: 0.6850 time: 0.0797s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8630 acc_val: 0.4500 loss_test: 1.2541 acc_test: 0.6880 time: 0.0915s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9395 acc_val: 0.4800 loss_test: 1.3056 acc_test: 0.6960 time: 0.0865s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0088 acc_val: 0.4900 loss_test: 1.3524 acc_test: 0.6960 time: 0.1046s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0331 acc_val: 0.5067 loss_test: 1.3857 acc_test: 0.6990 time: 0.1029s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0827 acc_val: 0.5000 loss_test: 1.4292 acc_test: 0.6970 time: 0.0899s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1054 acc_val: 0.4967 loss_test: 1.4557 acc_test: 0.6960 time: 0.0847s
Optimization Finished!
Total time elapsed: 49.5416s, best testing performance  0.701000, minimun loss  1.021953
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.1833 loss_val: 1.8068 acc_val: 0.1667 loss_test: 1.6999 acc_test: 0.4810 time: 0.0877s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9276 acc_val: 0.3400 loss_test: 1.2199 acc_test: 0.6410 time: 0.0789s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9111 acc_val: 0.3733 loss_test: 1.2080 acc_test: 0.6680 time: 0.1156s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9034 acc_val: 0.4067 loss_test: 1.2390 acc_test: 0.6730 time: 0.1136s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9761 acc_val: 0.4200 loss_test: 1.2863 acc_test: 0.6810 time: 0.0941s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0152 acc_val: 0.4400 loss_test: 1.3261 acc_test: 0.6930 time: 0.0694s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0188 acc_val: 0.4867 loss_test: 1.3516 acc_test: 0.6970 time: 0.0697s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0912 acc_val: 0.5067 loss_test: 1.3880 acc_test: 0.6960 time: 0.0699s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1688 acc_val: 0.5000 loss_test: 1.4340 acc_test: 0.6970 time: 0.0718s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1562 acc_val: 0.5133 loss_test: 1.4494 acc_test: 0.6990 time: 0.0715s
Optimization Finished!
Total time elapsed: 41.3982s, best testing performance  0.701000, minimun loss  1.025605
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8064 acc_train: 0.1583 loss_val: 1.8085 acc_val: 0.0800 loss_test: 1.7037 acc_test: 0.3820 time: 0.0789s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9124 acc_val: 0.3400 loss_test: 1.2230 acc_test: 0.6420 time: 0.0886s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8811 acc_val: 0.3800 loss_test: 1.2153 acc_test: 0.6650 time: 0.1023s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.7835 acc_val: 0.4300 loss_test: 1.2099 acc_test: 0.6810 time: 0.0976s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8605 acc_val: 0.4400 loss_test: 1.2585 acc_test: 0.6860 time: 0.1047s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9730 acc_val: 0.4667 loss_test: 1.3207 acc_test: 0.6920 time: 0.1037s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0102 acc_val: 0.4800 loss_test: 1.3585 acc_test: 0.6910 time: 0.1078s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0433 acc_val: 0.5100 loss_test: 1.3850 acc_test: 0.6930 time: 0.0912s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0632 acc_val: 0.5000 loss_test: 1.4063 acc_test: 0.6970 time: 0.1020s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1080 acc_val: 0.5100 loss_test: 1.4409 acc_test: 0.6990 time: 0.0975s
Optimization Finished!
Total time elapsed: 49.9822s, best testing performance  0.702000, minimun loss  1.022233
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7719 acc_train: 0.2750 loss_val: 1.8109 acc_val: 0.1633 loss_test: 1.6894 acc_test: 0.4980 time: 0.1018s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.9596 acc_val: 0.3700 loss_test: 1.2046 acc_test: 0.6580 time: 0.0880s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9832 acc_val: 0.3733 loss_test: 1.2308 acc_test: 0.6700 time: 0.0968s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 2.0176 acc_val: 0.4267 loss_test: 1.2693 acc_test: 0.6820 time: 0.0789s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0611 acc_val: 0.4400 loss_test: 1.3053 acc_test: 0.6920 time: 0.1009s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0825 acc_val: 0.4800 loss_test: 1.3342 acc_test: 0.6960 time: 0.0862s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1044 acc_val: 0.4800 loss_test: 1.3632 acc_test: 0.6990 time: 0.1128s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1325 acc_val: 0.4900 loss_test: 1.3954 acc_test: 0.6980 time: 0.0698s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1817 acc_val: 0.4900 loss_test: 1.4288 acc_test: 0.6980 time: 0.0697s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2183 acc_val: 0.5033 loss_test: 1.4580 acc_test: 0.6950 time: 0.0696s
Optimization Finished!
Total time elapsed: 44.4656s, best testing performance  0.701000, minimun loss  1.047055
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7867 acc_train: 0.1750 loss_val: 1.7972 acc_val: 0.1667 loss_test: 1.6953 acc_test: 0.4500 time: 0.0780s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8402 acc_val: 0.3967 loss_test: 1.1725 acc_test: 0.6580 time: 0.1081s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8592 acc_val: 0.4233 loss_test: 1.2020 acc_test: 0.6760 time: 0.0988s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9087 acc_val: 0.4300 loss_test: 1.2520 acc_test: 0.6790 time: 0.0875s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0398 acc_val: 0.4433 loss_test: 1.3164 acc_test: 0.6890 time: 0.0905s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0227 acc_val: 0.4800 loss_test: 1.3260 acc_test: 0.6920 time: 0.1153s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0837 acc_val: 0.4933 loss_test: 1.3607 acc_test: 0.6930 time: 0.0939s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1234 acc_val: 0.5033 loss_test: 1.3933 acc_test: 0.6940 time: 0.0970s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1321 acc_val: 0.5000 loss_test: 1.4175 acc_test: 0.6970 time: 0.0964s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.5100 loss_test: 1.4420 acc_test: 0.6990 time: 0.0899s
Optimization Finished!
Total time elapsed: 49.9904s, best testing performance  0.702000, minimun loss  1.016075
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8098 acc_train: 0.1250 loss_val: 1.8069 acc_val: 0.1633 loss_test: 1.7068 acc_test: 0.4860 time: 0.1137s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 2.1096 acc_val: 0.3367 loss_test: 1.2825 acc_test: 0.6430 time: 0.0870s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9900 acc_val: 0.3967 loss_test: 1.2618 acc_test: 0.6670 time: 0.1053s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9994 acc_val: 0.4367 loss_test: 1.2878 acc_test: 0.6810 time: 0.1317s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0261 acc_val: 0.4633 loss_test: 1.3198 acc_test: 0.6930 time: 0.0838s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0454 acc_val: 0.4767 loss_test: 1.3485 acc_test: 0.6990 time: 0.0894s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.4867 loss_test: 1.3847 acc_test: 0.6980 time: 0.0980s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1685 acc_val: 0.4867 loss_test: 1.4313 acc_test: 0.6970 time: 0.1332s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1557 acc_val: 0.5133 loss_test: 1.4582 acc_test: 0.6990 time: 0.0792s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2097 acc_val: 0.5100 loss_test: 1.4934 acc_test: 0.6980 time: 0.0695s
Optimization Finished!
Total time elapsed: 47.5343s, best testing performance  0.702000, minimun loss  1.039526
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8112 acc_train: 0.1583 loss_val: 1.8090 acc_val: 0.1733 loss_test: 1.7075 acc_test: 0.4310 time: 0.1092s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7460 acc_val: 0.4000 loss_test: 1.1339 acc_test: 0.6700 time: 0.0713s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.6373 acc_val: 0.4533 loss_test: 1.1064 acc_test: 0.6920 time: 0.0778s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.7182 acc_val: 0.4400 loss_test: 1.1632 acc_test: 0.6870 time: 0.1059s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8965 acc_val: 0.4467 loss_test: 1.2512 acc_test: 0.6910 time: 0.1114s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9455 acc_val: 0.4733 loss_test: 1.2930 acc_test: 0.6940 time: 0.0952s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0161 acc_val: 0.4800 loss_test: 1.3334 acc_test: 0.6920 time: 0.1229s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0424 acc_val: 0.4967 loss_test: 1.3592 acc_test: 0.6940 time: 0.1060s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0746 acc_val: 0.5067 loss_test: 1.3902 acc_test: 0.6950 time: 0.0902s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1317 acc_val: 0.5067 loss_test: 1.4205 acc_test: 0.7000 time: 0.0807s
Optimization Finished!
Total time elapsed: 47.2872s, best testing performance  0.701000, minimun loss  1.022763
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8196 acc_train: 0.0917 loss_val: 1.8065 acc_val: 0.0967 loss_test: 1.6787 acc_test: 0.3880 time: 0.0793s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7840 acc_val: 0.3900 loss_test: 1.1434 acc_test: 0.6660 time: 0.0864s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7163 acc_val: 0.4267 loss_test: 1.1376 acc_test: 0.6900 time: 0.1062s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.7306 acc_val: 0.4600 loss_test: 1.1698 acc_test: 0.6930 time: 0.1209s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9117 acc_val: 0.4367 loss_test: 1.2492 acc_test: 0.6910 time: 0.0958s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9854 acc_val: 0.4600 loss_test: 1.3011 acc_test: 0.6920 time: 0.0867s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0482 acc_val: 0.4700 loss_test: 1.3464 acc_test: 0.6920 time: 0.0862s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0725 acc_val: 0.4967 loss_test: 1.3828 acc_test: 0.6910 time: 0.1157s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1009 acc_val: 0.5133 loss_test: 1.4122 acc_test: 0.6970 time: 0.0906s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1245 acc_val: 0.5167 loss_test: 1.4494 acc_test: 0.6960 time: 0.0980s
Optimization Finished!
Total time elapsed: 49.0352s, best testing performance  0.698000, minimun loss  1.013156
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7850 acc_train: 0.1917 loss_val: 1.7913 acc_val: 0.1300 loss_test: 1.6701 acc_test: 0.5050 time: 0.1039s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.9102 acc_val: 0.3500 loss_test: 1.1781 acc_test: 0.6560 time: 0.0710s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8613 acc_val: 0.4133 loss_test: 1.1751 acc_test: 0.6770 time: 0.0743s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8859 acc_val: 0.4333 loss_test: 1.2138 acc_test: 0.6770 time: 0.0717s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9541 acc_val: 0.4400 loss_test: 1.2587 acc_test: 0.6850 time: 0.1139s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0137 acc_val: 0.4733 loss_test: 1.3072 acc_test: 0.6920 time: 0.1100s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0630 acc_val: 0.4867 loss_test: 1.3453 acc_test: 0.6920 time: 0.1138s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0772 acc_val: 0.4967 loss_test: 1.3721 acc_test: 0.6930 time: 0.1098s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1232 acc_val: 0.4867 loss_test: 1.4058 acc_test: 0.6920 time: 0.0770s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1680 acc_val: 0.4833 loss_test: 1.4443 acc_test: 0.6930 time: 0.1080s
Optimization Finished!
Total time elapsed: 44.3006s, best testing performance  0.697000, minimun loss  1.033769
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7861 acc_train: 0.2500 loss_val: 1.7989 acc_val: 0.1667 loss_test: 1.6804 acc_test: 0.4770 time: 0.1141s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.7985 acc_val: 0.4067 loss_test: 1.1290 acc_test: 0.6730 time: 0.0952s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7377 acc_val: 0.4467 loss_test: 1.1274 acc_test: 0.6890 time: 0.1325s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8009 acc_val: 0.4333 loss_test: 1.1823 acc_test: 0.6870 time: 0.0871s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8779 acc_val: 0.4567 loss_test: 1.2442 acc_test: 0.6930 time: 0.1153s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9646 acc_val: 0.4633 loss_test: 1.2984 acc_test: 0.6990 time: 0.0859s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0042 acc_val: 0.4900 loss_test: 1.3405 acc_test: 0.6940 time: 0.1155s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0473 acc_val: 0.5033 loss_test: 1.3796 acc_test: 0.6970 time: 0.0825s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0562 acc_val: 0.5067 loss_test: 1.4097 acc_test: 0.6950 time: 0.1010s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.0578 acc_val: 0.5033 loss_test: 1.4445 acc_test: 0.6930 time: 0.0840s
Optimization Finished!
Total time elapsed: 49.6859s, best testing performance  0.702000, minimun loss  1.028883
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 3, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7996 acc_train: 0.1417 loss_val: 1.8203 acc_val: 0.1067 loss_test: 1.6787 acc_test: 0.4600 time: 0.1025s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.9543 acc_val: 0.3467 loss_test: 1.2042 acc_test: 0.6490 time: 0.0695s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8539 acc_val: 0.4100 loss_test: 1.1853 acc_test: 0.6680 time: 0.0706s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8363 acc_val: 0.4133 loss_test: 1.2094 acc_test: 0.6770 time: 0.0717s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9375 acc_val: 0.4400 loss_test: 1.2725 acc_test: 0.6860 time: 0.0710s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0172 acc_val: 0.4667 loss_test: 1.3244 acc_test: 0.6900 time: 0.0717s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1095 acc_val: 0.4867 loss_test: 1.3732 acc_test: 0.6920 time: 0.1089s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1421 acc_val: 0.5067 loss_test: 1.4114 acc_test: 0.6940 time: 0.0761s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2283 acc_val: 0.4933 loss_test: 1.4490 acc_test: 0.6960 time: 0.0903s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2677 acc_val: 0.5000 loss_test: 1.4860 acc_test: 0.6990 time: 0.1250s
Optimization Finished!
Total time elapsed: 41.8727s, best testing performance  0.703000, minimun loss  1.018451
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1833 loss_val: 1.8072 acc_val: 0.1133 loss_test: 1.6989 acc_test: 0.4520 time: 0.0817s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7795 acc_val: 0.3733 loss_test: 1.1559 acc_test: 0.6520 time: 0.0902s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7120 acc_val: 0.4400 loss_test: 1.1357 acc_test: 0.6700 time: 0.1013s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7611 acc_val: 0.4600 loss_test: 1.1704 acc_test: 0.6770 time: 0.0962s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9007 acc_val: 0.4533 loss_test: 1.2622 acc_test: 0.6830 time: 0.1166s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0400 acc_val: 0.4833 loss_test: 1.3146 acc_test: 0.6970 time: 0.1188s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1147 acc_val: 0.4967 loss_test: 1.3718 acc_test: 0.6940 time: 0.1052s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1649 acc_val: 0.4967 loss_test: 1.4033 acc_test: 0.6950 time: 0.0981s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2026 acc_val: 0.5067 loss_test: 1.4292 acc_test: 0.6980 time: 0.0981s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2180 acc_val: 0.5033 loss_test: 1.4520 acc_test: 0.6930 time: 0.0948s
Optimization Finished!
Total time elapsed: 53.6180s, best testing performance  0.701000, minimun loss  1.004128
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7843 acc_train: 0.1583 loss_val: 1.8003 acc_val: 0.3300 loss_test: 1.6951 acc_test: 0.5030 time: 0.1066s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7910 acc_val: 0.3800 loss_test: 1.1517 acc_test: 0.6620 time: 0.0745s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7615 acc_val: 0.4233 loss_test: 1.1394 acc_test: 0.6750 time: 0.0771s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8114 acc_val: 0.4467 loss_test: 1.1870 acc_test: 0.6730 time: 0.0765s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.7881 acc_val: 0.4767 loss_test: 1.2092 acc_test: 0.6790 time: 0.0766s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9564 acc_val: 0.4967 loss_test: 1.2952 acc_test: 0.6890 time: 0.0769s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0312 acc_val: 0.4967 loss_test: 1.3525 acc_test: 0.6930 time: 0.1137s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0895 acc_val: 0.5067 loss_test: 1.3878 acc_test: 0.6940 time: 0.0865s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0922 acc_val: 0.5033 loss_test: 1.4186 acc_test: 0.6970 time: 0.1124s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1176 acc_val: 0.5100 loss_test: 1.4417 acc_test: 0.6920 time: 0.1160s
Optimization Finished!
Total time elapsed: 45.0090s, best testing performance  0.699000, minimun loss  0.991501
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7816 acc_train: 0.2083 loss_val: 1.8141 acc_val: 0.1467 loss_test: 1.6942 acc_test: 0.4740 time: 0.1286s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9085 acc_val: 0.3467 loss_test: 1.2025 acc_test: 0.6490 time: 0.0907s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9074 acc_val: 0.4067 loss_test: 1.1972 acc_test: 0.6640 time: 0.1237s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9096 acc_val: 0.4567 loss_test: 1.2201 acc_test: 0.6730 time: 0.0922s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8984 acc_val: 0.4867 loss_test: 1.2577 acc_test: 0.6790 time: 0.1039s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9820 acc_val: 0.5000 loss_test: 1.3106 acc_test: 0.6960 time: 0.0888s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0693 acc_val: 0.4967 loss_test: 1.3598 acc_test: 0.6950 time: 0.0925s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.5033 loss_test: 1.3897 acc_test: 0.6980 time: 0.1182s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1189 acc_val: 0.5100 loss_test: 1.4170 acc_test: 0.6990 time: 0.0832s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1906 acc_val: 0.5067 loss_test: 1.4506 acc_test: 0.7000 time: 0.1056s
Optimization Finished!
Total time elapsed: 53.5462s, best testing performance  0.704000, minimun loss  1.032065
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8037 acc_train: 0.1333 loss_val: 1.7989 acc_val: 0.0967 loss_test: 1.7122 acc_test: 0.3990 time: 0.1036s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8358 acc_val: 0.3600 loss_test: 1.1595 acc_test: 0.6540 time: 0.0744s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7562 acc_val: 0.4133 loss_test: 1.1351 acc_test: 0.6740 time: 0.0771s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8062 acc_val: 0.4500 loss_test: 1.1815 acc_test: 0.6770 time: 0.0777s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9629 acc_val: 0.4367 loss_test: 1.2641 acc_test: 0.6870 time: 0.0766s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0355 acc_val: 0.4567 loss_test: 1.3183 acc_test: 0.6890 time: 0.0775s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0810 acc_val: 0.4867 loss_test: 1.3549 acc_test: 0.6950 time: 0.1111s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0927 acc_val: 0.5033 loss_test: 1.3846 acc_test: 0.6990 time: 0.0878s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1458 acc_val: 0.5067 loss_test: 1.4243 acc_test: 0.6980 time: 0.0954s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1651 acc_val: 0.5133 loss_test: 1.4524 acc_test: 0.7000 time: 0.0903s
Optimization Finished!
Total time elapsed: 45.1472s, best testing performance  0.704000, minimun loss  1.002020
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8003 acc_train: 0.1250 loss_val: 1.8036 acc_val: 0.1800 loss_test: 1.7078 acc_test: 0.4160 time: 0.1193s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.9996 acc_val: 0.3300 loss_test: 1.2377 acc_test: 0.6430 time: 0.0864s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8853 acc_val: 0.4033 loss_test: 1.1951 acc_test: 0.6640 time: 0.1125s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9557 acc_val: 0.4233 loss_test: 1.2503 acc_test: 0.6680 time: 0.1001s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9803 acc_val: 0.4333 loss_test: 1.2922 acc_test: 0.6700 time: 0.0995s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0999 acc_val: 0.4767 loss_test: 1.3520 acc_test: 0.6880 time: 0.0981s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1450 acc_val: 0.4933 loss_test: 1.3753 acc_test: 0.6950 time: 0.0983s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1639 acc_val: 0.5000 loss_test: 1.4046 acc_test: 0.6950 time: 0.1114s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2083 acc_val: 0.4933 loss_test: 1.4359 acc_test: 0.6940 time: 0.1037s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2207 acc_val: 0.5000 loss_test: 1.4612 acc_test: 0.6900 time: 0.0894s
Optimization Finished!
Total time elapsed: 53.2185s, best testing performance  0.696000, minimun loss  1.013792
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8036 acc_train: 0.1250 loss_val: 1.8065 acc_val: 0.1467 loss_test: 1.7107 acc_test: 0.4470 time: 0.1025s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7792 acc_val: 0.3767 loss_test: 1.1560 acc_test: 0.6570 time: 0.0741s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8499 acc_val: 0.4033 loss_test: 1.1675 acc_test: 0.6770 time: 0.0770s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9071 acc_val: 0.4100 loss_test: 1.2063 acc_test: 0.6820 time: 0.0796s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9419 acc_val: 0.4233 loss_test: 1.2574 acc_test: 0.6830 time: 0.0766s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9891 acc_val: 0.4700 loss_test: 1.3124 acc_test: 0.6900 time: 0.0783s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0505 acc_val: 0.4967 loss_test: 1.3533 acc_test: 0.6980 time: 0.1139s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1060 acc_val: 0.5067 loss_test: 1.3866 acc_test: 0.6990 time: 0.1132s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1556 acc_val: 0.5067 loss_test: 1.4155 acc_test: 0.6970 time: 0.1015s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1791 acc_val: 0.5133 loss_test: 1.4438 acc_test: 0.7000 time: 0.0948s
Optimization Finished!
Total time elapsed: 44.9602s, best testing performance  0.705000, minimun loss  1.003350
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7844 acc_train: 0.1667 loss_val: 1.7955 acc_val: 0.1300 loss_test: 1.6945 acc_test: 0.4460 time: 0.1116s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7344 acc_val: 0.3867 loss_test: 1.1449 acc_test: 0.6590 time: 0.1059s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7669 acc_val: 0.4333 loss_test: 1.1431 acc_test: 0.6770 time: 0.0875s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.7984 acc_val: 0.4500 loss_test: 1.1765 acc_test: 0.6890 time: 0.1195s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8629 acc_val: 0.4567 loss_test: 1.2441 acc_test: 0.6850 time: 0.1032s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9079 acc_val: 0.4633 loss_test: 1.2876 acc_test: 0.6930 time: 0.1439s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9624 acc_val: 0.4733 loss_test: 1.3349 acc_test: 0.6980 time: 0.1057s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0325 acc_val: 0.5000 loss_test: 1.3741 acc_test: 0.6990 time: 0.1071s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1052 acc_val: 0.5000 loss_test: 1.4075 acc_test: 0.6990 time: 0.1490s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1264 acc_val: 0.5000 loss_test: 1.4306 acc_test: 0.7000 time: 0.1154s
Optimization Finished!
Total time elapsed: 53.0502s, best testing performance  0.702000, minimun loss  0.992903
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8085 acc_train: 0.0917 loss_val: 1.8103 acc_val: 0.1700 loss_test: 1.7240 acc_test: 0.3380 time: 0.1326s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7762 acc_val: 0.3733 loss_test: 1.1362 acc_test: 0.6610 time: 0.0744s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8913 acc_val: 0.4067 loss_test: 1.1685 acc_test: 0.6760 time: 0.0763s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9312 acc_val: 0.4267 loss_test: 1.2121 acc_test: 0.6780 time: 0.0764s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8644 acc_val: 0.4367 loss_test: 1.2234 acc_test: 0.6960 time: 0.0762s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9183 acc_val: 0.4700 loss_test: 1.2905 acc_test: 0.6930 time: 0.0766s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0416 acc_val: 0.4900 loss_test: 1.3573 acc_test: 0.6950 time: 0.1127s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0699 acc_val: 0.5000 loss_test: 1.3916 acc_test: 0.6950 time: 0.1158s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1040 acc_val: 0.5067 loss_test: 1.4224 acc_test: 0.6980 time: 0.1232s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1651 acc_val: 0.5067 loss_test: 1.4522 acc_test: 0.6980 time: 0.0992s
Optimization Finished!
Total time elapsed: 44.6909s, best testing performance  0.702000, minimun loss  0.994751
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7933 acc_train: 0.1417 loss_val: 1.7949 acc_val: 0.1567 loss_test: 1.7041 acc_test: 0.4940 time: 0.1190s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7684 acc_val: 0.4000 loss_test: 1.1474 acc_test: 0.6600 time: 0.1448s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9053 acc_val: 0.4000 loss_test: 1.1996 acc_test: 0.6610 time: 0.1028s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9912 acc_val: 0.3900 loss_test: 1.2517 acc_test: 0.6640 time: 0.1121s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0774 acc_val: 0.4100 loss_test: 1.3150 acc_test: 0.6760 time: 0.0860s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0855 acc_val: 0.4600 loss_test: 1.3534 acc_test: 0.6840 time: 0.0939s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1193 acc_val: 0.4833 loss_test: 1.3879 acc_test: 0.6920 time: 0.1228s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1378 acc_val: 0.4967 loss_test: 1.4084 acc_test: 0.6920 time: 0.1210s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1687 acc_val: 0.5000 loss_test: 1.4451 acc_test: 0.6920 time: 0.1172s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2350 acc_val: 0.4967 loss_test: 1.4782 acc_test: 0.6950 time: 0.0953s
Optimization Finished!
Total time elapsed: 53.5030s, best testing performance  0.700000, minimun loss  0.991000
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8102 acc_train: 0.1500 loss_val: 1.8169 acc_val: 0.1067 loss_test: 1.7134 acc_test: 0.3710 time: 0.1073s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7408 acc_val: 0.3767 loss_test: 1.1388 acc_test: 0.6620 time: 0.0782s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8129 acc_val: 0.4033 loss_test: 1.1613 acc_test: 0.6830 time: 0.0769s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8333 acc_val: 0.4133 loss_test: 1.1976 acc_test: 0.6830 time: 0.0795s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8849 acc_val: 0.4433 loss_test: 1.2590 acc_test: 0.6870 time: 0.0772s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0075 acc_val: 0.4667 loss_test: 1.3239 acc_test: 0.6910 time: 0.0769s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1045 acc_val: 0.4700 loss_test: 1.3709 acc_test: 0.6880 time: 0.0779s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1444 acc_val: 0.4800 loss_test: 1.3998 acc_test: 0.6930 time: 0.0866s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2227 acc_val: 0.4900 loss_test: 1.4423 acc_test: 0.6930 time: 0.0935s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1992 acc_val: 0.4933 loss_test: 1.4573 acc_test: 0.6990 time: 0.1050s
Optimization Finished!
Total time elapsed: 44.5534s, best testing performance  0.700000, minimun loss  0.994611
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1583 loss_val: 1.8011 acc_val: 0.1867 loss_test: 1.6869 acc_test: 0.4990 time: 0.1004s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8081 acc_val: 0.4200 loss_test: 1.1501 acc_test: 0.6700 time: 0.1106s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8392 acc_val: 0.4333 loss_test: 1.1669 acc_test: 0.6810 time: 0.1366s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9201 acc_val: 0.4400 loss_test: 1.2164 acc_test: 0.6850 time: 0.1071s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9636 acc_val: 0.4700 loss_test: 1.2608 acc_test: 0.6910 time: 0.0838s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9962 acc_val: 0.4800 loss_test: 1.2959 acc_test: 0.6960 time: 0.1491s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0459 acc_val: 0.4933 loss_test: 1.3383 acc_test: 0.6950 time: 0.1093s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0927 acc_val: 0.5000 loss_test: 1.3772 acc_test: 0.6950 time: 0.1203s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1416 acc_val: 0.5033 loss_test: 1.4136 acc_test: 0.6970 time: 0.0954s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1623 acc_val: 0.5033 loss_test: 1.4426 acc_test: 0.6930 time: 0.1947s
Optimization Finished!
Total time elapsed: 53.5502s, best testing performance  0.700000, minimun loss  1.023191
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7946 acc_train: 0.1917 loss_val: 1.8004 acc_val: 0.1600 loss_test: 1.6909 acc_test: 0.5070 time: 0.1001s
Epoch: 0051 loss_train: 0.0138 acc_train: 1.0000 loss_val: 1.7419 acc_val: 0.3867 loss_test: 1.1209 acc_test: 0.6650 time: 0.0767s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7593 acc_val: 0.4067 loss_test: 1.1455 acc_test: 0.6850 time: 0.0764s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9002 acc_val: 0.4433 loss_test: 1.2140 acc_test: 0.6880 time: 0.0771s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9713 acc_val: 0.4733 loss_test: 1.2629 acc_test: 0.6930 time: 0.0766s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9801 acc_val: 0.4867 loss_test: 1.2989 acc_test: 0.6940 time: 0.0775s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9896 acc_val: 0.5000 loss_test: 1.3350 acc_test: 0.6940 time: 0.0781s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0045 acc_val: 0.5033 loss_test: 1.3681 acc_test: 0.6990 time: 0.1158s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0229 acc_val: 0.5167 loss_test: 1.4010 acc_test: 0.6960 time: 0.1477s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0566 acc_val: 0.5167 loss_test: 1.4350 acc_test: 0.6970 time: 0.1015s
Optimization Finished!
Total time elapsed: 44.6475s, best testing performance  0.701000, minimun loss  1.012394
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7828 acc_train: 0.1917 loss_val: 1.8112 acc_val: 0.1000 loss_test: 1.6756 acc_test: 0.4230 time: 0.1271s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8442 acc_val: 0.3833 loss_test: 1.1729 acc_test: 0.6500 time: 0.1528s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8493 acc_val: 0.4067 loss_test: 1.1803 acc_test: 0.6700 time: 0.0920s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8692 acc_val: 0.4033 loss_test: 1.2119 acc_test: 0.6790 time: 0.1084s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9277 acc_val: 0.4533 loss_test: 1.2612 acc_test: 0.6890 time: 0.1024s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9824 acc_val: 0.4700 loss_test: 1.2991 acc_test: 0.6930 time: 0.0959s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0352 acc_val: 0.4800 loss_test: 1.3393 acc_test: 0.6960 time: 0.1280s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0827 acc_val: 0.4967 loss_test: 1.3743 acc_test: 0.6960 time: 0.1202s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0867 acc_val: 0.5000 loss_test: 1.4015 acc_test: 0.7000 time: 0.0962s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1071 acc_val: 0.5100 loss_test: 1.4263 acc_test: 0.7010 time: 0.1015s
Optimization Finished!
Total time elapsed: 52.8888s, best testing performance  0.704000, minimun loss  1.017101
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1750 loss_val: 1.7873 acc_val: 0.2167 loss_test: 1.6931 acc_test: 0.4640 time: 0.1043s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.7483 acc_val: 0.4000 loss_test: 1.1529 acc_test: 0.6680 time: 0.0755s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7767 acc_val: 0.4367 loss_test: 1.1724 acc_test: 0.6810 time: 0.0747s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8624 acc_val: 0.4467 loss_test: 1.2241 acc_test: 0.6840 time: 0.0762s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9538 acc_val: 0.4600 loss_test: 1.2783 acc_test: 0.6880 time: 0.0768s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9749 acc_val: 0.4833 loss_test: 1.3118 acc_test: 0.6920 time: 0.0796s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0106 acc_val: 0.5033 loss_test: 1.3490 acc_test: 0.6930 time: 0.0785s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0506 acc_val: 0.5033 loss_test: 1.3865 acc_test: 0.6990 time: 0.1141s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0759 acc_val: 0.5100 loss_test: 1.4165 acc_test: 0.7020 time: 0.1220s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1064 acc_val: 0.5133 loss_test: 1.4512 acc_test: 0.6970 time: 0.1260s
Optimization Finished!
Total time elapsed: 43.9679s, best testing performance  0.703000, minimun loss  1.032491
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7989 acc_train: 0.1583 loss_val: 1.8006 acc_val: 0.1667 loss_test: 1.6882 acc_test: 0.5150 time: 0.1057s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.8709 acc_val: 0.3467 loss_test: 1.1847 acc_test: 0.6510 time: 0.0982s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8702 acc_val: 0.3867 loss_test: 1.1857 acc_test: 0.6740 time: 0.1135s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9143 acc_val: 0.4300 loss_test: 1.2202 acc_test: 0.6850 time: 0.0859s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9822 acc_val: 0.4533 loss_test: 1.2685 acc_test: 0.6950 time: 0.1014s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0231 acc_val: 0.4733 loss_test: 1.3111 acc_test: 0.6960 time: 0.0871s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0730 acc_val: 0.4900 loss_test: 1.3486 acc_test: 0.6950 time: 0.0844s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0972 acc_val: 0.4967 loss_test: 1.3819 acc_test: 0.6970 time: 0.1040s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1328 acc_val: 0.4967 loss_test: 1.4164 acc_test: 0.6970 time: 0.1032s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1821 acc_val: 0.4933 loss_test: 1.4572 acc_test: 0.6940 time: 0.1125s
Optimization Finished!
Total time elapsed: 53.5348s, best testing performance  0.701000, minimun loss  1.026570
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.2000 loss_val: 1.8039 acc_val: 0.2067 loss_test: 1.6719 acc_test: 0.5260 time: 0.0997s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8813 acc_val: 0.3667 loss_test: 1.2035 acc_test: 0.6580 time: 0.0749s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8484 acc_val: 0.4033 loss_test: 1.2072 acc_test: 0.6770 time: 0.0746s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8547 acc_val: 0.4467 loss_test: 1.2381 acc_test: 0.6860 time: 0.0778s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9122 acc_val: 0.4767 loss_test: 1.2805 acc_test: 0.6950 time: 0.0764s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9846 acc_val: 0.5033 loss_test: 1.3230 acc_test: 0.6940 time: 0.0767s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.5000 loss_test: 1.3527 acc_test: 0.6960 time: 0.0775s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0829 acc_val: 0.5000 loss_test: 1.3869 acc_test: 0.6970 time: 0.1310s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1033 acc_val: 0.5167 loss_test: 1.4223 acc_test: 0.6980 time: 0.1072s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1714 acc_val: 0.5133 loss_test: 1.4569 acc_test: 0.7010 time: 0.1148s
Optimization Finished!
Total time elapsed: 43.2163s, best testing performance  0.704000, minimun loss  1.030204
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8059 acc_train: 0.1167 loss_val: 1.8108 acc_val: 0.1967 loss_test: 1.7019 acc_test: 0.4250 time: 0.1002s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.9016 acc_val: 0.3533 loss_test: 1.1851 acc_test: 0.6510 time: 0.1089s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8427 acc_val: 0.4100 loss_test: 1.1868 acc_test: 0.6700 time: 0.1124s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9141 acc_val: 0.4500 loss_test: 1.2367 acc_test: 0.6850 time: 0.1188s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9605 acc_val: 0.4733 loss_test: 1.2776 acc_test: 0.6930 time: 0.0963s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0215 acc_val: 0.4933 loss_test: 1.3215 acc_test: 0.6960 time: 0.1001s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0164 acc_val: 0.5067 loss_test: 1.3475 acc_test: 0.6960 time: 0.1214s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0587 acc_val: 0.5133 loss_test: 1.3818 acc_test: 0.6980 time: 0.1132s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0770 acc_val: 0.5133 loss_test: 1.4122 acc_test: 0.6970 time: 0.0916s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1124 acc_val: 0.5133 loss_test: 1.4494 acc_test: 0.6960 time: 0.1442s
Optimization Finished!
Total time elapsed: 52.9203s, best testing performance  0.701000, minimun loss  1.022255
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8088 acc_train: 0.0833 loss_val: 1.7836 acc_val: 0.2033 loss_test: 1.7151 acc_test: 0.4960 time: 0.0834s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8098 acc_val: 0.3700 loss_test: 1.1797 acc_test: 0.6580 time: 0.0751s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7744 acc_val: 0.4167 loss_test: 1.1756 acc_test: 0.6810 time: 0.0749s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8144 acc_val: 0.4367 loss_test: 1.2112 acc_test: 0.6830 time: 0.0760s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9038 acc_val: 0.4767 loss_test: 1.2681 acc_test: 0.6940 time: 0.0761s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9751 acc_val: 0.4867 loss_test: 1.3123 acc_test: 0.6960 time: 0.0770s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0105 acc_val: 0.4867 loss_test: 1.3515 acc_test: 0.6980 time: 0.0793s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0555 acc_val: 0.4967 loss_test: 1.3871 acc_test: 0.7010 time: 0.0783s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1028 acc_val: 0.5033 loss_test: 1.4221 acc_test: 0.7000 time: 0.1091s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1506 acc_val: 0.5000 loss_test: 1.4582 acc_test: 0.6990 time: 0.1364s
Optimization Finished!
Total time elapsed: 42.6716s, best testing performance  0.705000, minimun loss  1.041226
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.1333 loss_val: 1.7933 acc_val: 0.1867 loss_test: 1.6799 acc_test: 0.5270 time: 0.0938s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.9352 acc_val: 0.3633 loss_test: 1.2000 acc_test: 0.6520 time: 0.1207s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8647 acc_val: 0.4167 loss_test: 1.1960 acc_test: 0.6710 time: 0.0926s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9072 acc_val: 0.4367 loss_test: 1.2385 acc_test: 0.6880 time: 0.0955s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9690 acc_val: 0.4700 loss_test: 1.2973 acc_test: 0.6910 time: 0.1216s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9772 acc_val: 0.4867 loss_test: 1.3345 acc_test: 0.6930 time: 0.1063s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9988 acc_val: 0.5000 loss_test: 1.3751 acc_test: 0.6940 time: 0.1225s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0656 acc_val: 0.5000 loss_test: 1.4192 acc_test: 0.7010 time: 0.1052s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.5067 loss_test: 1.4518 acc_test: 0.6970 time: 0.0916s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0959 acc_val: 0.5133 loss_test: 1.4781 acc_test: 0.6960 time: 0.1104s
Optimization Finished!
Total time elapsed: 53.3165s, best testing performance  0.702000, minimun loss  1.014947
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8112 acc_train: 0.1167 loss_val: 1.8002 acc_val: 0.1467 loss_test: 1.6991 acc_test: 0.3720 time: 0.0963s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.7181 acc_val: 0.3967 loss_test: 1.1542 acc_test: 0.6610 time: 0.0750s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.6821 acc_val: 0.4367 loss_test: 1.1561 acc_test: 0.6870 time: 0.0746s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7676 acc_val: 0.4533 loss_test: 1.2129 acc_test: 0.6890 time: 0.0748s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.8889 acc_val: 0.4767 loss_test: 1.2714 acc_test: 0.6940 time: 0.0766s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9363 acc_val: 0.4900 loss_test: 1.3093 acc_test: 0.6910 time: 0.0770s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 1.9312 acc_val: 0.5000 loss_test: 1.3364 acc_test: 0.6930 time: 0.0761s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0227 acc_val: 0.4967 loss_test: 1.3852 acc_test: 0.6910 time: 0.0777s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0369 acc_val: 0.4967 loss_test: 1.4083 acc_test: 0.6930 time: 0.0870s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.0673 acc_val: 0.4867 loss_test: 1.4440 acc_test: 0.6950 time: 0.1041s
Optimization Finished!
Total time elapsed: 42.3456s, best testing performance  0.699000, minimun loss  1.035112
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7587 acc_train: 0.3083 loss_val: 1.7987 acc_val: 0.1467 loss_test: 1.6224 acc_test: 0.5360 time: 0.0999s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.6412 acc_val: 0.4333 loss_test: 1.1212 acc_test: 0.6750 time: 0.0943s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.6585 acc_val: 0.4500 loss_test: 1.1361 acc_test: 0.6900 time: 0.1297s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.7960 acc_val: 0.4600 loss_test: 1.2054 acc_test: 0.6910 time: 0.0964s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8526 acc_val: 0.4767 loss_test: 1.2594 acc_test: 0.6960 time: 0.1033s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9785 acc_val: 0.4700 loss_test: 1.3319 acc_test: 0.7000 time: 0.0979s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0160 acc_val: 0.4867 loss_test: 1.3639 acc_test: 0.7000 time: 0.1191s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1046 acc_val: 0.5067 loss_test: 1.4077 acc_test: 0.6980 time: 0.1084s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1298 acc_val: 0.5133 loss_test: 1.4364 acc_test: 0.7020 time: 0.0875s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1635 acc_val: 0.5133 loss_test: 1.4625 acc_test: 0.7000 time: 0.0992s
Optimization Finished!
Total time elapsed: 52.6409s, best testing performance  0.704000, minimun loss  0.984752
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8034 acc_train: 0.0917 loss_val: 1.8251 acc_val: 0.1167 loss_test: 1.6720 acc_test: 0.4410 time: 0.0883s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8280 acc_val: 0.3667 loss_test: 1.1900 acc_test: 0.6580 time: 0.0757s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8846 acc_val: 0.4000 loss_test: 1.2123 acc_test: 0.6710 time: 0.0755s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9697 acc_val: 0.3967 loss_test: 1.2722 acc_test: 0.6730 time: 0.0749s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9934 acc_val: 0.4367 loss_test: 1.3037 acc_test: 0.6870 time: 0.0761s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0726 acc_val: 0.4433 loss_test: 1.3497 acc_test: 0.6880 time: 0.0791s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1044 acc_val: 0.4767 loss_test: 1.3802 acc_test: 0.6920 time: 0.0776s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1601 acc_val: 0.4867 loss_test: 1.4177 acc_test: 0.6930 time: 0.0776s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2210 acc_val: 0.5000 loss_test: 1.4487 acc_test: 0.6930 time: 0.0779s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2402 acc_val: 0.5000 loss_test: 1.4742 acc_test: 0.6920 time: 0.0922s
Optimization Finished!
Total time elapsed: 42.2253s, best testing performance  0.698000, minimun loss  1.017404
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1083 loss_val: 1.8047 acc_val: 0.1467 loss_test: 1.6715 acc_test: 0.5100 time: 0.0895s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8917 acc_val: 0.3633 loss_test: 1.2085 acc_test: 0.6560 time: 0.1128s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8189 acc_val: 0.4367 loss_test: 1.1896 acc_test: 0.6820 time: 0.0975s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9362 acc_val: 0.4400 loss_test: 1.2510 acc_test: 0.6930 time: 0.1538s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0022 acc_val: 0.4533 loss_test: 1.3013 acc_test: 0.6920 time: 0.0938s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0430 acc_val: 0.4833 loss_test: 1.3399 acc_test: 0.6920 time: 0.0855s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1011 acc_val: 0.4867 loss_test: 1.3645 acc_test: 0.6910 time: 0.1090s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0927 acc_val: 0.5000 loss_test: 1.3894 acc_test: 0.6970 time: 0.1100s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1659 acc_val: 0.5067 loss_test: 1.4285 acc_test: 0.6950 time: 0.2159s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1819 acc_val: 0.5133 loss_test: 1.4536 acc_test: 0.7010 time: 0.0963s
Optimization Finished!
Total time elapsed: 53.6344s, best testing performance  0.702000, minimun loss  1.007110
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8037 acc_train: 0.1000 loss_val: 1.7948 acc_val: 0.1467 loss_test: 1.6699 acc_test: 0.5130 time: 0.1370s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8332 acc_val: 0.3867 loss_test: 1.1721 acc_test: 0.6590 time: 0.1125s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8078 acc_val: 0.4433 loss_test: 1.1788 acc_test: 0.6770 time: 0.0748s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8730 acc_val: 0.4400 loss_test: 1.2304 acc_test: 0.6860 time: 0.0763s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8409 acc_val: 0.4700 loss_test: 1.2506 acc_test: 0.6950 time: 0.0747s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0412 acc_val: 0.4867 loss_test: 1.3475 acc_test: 0.6910 time: 0.0765s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0711 acc_val: 0.4967 loss_test: 1.3729 acc_test: 0.6920 time: 0.0773s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1322 acc_val: 0.5033 loss_test: 1.4144 acc_test: 0.6940 time: 0.0772s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2058 acc_val: 0.4967 loss_test: 1.4562 acc_test: 0.6950 time: 0.0789s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2579 acc_val: 0.5000 loss_test: 1.4949 acc_test: 0.6990 time: 0.1054s
Optimization Finished!
Total time elapsed: 42.4535s, best testing performance  0.702000, minimun loss  1.003963
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8066 acc_train: 0.1167 loss_val: 1.8347 acc_val: 0.1800 loss_test: 1.6913 acc_test: 0.5010 time: 0.0945s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8301 acc_val: 0.3600 loss_test: 1.1812 acc_test: 0.6580 time: 0.1027s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7880 acc_val: 0.4100 loss_test: 1.1756 acc_test: 0.6830 time: 0.0916s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8886 acc_val: 0.4400 loss_test: 1.2352 acc_test: 0.6830 time: 0.1222s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9425 acc_val: 0.4567 loss_test: 1.2877 acc_test: 0.6870 time: 0.0975s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0139 acc_val: 0.4767 loss_test: 1.3251 acc_test: 0.6940 time: 0.1251s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0745 acc_val: 0.4800 loss_test: 1.3629 acc_test: 0.6950 time: 0.1154s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1194 acc_val: 0.5067 loss_test: 1.3949 acc_test: 0.6930 time: 0.1096s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1243 acc_val: 0.5033 loss_test: 1.4110 acc_test: 0.6940 time: 0.1157s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1848 acc_val: 0.5100 loss_test: 1.4407 acc_test: 0.6930 time: 0.1135s
Optimization Finished!
Total time elapsed: 52.8489s, best testing performance  0.701000, minimun loss  0.996648
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8117 acc_train: 0.1083 loss_val: 1.8080 acc_val: 0.1200 loss_test: 1.6907 acc_test: 0.4540 time: 0.1362s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.7502 acc_val: 0.4033 loss_test: 1.1501 acc_test: 0.6550 time: 0.0955s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7015 acc_val: 0.4467 loss_test: 1.1451 acc_test: 0.6790 time: 0.0754s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8010 acc_val: 0.4400 loss_test: 1.2074 acc_test: 0.6850 time: 0.0749s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8974 acc_val: 0.4633 loss_test: 1.2565 acc_test: 0.6930 time: 0.0748s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9892 acc_val: 0.4900 loss_test: 1.3041 acc_test: 0.6960 time: 0.0774s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0427 acc_val: 0.4967 loss_test: 1.3398 acc_test: 0.6990 time: 0.0769s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0736 acc_val: 0.5033 loss_test: 1.3749 acc_test: 0.6980 time: 0.0801s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1007 acc_val: 0.4933 loss_test: 1.4059 acc_test: 0.6970 time: 0.0770s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1701 acc_val: 0.5033 loss_test: 1.4499 acc_test: 0.7000 time: 0.0950s
Optimization Finished!
Total time elapsed: 42.6041s, best testing performance  0.704000, minimun loss  1.015509
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7857 acc_train: 0.1917 loss_val: 1.7736 acc_val: 0.2167 loss_test: 1.6728 acc_test: 0.5520 time: 0.1055s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7703 acc_val: 0.4033 loss_test: 1.1404 acc_test: 0.6650 time: 0.0926s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7743 acc_val: 0.4500 loss_test: 1.1561 acc_test: 0.6910 time: 0.1154s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8582 acc_val: 0.4367 loss_test: 1.2164 acc_test: 0.6870 time: 0.0909s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9450 acc_val: 0.4600 loss_test: 1.2682 acc_test: 0.6930 time: 0.0965s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0114 acc_val: 0.4667 loss_test: 1.3127 acc_test: 0.6940 time: 0.1256s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0429 acc_val: 0.4900 loss_test: 1.3474 acc_test: 0.6970 time: 0.0948s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0769 acc_val: 0.5000 loss_test: 1.3844 acc_test: 0.7030 time: 0.1338s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1751 acc_val: 0.5067 loss_test: 1.4317 acc_test: 0.7000 time: 0.1012s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1968 acc_val: 0.5033 loss_test: 1.4678 acc_test: 0.7010 time: 0.0888s
Optimization Finished!
Total time elapsed: 53.5482s, best testing performance  0.704000, minimun loss  1.000948
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7922 acc_train: 0.1583 loss_val: 1.8087 acc_val: 0.1533 loss_test: 1.6661 acc_test: 0.4900 time: 0.1246s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.9085 acc_val: 0.3533 loss_test: 1.2184 acc_test: 0.6560 time: 0.1212s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8684 acc_val: 0.4167 loss_test: 1.2118 acc_test: 0.6710 time: 0.0752s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8567 acc_val: 0.4500 loss_test: 1.2338 acc_test: 0.6850 time: 0.0751s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9283 acc_val: 0.4733 loss_test: 1.2806 acc_test: 0.6970 time: 0.0764s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9915 acc_val: 0.4800 loss_test: 1.3211 acc_test: 0.6920 time: 0.0750s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0070 acc_val: 0.5000 loss_test: 1.3495 acc_test: 0.6960 time: 0.0799s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0269 acc_val: 0.5133 loss_test: 1.3828 acc_test: 0.6980 time: 0.0802s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.5167 loss_test: 1.4136 acc_test: 0.6980 time: 0.0769s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1164 acc_val: 0.5100 loss_test: 1.4416 acc_test: 0.6980 time: 0.0785s
Optimization Finished!
Total time elapsed: 42.1340s, best testing performance  0.701000, minimun loss  1.057958
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7915 acc_train: 0.1250 loss_val: 1.7981 acc_val: 0.1800 loss_test: 1.6811 acc_test: 0.5090 time: 0.0983s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.7296 acc_val: 0.3900 loss_test: 1.1286 acc_test: 0.6660 time: 0.1268s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7689 acc_val: 0.4467 loss_test: 1.1478 acc_test: 0.6880 time: 0.1016s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8953 acc_val: 0.4400 loss_test: 1.2097 acc_test: 0.6900 time: 0.0964s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9496 acc_val: 0.4567 loss_test: 1.2567 acc_test: 0.6940 time: 0.0959s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9632 acc_val: 0.4733 loss_test: 1.2906 acc_test: 0.6920 time: 0.1098s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0262 acc_val: 0.4933 loss_test: 1.3312 acc_test: 0.6910 time: 0.1125s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0499 acc_val: 0.5000 loss_test: 1.3609 acc_test: 0.6990 time: 0.1007s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0884 acc_val: 0.4967 loss_test: 1.4020 acc_test: 0.6970 time: 0.1077s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1276 acc_val: 0.5033 loss_test: 1.4288 acc_test: 0.7000 time: 0.0939s
Optimization Finished!
Total time elapsed: 53.3847s, best testing performance  0.705000, minimun loss  1.010353
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7977 acc_train: 0.1167 loss_val: 1.7542 acc_val: 0.2867 loss_test: 1.6793 acc_test: 0.5480 time: 0.1082s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.7963 acc_val: 0.3833 loss_test: 1.1683 acc_test: 0.6530 time: 0.1100s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8057 acc_val: 0.4267 loss_test: 1.1872 acc_test: 0.6710 time: 0.0942s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8885 acc_val: 0.4200 loss_test: 1.2381 acc_test: 0.6860 time: 0.0744s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9630 acc_val: 0.4700 loss_test: 1.2854 acc_test: 0.6930 time: 0.0750s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0394 acc_val: 0.4800 loss_test: 1.3311 acc_test: 0.6940 time: 0.0746s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0911 acc_val: 0.5000 loss_test: 1.3762 acc_test: 0.7000 time: 0.0762s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1050 acc_val: 0.5067 loss_test: 1.4054 acc_test: 0.7010 time: 0.0768s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1866 acc_val: 0.5133 loss_test: 1.4513 acc_test: 0.6960 time: 0.0793s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2053 acc_val: 0.5100 loss_test: 1.4860 acc_test: 0.6940 time: 0.0799s
Optimization Finished!
Total time elapsed: 42.1670s, best testing performance  0.704000, minimun loss  1.019348
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8254 acc_train: 0.0917 loss_val: 1.8037 acc_val: 0.1533 loss_test: 1.7099 acc_test: 0.4110 time: 0.0816s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.7841 acc_val: 0.3967 loss_test: 1.1563 acc_test: 0.6710 time: 0.0849s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8009 acc_val: 0.4267 loss_test: 1.1776 acc_test: 0.6820 time: 0.1133s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8780 acc_val: 0.4367 loss_test: 1.2294 acc_test: 0.6890 time: 0.1062s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9621 acc_val: 0.4633 loss_test: 1.2782 acc_test: 0.6880 time: 0.0889s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0045 acc_val: 0.4767 loss_test: 1.3170 acc_test: 0.6930 time: 0.1055s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0330 acc_val: 0.4933 loss_test: 1.3509 acc_test: 0.6930 time: 0.1132s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0622 acc_val: 0.5067 loss_test: 1.3844 acc_test: 0.6970 time: 0.0970s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1014 acc_val: 0.5033 loss_test: 1.4173 acc_test: 0.6940 time: 0.1133s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1091 acc_val: 0.5100 loss_test: 1.4404 acc_test: 0.6970 time: 0.1070s
Optimization Finished!
Total time elapsed: 53.7434s, best testing performance  0.699000, minimun loss  1.025526
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8040 acc_train: 0.1250 loss_val: 1.7959 acc_val: 0.1833 loss_test: 1.6937 acc_test: 0.5130 time: 0.1050s
Epoch: 0051 loss_train: 0.0136 acc_train: 1.0000 loss_val: 1.8255 acc_val: 0.3933 loss_test: 1.1528 acc_test: 0.6660 time: 0.0953s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7998 acc_val: 0.4333 loss_test: 1.1572 acc_test: 0.6820 time: 0.1369s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8807 acc_val: 0.4433 loss_test: 1.2091 acc_test: 0.6880 time: 0.0753s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9399 acc_val: 0.4600 loss_test: 1.2558 acc_test: 0.6900 time: 0.0757s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9859 acc_val: 0.4733 loss_test: 1.3021 acc_test: 0.6940 time: 0.0743s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0199 acc_val: 0.4800 loss_test: 1.3384 acc_test: 0.6930 time: 0.0765s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0903 acc_val: 0.4967 loss_test: 1.3851 acc_test: 0.6970 time: 0.0780s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1335 acc_val: 0.5067 loss_test: 1.4196 acc_test: 0.6970 time: 0.0764s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1938 acc_val: 0.5033 loss_test: 1.4596 acc_test: 0.6980 time: 0.0788s
Optimization Finished!
Total time elapsed: 41.9778s, best testing performance  0.703000, minimun loss  1.019109
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7992 acc_train: 0.1833 loss_val: 1.8053 acc_val: 0.1167 loss_test: 1.7058 acc_test: 0.3960 time: 0.0848s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8678 acc_val: 0.3433 loss_test: 1.1743 acc_test: 0.6550 time: 0.1049s
Epoch: 0101 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8633 acc_val: 0.4000 loss_test: 1.1823 acc_test: 0.6690 time: 0.1211s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8126 acc_val: 0.4367 loss_test: 1.1977 acc_test: 0.6830 time: 0.1389s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8885 acc_val: 0.4667 loss_test: 1.2376 acc_test: 0.6890 time: 0.1251s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9711 acc_val: 0.4733 loss_test: 1.2830 acc_test: 0.6930 time: 0.1037s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0091 acc_val: 0.4733 loss_test: 1.3167 acc_test: 0.6970 time: 0.0973s
Epoch: 0351 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0472 acc_val: 0.5000 loss_test: 1.3530 acc_test: 0.6960 time: 0.0925s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0630 acc_val: 0.5100 loss_test: 1.3835 acc_test: 0.6990 time: 0.1312s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0952 acc_val: 0.5133 loss_test: 1.4141 acc_test: 0.6960 time: 0.1122s
Optimization Finished!
Total time elapsed: 52.9701s, best testing performance  0.700000, minimun loss  1.033664
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7735 acc_train: 0.2667 loss_val: 1.7959 acc_val: 0.1800 loss_test: 1.6764 acc_test: 0.4830 time: 0.0960s
Epoch: 0051 loss_train: 0.0141 acc_train: 1.0000 loss_val: 1.7723 acc_val: 0.3867 loss_test: 1.1388 acc_test: 0.6650 time: 0.1264s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7699 acc_val: 0.4233 loss_test: 1.1503 acc_test: 0.6850 time: 0.1291s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8032 acc_val: 0.4500 loss_test: 1.1881 acc_test: 0.6940 time: 0.0752s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9128 acc_val: 0.4467 loss_test: 1.2453 acc_test: 0.6920 time: 0.0747s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9716 acc_val: 0.4700 loss_test: 1.2885 acc_test: 0.6910 time: 0.0773s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0310 acc_val: 0.4833 loss_test: 1.3336 acc_test: 0.6910 time: 0.0783s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.4967 loss_test: 1.3729 acc_test: 0.6930 time: 0.0801s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1024 acc_val: 0.5033 loss_test: 1.4020 acc_test: 0.6960 time: 0.0765s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1556 acc_val: 0.5000 loss_test: 1.4351 acc_test: 0.6960 time: 0.0776s
Optimization Finished!
Total time elapsed: 42.5574s, best testing performance  0.699000, minimun loss  1.020324
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7862 acc_train: 0.2083 loss_val: 1.8011 acc_val: 0.1600 loss_test: 1.6745 acc_test: 0.4420 time: 0.0997s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8057 acc_val: 0.3867 loss_test: 1.1982 acc_test: 0.6650 time: 0.0903s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8043 acc_val: 0.4367 loss_test: 1.1984 acc_test: 0.6780 time: 0.1097s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.4600 loss_test: 1.2263 acc_test: 0.6870 time: 0.0884s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9186 acc_val: 0.4767 loss_test: 1.2688 acc_test: 0.6910 time: 0.1102s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9554 acc_val: 0.4933 loss_test: 1.3077 acc_test: 0.6950 time: 0.0948s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9892 acc_val: 0.4967 loss_test: 1.3432 acc_test: 0.6960 time: 0.0875s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0398 acc_val: 0.5067 loss_test: 1.3818 acc_test: 0.7010 time: 0.0829s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0882 acc_val: 0.5067 loss_test: 1.4144 acc_test: 0.7000 time: 0.1225s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1382 acc_val: 0.5100 loss_test: 1.4573 acc_test: 0.7000 time: 0.0987s
Optimization Finished!
Total time elapsed: 53.0543s, best testing performance  0.705000, minimun loss  1.045480
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8285 acc_train: 0.0583 loss_val: 1.7814 acc_val: 0.2267 loss_test: 1.7123 acc_test: 0.3930 time: 0.1077s
Epoch: 0051 loss_train: 0.0150 acc_train: 1.0000 loss_val: 1.7508 acc_val: 0.3800 loss_test: 1.1297 acc_test: 0.6660 time: 0.1245s
Epoch: 0101 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7756 acc_val: 0.4400 loss_test: 1.1483 acc_test: 0.6880 time: 0.0848s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8666 acc_val: 0.4467 loss_test: 1.2107 acc_test: 0.6890 time: 0.0913s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9081 acc_val: 0.4667 loss_test: 1.2563 acc_test: 0.6950 time: 0.0749s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9597 acc_val: 0.4867 loss_test: 1.3080 acc_test: 0.6930 time: 0.0750s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0025 acc_val: 0.4867 loss_test: 1.3567 acc_test: 0.6960 time: 0.0749s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0409 acc_val: 0.4967 loss_test: 1.4007 acc_test: 0.7000 time: 0.0781s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.5033 loss_test: 1.4500 acc_test: 0.6990 time: 0.0771s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1226 acc_val: 0.5067 loss_test: 1.4816 acc_test: 0.6990 time: 0.0777s
Optimization Finished!
Total time elapsed: 43.3026s, best testing performance  0.703000, minimun loss  1.020682
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7897 acc_train: 0.1833 loss_val: 1.7920 acc_val: 0.1167 loss_test: 1.7042 acc_test: 0.4430 time: 0.1160s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8047 acc_val: 0.4100 loss_test: 1.1557 acc_test: 0.6590 time: 0.0930s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7742 acc_val: 0.4433 loss_test: 1.1550 acc_test: 0.6830 time: 0.1197s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9181 acc_val: 0.4367 loss_test: 1.2281 acc_test: 0.6830 time: 0.1209s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9934 acc_val: 0.4533 loss_test: 1.2774 acc_test: 0.6900 time: 0.1301s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0259 acc_val: 0.4867 loss_test: 1.3187 acc_test: 0.6970 time: 0.1063s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0775 acc_val: 0.5033 loss_test: 1.3674 acc_test: 0.7000 time: 0.0917s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1286 acc_val: 0.5067 loss_test: 1.4137 acc_test: 0.7000 time: 0.1244s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1562 acc_val: 0.5133 loss_test: 1.4505 acc_test: 0.7010 time: 0.1055s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.1724 acc_val: 0.5200 loss_test: 1.4796 acc_test: 0.7020 time: 0.1167s
Optimization Finished!
Total time elapsed: 53.3037s, best testing performance  0.708000, minimun loss  1.028629
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8078 acc_train: 0.1833 loss_val: 1.7936 acc_val: 0.1867 loss_test: 1.7111 acc_test: 0.4940 time: 0.0868s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8084 acc_val: 0.3767 loss_test: 1.1457 acc_test: 0.6600 time: 0.0946s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7969 acc_val: 0.4233 loss_test: 1.1499 acc_test: 0.6830 time: 0.0974s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8852 acc_val: 0.4567 loss_test: 1.2075 acc_test: 0.6920 time: 0.1159s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9524 acc_val: 0.4700 loss_test: 1.2614 acc_test: 0.6950 time: 0.0750s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9978 acc_val: 0.4700 loss_test: 1.3146 acc_test: 0.6960 time: 0.0753s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0869 acc_val: 0.4900 loss_test: 1.3817 acc_test: 0.6970 time: 0.0749s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1805 acc_val: 0.4867 loss_test: 1.4463 acc_test: 0.6950 time: 0.0796s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2595 acc_val: 0.4867 loss_test: 1.5011 acc_test: 0.6960 time: 0.0766s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.3253 acc_val: 0.4867 loss_test: 1.5453 acc_test: 0.6930 time: 0.0776s
Optimization Finished!
Total time elapsed: 43.5737s, best testing performance  0.700000, minimun loss  1.025054
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7948 acc_train: 0.1750 loss_val: 1.7884 acc_val: 0.1467 loss_test: 1.6892 acc_test: 0.5370 time: 0.1116s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.8662 acc_val: 0.3600 loss_test: 1.1830 acc_test: 0.6480 time: 0.1118s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7987 acc_val: 0.4100 loss_test: 1.1709 acc_test: 0.6810 time: 0.1217s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.9021 acc_val: 0.4267 loss_test: 1.2228 acc_test: 0.6820 time: 0.0844s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9726 acc_val: 0.4533 loss_test: 1.2694 acc_test: 0.6900 time: 0.1103s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0177 acc_val: 0.4733 loss_test: 1.3069 acc_test: 0.6960 time: 0.1133s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0402 acc_val: 0.4900 loss_test: 1.3406 acc_test: 0.6940 time: 0.0964s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0873 acc_val: 0.4967 loss_test: 1.3706 acc_test: 0.6950 time: 0.0924s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1418 acc_val: 0.5000 loss_test: 1.4073 acc_test: 0.6940 time: 0.0994s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1753 acc_val: 0.4967 loss_test: 1.4375 acc_test: 0.6950 time: 0.1276s
Optimization Finished!
Total time elapsed: 53.4116s, best testing performance  0.700000, minimun loss  1.032985
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8044 acc_train: 0.0667 loss_val: 1.7956 acc_val: 0.1233 loss_test: 1.7181 acc_test: 0.3750 time: 0.0891s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7613 acc_val: 0.4100 loss_test: 1.1552 acc_test: 0.6680 time: 0.1116s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8326 acc_val: 0.4367 loss_test: 1.1849 acc_test: 0.6840 time: 0.0926s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8905 acc_val: 0.4500 loss_test: 1.2299 acc_test: 0.6900 time: 0.0850s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9692 acc_val: 0.4700 loss_test: 1.2787 acc_test: 0.6980 time: 0.1108s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0358 acc_val: 0.4900 loss_test: 1.3248 acc_test: 0.6940 time: 0.0766s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0656 acc_val: 0.4933 loss_test: 1.3577 acc_test: 0.6960 time: 0.0755s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1380 acc_val: 0.5067 loss_test: 1.4027 acc_test: 0.6940 time: 0.0763s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1633 acc_val: 0.5067 loss_test: 1.4386 acc_test: 0.6960 time: 0.0769s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2214 acc_val: 0.5100 loss_test: 1.4775 acc_test: 0.6960 time: 0.0782s
Optimization Finished!
Total time elapsed: 44.2112s, best testing performance  0.699000, minimun loss  1.025524
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7801 acc_train: 0.2000 loss_val: 1.8103 acc_val: 0.1967 loss_test: 1.6917 acc_test: 0.5400 time: 0.1127s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8116 acc_val: 0.3933 loss_test: 1.1943 acc_test: 0.6580 time: 0.1184s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8289 acc_val: 0.4333 loss_test: 1.2064 acc_test: 0.6790 time: 0.0834s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8849 acc_val: 0.4567 loss_test: 1.2512 acc_test: 0.6840 time: 0.1113s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9483 acc_val: 0.4600 loss_test: 1.2892 acc_test: 0.6940 time: 0.1105s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0284 acc_val: 0.4867 loss_test: 1.3342 acc_test: 0.6990 time: 0.0914s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0569 acc_val: 0.5000 loss_test: 1.3652 acc_test: 0.6980 time: 0.1117s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0911 acc_val: 0.5000 loss_test: 1.3971 acc_test: 0.6990 time: 0.0870s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1372 acc_val: 0.5100 loss_test: 1.4235 acc_test: 0.7050 time: 0.0948s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.5133 loss_test: 1.4560 acc_test: 0.7050 time: 0.1046s
Optimization Finished!
Total time elapsed: 53.5511s, best testing performance  0.707000, minimun loss  1.024262
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8108 acc_train: 0.1083 loss_val: 1.8116 acc_val: 0.1467 loss_test: 1.7251 acc_test: 0.4070 time: 0.1206s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7318 acc_val: 0.4100 loss_test: 1.1561 acc_test: 0.6730 time: 0.1158s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7090 acc_val: 0.4600 loss_test: 1.1690 acc_test: 0.6930 time: 0.1371s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8168 acc_val: 0.4433 loss_test: 1.2413 acc_test: 0.6900 time: 0.1069s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.7912 acc_val: 0.4467 loss_test: 1.2626 acc_test: 0.6940 time: 0.1131s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.8972 acc_val: 0.4733 loss_test: 1.3152 acc_test: 0.6940 time: 0.0741s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 1.9806 acc_val: 0.4700 loss_test: 1.3610 acc_test: 0.7000 time: 0.0753s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0863 acc_val: 0.5067 loss_test: 1.3990 acc_test: 0.6960 time: 0.0751s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1290 acc_val: 0.5133 loss_test: 1.4324 acc_test: 0.6920 time: 0.0796s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1576 acc_val: 0.5067 loss_test: 1.4580 acc_test: 0.6910 time: 0.0801s
Optimization Finished!
Total time elapsed: 44.7896s, best testing performance  0.704000, minimun loss  1.023928
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.1083 loss_val: 1.7793 acc_val: 0.2267 loss_test: 1.6791 acc_test: 0.4740 time: 0.1135s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7912 acc_val: 0.3933 loss_test: 1.1908 acc_test: 0.6590 time: 0.1216s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7405 acc_val: 0.4300 loss_test: 1.1847 acc_test: 0.6780 time: 0.0894s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8071 acc_val: 0.4633 loss_test: 1.2319 acc_test: 0.6850 time: 0.1616s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8185 acc_val: 0.4833 loss_test: 1.2587 acc_test: 0.6980 time: 0.0932s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9505 acc_val: 0.4733 loss_test: 1.3205 acc_test: 0.6980 time: 0.0962s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0286 acc_val: 0.5033 loss_test: 1.3598 acc_test: 0.7010 time: 0.1138s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0742 acc_val: 0.5000 loss_test: 1.3843 acc_test: 0.6970 time: 0.1049s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1295 acc_val: 0.5067 loss_test: 1.4105 acc_test: 0.6980 time: 0.0903s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1502 acc_val: 0.5033 loss_test: 1.4382 acc_test: 0.7020 time: 0.1093s
Optimization Finished!
Total time elapsed: 53.1708s, best testing performance  0.704000, minimun loss  1.009891
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7686 acc_train: 0.2333 loss_val: 1.8163 acc_val: 0.1400 loss_test: 1.6850 acc_test: 0.5380 time: 0.0881s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8818 acc_val: 0.3833 loss_test: 1.2089 acc_test: 0.6580 time: 0.1238s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8338 acc_val: 0.4133 loss_test: 1.2060 acc_test: 0.6830 time: 0.1316s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8629 acc_val: 0.4367 loss_test: 1.2426 acc_test: 0.6860 time: 0.1140s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9132 acc_val: 0.4733 loss_test: 1.2898 acc_test: 0.6920 time: 0.1130s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0006 acc_val: 0.4967 loss_test: 1.3323 acc_test: 0.6970 time: 0.1408s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0453 acc_val: 0.5033 loss_test: 1.3562 acc_test: 0.6980 time: 0.0750s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1342 acc_val: 0.4967 loss_test: 1.4002 acc_test: 0.6970 time: 0.0752s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1857 acc_val: 0.5067 loss_test: 1.4357 acc_test: 0.6990 time: 0.0755s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1718 acc_val: 0.5133 loss_test: 1.4526 acc_test: 0.6960 time: 0.0766s
Optimization Finished!
Total time elapsed: 45.9385s, best testing performance  0.701000, minimun loss  1.009215
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8019 acc_train: 0.1083 loss_val: 1.8281 acc_val: 0.1567 loss_test: 1.6800 acc_test: 0.4850 time: 0.1066s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7195 acc_val: 0.4067 loss_test: 1.1447 acc_test: 0.6600 time: 0.1188s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7150 acc_val: 0.4533 loss_test: 1.1641 acc_test: 0.6880 time: 0.0944s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.4500 loss_test: 1.2274 acc_test: 0.6880 time: 0.0937s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.7750 acc_val: 0.4667 loss_test: 1.2390 acc_test: 0.6970 time: 0.0981s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.8875 acc_val: 0.4767 loss_test: 1.3018 acc_test: 0.6970 time: 0.1321s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0317 acc_val: 0.5033 loss_test: 1.3602 acc_test: 0.6970 time: 0.1271s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0944 acc_val: 0.5000 loss_test: 1.3967 acc_test: 0.6940 time: 0.0952s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1203 acc_val: 0.4967 loss_test: 1.4195 acc_test: 0.6990 time: 0.1153s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1383 acc_val: 0.5100 loss_test: 1.4477 acc_test: 0.6970 time: 0.1227s
Optimization Finished!
Total time elapsed: 53.9389s, best testing performance  0.701000, minimun loss  0.995237
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8058 acc_train: 0.1000 loss_val: 1.8167 acc_val: 0.1533 loss_test: 1.7037 acc_test: 0.4790 time: 0.1659s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8271 acc_val: 0.3633 loss_test: 1.1853 acc_test: 0.6590 time: 0.1134s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8274 acc_val: 0.4100 loss_test: 1.1924 acc_test: 0.6800 time: 0.0902s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7960 acc_val: 0.4300 loss_test: 1.2124 acc_test: 0.6810 time: 0.0847s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9594 acc_val: 0.4400 loss_test: 1.2912 acc_test: 0.6900 time: 0.0874s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0402 acc_val: 0.4867 loss_test: 1.3348 acc_test: 0.6940 time: 0.1111s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1030 acc_val: 0.4833 loss_test: 1.3825 acc_test: 0.6950 time: 0.0871s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1412 acc_val: 0.4967 loss_test: 1.4203 acc_test: 0.6990 time: 0.1614s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1730 acc_val: 0.5033 loss_test: 1.4574 acc_test: 0.7000 time: 0.1238s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2291 acc_val: 0.5133 loss_test: 1.4927 acc_test: 0.7020 time: 0.0923s
Optimization Finished!
Total time elapsed: 53.6822s, best testing performance  0.704000, minimun loss  1.025115
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1667 loss_val: 1.8007 acc_val: 0.1867 loss_test: 1.7002 acc_test: 0.4300 time: 0.1240s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8842 acc_val: 0.3600 loss_test: 1.2130 acc_test: 0.6490 time: 0.0788s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8797 acc_val: 0.4033 loss_test: 1.2138 acc_test: 0.6740 time: 0.0762s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9440 acc_val: 0.4300 loss_test: 1.2637 acc_test: 0.6760 time: 0.0767s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0259 acc_val: 0.4533 loss_test: 1.3193 acc_test: 0.6890 time: 0.1257s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0616 acc_val: 0.4800 loss_test: 1.3531 acc_test: 0.6910 time: 0.1231s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0757 acc_val: 0.4933 loss_test: 1.3825 acc_test: 0.6920 time: 0.1001s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0803 acc_val: 0.5067 loss_test: 1.4048 acc_test: 0.6930 time: 0.1382s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1429 acc_val: 0.5033 loss_test: 1.4410 acc_test: 0.6930 time: 0.1285s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1739 acc_val: 0.5000 loss_test: 1.4664 acc_test: 0.6930 time: 0.1272s
Optimization Finished!
Total time elapsed: 47.9691s, best testing performance  0.700000, minimun loss  1.023542
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7992 acc_train: 0.1417 loss_val: 1.7897 acc_val: 0.1900 loss_test: 1.7104 acc_test: 0.4780 time: 0.1056s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8448 acc_val: 0.3833 loss_test: 1.1953 acc_test: 0.6570 time: 0.1218s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.9147 acc_val: 0.4033 loss_test: 1.2165 acc_test: 0.6730 time: 0.1133s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9537 acc_val: 0.4333 loss_test: 1.2482 acc_test: 0.6810 time: 0.1099s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9929 acc_val: 0.4400 loss_test: 1.3049 acc_test: 0.6810 time: 0.0839s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0202 acc_val: 0.4767 loss_test: 1.3454 acc_test: 0.6910 time: 0.0957s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1025 acc_val: 0.4900 loss_test: 1.3976 acc_test: 0.6920 time: 0.0892s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1624 acc_val: 0.5000 loss_test: 1.4396 acc_test: 0.6940 time: 0.1013s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2245 acc_val: 0.5033 loss_test: 1.4795 acc_test: 0.6980 time: 0.0959s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.3037 acc_val: 0.5100 loss_test: 1.5151 acc_test: 0.7040 time: 0.0911s
Optimization Finished!
Total time elapsed: 53.5579s, best testing performance  0.706000, minimun loss  1.033611
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8045 acc_train: 0.1083 loss_val: 1.8125 acc_val: 0.1433 loss_test: 1.6972 acc_test: 0.5030 time: 0.1106s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.9254 acc_val: 0.3400 loss_test: 1.2110 acc_test: 0.6480 time: 0.0748s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8381 acc_val: 0.3900 loss_test: 1.1847 acc_test: 0.6780 time: 0.0748s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8567 acc_val: 0.4100 loss_test: 1.2183 acc_test: 0.6810 time: 0.0771s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9777 acc_val: 0.4267 loss_test: 1.2896 acc_test: 0.6840 time: 0.0772s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9762 acc_val: 0.4600 loss_test: 1.3116 acc_test: 0.6950 time: 0.0780s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0081 acc_val: 0.4800 loss_test: 1.3430 acc_test: 0.6950 time: 0.0784s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0415 acc_val: 0.5100 loss_test: 1.3737 acc_test: 0.7010 time: 0.0766s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0858 acc_val: 0.5233 loss_test: 1.4081 acc_test: 0.6990 time: 0.0770s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1684 acc_val: 0.5133 loss_test: 1.4523 acc_test: 0.7000 time: 0.1014s
Optimization Finished!
Total time elapsed: 41.2463s, best testing performance  0.704000, minimun loss  1.004982
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7936 acc_train: 0.2083 loss_val: 1.8242 acc_val: 0.1900 loss_test: 1.6967 acc_test: 0.4490 time: 0.1021s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.9050 acc_val: 0.3500 loss_test: 1.1929 acc_test: 0.6590 time: 0.1013s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.9145 acc_val: 0.3933 loss_test: 1.2035 acc_test: 0.6740 time: 0.0915s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9141 acc_val: 0.4100 loss_test: 1.2384 acc_test: 0.6840 time: 0.0999s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9649 acc_val: 0.4567 loss_test: 1.2937 acc_test: 0.6950 time: 0.1128s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0500 acc_val: 0.4833 loss_test: 1.3346 acc_test: 0.6990 time: 0.1482s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0830 acc_val: 0.4967 loss_test: 1.3733 acc_test: 0.6930 time: 0.1015s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1132 acc_val: 0.4967 loss_test: 1.4019 acc_test: 0.6970 time: 0.0858s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1287 acc_val: 0.5133 loss_test: 1.4343 acc_test: 0.7020 time: 0.0947s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1679 acc_val: 0.5100 loss_test: 1.4660 acc_test: 0.7030 time: 0.1103s
Optimization Finished!
Total time elapsed: 53.8771s, best testing performance  0.703000, minimun loss  1.001470
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7962 acc_train: 0.1917 loss_val: 1.8157 acc_val: 0.1000 loss_test: 1.6851 acc_test: 0.4630 time: 0.1345s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7768 acc_val: 0.3900 loss_test: 1.1436 acc_test: 0.6670 time: 0.1136s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7101 acc_val: 0.4400 loss_test: 1.1424 acc_test: 0.6840 time: 0.1242s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.7524 acc_val: 0.4367 loss_test: 1.1904 acc_test: 0.6870 time: 0.1024s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8842 acc_val: 0.4533 loss_test: 1.2601 acc_test: 0.6840 time: 0.1211s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9484 acc_val: 0.4700 loss_test: 1.3032 acc_test: 0.6940 time: 0.1124s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9738 acc_val: 0.4800 loss_test: 1.3410 acc_test: 0.6950 time: 0.0754s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0392 acc_val: 0.5033 loss_test: 1.3821 acc_test: 0.6990 time: 0.0748s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0690 acc_val: 0.5100 loss_test: 1.4140 acc_test: 0.7030 time: 0.0800s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1387 acc_val: 0.5100 loss_test: 1.4603 acc_test: 0.7020 time: 0.0800s
Optimization Finished!
Total time elapsed: 46.6451s, best testing performance  0.703000, minimun loss  1.005352
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7957 acc_train: 0.1167 loss_val: 1.7968 acc_val: 0.1500 loss_test: 1.6883 acc_test: 0.4570 time: 0.0923s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.7608 acc_val: 0.4033 loss_test: 1.1416 acc_test: 0.6660 time: 0.1162s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7978 acc_val: 0.4367 loss_test: 1.1626 acc_test: 0.6810 time: 0.1128s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9019 acc_val: 0.4433 loss_test: 1.2191 acc_test: 0.6860 time: 0.0979s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9508 acc_val: 0.4667 loss_test: 1.2673 acc_test: 0.6920 time: 0.1170s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9733 acc_val: 0.4767 loss_test: 1.3039 acc_test: 0.6920 time: 0.1248s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0395 acc_val: 0.4800 loss_test: 1.3453 acc_test: 0.6970 time: 0.1268s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1091 acc_val: 0.5033 loss_test: 1.3841 acc_test: 0.6990 time: 0.0909s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1382 acc_val: 0.5100 loss_test: 1.4149 acc_test: 0.7000 time: 0.0874s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2100 acc_val: 0.5067 loss_test: 1.4521 acc_test: 0.6970 time: 0.1262s
Optimization Finished!
Total time elapsed: 53.8995s, best testing performance  0.702000, minimun loss  1.020066
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7903 acc_train: 0.1500 loss_val: 1.8212 acc_val: 0.1833 loss_test: 1.6754 acc_test: 0.4300 time: 0.0969s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8475 acc_val: 0.3833 loss_test: 1.1686 acc_test: 0.6680 time: 0.1354s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8363 acc_val: 0.4167 loss_test: 1.1708 acc_test: 0.6830 time: 0.0960s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8851 acc_val: 0.4200 loss_test: 1.2055 acc_test: 0.6860 time: 0.1216s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0186 acc_val: 0.4367 loss_test: 1.2746 acc_test: 0.6870 time: 0.0926s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.4700 loss_test: 1.3155 acc_test: 0.6900 time: 0.1184s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1093 acc_val: 0.4767 loss_test: 1.3507 acc_test: 0.6930 time: 0.1208s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1833 acc_val: 0.4800 loss_test: 1.3949 acc_test: 0.6960 time: 0.0913s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2092 acc_val: 0.4867 loss_test: 1.4291 acc_test: 0.6950 time: 0.1545s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2836 acc_val: 0.4867 loss_test: 1.4644 acc_test: 0.6940 time: 0.1078s
Optimization Finished!
Total time elapsed: 53.6615s, best testing performance  0.698000, minimun loss  1.028061
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8176 acc_train: 0.0500 loss_val: 1.8401 acc_val: 0.0900 loss_test: 1.7014 acc_test: 0.4270 time: 0.1037s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8846 acc_val: 0.3767 loss_test: 1.1725 acc_test: 0.6530 time: 0.0779s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8377 acc_val: 0.4100 loss_test: 1.1766 acc_test: 0.6740 time: 0.0766s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8983 acc_val: 0.4100 loss_test: 1.2201 acc_test: 0.6820 time: 0.0772s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9546 acc_val: 0.4433 loss_test: 1.2692 acc_test: 0.6850 time: 0.1008s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0192 acc_val: 0.4600 loss_test: 1.3232 acc_test: 0.6910 time: 0.0843s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1029 acc_val: 0.4800 loss_test: 1.3721 acc_test: 0.6890 time: 0.1312s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1492 acc_val: 0.4867 loss_test: 1.4132 acc_test: 0.6940 time: 0.1132s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2032 acc_val: 0.4933 loss_test: 1.4560 acc_test: 0.6960 time: 0.0918s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2485 acc_val: 0.5000 loss_test: 1.4892 acc_test: 0.6960 time: 0.0908s
Optimization Finished!
Total time elapsed: 48.0396s, best testing performance  0.703000, minimun loss  1.010602
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 4, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7760 acc_train: 0.2583 loss_val: 1.8109 acc_val: 0.1900 loss_test: 1.6684 acc_test: 0.5220 time: 0.1141s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7648 acc_val: 0.4067 loss_test: 1.1562 acc_test: 0.6670 time: 0.1010s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7895 acc_val: 0.4133 loss_test: 1.1739 acc_test: 0.6870 time: 0.1237s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9014 acc_val: 0.4267 loss_test: 1.2264 acc_test: 0.6840 time: 0.0874s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9946 acc_val: 0.4533 loss_test: 1.2828 acc_test: 0.6900 time: 0.1197s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0306 acc_val: 0.4700 loss_test: 1.3294 acc_test: 0.6930 time: 0.1165s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0658 acc_val: 0.4900 loss_test: 1.3719 acc_test: 0.6910 time: 0.1028s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1085 acc_val: 0.4900 loss_test: 1.4173 acc_test: 0.6920 time: 0.0963s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1445 acc_val: 0.4967 loss_test: 1.4554 acc_test: 0.6970 time: 0.1250s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1539 acc_val: 0.5033 loss_test: 1.4879 acc_test: 0.7000 time: 0.1045s
Optimization Finished!
Total time elapsed: 53.4555s, best testing performance  0.700000, minimun loss  1.039208
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8003 acc_train: 0.1250 loss_val: 1.7960 acc_val: 0.1900 loss_test: 1.6986 acc_test: 0.4640 time: 0.1125s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8572 acc_val: 0.3500 loss_test: 1.1898 acc_test: 0.6550 time: 0.0809s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8660 acc_val: 0.3900 loss_test: 1.1977 acc_test: 0.6650 time: 0.0813s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8822 acc_val: 0.4400 loss_test: 1.2358 acc_test: 0.6760 time: 0.0800s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9686 acc_val: 0.4533 loss_test: 1.2979 acc_test: 0.6750 time: 0.0827s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9794 acc_val: 0.4833 loss_test: 1.3320 acc_test: 0.6910 time: 0.0842s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9965 acc_val: 0.4933 loss_test: 1.3575 acc_test: 0.6930 time: 0.0873s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0475 acc_val: 0.5033 loss_test: 1.3912 acc_test: 0.6970 time: 0.0839s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0794 acc_val: 0.5133 loss_test: 1.4241 acc_test: 0.6960 time: 0.0847s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1514 acc_val: 0.5100 loss_test: 1.4686 acc_test: 0.6990 time: 0.1258s
Optimization Finished!
Total time elapsed: 46.1035s, best testing performance  0.702000, minimun loss  1.002967
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.1417 loss_val: 1.8079 acc_val: 0.1333 loss_test: 1.7012 acc_test: 0.4930 time: 0.1128s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7999 acc_val: 0.3600 loss_test: 1.1592 acc_test: 0.6470 time: 0.1168s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8058 acc_val: 0.4033 loss_test: 1.1688 acc_test: 0.6660 time: 0.1106s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.7934 acc_val: 0.4533 loss_test: 1.1924 acc_test: 0.6760 time: 0.1397s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8177 acc_val: 0.4767 loss_test: 1.2329 acc_test: 0.6920 time: 0.1350s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9748 acc_val: 0.4667 loss_test: 1.3141 acc_test: 0.6950 time: 0.1328s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0978 acc_val: 0.4900 loss_test: 1.3685 acc_test: 0.6960 time: 0.1299s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1334 acc_val: 0.5100 loss_test: 1.4031 acc_test: 0.6970 time: 0.1080s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1930 acc_val: 0.5033 loss_test: 1.4406 acc_test: 0.6960 time: 0.1008s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2558 acc_val: 0.5100 loss_test: 1.4695 acc_test: 0.7000 time: 0.0907s
Optimization Finished!
Total time elapsed: 59.2657s, best testing performance  0.702000, minimun loss  1.020102
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1083 loss_val: 1.7938 acc_val: 0.1733 loss_test: 1.7021 acc_test: 0.4510 time: 0.1157s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7418 acc_val: 0.4067 loss_test: 1.1352 acc_test: 0.6730 time: 0.1197s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8013 acc_val: 0.4400 loss_test: 1.1664 acc_test: 0.6720 time: 0.1219s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8813 acc_val: 0.4733 loss_test: 1.2212 acc_test: 0.6760 time: 0.1203s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.8989 acc_val: 0.4767 loss_test: 1.2757 acc_test: 0.6820 time: 0.0811s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0194 acc_val: 0.4900 loss_test: 1.3297 acc_test: 0.6900 time: 0.0812s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1231 acc_val: 0.4967 loss_test: 1.3871 acc_test: 0.6940 time: 0.0843s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1602 acc_val: 0.4967 loss_test: 1.4189 acc_test: 0.6880 time: 0.0855s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1969 acc_val: 0.5033 loss_test: 1.4477 acc_test: 0.6940 time: 0.0830s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2182 acc_val: 0.5100 loss_test: 1.4781 acc_test: 0.6940 time: 0.0827s
Optimization Finished!
Total time elapsed: 46.7425s, best testing performance  0.697000, minimun loss  1.003460
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7966 acc_train: 0.2000 loss_val: 1.7920 acc_val: 0.1200 loss_test: 1.6824 acc_test: 0.4390 time: 0.1289s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8600 acc_val: 0.3767 loss_test: 1.1898 acc_test: 0.6540 time: 0.1084s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8384 acc_val: 0.3867 loss_test: 1.1869 acc_test: 0.6720 time: 0.1282s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8859 acc_val: 0.4467 loss_test: 1.2235 acc_test: 0.6790 time: 0.1075s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9833 acc_val: 0.4667 loss_test: 1.2881 acc_test: 0.6820 time: 0.1360s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0793 acc_val: 0.4600 loss_test: 1.3530 acc_test: 0.6870 time: 0.1018s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1476 acc_val: 0.5033 loss_test: 1.3928 acc_test: 0.6950 time: 0.1048s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1797 acc_val: 0.5033 loss_test: 1.4295 acc_test: 0.6920 time: 0.1069s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1902 acc_val: 0.5067 loss_test: 1.4548 acc_test: 0.6930 time: 0.1330s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2382 acc_val: 0.5167 loss_test: 1.4885 acc_test: 0.6990 time: 0.0960s
Optimization Finished!
Total time elapsed: 59.5684s, best testing performance  0.702000, minimun loss  0.983208
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7981 acc_train: 0.1500 loss_val: 1.7873 acc_val: 0.2000 loss_test: 1.6967 acc_test: 0.4710 time: 0.1375s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9212 acc_val: 0.3433 loss_test: 1.1897 acc_test: 0.6510 time: 0.0946s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8824 acc_val: 0.4067 loss_test: 1.1852 acc_test: 0.6690 time: 0.1055s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9192 acc_val: 0.4600 loss_test: 1.2279 acc_test: 0.6730 time: 0.1136s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0633 acc_val: 0.4467 loss_test: 1.3159 acc_test: 0.6760 time: 0.1094s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1502 acc_val: 0.4467 loss_test: 1.3604 acc_test: 0.6840 time: 0.1108s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1526 acc_val: 0.4900 loss_test: 1.3954 acc_test: 0.6900 time: 0.0814s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1624 acc_val: 0.5100 loss_test: 1.4195 acc_test: 0.6950 time: 0.0818s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1691 acc_val: 0.5100 loss_test: 1.4472 acc_test: 0.6960 time: 0.0816s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2099 acc_val: 0.5100 loss_test: 1.4698 acc_test: 0.7020 time: 0.0832s
Optimization Finished!
Total time elapsed: 51.5067s, best testing performance  0.703000, minimun loss  0.998884
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8211 acc_train: 0.0917 loss_val: 1.7774 acc_val: 0.2267 loss_test: 1.7004 acc_test: 0.5580 time: 0.1227s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8016 acc_val: 0.4133 loss_test: 1.1491 acc_test: 0.6630 time: 0.1428s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8330 acc_val: 0.4100 loss_test: 1.1599 acc_test: 0.6790 time: 0.1089s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8948 acc_val: 0.4133 loss_test: 1.2013 acc_test: 0.6790 time: 0.0972s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8782 acc_val: 0.4733 loss_test: 1.2482 acc_test: 0.6920 time: 0.0926s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0058 acc_val: 0.4900 loss_test: 1.3215 acc_test: 0.6940 time: 0.0930s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0723 acc_val: 0.4867 loss_test: 1.3664 acc_test: 0.6930 time: 0.1511s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0771 acc_val: 0.4967 loss_test: 1.3944 acc_test: 0.6920 time: 0.1165s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1579 acc_val: 0.5033 loss_test: 1.4316 acc_test: 0.6900 time: 0.1189s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1760 acc_val: 0.5000 loss_test: 1.4526 acc_test: 0.6920 time: 0.1232s
Optimization Finished!
Total time elapsed: 59.0584s, best testing performance  0.696000, minimun loss  1.015228
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7877 acc_train: 0.2083 loss_val: 1.8087 acc_val: 0.1900 loss_test: 1.6837 acc_test: 0.5200 time: 0.1672s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8392 acc_val: 0.3733 loss_test: 1.1551 acc_test: 0.6520 time: 0.1143s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7385 acc_val: 0.4200 loss_test: 1.1264 acc_test: 0.6770 time: 0.1330s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.7594 acc_val: 0.4233 loss_test: 1.1632 acc_test: 0.6820 time: 0.1296s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9320 acc_val: 0.4467 loss_test: 1.2561 acc_test: 0.6930 time: 0.0928s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9871 acc_val: 0.4733 loss_test: 1.3082 acc_test: 0.6920 time: 0.1318s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0350 acc_val: 0.5033 loss_test: 1.3504 acc_test: 0.6970 time: 0.1312s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0913 acc_val: 0.5067 loss_test: 1.3984 acc_test: 0.6960 time: 0.1010s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1254 acc_val: 0.5133 loss_test: 1.4347 acc_test: 0.7010 time: 0.1308s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1382 acc_val: 0.5167 loss_test: 1.4608 acc_test: 0.6980 time: 0.0822s
Optimization Finished!
Total time elapsed: 55.9385s, best testing performance  0.703000, minimun loss  0.992715
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1917 loss_val: 1.8167 acc_val: 0.1067 loss_test: 1.6945 acc_test: 0.4520 time: 0.1118s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7663 acc_val: 0.3933 loss_test: 1.1374 acc_test: 0.6630 time: 0.0851s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7890 acc_val: 0.4367 loss_test: 1.1444 acc_test: 0.6790 time: 0.1088s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9094 acc_val: 0.4400 loss_test: 1.2101 acc_test: 0.6880 time: 0.1434s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0303 acc_val: 0.4600 loss_test: 1.2749 acc_test: 0.6910 time: 0.1390s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0527 acc_val: 0.4733 loss_test: 1.3202 acc_test: 0.6940 time: 0.1100s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0647 acc_val: 0.4800 loss_test: 1.3503 acc_test: 0.6940 time: 0.1234s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0871 acc_val: 0.5067 loss_test: 1.3864 acc_test: 0.6920 time: 0.1239s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1105 acc_val: 0.5100 loss_test: 1.4162 acc_test: 0.6970 time: 0.0870s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1379 acc_val: 0.5167 loss_test: 1.4456 acc_test: 0.6960 time: 0.1352s
Optimization Finished!
Total time elapsed: 56.6871s, best testing performance  0.699000, minimun loss  1.005495
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7832 acc_train: 0.1917 loss_val: 1.8061 acc_val: 0.2100 loss_test: 1.6795 acc_test: 0.5050 time: 0.1146s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8166 acc_val: 0.3800 loss_test: 1.1671 acc_test: 0.6590 time: 0.1330s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7736 acc_val: 0.4233 loss_test: 1.1555 acc_test: 0.6780 time: 0.1315s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8309 acc_val: 0.4200 loss_test: 1.1914 acc_test: 0.6830 time: 0.1162s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9457 acc_val: 0.4600 loss_test: 1.2630 acc_test: 0.6890 time: 0.1324s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0568 acc_val: 0.4800 loss_test: 1.3175 acc_test: 0.6920 time: 0.1251s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1039 acc_val: 0.4867 loss_test: 1.3655 acc_test: 0.6920 time: 0.1220s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1515 acc_val: 0.4867 loss_test: 1.3990 acc_test: 0.6950 time: 0.1089s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1396 acc_val: 0.5067 loss_test: 1.4232 acc_test: 0.6960 time: 0.1054s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2031 acc_val: 0.5000 loss_test: 1.4564 acc_test: 0.6940 time: 0.1148s
Optimization Finished!
Total time elapsed: 59.0216s, best testing performance  0.699000, minimun loss  1.005165
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7817 acc_train: 0.2000 loss_val: 1.7868 acc_val: 0.2333 loss_test: 1.6773 acc_test: 0.5060 time: 0.1250s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7547 acc_val: 0.3600 loss_test: 1.1513 acc_test: 0.6570 time: 0.0862s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8109 acc_val: 0.4067 loss_test: 1.1680 acc_test: 0.6700 time: 0.0831s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8664 acc_val: 0.4267 loss_test: 1.2097 acc_test: 0.6770 time: 0.0840s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9788 acc_val: 0.4533 loss_test: 1.2812 acc_test: 0.6860 time: 0.1129s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0271 acc_val: 0.4733 loss_test: 1.3342 acc_test: 0.6900 time: 0.1144s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0590 acc_val: 0.4833 loss_test: 1.3781 acc_test: 0.6930 time: 0.1254s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0825 acc_val: 0.4867 loss_test: 1.4130 acc_test: 0.6950 time: 0.0978s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1461 acc_val: 0.4900 loss_test: 1.4564 acc_test: 0.6990 time: 0.1008s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1476 acc_val: 0.4900 loss_test: 1.4816 acc_test: 0.7010 time: 0.1038s
Optimization Finished!
Total time elapsed: 52.9543s, best testing performance  0.706000, minimun loss  1.004873
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7939 acc_train: 0.1417 loss_val: 1.8061 acc_val: 0.0700 loss_test: 1.6831 acc_test: 0.3490 time: 0.1079s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7371 acc_val: 0.3867 loss_test: 1.1419 acc_test: 0.6610 time: 0.1384s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7973 acc_val: 0.4200 loss_test: 1.1705 acc_test: 0.6740 time: 0.1183s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9443 acc_val: 0.4100 loss_test: 1.2407 acc_test: 0.6810 time: 0.0985s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0362 acc_val: 0.4200 loss_test: 1.2969 acc_test: 0.6910 time: 0.1314s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0590 acc_val: 0.4667 loss_test: 1.3296 acc_test: 0.6940 time: 0.1430s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0931 acc_val: 0.4833 loss_test: 1.3656 acc_test: 0.6920 time: 0.0948s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1354 acc_val: 0.5100 loss_test: 1.3991 acc_test: 0.7000 time: 0.0935s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1429 acc_val: 0.4933 loss_test: 1.4286 acc_test: 0.7030 time: 0.0915s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2096 acc_val: 0.4967 loss_test: 1.4686 acc_test: 0.6990 time: 0.1133s
Optimization Finished!
Total time elapsed: 60.0769s, best testing performance  0.704000, minimun loss  1.006005
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7889 acc_train: 0.1333 loss_val: 1.8155 acc_val: 0.1567 loss_test: 1.6781 acc_test: 0.4680 time: 0.1091s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7804 acc_val: 0.3767 loss_test: 1.1621 acc_test: 0.6510 time: 0.0811s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7867 acc_val: 0.4000 loss_test: 1.1807 acc_test: 0.6650 time: 0.0835s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8541 acc_val: 0.4033 loss_test: 1.2335 acc_test: 0.6700 time: 0.0832s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9382 acc_val: 0.4533 loss_test: 1.2800 acc_test: 0.6870 time: 0.0821s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9880 acc_val: 0.4500 loss_test: 1.3178 acc_test: 0.6930 time: 0.0835s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0159 acc_val: 0.4800 loss_test: 1.3479 acc_test: 0.6930 time: 0.1207s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1065 acc_val: 0.4867 loss_test: 1.3911 acc_test: 0.6930 time: 0.0966s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1584 acc_val: 0.4967 loss_test: 1.4222 acc_test: 0.6950 time: 0.1032s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1997 acc_val: 0.5000 loss_test: 1.4563 acc_test: 0.6970 time: 0.1063s
Optimization Finished!
Total time elapsed: 49.3624s, best testing performance  0.702000, minimun loss  1.003134
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8046 acc_train: 0.0917 loss_val: 1.8132 acc_val: 0.1633 loss_test: 1.6873 acc_test: 0.4980 time: 0.0972s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.7034 acc_val: 0.3900 loss_test: 1.1421 acc_test: 0.6640 time: 0.1016s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7667 acc_val: 0.4100 loss_test: 1.1805 acc_test: 0.6740 time: 0.0938s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8771 acc_val: 0.4167 loss_test: 1.2343 acc_test: 0.6750 time: 0.1378s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8583 acc_val: 0.4767 loss_test: 1.2696 acc_test: 0.6920 time: 0.1055s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9805 acc_val: 0.4867 loss_test: 1.3215 acc_test: 0.6960 time: 0.1370s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0852 acc_val: 0.4900 loss_test: 1.3748 acc_test: 0.6920 time: 0.1109s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.4967 loss_test: 1.4149 acc_test: 0.6930 time: 0.1403s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1973 acc_val: 0.4967 loss_test: 1.4478 acc_test: 0.6940 time: 0.1268s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2518 acc_val: 0.5067 loss_test: 1.4835 acc_test: 0.6910 time: 0.1075s
Optimization Finished!
Total time elapsed: 59.0856s, best testing performance  0.700000, minimun loss  1.012132
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7890 acc_train: 0.2000 loss_val: 1.7937 acc_val: 0.1967 loss_test: 1.6736 acc_test: 0.5400 time: 0.1058s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8475 acc_val: 0.3800 loss_test: 1.1827 acc_test: 0.6500 time: 0.0810s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8498 acc_val: 0.4033 loss_test: 1.1940 acc_test: 0.6740 time: 0.0810s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8960 acc_val: 0.4200 loss_test: 1.2341 acc_test: 0.6710 time: 0.0809s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9528 acc_val: 0.4633 loss_test: 1.2769 acc_test: 0.6860 time: 0.0829s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0443 acc_val: 0.4867 loss_test: 1.3314 acc_test: 0.6950 time: 0.0830s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1309 acc_val: 0.4933 loss_test: 1.3762 acc_test: 0.6920 time: 0.0837s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1604 acc_val: 0.5033 loss_test: 1.4080 acc_test: 0.6950 time: 0.0837s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1875 acc_val: 0.5033 loss_test: 1.4431 acc_test: 0.6940 time: 0.0847s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2652 acc_val: 0.4900 loss_test: 1.4885 acc_test: 0.6970 time: 0.1333s
Optimization Finished!
Total time elapsed: 45.9103s, best testing performance  0.698000, minimun loss  1.022506
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7848 acc_train: 0.2000 loss_val: 1.8143 acc_val: 0.1533 loss_test: 1.6809 acc_test: 0.4840 time: 0.1804s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8749 acc_val: 0.3600 loss_test: 1.1888 acc_test: 0.6520 time: 0.1207s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8593 acc_val: 0.3900 loss_test: 1.2004 acc_test: 0.6680 time: 0.1946s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 2.0440 acc_val: 0.3933 loss_test: 1.2827 acc_test: 0.6700 time: 0.1218s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0778 acc_val: 0.4500 loss_test: 1.3162 acc_test: 0.6890 time: 0.1148s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1073 acc_val: 0.4667 loss_test: 1.3501 acc_test: 0.6940 time: 0.0989s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1245 acc_val: 0.4967 loss_test: 1.3802 acc_test: 0.6980 time: 0.1343s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1630 acc_val: 0.5033 loss_test: 1.4211 acc_test: 0.6960 time: 0.1120s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1945 acc_val: 0.5067 loss_test: 1.4501 acc_test: 0.7000 time: 0.1327s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1919 acc_val: 0.5000 loss_test: 1.4723 acc_test: 0.7010 time: 0.1137s
Optimization Finished!
Total time elapsed: 60.2741s, best testing performance  0.702000, minimun loss  1.008772
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8079 acc_train: 0.0917 loss_val: 1.8005 acc_val: 0.1333 loss_test: 1.6825 acc_test: 0.5030 time: 0.1139s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.9424 acc_val: 0.3433 loss_test: 1.2043 acc_test: 0.6430 time: 0.1410s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7922 acc_val: 0.4233 loss_test: 1.1725 acc_test: 0.6670 time: 0.1065s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8737 acc_val: 0.4167 loss_test: 1.2224 acc_test: 0.6750 time: 0.0819s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9620 acc_val: 0.4267 loss_test: 1.2778 acc_test: 0.6810 time: 0.0808s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0677 acc_val: 0.4700 loss_test: 1.3389 acc_test: 0.6960 time: 0.0850s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0691 acc_val: 0.5100 loss_test: 1.3656 acc_test: 0.6960 time: 0.0837s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.5100 loss_test: 1.3989 acc_test: 0.6990 time: 0.0860s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1756 acc_val: 0.5067 loss_test: 1.4395 acc_test: 0.6970 time: 0.0831s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1935 acc_val: 0.5033 loss_test: 1.4683 acc_test: 0.6980 time: 0.0835s
Optimization Finished!
Total time elapsed: 47.0300s, best testing performance  0.702000, minimun loss  1.000970
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8050 acc_train: 0.1417 loss_val: 1.7954 acc_val: 0.1800 loss_test: 1.6945 acc_test: 0.4730 time: 0.1349s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9302 acc_val: 0.3900 loss_test: 1.2257 acc_test: 0.6560 time: 0.1067s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8708 acc_val: 0.4300 loss_test: 1.2224 acc_test: 0.6760 time: 0.1437s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9822 acc_val: 0.4300 loss_test: 1.2840 acc_test: 0.6800 time: 0.0962s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0417 acc_val: 0.4733 loss_test: 1.3157 acc_test: 0.6980 time: 0.1186s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0897 acc_val: 0.4900 loss_test: 1.3503 acc_test: 0.6930 time: 0.1165s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1380 acc_val: 0.4900 loss_test: 1.3850 acc_test: 0.6950 time: 0.1197s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1459 acc_val: 0.5067 loss_test: 1.4129 acc_test: 0.7000 time: 0.1399s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1516 acc_val: 0.5067 loss_test: 1.4355 acc_test: 0.7040 time: 0.1242s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1844 acc_val: 0.5167 loss_test: 1.4576 acc_test: 0.7030 time: 0.1120s
Optimization Finished!
Total time elapsed: 58.6538s, best testing performance  0.708000, minimun loss  1.040204
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7905 acc_train: 0.1500 loss_val: 1.7898 acc_val: 0.1533 loss_test: 1.6739 acc_test: 0.5070 time: 0.1228s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.9599 acc_val: 0.3833 loss_test: 1.2274 acc_test: 0.6540 time: 0.1294s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8607 acc_val: 0.4300 loss_test: 1.2127 acc_test: 0.6750 time: 0.1261s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9498 acc_val: 0.4333 loss_test: 1.2656 acc_test: 0.6830 time: 0.1129s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0778 acc_val: 0.4567 loss_test: 1.3284 acc_test: 0.6880 time: 0.1128s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1135 acc_val: 0.4767 loss_test: 1.3657 acc_test: 0.6940 time: 0.0917s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1623 acc_val: 0.4800 loss_test: 1.4064 acc_test: 0.6960 time: 0.0816s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2166 acc_val: 0.4967 loss_test: 1.4414 acc_test: 0.6950 time: 0.0813s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2372 acc_val: 0.5033 loss_test: 1.4672 acc_test: 0.6990 time: 0.0810s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2390 acc_val: 0.4967 loss_test: 1.4830 acc_test: 0.6930 time: 0.0843s
Optimization Finished!
Total time elapsed: 51.5750s, best testing performance  0.705000, minimun loss  1.014998
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7769 acc_train: 0.2667 loss_val: 1.7960 acc_val: 0.1100 loss_test: 1.6673 acc_test: 0.4120 time: 0.1544s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.9023 acc_val: 0.3567 loss_test: 1.1964 acc_test: 0.6520 time: 0.1216s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8355 acc_val: 0.4067 loss_test: 1.1889 acc_test: 0.6740 time: 0.1739s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8405 acc_val: 0.4200 loss_test: 1.2238 acc_test: 0.6790 time: 0.1289s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0290 acc_val: 0.4333 loss_test: 1.3026 acc_test: 0.6880 time: 0.1597s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0607 acc_val: 0.4667 loss_test: 1.3381 acc_test: 0.6960 time: 0.1151s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0663 acc_val: 0.4900 loss_test: 1.3640 acc_test: 0.6960 time: 0.1411s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1280 acc_val: 0.5100 loss_test: 1.4044 acc_test: 0.6950 time: 0.1332s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1859 acc_val: 0.5067 loss_test: 1.4399 acc_test: 0.6960 time: 0.1149s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2388 acc_val: 0.5133 loss_test: 1.4740 acc_test: 0.6960 time: 0.1170s
Optimization Finished!
Total time elapsed: 59.3496s, best testing performance  0.700000, minimun loss  1.007013
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1583 loss_val: 1.8325 acc_val: 0.1233 loss_test: 1.6910 acc_test: 0.4700 time: 0.1366s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8750 acc_val: 0.3500 loss_test: 1.2057 acc_test: 0.6460 time: 0.1209s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8790 acc_val: 0.4133 loss_test: 1.2172 acc_test: 0.6670 time: 0.1269s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9642 acc_val: 0.4300 loss_test: 1.2711 acc_test: 0.6780 time: 0.1731s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0674 acc_val: 0.4533 loss_test: 1.3209 acc_test: 0.6900 time: 0.1133s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1252 acc_val: 0.4800 loss_test: 1.3596 acc_test: 0.6940 time: 0.1068s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1289 acc_val: 0.4933 loss_test: 1.3841 acc_test: 0.6930 time: 0.1299s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.5000 loss_test: 1.4148 acc_test: 0.6930 time: 0.1073s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2024 acc_val: 0.5000 loss_test: 1.4408 acc_test: 0.6990 time: 0.1327s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2242 acc_val: 0.5100 loss_test: 1.4733 acc_test: 0.6980 time: 0.0810s
Optimization Finished!
Total time elapsed: 55.7973s, best testing performance  0.704000, minimun loss  1.012511
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.2000 loss_val: 1.8185 acc_val: 0.1067 loss_test: 1.6835 acc_test: 0.4430 time: 0.1277s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.8481 acc_val: 0.3900 loss_test: 1.1763 acc_test: 0.6570 time: 0.0846s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8264 acc_val: 0.4167 loss_test: 1.1868 acc_test: 0.6730 time: 0.0953s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9064 acc_val: 0.4267 loss_test: 1.2339 acc_test: 0.6850 time: 0.1046s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9822 acc_val: 0.4633 loss_test: 1.2822 acc_test: 0.6890 time: 0.1104s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0201 acc_val: 0.4933 loss_test: 1.3187 acc_test: 0.6920 time: 0.1282s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0386 acc_val: 0.5000 loss_test: 1.3493 acc_test: 0.6910 time: 0.1271s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0823 acc_val: 0.4967 loss_test: 1.3926 acc_test: 0.6930 time: 0.1381s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1153 acc_val: 0.5100 loss_test: 1.4248 acc_test: 0.6980 time: 0.1416s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1575 acc_val: 0.5100 loss_test: 1.4554 acc_test: 0.7000 time: 0.1078s
Optimization Finished!
Total time elapsed: 56.8421s, best testing performance  0.703000, minimun loss  1.023356
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7907 acc_train: 0.1667 loss_val: 1.8243 acc_val: 0.1367 loss_test: 1.6697 acc_test: 0.5050 time: 0.1902s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8429 acc_val: 0.3833 loss_test: 1.1808 acc_test: 0.6500 time: 0.1107s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8453 acc_val: 0.4200 loss_test: 1.1978 acc_test: 0.6710 time: 0.1205s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9139 acc_val: 0.4367 loss_test: 1.2396 acc_test: 0.6840 time: 0.1170s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9730 acc_val: 0.4533 loss_test: 1.2843 acc_test: 0.6870 time: 0.1126s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0121 acc_val: 0.4800 loss_test: 1.3235 acc_test: 0.6940 time: 0.1363s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0716 acc_val: 0.4967 loss_test: 1.3713 acc_test: 0.6950 time: 0.1035s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1595 acc_val: 0.5100 loss_test: 1.4247 acc_test: 0.6940 time: 0.0958s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2175 acc_val: 0.5067 loss_test: 1.4588 acc_test: 0.6950 time: 0.1334s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2875 acc_val: 0.5067 loss_test: 1.5038 acc_test: 0.6930 time: 0.0990s
Optimization Finished!
Total time elapsed: 58.7611s, best testing performance  0.698000, minimun loss  1.005145
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7696 acc_train: 0.3000 loss_val: 1.8084 acc_val: 0.1133 loss_test: 1.6675 acc_test: 0.5040 time: 0.1145s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8557 acc_val: 0.3767 loss_test: 1.1794 acc_test: 0.6540 time: 0.0829s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8612 acc_val: 0.4267 loss_test: 1.1930 acc_test: 0.6740 time: 0.0832s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9273 acc_val: 0.4367 loss_test: 1.2402 acc_test: 0.6860 time: 0.0847s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0063 acc_val: 0.4567 loss_test: 1.2916 acc_test: 0.6910 time: 0.1060s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.4767 loss_test: 1.3302 acc_test: 0.6900 time: 0.1185s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0875 acc_val: 0.4900 loss_test: 1.3709 acc_test: 0.6920 time: 0.0921s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1277 acc_val: 0.5000 loss_test: 1.4081 acc_test: 0.6990 time: 0.1030s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1895 acc_val: 0.5033 loss_test: 1.4449 acc_test: 0.6990 time: 0.1364s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2620 acc_val: 0.5033 loss_test: 1.4835 acc_test: 0.6970 time: 0.1096s
Optimization Finished!
Total time elapsed: 52.8529s, best testing performance  0.702000, minimun loss  1.009753
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1083 loss_val: 1.7805 acc_val: 0.1700 loss_test: 1.6626 acc_test: 0.5150 time: 0.1217s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7059 acc_val: 0.4033 loss_test: 1.1347 acc_test: 0.6620 time: 0.1228s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7012 acc_val: 0.4467 loss_test: 1.1439 acc_test: 0.6820 time: 0.1212s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7656 acc_val: 0.4600 loss_test: 1.1947 acc_test: 0.6860 time: 0.1059s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9284 acc_val: 0.4567 loss_test: 1.2592 acc_test: 0.6930 time: 0.1355s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0227 acc_val: 0.4767 loss_test: 1.3106 acc_test: 0.6950 time: 0.1349s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0810 acc_val: 0.4867 loss_test: 1.3531 acc_test: 0.6900 time: 0.1056s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1483 acc_val: 0.4967 loss_test: 1.3882 acc_test: 0.6920 time: 0.1333s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2079 acc_val: 0.4933 loss_test: 1.4277 acc_test: 0.6950 time: 0.1065s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2736 acc_val: 0.4967 loss_test: 1.4653 acc_test: 0.6960 time: 0.1102s
Optimization Finished!
Total time elapsed: 58.7398s, best testing performance  0.696000, minimun loss  1.020676
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7811 acc_train: 0.1417 loss_val: 1.7868 acc_val: 0.2300 loss_test: 1.6903 acc_test: 0.4770 time: 0.1054s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8951 acc_val: 0.3800 loss_test: 1.1808 acc_test: 0.6550 time: 0.0805s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8541 acc_val: 0.4367 loss_test: 1.1842 acc_test: 0.6800 time: 0.0837s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9308 acc_val: 0.4433 loss_test: 1.2288 acc_test: 0.6890 time: 0.0826s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0006 acc_val: 0.4533 loss_test: 1.2807 acc_test: 0.6870 time: 0.0864s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0325 acc_val: 0.4700 loss_test: 1.3165 acc_test: 0.6950 time: 0.0832s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0556 acc_val: 0.4800 loss_test: 1.3590 acc_test: 0.6950 time: 0.1315s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0973 acc_val: 0.5033 loss_test: 1.3988 acc_test: 0.6970 time: 0.1084s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1691 acc_val: 0.5133 loss_test: 1.4448 acc_test: 0.7010 time: 0.0935s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2161 acc_val: 0.5100 loss_test: 1.4825 acc_test: 0.6970 time: 0.1232s
Optimization Finished!
Total time elapsed: 48.6477s, best testing performance  0.702000, minimun loss  1.028059
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7897 acc_train: 0.1500 loss_val: 1.7971 acc_val: 0.1667 loss_test: 1.6932 acc_test: 0.4780 time: 0.1620s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9177 acc_val: 0.3833 loss_test: 1.2186 acc_test: 0.6580 time: 0.0897s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8478 acc_val: 0.4300 loss_test: 1.2079 acc_test: 0.6670 time: 0.0935s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9007 acc_val: 0.4400 loss_test: 1.2683 acc_test: 0.6800 time: 0.1034s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9811 acc_val: 0.4567 loss_test: 1.3109 acc_test: 0.6930 time: 0.0937s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0541 acc_val: 0.4800 loss_test: 1.3536 acc_test: 0.6900 time: 0.1242s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0674 acc_val: 0.4933 loss_test: 1.3827 acc_test: 0.6940 time: 0.1144s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1058 acc_val: 0.4967 loss_test: 1.4216 acc_test: 0.6970 time: 0.1221s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1394 acc_val: 0.5033 loss_test: 1.4519 acc_test: 0.6970 time: 0.1498s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1199 acc_val: 0.5033 loss_test: 1.4761 acc_test: 0.6970 time: 0.0995s
Optimization Finished!
Total time elapsed: 59.1680s, best testing performance  0.702000, minimun loss  1.004157
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8053 acc_train: 0.1167 loss_val: 1.8110 acc_val: 0.1233 loss_test: 1.6995 acc_test: 0.4530 time: 0.1763s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 2.0011 acc_val: 0.3500 loss_test: 1.2285 acc_test: 0.6540 time: 0.0816s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8630 acc_val: 0.4100 loss_test: 1.2026 acc_test: 0.6640 time: 0.0815s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9287 acc_val: 0.4333 loss_test: 1.2576 acc_test: 0.6750 time: 0.0832s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0453 acc_val: 0.4433 loss_test: 1.3136 acc_test: 0.6810 time: 0.0827s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0925 acc_val: 0.4633 loss_test: 1.3443 acc_test: 0.6890 time: 0.0830s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1591 acc_val: 0.4833 loss_test: 1.3853 acc_test: 0.6880 time: 0.0832s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2094 acc_val: 0.4933 loss_test: 1.4204 acc_test: 0.6910 time: 0.0834s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2837 acc_val: 0.4833 loss_test: 1.4640 acc_test: 0.6920 time: 0.0849s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3072 acc_val: 0.4900 loss_test: 1.4869 acc_test: 0.6910 time: 0.1029s
Optimization Finished!
Total time elapsed: 45.8190s, best testing performance  0.697000, minimun loss  1.000901
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7848 acc_train: 0.2250 loss_val: 1.8007 acc_val: 0.1333 loss_test: 1.6800 acc_test: 0.4510 time: 0.1140s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.9760 acc_val: 0.3567 loss_test: 1.2270 acc_test: 0.6590 time: 0.1573s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8883 acc_val: 0.4133 loss_test: 1.2115 acc_test: 0.6740 time: 0.1435s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9712 acc_val: 0.4267 loss_test: 1.2660 acc_test: 0.6810 time: 0.1014s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0298 acc_val: 0.4467 loss_test: 1.3067 acc_test: 0.6890 time: 0.1316s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0707 acc_val: 0.4667 loss_test: 1.3408 acc_test: 0.6940 time: 0.1227s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1137 acc_val: 0.4867 loss_test: 1.3773 acc_test: 0.6920 time: 0.1071s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.4933 loss_test: 1.4036 acc_test: 0.6970 time: 0.1290s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1751 acc_val: 0.4900 loss_test: 1.4309 acc_test: 0.6960 time: 0.1066s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2027 acc_val: 0.5033 loss_test: 1.4575 acc_test: 0.6980 time: 0.1364s
Optimization Finished!
Total time elapsed: 59.2395s, best testing performance  0.702000, minimun loss  1.004376
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7747 acc_train: 0.2750 loss_val: 1.8082 acc_val: 0.1267 loss_test: 1.6646 acc_test: 0.5080 time: 0.1224s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9477 acc_val: 0.3533 loss_test: 1.2329 acc_test: 0.6560 time: 0.1036s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8710 acc_val: 0.4167 loss_test: 1.2082 acc_test: 0.6730 time: 0.1218s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9407 acc_val: 0.4567 loss_test: 1.2598 acc_test: 0.6930 time: 0.0876s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0324 acc_val: 0.4633 loss_test: 1.3112 acc_test: 0.6910 time: 0.0817s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0807 acc_val: 0.4733 loss_test: 1.3457 acc_test: 0.6960 time: 0.0835s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0966 acc_val: 0.4967 loss_test: 1.3700 acc_test: 0.6910 time: 0.0831s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1665 acc_val: 0.5067 loss_test: 1.4086 acc_test: 0.6950 time: 0.0858s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1976 acc_val: 0.5000 loss_test: 1.4352 acc_test: 0.6960 time: 0.0832s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2070 acc_val: 0.5033 loss_test: 1.4526 acc_test: 0.6980 time: 0.0828s
Optimization Finished!
Total time elapsed: 46.6056s, best testing performance  0.701000, minimun loss  1.005649
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8142 acc_train: 0.1250 loss_val: 1.7930 acc_val: 0.1733 loss_test: 1.6872 acc_test: 0.4630 time: 0.1347s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9573 acc_val: 0.3567 loss_test: 1.2272 acc_test: 0.6540 time: 0.1413s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8738 acc_val: 0.4167 loss_test: 1.2042 acc_test: 0.6640 time: 0.1139s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9010 acc_val: 0.4433 loss_test: 1.2435 acc_test: 0.6810 time: 0.1202s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0010 acc_val: 0.4567 loss_test: 1.3017 acc_test: 0.6850 time: 0.1140s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0283 acc_val: 0.4700 loss_test: 1.3333 acc_test: 0.6890 time: 0.1353s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0738 acc_val: 0.4867 loss_test: 1.3696 acc_test: 0.6920 time: 0.0996s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1121 acc_val: 0.5033 loss_test: 1.3979 acc_test: 0.6940 time: 0.1296s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1399 acc_val: 0.5000 loss_test: 1.4246 acc_test: 0.6950 time: 0.1271s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1525 acc_val: 0.5100 loss_test: 1.4479 acc_test: 0.7000 time: 0.1068s
Optimization Finished!
Total time elapsed: 59.4527s, best testing performance  0.701000, minimun loss  1.006226
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7804 acc_train: 0.1917 loss_val: 1.8173 acc_val: 0.1067 loss_test: 1.7074 acc_test: 0.4190 time: 0.1483s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7803 acc_val: 0.3733 loss_test: 1.1787 acc_test: 0.6540 time: 0.1056s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8030 acc_val: 0.4433 loss_test: 1.1928 acc_test: 0.6740 time: 0.1342s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8557 acc_val: 0.4433 loss_test: 1.2368 acc_test: 0.6850 time: 0.0958s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9591 acc_val: 0.4433 loss_test: 1.2900 acc_test: 0.6850 time: 0.0956s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0489 acc_val: 0.4767 loss_test: 1.3374 acc_test: 0.6950 time: 0.0978s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0418 acc_val: 0.4867 loss_test: 1.3528 acc_test: 0.6950 time: 0.0804s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0875 acc_val: 0.5000 loss_test: 1.3819 acc_test: 0.6970 time: 0.0810s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1295 acc_val: 0.4967 loss_test: 1.4118 acc_test: 0.7030 time: 0.0808s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1951 acc_val: 0.5033 loss_test: 1.4487 acc_test: 0.7020 time: 0.0834s
Optimization Finished!
Total time elapsed: 51.0535s, best testing performance  0.704000, minimun loss  0.993945
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.1167 loss_val: 1.7988 acc_val: 0.1167 loss_test: 1.7045 acc_test: 0.4090 time: 0.1310s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8034 acc_val: 0.3967 loss_test: 1.1656 acc_test: 0.6590 time: 0.1045s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7886 acc_val: 0.4400 loss_test: 1.1813 acc_test: 0.6770 time: 0.1015s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.7750 acc_val: 0.4733 loss_test: 1.2061 acc_test: 0.6860 time: 0.1177s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8129 acc_val: 0.4733 loss_test: 1.2630 acc_test: 0.6920 time: 0.1193s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9591 acc_val: 0.4667 loss_test: 1.3291 acc_test: 0.6900 time: 0.0994s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0593 acc_val: 0.4867 loss_test: 1.3647 acc_test: 0.6980 time: 0.0958s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1306 acc_val: 0.5000 loss_test: 1.3993 acc_test: 0.6980 time: 0.1163s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1525 acc_val: 0.5067 loss_test: 1.4271 acc_test: 0.6990 time: 0.0905s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2106 acc_val: 0.5033 loss_test: 1.4570 acc_test: 0.6970 time: 0.1109s
Optimization Finished!
Total time elapsed: 59.1687s, best testing performance  0.703000, minimun loss  0.990398
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1500 loss_val: 1.8065 acc_val: 0.1267 loss_test: 1.6990 acc_test: 0.4440 time: 0.1478s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.9402 acc_val: 0.3667 loss_test: 1.2371 acc_test: 0.6400 time: 0.1003s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8904 acc_val: 0.4233 loss_test: 1.2257 acc_test: 0.6720 time: 0.1012s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8418 acc_val: 0.4533 loss_test: 1.2418 acc_test: 0.6830 time: 0.1292s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8013 acc_val: 0.4833 loss_test: 1.2680 acc_test: 0.6860 time: 0.1059s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.8922 acc_val: 0.4733 loss_test: 1.3164 acc_test: 0.6890 time: 0.1462s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 1.9945 acc_val: 0.4833 loss_test: 1.3661 acc_test: 0.6970 time: 0.1190s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1091 acc_val: 0.4833 loss_test: 1.4014 acc_test: 0.6980 time: 0.1325s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1249 acc_val: 0.5067 loss_test: 1.4251 acc_test: 0.7040 time: 0.0819s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1581 acc_val: 0.4933 loss_test: 1.4467 acc_test: 0.7030 time: 0.0814s
Optimization Finished!
Total time elapsed: 55.4748s, best testing performance  0.707000, minimun loss  1.015435
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7999 acc_train: 0.1417 loss_val: 1.8187 acc_val: 0.1600 loss_test: 1.7175 acc_test: 0.4610 time: 0.1299s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8144 acc_val: 0.4000 loss_test: 1.1997 acc_test: 0.6550 time: 0.0850s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8918 acc_val: 0.4100 loss_test: 1.2373 acc_test: 0.6590 time: 0.1315s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8819 acc_val: 0.4333 loss_test: 1.2572 acc_test: 0.6710 time: 0.1211s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8890 acc_val: 0.4433 loss_test: 1.2892 acc_test: 0.6840 time: 0.1455s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9024 acc_val: 0.4633 loss_test: 1.3131 acc_test: 0.6980 time: 0.0986s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9882 acc_val: 0.4767 loss_test: 1.3561 acc_test: 0.6950 time: 0.1293s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0598 acc_val: 0.4933 loss_test: 1.3952 acc_test: 0.6950 time: 0.1132s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1430 acc_val: 0.5000 loss_test: 1.4294 acc_test: 0.6940 time: 0.1154s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1486 acc_val: 0.5067 loss_test: 1.4504 acc_test: 0.7010 time: 0.1293s
Optimization Finished!
Total time elapsed: 57.6452s, best testing performance  0.702000, minimun loss  1.025899
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7628 acc_train: 0.3417 loss_val: 1.7950 acc_val: 0.1300 loss_test: 1.6746 acc_test: 0.4850 time: 0.1579s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 2.0051 acc_val: 0.3333 loss_test: 1.2731 acc_test: 0.6420 time: 0.1042s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8727 acc_val: 0.4100 loss_test: 1.2362 acc_test: 0.6700 time: 0.0876s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8404 acc_val: 0.4267 loss_test: 1.2611 acc_test: 0.6770 time: 0.1296s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8845 acc_val: 0.4633 loss_test: 1.2996 acc_test: 0.6830 time: 0.0941s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9650 acc_val: 0.4733 loss_test: 1.3400 acc_test: 0.6930 time: 0.1350s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0169 acc_val: 0.4767 loss_test: 1.3680 acc_test: 0.6970 time: 0.1342s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0327 acc_val: 0.4933 loss_test: 1.3904 acc_test: 0.6970 time: 0.1315s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0660 acc_val: 0.5067 loss_test: 1.4233 acc_test: 0.6980 time: 0.1188s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1240 acc_val: 0.5100 loss_test: 1.4555 acc_test: 0.6950 time: 0.0920s
Optimization Finished!
Total time elapsed: 58.8321s, best testing performance  0.702000, minimun loss  1.029668
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7884 acc_train: 0.2083 loss_val: 1.7986 acc_val: 0.2033 loss_test: 1.6701 acc_test: 0.5210 time: 0.1202s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8248 acc_val: 0.3867 loss_test: 1.1561 acc_test: 0.6600 time: 0.0834s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8092 acc_val: 0.4300 loss_test: 1.1696 acc_test: 0.6770 time: 0.0857s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8625 acc_val: 0.4200 loss_test: 1.2126 acc_test: 0.6820 time: 0.0852s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9414 acc_val: 0.4567 loss_test: 1.2532 acc_test: 0.6910 time: 0.1058s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9837 acc_val: 0.4733 loss_test: 1.2929 acc_test: 0.6940 time: 0.1130s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0348 acc_val: 0.4667 loss_test: 1.3338 acc_test: 0.6980 time: 0.0925s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0635 acc_val: 0.4833 loss_test: 1.3695 acc_test: 0.7030 time: 0.1215s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.5067 loss_test: 1.4054 acc_test: 0.7040 time: 0.1396s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1303 acc_val: 0.5067 loss_test: 1.4421 acc_test: 0.7050 time: 0.1613s
Optimization Finished!
Total time elapsed: 53.3712s, best testing performance  0.708000, minimun loss  0.999294
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1833 loss_val: 1.8070 acc_val: 0.1367 loss_test: 1.6798 acc_test: 0.5030 time: 0.1559s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.7763 acc_val: 0.3833 loss_test: 1.1465 acc_test: 0.6610 time: 0.1339s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8427 acc_val: 0.4333 loss_test: 1.1819 acc_test: 0.6780 time: 0.1060s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8951 acc_val: 0.4367 loss_test: 1.2183 acc_test: 0.6890 time: 0.1006s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9843 acc_val: 0.4567 loss_test: 1.2682 acc_test: 0.6900 time: 0.1335s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0451 acc_val: 0.4667 loss_test: 1.3117 acc_test: 0.6900 time: 0.1480s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0862 acc_val: 0.4833 loss_test: 1.3446 acc_test: 0.6950 time: 0.1218s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1318 acc_val: 0.5100 loss_test: 1.3852 acc_test: 0.6930 time: 0.0948s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1861 acc_val: 0.5067 loss_test: 1.4269 acc_test: 0.6930 time: 0.1161s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2457 acc_val: 0.5033 loss_test: 1.4693 acc_test: 0.6930 time: 0.1401s
Optimization Finished!
Total time elapsed: 59.4534s, best testing performance  0.697000, minimun loss  1.011309
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7790 acc_train: 0.2417 loss_val: 1.7782 acc_val: 0.2100 loss_test: 1.6775 acc_test: 0.5280 time: 0.1204s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7630 acc_val: 0.3800 loss_test: 1.1620 acc_test: 0.6610 time: 0.0836s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7115 acc_val: 0.4500 loss_test: 1.1618 acc_test: 0.6770 time: 0.0824s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.7833 acc_val: 0.4633 loss_test: 1.2108 acc_test: 0.6810 time: 0.0830s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8843 acc_val: 0.4800 loss_test: 1.2608 acc_test: 0.6930 time: 0.0821s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9861 acc_val: 0.4800 loss_test: 1.3139 acc_test: 0.6920 time: 0.0847s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0474 acc_val: 0.5000 loss_test: 1.3518 acc_test: 0.6930 time: 0.1235s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0861 acc_val: 0.5000 loss_test: 1.3865 acc_test: 0.6920 time: 0.1488s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1592 acc_val: 0.5100 loss_test: 1.4271 acc_test: 0.6910 time: 0.1186s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1731 acc_val: 0.5067 loss_test: 1.4504 acc_test: 0.6930 time: 0.1219s
Optimization Finished!
Total time elapsed: 50.0036s, best testing performance  0.697000, minimun loss  1.004894
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8103 acc_train: 0.1000 loss_val: 1.8011 acc_val: 0.1133 loss_test: 1.6787 acc_test: 0.4340 time: 0.1095s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.7470 acc_val: 0.3800 loss_test: 1.1710 acc_test: 0.6630 time: 0.1259s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8014 acc_val: 0.4367 loss_test: 1.1983 acc_test: 0.6770 time: 0.1138s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8830 acc_val: 0.4433 loss_test: 1.2457 acc_test: 0.6860 time: 0.1365s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9512 acc_val: 0.4500 loss_test: 1.2801 acc_test: 0.6870 time: 0.1310s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0655 acc_val: 0.4500 loss_test: 1.3338 acc_test: 0.6900 time: 0.0940s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1151 acc_val: 0.4633 loss_test: 1.3682 acc_test: 0.6930 time: 0.1279s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2223 acc_val: 0.4600 loss_test: 1.4196 acc_test: 0.6900 time: 0.1089s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2583 acc_val: 0.4800 loss_test: 1.4545 acc_test: 0.6930 time: 0.1338s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3082 acc_val: 0.4767 loss_test: 1.4888 acc_test: 0.6960 time: 0.1069s
Optimization Finished!
Total time elapsed: 59.1918s, best testing performance  0.696000, minimun loss  1.018517
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8123 acc_train: 0.0917 loss_val: 1.8176 acc_val: 0.1300 loss_test: 1.6837 acc_test: 0.4710 time: 0.1502s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.7330 acc_val: 0.3933 loss_test: 1.1409 acc_test: 0.6640 time: 0.0817s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7037 acc_val: 0.4633 loss_test: 1.1589 acc_test: 0.6810 time: 0.0815s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.7506 acc_val: 0.4533 loss_test: 1.2095 acc_test: 0.6800 time: 0.0805s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8549 acc_val: 0.4700 loss_test: 1.2695 acc_test: 0.6900 time: 0.0867s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9805 acc_val: 0.4700 loss_test: 1.3306 acc_test: 0.6920 time: 0.0857s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0715 acc_val: 0.4767 loss_test: 1.3866 acc_test: 0.6910 time: 0.0837s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1373 acc_val: 0.5067 loss_test: 1.4358 acc_test: 0.6950 time: 0.0858s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1707 acc_val: 0.5200 loss_test: 1.4773 acc_test: 0.6960 time: 0.1089s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2560 acc_val: 0.5067 loss_test: 1.5316 acc_test: 0.6920 time: 0.1256s
Optimization Finished!
Total time elapsed: 45.9132s, best testing performance  0.698000, minimun loss  1.001912
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7942 acc_train: 0.1917 loss_val: 1.7804 acc_val: 0.2167 loss_test: 1.6671 acc_test: 0.4980 time: 0.1019s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7636 acc_val: 0.4067 loss_test: 1.1636 acc_test: 0.6660 time: 0.1241s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7661 acc_val: 0.4333 loss_test: 1.1975 acc_test: 0.6780 time: 0.1372s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8484 acc_val: 0.4233 loss_test: 1.2504 acc_test: 0.6840 time: 0.1047s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.8992 acc_val: 0.4600 loss_test: 1.2804 acc_test: 0.6880 time: 0.1045s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0179 acc_val: 0.4767 loss_test: 1.3384 acc_test: 0.6940 time: 0.1328s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1177 acc_val: 0.4767 loss_test: 1.3763 acc_test: 0.6950 time: 0.1295s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1826 acc_val: 0.4867 loss_test: 1.4154 acc_test: 0.6940 time: 0.1207s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1878 acc_val: 0.5067 loss_test: 1.4426 acc_test: 0.6990 time: 0.1345s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2653 acc_val: 0.5000 loss_test: 1.4791 acc_test: 0.6950 time: 0.1042s
Optimization Finished!
Total time elapsed: 59.4616s, best testing performance  0.702000, minimun loss  1.004379
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8036 acc_train: 0.1417 loss_val: 1.7915 acc_val: 0.1167 loss_test: 1.6877 acc_test: 0.4660 time: 0.1175s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7718 acc_val: 0.3800 loss_test: 1.1840 acc_test: 0.6580 time: 0.1065s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7419 acc_val: 0.4367 loss_test: 1.1947 acc_test: 0.6760 time: 0.0919s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.7927 acc_val: 0.4533 loss_test: 1.2327 acc_test: 0.6810 time: 0.0811s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4633 loss_test: 1.2872 acc_test: 0.6940 time: 0.0809s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0071 acc_val: 0.4833 loss_test: 1.3372 acc_test: 0.6920 time: 0.0809s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1306 acc_val: 0.4767 loss_test: 1.3910 acc_test: 0.6920 time: 0.0835s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1198 acc_val: 0.4933 loss_test: 1.4114 acc_test: 0.6980 time: 0.0835s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2133 acc_val: 0.4933 loss_test: 1.4574 acc_test: 0.6940 time: 0.0827s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2126 acc_val: 0.5067 loss_test: 1.4727 acc_test: 0.6980 time: 0.0832s
Optimization Finished!
Total time elapsed: 45.8821s, best testing performance  0.701000, minimun loss  1.009789
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7997 acc_train: 0.1833 loss_val: 1.7981 acc_val: 0.1400 loss_test: 1.6886 acc_test: 0.4680 time: 0.1853s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7908 acc_val: 0.3967 loss_test: 1.1899 acc_test: 0.6580 time: 0.1294s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7688 acc_val: 0.4400 loss_test: 1.1944 acc_test: 0.6770 time: 0.1065s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8198 acc_val: 0.4533 loss_test: 1.2306 acc_test: 0.6870 time: 0.1558s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8914 acc_val: 0.4600 loss_test: 1.2801 acc_test: 0.6830 time: 0.1261s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0088 acc_val: 0.4867 loss_test: 1.3428 acc_test: 0.6970 time: 0.1180s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1315 acc_val: 0.4833 loss_test: 1.3816 acc_test: 0.6970 time: 0.1113s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1670 acc_val: 0.4967 loss_test: 1.4172 acc_test: 0.6980 time: 0.0904s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2461 acc_val: 0.4933 loss_test: 1.4636 acc_test: 0.6940 time: 0.1364s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2865 acc_val: 0.4967 loss_test: 1.4970 acc_test: 0.6980 time: 0.1372s
Optimization Finished!
Total time elapsed: 59.3436s, best testing performance  0.700000, minimun loss  1.002012
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8094 acc_train: 0.1167 loss_val: 1.7941 acc_val: 0.1367 loss_test: 1.6950 acc_test: 0.4870 time: 0.1283s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7805 acc_val: 0.3867 loss_test: 1.1784 acc_test: 0.6620 time: 0.1064s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7573 acc_val: 0.4400 loss_test: 1.1878 acc_test: 0.6750 time: 0.0978s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9024 acc_val: 0.4400 loss_test: 1.2505 acc_test: 0.6830 time: 0.1088s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9778 acc_val: 0.4433 loss_test: 1.3001 acc_test: 0.6930 time: 0.1233s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0537 acc_val: 0.4667 loss_test: 1.3464 acc_test: 0.6920 time: 0.0807s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1115 acc_val: 0.4833 loss_test: 1.3901 acc_test: 0.6920 time: 0.0810s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1463 acc_val: 0.5033 loss_test: 1.4221 acc_test: 0.6940 time: 0.0810s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.4967 loss_test: 1.4585 acc_test: 0.6940 time: 0.0838s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1799 acc_val: 0.5100 loss_test: 1.4780 acc_test: 0.7000 time: 0.0834s
Optimization Finished!
Total time elapsed: 50.0625s, best testing performance  0.701000, minimun loss  0.994042
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7899 acc_train: 0.1667 loss_val: 1.8268 acc_val: 0.1267 loss_test: 1.6849 acc_test: 0.5020 time: 0.1281s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8207 acc_val: 0.3867 loss_test: 1.1805 acc_test: 0.6600 time: 0.1085s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8801 acc_val: 0.4233 loss_test: 1.2114 acc_test: 0.6740 time: 0.1135s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9746 acc_val: 0.4400 loss_test: 1.2672 acc_test: 0.6760 time: 0.1219s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0383 acc_val: 0.4433 loss_test: 1.3086 acc_test: 0.6870 time: 0.1343s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0917 acc_val: 0.4800 loss_test: 1.3511 acc_test: 0.6960 time: 0.1120s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0902 acc_val: 0.4967 loss_test: 1.3802 acc_test: 0.6940 time: 0.1067s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0984 acc_val: 0.5100 loss_test: 1.4041 acc_test: 0.6990 time: 0.1361s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1408 acc_val: 0.5133 loss_test: 1.4427 acc_test: 0.6980 time: 0.0959s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1700 acc_val: 0.5133 loss_test: 1.4724 acc_test: 0.7000 time: 0.1218s
Optimization Finished!
Total time elapsed: 59.9667s, best testing performance  0.704000, minimun loss  1.022716
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7872 acc_train: 0.1583 loss_val: 1.8068 acc_val: 0.1567 loss_test: 1.6627 acc_test: 0.5240 time: 0.1346s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.8038 acc_val: 0.3867 loss_test: 1.1593 acc_test: 0.6610 time: 0.1319s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8273 acc_val: 0.4233 loss_test: 1.1806 acc_test: 0.6840 time: 0.1238s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4333 loss_test: 1.2244 acc_test: 0.6950 time: 0.1446s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9720 acc_val: 0.4500 loss_test: 1.2779 acc_test: 0.6940 time: 0.1281s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0401 acc_val: 0.4600 loss_test: 1.3261 acc_test: 0.6970 time: 0.1183s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0753 acc_val: 0.4867 loss_test: 1.3645 acc_test: 0.6970 time: 0.0993s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1370 acc_val: 0.4867 loss_test: 1.4110 acc_test: 0.6980 time: 0.1291s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.4933 loss_test: 1.4501 acc_test: 0.6930 time: 0.0807s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2423 acc_val: 0.5100 loss_test: 1.5008 acc_test: 0.6920 time: 0.0834s
Optimization Finished!
Total time elapsed: 54.3221s, best testing performance  0.701000, minimun loss  1.025464
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7925 acc_train: 0.1750 loss_val: 1.7897 acc_val: 0.1667 loss_test: 1.6924 acc_test: 0.5040 time: 0.1329s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7346 acc_val: 0.4067 loss_test: 1.1455 acc_test: 0.6690 time: 0.1104s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7473 acc_val: 0.4300 loss_test: 1.1612 acc_test: 0.6840 time: 0.0918s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8490 acc_val: 0.4233 loss_test: 1.2106 acc_test: 0.6910 time: 0.1116s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9321 acc_val: 0.4400 loss_test: 1.2611 acc_test: 0.6880 time: 0.1045s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0002 acc_val: 0.4633 loss_test: 1.3060 acc_test: 0.6910 time: 0.1114s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0406 acc_val: 0.4767 loss_test: 1.3445 acc_test: 0.6910 time: 0.0936s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0793 acc_val: 0.5033 loss_test: 1.3813 acc_test: 0.6940 time: 0.1196s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0960 acc_val: 0.5033 loss_test: 1.4105 acc_test: 0.6960 time: 0.1081s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1207 acc_val: 0.5133 loss_test: 1.4381 acc_test: 0.6990 time: 0.0946s
Optimization Finished!
Total time elapsed: 58.8977s, best testing performance  0.702000, minimun loss  1.021800
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8041 acc_train: 0.1500 loss_val: 1.8125 acc_val: 0.1700 loss_test: 1.6998 acc_test: 0.4710 time: 0.1836s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7943 acc_val: 0.4067 loss_test: 1.1594 acc_test: 0.6630 time: 0.0959s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7813 acc_val: 0.4500 loss_test: 1.1709 acc_test: 0.6810 time: 0.1190s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8115 acc_val: 0.4433 loss_test: 1.2096 acc_test: 0.6870 time: 0.1442s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8969 acc_val: 0.4567 loss_test: 1.2567 acc_test: 0.6920 time: 0.1305s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9568 acc_val: 0.4767 loss_test: 1.2983 acc_test: 0.6940 time: 0.1012s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0182 acc_val: 0.4967 loss_test: 1.3406 acc_test: 0.6950 time: 0.1309s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0356 acc_val: 0.5000 loss_test: 1.3723 acc_test: 0.7000 time: 0.1462s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0928 acc_val: 0.5067 loss_test: 1.4106 acc_test: 0.7000 time: 0.1382s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1326 acc_val: 0.5133 loss_test: 1.4436 acc_test: 0.7000 time: 0.1080s
Optimization Finished!
Total time elapsed: 58.5246s, best testing performance  0.706000, minimun loss  1.014267
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7902 acc_train: 0.1750 loss_val: 1.7664 acc_val: 0.2300 loss_test: 1.6807 acc_test: 0.4550 time: 0.1225s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.7256 acc_val: 0.3900 loss_test: 1.1214 acc_test: 0.6730 time: 0.0828s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7597 acc_val: 0.4233 loss_test: 1.1507 acc_test: 0.6850 time: 0.0846s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8299 acc_val: 0.4367 loss_test: 1.1907 acc_test: 0.6950 time: 0.1237s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8837 acc_val: 0.4567 loss_test: 1.2356 acc_test: 0.6910 time: 0.1329s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9688 acc_val: 0.4733 loss_test: 1.2842 acc_test: 0.6930 time: 0.1041s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0357 acc_val: 0.4900 loss_test: 1.3297 acc_test: 0.6940 time: 0.1108s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1008 acc_val: 0.5033 loss_test: 1.3705 acc_test: 0.6950 time: 0.1577s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1388 acc_val: 0.5033 loss_test: 1.3998 acc_test: 0.6960 time: 0.0997s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1877 acc_val: 0.5033 loss_test: 1.4332 acc_test: 0.6990 time: 0.1033s
Optimization Finished!
Total time elapsed: 55.1721s, best testing performance  0.701000, minimun loss  1.013552
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7863 acc_train: 0.2000 loss_val: 1.8087 acc_val: 0.1100 loss_test: 1.6759 acc_test: 0.4050 time: 0.1430s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7957 acc_val: 0.3967 loss_test: 1.1640 acc_test: 0.6580 time: 0.1073s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8017 acc_val: 0.4167 loss_test: 1.1737 acc_test: 0.6810 time: 0.1254s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8342 acc_val: 0.4333 loss_test: 1.2039 acc_test: 0.6910 time: 0.1093s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8838 acc_val: 0.4533 loss_test: 1.2474 acc_test: 0.6910 time: 0.1132s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9215 acc_val: 0.4867 loss_test: 1.2855 acc_test: 0.6940 time: 0.1298s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9920 acc_val: 0.4833 loss_test: 1.3304 acc_test: 0.6980 time: 0.1304s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0617 acc_val: 0.5033 loss_test: 1.3744 acc_test: 0.6990 time: 0.1341s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0881 acc_val: 0.5167 loss_test: 1.4070 acc_test: 0.6980 time: 0.1284s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1103 acc_val: 0.5033 loss_test: 1.4376 acc_test: 0.6980 time: 0.1169s
Optimization Finished!
Total time elapsed: 59.0637s, best testing performance  0.701000, minimun loss  1.018101
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8061 acc_train: 0.1500 loss_val: 1.8283 acc_val: 0.0933 loss_test: 1.6690 acc_test: 0.3820 time: 0.0964s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8236 acc_val: 0.3800 loss_test: 1.1622 acc_test: 0.6580 time: 0.0848s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8554 acc_val: 0.4200 loss_test: 1.1926 acc_test: 0.6750 time: 0.0846s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9400 acc_val: 0.4200 loss_test: 1.2504 acc_test: 0.6860 time: 0.0826s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9562 acc_val: 0.4500 loss_test: 1.2834 acc_test: 0.6920 time: 0.0834s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0312 acc_val: 0.4600 loss_test: 1.3327 acc_test: 0.6950 time: 0.1089s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1048 acc_val: 0.4633 loss_test: 1.3698 acc_test: 0.6930 time: 0.0939s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1479 acc_val: 0.4900 loss_test: 1.4037 acc_test: 0.6940 time: 0.1231s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1988 acc_val: 0.4900 loss_test: 1.4377 acc_test: 0.6950 time: 0.1423s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2112 acc_val: 0.4933 loss_test: 1.4557 acc_test: 0.6960 time: 0.1246s
Optimization Finished!
Total time elapsed: 51.3712s, best testing performance  0.699000, minimun loss  1.027142
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8007 acc_train: 0.1167 loss_val: 1.8095 acc_val: 0.1500 loss_test: 1.6716 acc_test: 0.4940 time: 0.1022s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7803 acc_val: 0.3933 loss_test: 1.1507 acc_test: 0.6710 time: 0.1284s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8459 acc_val: 0.4300 loss_test: 1.1883 acc_test: 0.6880 time: 0.0976s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8949 acc_val: 0.4433 loss_test: 1.2279 acc_test: 0.6930 time: 0.1239s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9771 acc_val: 0.4667 loss_test: 1.2927 acc_test: 0.6940 time: 0.1356s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0662 acc_val: 0.4867 loss_test: 1.3430 acc_test: 0.6940 time: 0.1272s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1249 acc_val: 0.4933 loss_test: 1.3816 acc_test: 0.6930 time: 0.1279s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1304 acc_val: 0.4933 loss_test: 1.4128 acc_test: 0.6930 time: 0.0896s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2128 acc_val: 0.4933 loss_test: 1.4572 acc_test: 0.6940 time: 0.1199s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2109 acc_val: 0.5033 loss_test: 1.4787 acc_test: 0.6990 time: 0.1198s
Optimization Finished!
Total time elapsed: 59.9039s, best testing performance  0.702000, minimun loss  1.011586
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1917 loss_val: 1.8311 acc_val: 0.0467 loss_test: 1.6709 acc_test: 0.3390 time: 0.1161s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8605 acc_val: 0.3733 loss_test: 1.1640 acc_test: 0.6660 time: 0.0812s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8266 acc_val: 0.4333 loss_test: 1.1708 acc_test: 0.6850 time: 0.0809s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8907 acc_val: 0.4533 loss_test: 1.2238 acc_test: 0.6920 time: 0.0832s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9415 acc_val: 0.4667 loss_test: 1.2688 acc_test: 0.7010 time: 0.0834s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0128 acc_val: 0.4733 loss_test: 1.3285 acc_test: 0.6990 time: 0.0836s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1054 acc_val: 0.4867 loss_test: 1.3767 acc_test: 0.6950 time: 0.0832s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1412 acc_val: 0.4967 loss_test: 1.4196 acc_test: 0.6950 time: 0.1356s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1769 acc_val: 0.5100 loss_test: 1.4613 acc_test: 0.7000 time: 0.1046s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2522 acc_val: 0.5033 loss_test: 1.5067 acc_test: 0.6970 time: 0.0992s
Optimization Finished!
Total time elapsed: 47.1294s, best testing performance  0.702000, minimun loss  1.009006
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7961 acc_train: 0.1917 loss_val: 1.7995 acc_val: 0.1567 loss_test: 1.6826 acc_test: 0.4970 time: 0.1868s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.9143 acc_val: 0.3533 loss_test: 1.2035 acc_test: 0.6500 time: 0.1137s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8952 acc_val: 0.4200 loss_test: 1.2158 acc_test: 0.6760 time: 0.1242s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9555 acc_val: 0.4367 loss_test: 1.2576 acc_test: 0.6860 time: 0.0978s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9975 acc_val: 0.4600 loss_test: 1.2941 acc_test: 0.6950 time: 0.1142s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0345 acc_val: 0.4700 loss_test: 1.3356 acc_test: 0.6940 time: 0.1322s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0667 acc_val: 0.4900 loss_test: 1.3684 acc_test: 0.6970 time: 0.1135s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1254 acc_val: 0.5033 loss_test: 1.4083 acc_test: 0.6990 time: 0.1224s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1772 acc_val: 0.4967 loss_test: 1.4468 acc_test: 0.6980 time: 0.1184s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1849 acc_val: 0.5000 loss_test: 1.4727 acc_test: 0.7000 time: 0.1220s
Optimization Finished!
Total time elapsed: 59.6843s, best testing performance  0.707000, minimun loss  1.004204
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 5, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7959 acc_train: 0.1667 loss_val: 1.8160 acc_val: 0.0833 loss_test: 1.6757 acc_test: 0.4440 time: 0.1408s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7107 acc_val: 0.4100 loss_test: 1.1267 acc_test: 0.6690 time: 0.1569s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.6835 acc_val: 0.4433 loss_test: 1.1393 acc_test: 0.6780 time: 0.0809s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.7349 acc_val: 0.4600 loss_test: 1.1762 acc_test: 0.6820 time: 0.0821s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8736 acc_val: 0.4333 loss_test: 1.2528 acc_test: 0.6860 time: 0.0823s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0196 acc_val: 0.4567 loss_test: 1.3181 acc_test: 0.6900 time: 0.0835s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0540 acc_val: 0.4767 loss_test: 1.3450 acc_test: 0.6940 time: 0.0843s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4933 loss_test: 1.3797 acc_test: 0.6960 time: 0.0834s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1586 acc_val: 0.4867 loss_test: 1.4177 acc_test: 0.6930 time: 0.0838s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2146 acc_val: 0.5000 loss_test: 1.4485 acc_test: 0.6940 time: 0.0850s
Optimization Finished!
Total time elapsed: 45.6442s, best testing performance  0.699000, minimun loss  0.994567
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7858 acc_train: 0.2000 loss_val: 1.8104 acc_val: 0.1167 loss_test: 1.6794 acc_test: 0.4010 time: 0.1101s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8904 acc_val: 0.3667 loss_test: 1.2012 acc_test: 0.6430 time: 0.0992s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8367 acc_val: 0.4100 loss_test: 1.1884 acc_test: 0.6680 time: 0.1192s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.7921 acc_val: 0.4700 loss_test: 1.2040 acc_test: 0.6720 time: 0.1489s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.8978 acc_val: 0.4700 loss_test: 1.2723 acc_test: 0.6820 time: 0.1186s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0432 acc_val: 0.4800 loss_test: 1.3398 acc_test: 0.6900 time: 0.1638s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0913 acc_val: 0.4933 loss_test: 1.3789 acc_test: 0.6930 time: 0.1220s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1395 acc_val: 0.5033 loss_test: 1.4142 acc_test: 0.6920 time: 0.0989s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1682 acc_val: 0.5033 loss_test: 1.4372 acc_test: 0.6950 time: 0.1208s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1939 acc_val: 0.5067 loss_test: 1.4652 acc_test: 0.6930 time: 0.1255s
Optimization Finished!
Total time elapsed: 64.1442s, best testing performance  0.699000, minimun loss  1.024400
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.2000 loss_val: 1.7964 acc_val: 0.1933 loss_test: 1.6980 acc_test: 0.4720 time: 0.1044s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.9167 acc_val: 0.3367 loss_test: 1.1946 acc_test: 0.6510 time: 0.1622s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8026 acc_val: 0.4400 loss_test: 1.1543 acc_test: 0.6760 time: 0.1265s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8268 acc_val: 0.4567 loss_test: 1.1926 acc_test: 0.6740 time: 0.0864s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9103 acc_val: 0.4633 loss_test: 1.2623 acc_test: 0.6850 time: 0.0876s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0035 acc_val: 0.4833 loss_test: 1.3314 acc_test: 0.6910 time: 0.0865s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0749 acc_val: 0.4967 loss_test: 1.3876 acc_test: 0.6960 time: 0.0918s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1104 acc_val: 0.5000 loss_test: 1.4283 acc_test: 0.6960 time: 0.0899s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.5033 loss_test: 1.4603 acc_test: 0.6970 time: 0.0891s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1370 acc_val: 0.5233 loss_test: 1.4811 acc_test: 0.7010 time: 0.0906s
Optimization Finished!
Total time elapsed: 50.1223s, best testing performance  0.702000, minimun loss  1.038456
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8000 acc_train: 0.1417 loss_val: 1.7763 acc_val: 0.2000 loss_test: 1.7292 acc_test: 0.4300 time: 0.1801s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9709 acc_val: 0.3667 loss_test: 1.1961 acc_test: 0.6600 time: 0.1456s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8590 acc_val: 0.4233 loss_test: 1.1657 acc_test: 0.6820 time: 0.1221s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8264 acc_val: 0.4667 loss_test: 1.1784 acc_test: 0.6800 time: 0.1021s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9847 acc_val: 0.4600 loss_test: 1.2823 acc_test: 0.6850 time: 0.1149s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0426 acc_val: 0.4800 loss_test: 1.3294 acc_test: 0.6890 time: 0.1181s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0768 acc_val: 0.4933 loss_test: 1.3613 acc_test: 0.6950 time: 0.1309s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1242 acc_val: 0.5033 loss_test: 1.3920 acc_test: 0.6960 time: 0.1220s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1454 acc_val: 0.5067 loss_test: 1.4251 acc_test: 0.6900 time: 0.1480s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2234 acc_val: 0.5000 loss_test: 1.4578 acc_test: 0.6900 time: 0.1259s
Optimization Finished!
Total time elapsed: 62.6187s, best testing performance  0.698000, minimun loss  1.039911
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7828 acc_train: 0.2500 loss_val: 1.8140 acc_val: 0.1767 loss_test: 1.7165 acc_test: 0.5000 time: 0.1837s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9180 acc_val: 0.3600 loss_test: 1.1908 acc_test: 0.6520 time: 0.1122s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8503 acc_val: 0.4100 loss_test: 1.1787 acc_test: 0.6710 time: 0.1135s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8753 acc_val: 0.4433 loss_test: 1.2290 acc_test: 0.6680 time: 0.1364s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0448 acc_val: 0.4500 loss_test: 1.3109 acc_test: 0.6850 time: 0.0872s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1005 acc_val: 0.4767 loss_test: 1.3524 acc_test: 0.6950 time: 0.0867s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0754 acc_val: 0.4967 loss_test: 1.3762 acc_test: 0.6960 time: 0.0888s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1403 acc_val: 0.5167 loss_test: 1.4239 acc_test: 0.6950 time: 0.0902s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2038 acc_val: 0.5100 loss_test: 1.4587 acc_test: 0.6970 time: 0.0893s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2258 acc_val: 0.5167 loss_test: 1.4886 acc_test: 0.6980 time: 0.0898s
Optimization Finished!
Total time elapsed: 50.5227s, best testing performance  0.701000, minimun loss  1.014429
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7839 acc_train: 0.2000 loss_val: 1.8114 acc_val: 0.1200 loss_test: 1.6796 acc_test: 0.4480 time: 0.1374s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8923 acc_val: 0.3667 loss_test: 1.1907 acc_test: 0.6530 time: 0.1186s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8807 acc_val: 0.4100 loss_test: 1.1988 acc_test: 0.6690 time: 0.1350s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8184 acc_val: 0.4600 loss_test: 1.2078 acc_test: 0.6730 time: 0.1026s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.8804 acc_val: 0.4700 loss_test: 1.2717 acc_test: 0.6780 time: 0.1312s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0768 acc_val: 0.4600 loss_test: 1.3613 acc_test: 0.6920 time: 0.1397s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1104 acc_val: 0.4867 loss_test: 1.3948 acc_test: 0.6950 time: 0.1546s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1593 acc_val: 0.4867 loss_test: 1.4278 acc_test: 0.6970 time: 0.1331s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1657 acc_val: 0.4933 loss_test: 1.4530 acc_test: 0.6950 time: 0.1092s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1679 acc_val: 0.5067 loss_test: 1.4711 acc_test: 0.6980 time: 0.1493s
Optimization Finished!
Total time elapsed: 63.2652s, best testing performance  0.700000, minimun loss  1.020594
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7887 acc_train: 0.1500 loss_val: 1.8147 acc_val: 0.1100 loss_test: 1.6837 acc_test: 0.4720 time: 0.1077s
Epoch: 0051 loss_train: 0.0136 acc_train: 1.0000 loss_val: 1.7736 acc_val: 0.3767 loss_test: 1.1312 acc_test: 0.6590 time: 0.1128s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8539 acc_val: 0.4267 loss_test: 1.1692 acc_test: 0.6740 time: 0.1114s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9059 acc_val: 0.4500 loss_test: 1.2129 acc_test: 0.6870 time: 0.1303s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9919 acc_val: 0.4600 loss_test: 1.2733 acc_test: 0.6900 time: 0.0867s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0534 acc_val: 0.4833 loss_test: 1.3210 acc_test: 0.6940 time: 0.0875s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0977 acc_val: 0.4867 loss_test: 1.3621 acc_test: 0.6930 time: 0.0872s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1336 acc_val: 0.4833 loss_test: 1.4039 acc_test: 0.6950 time: 0.0890s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1683 acc_val: 0.5033 loss_test: 1.4392 acc_test: 0.6980 time: 0.0892s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2062 acc_val: 0.5067 loss_test: 1.4747 acc_test: 0.7000 time: 0.0888s
Optimization Finished!
Total time elapsed: 51.0495s, best testing performance  0.701000, minimun loss  1.008217
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1000 loss_val: 1.8000 acc_val: 0.1833 loss_test: 1.6910 acc_test: 0.4770 time: 0.1226s
Epoch: 0051 loss_train: 0.0135 acc_train: 1.0000 loss_val: 1.8420 acc_val: 0.3600 loss_test: 1.1631 acc_test: 0.6470 time: 0.1380s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8678 acc_val: 0.4000 loss_test: 1.1775 acc_test: 0.6730 time: 0.1167s
Epoch: 0151 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9331 acc_val: 0.4333 loss_test: 1.2314 acc_test: 0.6860 time: 0.1102s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9866 acc_val: 0.4500 loss_test: 1.2687 acc_test: 0.6860 time: 0.1225s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0407 acc_val: 0.4600 loss_test: 1.3098 acc_test: 0.6920 time: 0.1236s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0714 acc_val: 0.4767 loss_test: 1.3464 acc_test: 0.6930 time: 0.1049s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1174 acc_val: 0.4867 loss_test: 1.3811 acc_test: 0.6960 time: 0.1352s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1782 acc_val: 0.5000 loss_test: 1.4192 acc_test: 0.6960 time: 0.1202s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2022 acc_val: 0.5067 loss_test: 1.4462 acc_test: 0.6970 time: 0.1453s
Optimization Finished!
Total time elapsed: 63.0746s, best testing performance  0.699000, minimun loss  1.016756
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7964 acc_train: 0.1167 loss_val: 1.8057 acc_val: 0.0967 loss_test: 1.7014 acc_test: 0.4210 time: 0.1294s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8493 acc_val: 0.3633 loss_test: 1.1662 acc_test: 0.6540 time: 0.1232s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8399 acc_val: 0.4067 loss_test: 1.1709 acc_test: 0.6760 time: 0.1378s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9124 acc_val: 0.4300 loss_test: 1.2221 acc_test: 0.6810 time: 0.1045s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9555 acc_val: 0.4500 loss_test: 1.2643 acc_test: 0.6870 time: 0.0983s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9960 acc_val: 0.4667 loss_test: 1.3064 acc_test: 0.6890 time: 0.0872s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0346 acc_val: 0.4767 loss_test: 1.3442 acc_test: 0.6900 time: 0.0868s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0736 acc_val: 0.5033 loss_test: 1.3771 acc_test: 0.6940 time: 0.0866s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1224 acc_val: 0.5067 loss_test: 1.4180 acc_test: 0.6960 time: 0.0898s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1686 acc_val: 0.5033 loss_test: 1.4498 acc_test: 0.6950 time: 0.0905s
Optimization Finished!
Total time elapsed: 52.7504s, best testing performance  0.704000, minimun loss  1.026306
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7719 acc_train: 0.2667 loss_val: 1.7831 acc_val: 0.1767 loss_test: 1.6721 acc_test: 0.5360 time: 0.1205s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.7696 acc_val: 0.3800 loss_test: 1.1395 acc_test: 0.6600 time: 0.1521s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7948 acc_val: 0.4200 loss_test: 1.1523 acc_test: 0.6830 time: 0.1002s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4200 loss_test: 1.2102 acc_test: 0.6840 time: 0.1190s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9949 acc_val: 0.4533 loss_test: 1.2695 acc_test: 0.6840 time: 0.1280s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0539 acc_val: 0.4733 loss_test: 1.3149 acc_test: 0.6860 time: 0.1157s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1077 acc_val: 0.4733 loss_test: 1.3587 acc_test: 0.6880 time: 0.1479s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1429 acc_val: 0.4800 loss_test: 1.3931 acc_test: 0.6910 time: 0.1450s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1748 acc_val: 0.5000 loss_test: 1.4275 acc_test: 0.6900 time: 0.1063s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1952 acc_val: 0.5000 loss_test: 1.4588 acc_test: 0.6890 time: 0.1496s
Optimization Finished!
Total time elapsed: 63.8789s, best testing performance  0.695000, minimun loss  1.002903
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7856 acc_train: 0.2000 loss_val: 1.8019 acc_val: 0.2400 loss_test: 1.6855 acc_test: 0.5170 time: 0.1653s
Epoch: 0051 loss_train: 0.0137 acc_train: 1.0000 loss_val: 1.8741 acc_val: 0.3700 loss_test: 1.1669 acc_test: 0.6570 time: 0.0971s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8699 acc_val: 0.4100 loss_test: 1.1736 acc_test: 0.6650 time: 0.1431s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9750 acc_val: 0.4267 loss_test: 1.2260 acc_test: 0.6810 time: 0.1223s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.0596 acc_val: 0.4467 loss_test: 1.2814 acc_test: 0.6780 time: 0.1153s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1072 acc_val: 0.4600 loss_test: 1.3204 acc_test: 0.6850 time: 0.0863s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1601 acc_val: 0.4733 loss_test: 1.3598 acc_test: 0.6860 time: 0.0869s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2115 acc_val: 0.4900 loss_test: 1.4024 acc_test: 0.6900 time: 0.0870s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2565 acc_val: 0.4933 loss_test: 1.4396 acc_test: 0.6920 time: 0.0893s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2935 acc_val: 0.4933 loss_test: 1.4696 acc_test: 0.6910 time: 0.0895s
Optimization Finished!
Total time elapsed: 53.3949s, best testing performance  0.693000, minimun loss  1.012668
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8106 acc_train: 0.1083 loss_val: 1.8260 acc_val: 0.1600 loss_test: 1.6766 acc_test: 0.4600 time: 0.1291s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8568 acc_val: 0.3600 loss_test: 1.1715 acc_test: 0.6560 time: 0.1522s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8970 acc_val: 0.3800 loss_test: 1.1971 acc_test: 0.6710 time: 0.1298s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9970 acc_val: 0.4333 loss_test: 1.2459 acc_test: 0.6800 time: 0.1233s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0397 acc_val: 0.4433 loss_test: 1.2908 acc_test: 0.6800 time: 0.1534s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.1112 acc_val: 0.4633 loss_test: 1.3338 acc_test: 0.6890 time: 0.1047s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1591 acc_val: 0.4567 loss_test: 1.3694 acc_test: 0.6910 time: 0.1405s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1844 acc_val: 0.4900 loss_test: 1.4069 acc_test: 0.6920 time: 0.1260s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2019 acc_val: 0.4933 loss_test: 1.4366 acc_test: 0.6980 time: 0.0981s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1925 acc_val: 0.5067 loss_test: 1.4569 acc_test: 0.6950 time: 0.1029s
Optimization Finished!
Total time elapsed: 63.8331s, best testing performance  0.700000, minimun loss  0.987482
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7997 acc_train: 0.1583 loss_val: 1.8136 acc_val: 0.1300 loss_test: 1.6875 acc_test: 0.4960 time: 0.1602s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8536 acc_val: 0.3767 loss_test: 1.1770 acc_test: 0.6550 time: 0.1586s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8480 acc_val: 0.4067 loss_test: 1.1889 acc_test: 0.6690 time: 0.0954s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9048 acc_val: 0.4233 loss_test: 1.2372 acc_test: 0.6710 time: 0.1476s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0078 acc_val: 0.4533 loss_test: 1.2953 acc_test: 0.6900 time: 0.1461s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0300 acc_val: 0.4767 loss_test: 1.3218 acc_test: 0.6940 time: 0.1222s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0528 acc_val: 0.4967 loss_test: 1.3495 acc_test: 0.6940 time: 0.0875s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0790 acc_val: 0.4967 loss_test: 1.3820 acc_test: 0.6920 time: 0.0882s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1257 acc_val: 0.5000 loss_test: 1.4178 acc_test: 0.6940 time: 0.0871s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1600 acc_val: 0.5100 loss_test: 1.4416 acc_test: 0.6900 time: 0.0931s
Optimization Finished!
Total time elapsed: 54.9553s, best testing performance  0.697000, minimun loss  0.993831
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7673 acc_train: 0.2750 loss_val: 1.7727 acc_val: 0.2133 loss_test: 1.6688 acc_test: 0.5380 time: 0.1279s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8232 acc_val: 0.3567 loss_test: 1.1780 acc_test: 0.6490 time: 0.1283s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7766 acc_val: 0.4133 loss_test: 1.1760 acc_test: 0.6680 time: 0.1031s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8461 acc_val: 0.4267 loss_test: 1.2305 acc_test: 0.6720 time: 0.1349s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9178 acc_val: 0.4633 loss_test: 1.2751 acc_test: 0.6880 time: 0.1259s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9738 acc_val: 0.4700 loss_test: 1.3185 acc_test: 0.6980 time: 0.1020s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0426 acc_val: 0.4900 loss_test: 1.3533 acc_test: 0.6960 time: 0.1206s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1029 acc_val: 0.5067 loss_test: 1.3907 acc_test: 0.6950 time: 0.1480s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1342 acc_val: 0.5000 loss_test: 1.4191 acc_test: 0.6920 time: 0.1124s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1871 acc_val: 0.5033 loss_test: 1.4517 acc_test: 0.6940 time: 0.1059s
Optimization Finished!
Total time elapsed: 63.1504s, best testing performance  0.700000, minimun loss  0.995485
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7845 acc_train: 0.1417 loss_val: 1.7833 acc_val: 0.1567 loss_test: 1.6875 acc_test: 0.4940 time: 0.1071s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7780 acc_val: 0.3967 loss_test: 1.1468 acc_test: 0.6620 time: 0.1270s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7582 acc_val: 0.4367 loss_test: 1.1599 acc_test: 0.6790 time: 0.1060s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8066 acc_val: 0.4667 loss_test: 1.2200 acc_test: 0.6770 time: 0.1333s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9754 acc_val: 0.4667 loss_test: 1.2922 acc_test: 0.6900 time: 0.1048s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0290 acc_val: 0.4833 loss_test: 1.3266 acc_test: 0.6920 time: 0.1498s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0746 acc_val: 0.5000 loss_test: 1.3713 acc_test: 0.6950 time: 0.0987s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1272 acc_val: 0.5033 loss_test: 1.4135 acc_test: 0.6960 time: 0.0866s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1512 acc_val: 0.5133 loss_test: 1.4403 acc_test: 0.6950 time: 0.0886s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2054 acc_val: 0.5100 loss_test: 1.4783 acc_test: 0.6960 time: 0.0871s
Optimization Finished!
Total time elapsed: 56.1368s, best testing performance  0.700000, minimun loss  0.994181
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7893 acc_train: 0.1583 loss_val: 1.7873 acc_val: 0.1600 loss_test: 1.6689 acc_test: 0.5270 time: 0.1295s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9090 acc_val: 0.3667 loss_test: 1.2103 acc_test: 0.6490 time: 0.1445s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8535 acc_val: 0.3933 loss_test: 1.1993 acc_test: 0.6700 time: 0.1216s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9530 acc_val: 0.4200 loss_test: 1.2484 acc_test: 0.6820 time: 0.1263s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0241 acc_val: 0.4600 loss_test: 1.2930 acc_test: 0.6910 time: 0.1082s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0622 acc_val: 0.4767 loss_test: 1.3333 acc_test: 0.6890 time: 0.1464s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1303 acc_val: 0.4967 loss_test: 1.3721 acc_test: 0.6930 time: 0.1030s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1395 acc_val: 0.5000 loss_test: 1.3956 acc_test: 0.6920 time: 0.1509s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1980 acc_val: 0.5067 loss_test: 1.4295 acc_test: 0.6910 time: 0.1442s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2086 acc_val: 0.5100 loss_test: 1.4515 acc_test: 0.6920 time: 0.1133s
Optimization Finished!
Total time elapsed: 63.4102s, best testing performance  0.698000, minimun loss  1.004834
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8069 acc_train: 0.1417 loss_val: 1.8215 acc_val: 0.1500 loss_test: 1.6831 acc_test: 0.5080 time: 0.1102s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7972 acc_val: 0.3800 loss_test: 1.1640 acc_test: 0.6600 time: 0.1667s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8613 acc_val: 0.4267 loss_test: 1.1885 acc_test: 0.6800 time: 0.1043s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9176 acc_val: 0.4367 loss_test: 1.2300 acc_test: 0.6880 time: 0.1297s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9766 acc_val: 0.4700 loss_test: 1.2794 acc_test: 0.6830 time: 0.1292s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9890 acc_val: 0.4800 loss_test: 1.3118 acc_test: 0.6910 time: 0.1385s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0255 acc_val: 0.4900 loss_test: 1.3436 acc_test: 0.6930 time: 0.1166s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0662 acc_val: 0.5033 loss_test: 1.3779 acc_test: 0.7000 time: 0.1011s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1078 acc_val: 0.5067 loss_test: 1.4130 acc_test: 0.6960 time: 0.0873s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1435 acc_val: 0.5100 loss_test: 1.4408 acc_test: 0.6960 time: 0.0873s
Optimization Finished!
Total time elapsed: 57.5832s, best testing performance  0.701000, minimun loss  1.015495
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8033 acc_train: 0.1583 loss_val: 1.8313 acc_val: 0.0733 loss_test: 1.6688 acc_test: 0.4740 time: 0.1466s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8676 acc_val: 0.3733 loss_test: 1.1889 acc_test: 0.6540 time: 0.1130s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8036 acc_val: 0.4233 loss_test: 1.1846 acc_test: 0.6760 time: 0.1179s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.4633 loss_test: 1.2223 acc_test: 0.6840 time: 0.1337s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9391 acc_val: 0.4733 loss_test: 1.2734 acc_test: 0.6860 time: 0.1359s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0386 acc_val: 0.4700 loss_test: 1.3277 acc_test: 0.6920 time: 0.1348s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1402 acc_val: 0.4933 loss_test: 1.3828 acc_test: 0.6950 time: 0.1218s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1793 acc_val: 0.5033 loss_test: 1.4272 acc_test: 0.6920 time: 0.1385s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2372 acc_val: 0.4967 loss_test: 1.4704 acc_test: 0.6950 time: 0.1073s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2733 acc_val: 0.4900 loss_test: 1.5084 acc_test: 0.6920 time: 0.1791s
Optimization Finished!
Total time elapsed: 63.0969s, best testing performance  0.697000, minimun loss  1.013359
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7812 acc_train: 0.2250 loss_val: 1.8114 acc_val: 0.1267 loss_test: 1.6770 acc_test: 0.5130 time: 0.1127s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7475 acc_val: 0.4133 loss_test: 1.1442 acc_test: 0.6610 time: 0.1354s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7615 acc_val: 0.4467 loss_test: 1.1673 acc_test: 0.6770 time: 0.1395s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8646 acc_val: 0.4400 loss_test: 1.2158 acc_test: 0.6890 time: 0.1413s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9637 acc_val: 0.4667 loss_test: 1.2680 acc_test: 0.6880 time: 0.1175s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0166 acc_val: 0.4700 loss_test: 1.3061 acc_test: 0.6920 time: 0.1060s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0723 acc_val: 0.4800 loss_test: 1.3458 acc_test: 0.6910 time: 0.1413s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0846 acc_val: 0.5033 loss_test: 1.3754 acc_test: 0.6920 time: 0.1101s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1189 acc_val: 0.5033 loss_test: 1.4106 acc_test: 0.6910 time: 0.1291s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1793 acc_val: 0.5133 loss_test: 1.4425 acc_test: 0.6900 time: 0.0871s
Optimization Finished!
Total time elapsed: 59.2838s, best testing performance  0.698000, minimun loss  1.005865
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7939 acc_train: 0.1250 loss_val: 1.8143 acc_val: 0.1867 loss_test: 1.6840 acc_test: 0.5090 time: 0.1276s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7632 acc_val: 0.3967 loss_test: 1.1559 acc_test: 0.6610 time: 0.1453s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7843 acc_val: 0.4300 loss_test: 1.1752 acc_test: 0.6820 time: 0.1514s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8526 acc_val: 0.4700 loss_test: 1.2181 acc_test: 0.6870 time: 0.1163s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9178 acc_val: 0.4733 loss_test: 1.2691 acc_test: 0.6890 time: 0.1318s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9851 acc_val: 0.4933 loss_test: 1.3146 acc_test: 0.6910 time: 0.1213s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0396 acc_val: 0.5000 loss_test: 1.3562 acc_test: 0.6940 time: 0.1063s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0995 acc_val: 0.4967 loss_test: 1.3999 acc_test: 0.6950 time: 0.1219s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1557 acc_val: 0.5033 loss_test: 1.4427 acc_test: 0.6950 time: 0.1612s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1869 acc_val: 0.5100 loss_test: 1.4728 acc_test: 0.6940 time: 0.1072s
Optimization Finished!
Total time elapsed: 61.9884s, best testing performance  0.700000, minimun loss  1.007842
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8117 acc_train: 0.0833 loss_val: 1.7906 acc_val: 0.1867 loss_test: 1.6712 acc_test: 0.5220 time: 0.1081s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7704 acc_val: 0.3867 loss_test: 1.1491 acc_test: 0.6620 time: 0.1155s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8244 acc_val: 0.4267 loss_test: 1.1830 acc_test: 0.6720 time: 0.1411s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9133 acc_val: 0.4433 loss_test: 1.2447 acc_test: 0.6740 time: 0.1406s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9617 acc_val: 0.4700 loss_test: 1.2823 acc_test: 0.6880 time: 0.1207s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0580 acc_val: 0.4767 loss_test: 1.3347 acc_test: 0.6910 time: 0.1249s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1017 acc_val: 0.5000 loss_test: 1.3668 acc_test: 0.6930 time: 0.1412s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1903 acc_val: 0.4933 loss_test: 1.4130 acc_test: 0.6930 time: 0.1121s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2354 acc_val: 0.5067 loss_test: 1.4465 acc_test: 0.6950 time: 0.1045s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.3181 acc_val: 0.4967 loss_test: 1.4822 acc_test: 0.6930 time: 0.0876s
Optimization Finished!
Total time elapsed: 60.8390s, best testing performance  0.698000, minimun loss  0.995968
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7802 acc_train: 0.2500 loss_val: 1.7888 acc_val: 0.0900 loss_test: 1.6892 acc_test: 0.4470 time: 0.1401s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8125 acc_val: 0.3800 loss_test: 1.1959 acc_test: 0.6500 time: 0.0913s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7942 acc_val: 0.4300 loss_test: 1.2027 acc_test: 0.6700 time: 0.1202s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9035 acc_val: 0.4400 loss_test: 1.2531 acc_test: 0.6810 time: 0.1359s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9684 acc_val: 0.4700 loss_test: 1.2960 acc_test: 0.6900 time: 0.1076s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0128 acc_val: 0.4833 loss_test: 1.3359 acc_test: 0.6930 time: 0.1074s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.4867 loss_test: 1.3736 acc_test: 0.6940 time: 0.1221s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1247 acc_val: 0.5000 loss_test: 1.4110 acc_test: 0.6940 time: 0.1154s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1306 acc_val: 0.5067 loss_test: 1.4362 acc_test: 0.6920 time: 0.1349s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1862 acc_val: 0.5033 loss_test: 1.4625 acc_test: 0.6960 time: 0.1304s
Optimization Finished!
Total time elapsed: 60.5428s, best testing performance  0.700000, minimun loss  1.012850
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7946 acc_train: 0.1083 loss_val: 1.8066 acc_val: 0.1567 loss_test: 1.6884 acc_test: 0.4640 time: 0.1419s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7202 acc_val: 0.4233 loss_test: 1.1517 acc_test: 0.6650 time: 0.1525s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7259 acc_val: 0.4633 loss_test: 1.1616 acc_test: 0.6850 time: 0.1422s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8151 acc_val: 0.4567 loss_test: 1.2133 acc_test: 0.6940 time: 0.1191s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9198 acc_val: 0.4533 loss_test: 1.2706 acc_test: 0.6950 time: 0.1644s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0023 acc_val: 0.4767 loss_test: 1.3200 acc_test: 0.6920 time: 0.1182s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0579 acc_val: 0.4967 loss_test: 1.3733 acc_test: 0.6970 time: 0.1239s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1189 acc_val: 0.4967 loss_test: 1.4244 acc_test: 0.6990 time: 0.1184s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1341 acc_val: 0.5033 loss_test: 1.4601 acc_test: 0.7000 time: 0.1134s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1986 acc_val: 0.5067 loss_test: 1.5040 acc_test: 0.7000 time: 0.0933s
Optimization Finished!
Total time elapsed: 61.5734s, best testing performance  0.702000, minimun loss  1.009111
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7968 acc_train: 0.1500 loss_val: 1.8186 acc_val: 0.1400 loss_test: 1.6835 acc_test: 0.4680 time: 0.1208s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.9361 acc_val: 0.3767 loss_test: 1.2103 acc_test: 0.6570 time: 0.0897s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.9303 acc_val: 0.4167 loss_test: 1.2179 acc_test: 0.6720 time: 0.1260s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.4367 loss_test: 1.2658 acc_test: 0.6830 time: 0.1287s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0601 acc_val: 0.4633 loss_test: 1.3080 acc_test: 0.6870 time: 0.1440s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.1014 acc_val: 0.4733 loss_test: 1.3475 acc_test: 0.6870 time: 0.1429s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1097 acc_val: 0.4867 loss_test: 1.3709 acc_test: 0.6920 time: 0.1046s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1098 acc_val: 0.5033 loss_test: 1.4001 acc_test: 0.6940 time: 0.0971s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1746 acc_val: 0.5067 loss_test: 1.4389 acc_test: 0.6940 time: 0.1410s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2282 acc_val: 0.5000 loss_test: 1.4703 acc_test: 0.6950 time: 0.1140s
Optimization Finished!
Total time elapsed: 59.6218s, best testing performance  0.697000, minimun loss  1.011247
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7924 acc_train: 0.1417 loss_val: 1.7931 acc_val: 0.1767 loss_test: 1.6714 acc_test: 0.5420 time: 0.1452s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.9265 acc_val: 0.3700 loss_test: 1.2101 acc_test: 0.6470 time: 0.1053s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8767 acc_val: 0.4200 loss_test: 1.2071 acc_test: 0.6670 time: 0.1167s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9179 acc_val: 0.4267 loss_test: 1.2405 acc_test: 0.6810 time: 0.1138s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9737 acc_val: 0.4567 loss_test: 1.2795 acc_test: 0.6890 time: 0.1123s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9816 acc_val: 0.4800 loss_test: 1.3128 acc_test: 0.6890 time: 0.1107s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0564 acc_val: 0.5067 loss_test: 1.3558 acc_test: 0.6940 time: 0.1085s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0843 acc_val: 0.5100 loss_test: 1.3895 acc_test: 0.6970 time: 0.1145s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1346 acc_val: 0.5067 loss_test: 1.4196 acc_test: 0.6980 time: 0.1042s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1709 acc_val: 0.5000 loss_test: 1.4541 acc_test: 0.6980 time: 0.1039s
Optimization Finished!
Total time elapsed: 62.9137s, best testing performance  0.700000, minimun loss  1.016998
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7887 acc_train: 0.2083 loss_val: 1.8142 acc_val: 0.1567 loss_test: 1.6962 acc_test: 0.4800 time: 0.1371s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7124 acc_val: 0.4133 loss_test: 1.1471 acc_test: 0.6600 time: 0.0891s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7310 acc_val: 0.4633 loss_test: 1.1691 acc_test: 0.6760 time: 0.0910s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8467 acc_val: 0.4633 loss_test: 1.2281 acc_test: 0.6820 time: 0.1462s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9115 acc_val: 0.4767 loss_test: 1.2691 acc_test: 0.6860 time: 0.1025s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9885 acc_val: 0.4867 loss_test: 1.3157 acc_test: 0.6890 time: 0.1261s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0638 acc_val: 0.4900 loss_test: 1.3611 acc_test: 0.6900 time: 0.1024s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.4800 loss_test: 1.4101 acc_test: 0.6970 time: 0.1095s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1884 acc_val: 0.4867 loss_test: 1.4554 acc_test: 0.6970 time: 0.1312s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2308 acc_val: 0.4933 loss_test: 1.4906 acc_test: 0.7000 time: 0.1521s
Optimization Finished!
Total time elapsed: 59.0326s, best testing performance  0.701000, minimun loss  0.998242
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8073 acc_train: 0.1000 loss_val: 1.7805 acc_val: 0.1600 loss_test: 1.6860 acc_test: 0.4600 time: 0.1716s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8004 acc_val: 0.4033 loss_test: 1.1740 acc_test: 0.6510 time: 0.1172s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7584 acc_val: 0.4533 loss_test: 1.1810 acc_test: 0.6770 time: 0.1296s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8805 acc_val: 0.4633 loss_test: 1.2531 acc_test: 0.6780 time: 0.1201s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9922 acc_val: 0.4633 loss_test: 1.3063 acc_test: 0.6850 time: 0.1063s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0420 acc_val: 0.4767 loss_test: 1.3473 acc_test: 0.6890 time: 0.1356s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0926 acc_val: 0.4967 loss_test: 1.3866 acc_test: 0.6920 time: 0.1275s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1465 acc_val: 0.5000 loss_test: 1.4190 acc_test: 0.6930 time: 0.1259s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1858 acc_val: 0.5033 loss_test: 1.4534 acc_test: 0.6930 time: 0.1154s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2301 acc_val: 0.4933 loss_test: 1.4933 acc_test: 0.6990 time: 0.1036s
Optimization Finished!
Total time elapsed: 63.5199s, best testing performance  0.699000, minimun loss  0.995368
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8036 acc_train: 0.1333 loss_val: 1.8053 acc_val: 0.1400 loss_test: 1.6885 acc_test: 0.4330 time: 0.1225s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8500 acc_val: 0.4000 loss_test: 1.2161 acc_test: 0.6590 time: 0.0891s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7857 acc_val: 0.4500 loss_test: 1.2145 acc_test: 0.6810 time: 0.0894s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.7807 acc_val: 0.4833 loss_test: 1.2326 acc_test: 0.6820 time: 0.1536s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8452 acc_val: 0.4867 loss_test: 1.2830 acc_test: 0.6900 time: 0.1327s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9529 acc_val: 0.4867 loss_test: 1.3399 acc_test: 0.6970 time: 0.1059s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0763 acc_val: 0.4900 loss_test: 1.3949 acc_test: 0.6920 time: 0.1561s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1461 acc_val: 0.5033 loss_test: 1.4223 acc_test: 0.6930 time: 0.1167s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2066 acc_val: 0.5000 loss_test: 1.4537 acc_test: 0.6910 time: 0.1014s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2576 acc_val: 0.5000 loss_test: 1.4790 acc_test: 0.6950 time: 0.1057s
Optimization Finished!
Total time elapsed: 58.4240s, best testing performance  0.698000, minimun loss  1.032251
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7989 acc_train: 0.1250 loss_val: 1.8182 acc_val: 0.1633 loss_test: 1.6770 acc_test: 0.4840 time: 0.1152s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7768 acc_val: 0.3700 loss_test: 1.1648 acc_test: 0.6540 time: 0.1048s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7509 acc_val: 0.4433 loss_test: 1.1799 acc_test: 0.6760 time: 0.1340s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8244 acc_val: 0.4467 loss_test: 1.2302 acc_test: 0.6870 time: 0.1297s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9373 acc_val: 0.4767 loss_test: 1.2811 acc_test: 0.6940 time: 0.1313s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0403 acc_val: 0.4800 loss_test: 1.3329 acc_test: 0.6910 time: 0.1338s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0633 acc_val: 0.5000 loss_test: 1.3658 acc_test: 0.6950 time: 0.1415s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0699 acc_val: 0.5033 loss_test: 1.3879 acc_test: 0.6920 time: 0.1460s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1398 acc_val: 0.5100 loss_test: 1.4307 acc_test: 0.6930 time: 0.1137s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1889 acc_val: 0.5067 loss_test: 1.4571 acc_test: 0.6930 time: 0.1254s
Optimization Finished!
Total time elapsed: 63.5779s, best testing performance  0.702000, minimun loss  0.978989
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8038 acc_train: 0.2000 loss_val: 1.8418 acc_val: 0.0767 loss_test: 1.6573 acc_test: 0.4150 time: 0.1339s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7961 acc_val: 0.3867 loss_test: 1.1863 acc_test: 0.6600 time: 0.0887s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8060 acc_val: 0.4300 loss_test: 1.2052 acc_test: 0.6820 time: 0.0898s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9160 acc_val: 0.4500 loss_test: 1.2652 acc_test: 0.6850 time: 0.0904s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0316 acc_val: 0.4533 loss_test: 1.3159 acc_test: 0.6890 time: 0.1233s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0997 acc_val: 0.4667 loss_test: 1.3511 acc_test: 0.6930 time: 0.1047s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1376 acc_val: 0.4833 loss_test: 1.3854 acc_test: 0.6890 time: 0.1449s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1837 acc_val: 0.4933 loss_test: 1.4211 acc_test: 0.6920 time: 0.1079s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1944 acc_val: 0.4867 loss_test: 1.4389 acc_test: 0.6910 time: 0.1273s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1675 acc_val: 0.4967 loss_test: 1.4510 acc_test: 0.6970 time: 0.1296s
Optimization Finished!
Total time elapsed: 57.8115s, best testing performance  0.699000, minimun loss  1.001090
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7850 acc_train: 0.1917 loss_val: 1.8083 acc_val: 0.0967 loss_test: 1.6713 acc_test: 0.4200 time: 0.1394s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8904 acc_val: 0.3933 loss_test: 1.2115 acc_test: 0.6510 time: 0.1097s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8183 acc_val: 0.4333 loss_test: 1.2112 acc_test: 0.6780 time: 0.1318s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8340 acc_val: 0.4600 loss_test: 1.2474 acc_test: 0.6790 time: 0.1361s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9343 acc_val: 0.4667 loss_test: 1.3132 acc_test: 0.6820 time: 0.1439s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0729 acc_val: 0.4833 loss_test: 1.3658 acc_test: 0.6940 time: 0.1202s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1743 acc_val: 0.4900 loss_test: 1.4087 acc_test: 0.6910 time: 0.1512s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2081 acc_val: 0.5000 loss_test: 1.4302 acc_test: 0.6940 time: 0.1405s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2419 acc_val: 0.5067 loss_test: 1.4626 acc_test: 0.6950 time: 0.1003s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2829 acc_val: 0.5100 loss_test: 1.4919 acc_test: 0.6940 time: 0.1172s
Optimization Finished!
Total time elapsed: 63.5824s, best testing performance  0.698000, minimun loss  1.005823
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7875 acc_train: 0.1917 loss_val: 1.8104 acc_val: 0.1833 loss_test: 1.6604 acc_test: 0.5550 time: 0.1378s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.6930 acc_val: 0.3933 loss_test: 1.1359 acc_test: 0.6600 time: 0.0890s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7274 acc_val: 0.4400 loss_test: 1.1688 acc_test: 0.6760 time: 0.0893s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8234 acc_val: 0.4500 loss_test: 1.2293 acc_test: 0.6780 time: 0.0909s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9347 acc_val: 0.4733 loss_test: 1.2811 acc_test: 0.6930 time: 0.1019s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0284 acc_val: 0.4867 loss_test: 1.3275 acc_test: 0.6950 time: 0.1462s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0674 acc_val: 0.5033 loss_test: 1.3709 acc_test: 0.6950 time: 0.1269s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0727 acc_val: 0.5200 loss_test: 1.4044 acc_test: 0.6980 time: 0.1398s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1063 acc_val: 0.5200 loss_test: 1.4453 acc_test: 0.6960 time: 0.1250s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1544 acc_val: 0.5200 loss_test: 1.4872 acc_test: 0.7000 time: 0.1050s
Optimization Finished!
Total time elapsed: 56.6837s, best testing performance  0.704000, minimun loss  1.004687
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7847 acc_train: 0.2083 loss_val: 1.8211 acc_val: 0.1500 loss_test: 1.6634 acc_test: 0.4970 time: 0.1154s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7543 acc_val: 0.3900 loss_test: 1.1530 acc_test: 0.6570 time: 0.1230s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7333 acc_val: 0.4700 loss_test: 1.1638 acc_test: 0.6850 time: 0.1408s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8021 acc_val: 0.4667 loss_test: 1.2123 acc_test: 0.6850 time: 0.1426s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9218 acc_val: 0.4933 loss_test: 1.2714 acc_test: 0.6950 time: 0.1088s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0269 acc_val: 0.4933 loss_test: 1.3222 acc_test: 0.6940 time: 0.1183s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.5033 loss_test: 1.3577 acc_test: 0.6950 time: 0.1442s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1506 acc_val: 0.5067 loss_test: 1.4047 acc_test: 0.6930 time: 0.1276s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2044 acc_val: 0.5100 loss_test: 1.4474 acc_test: 0.6950 time: 0.1425s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2536 acc_val: 0.5100 loss_test: 1.4760 acc_test: 0.6980 time: 0.1120s
Optimization Finished!
Total time elapsed: 64.0683s, best testing performance  0.699000, minimun loss  1.011816
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.1583 loss_val: 1.8308 acc_val: 0.1067 loss_test: 1.6729 acc_test: 0.4820 time: 0.1055s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7771 acc_val: 0.3733 loss_test: 1.1603 acc_test: 0.6550 time: 0.0896s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8972 acc_val: 0.4133 loss_test: 1.2079 acc_test: 0.6750 time: 0.0881s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9532 acc_val: 0.4333 loss_test: 1.2447 acc_test: 0.6900 time: 0.0894s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0112 acc_val: 0.4633 loss_test: 1.2851 acc_test: 0.6890 time: 0.1083s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0425 acc_val: 0.4900 loss_test: 1.3198 acc_test: 0.6930 time: 0.1307s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0970 acc_val: 0.5033 loss_test: 1.3609 acc_test: 0.6960 time: 0.1154s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1659 acc_val: 0.5067 loss_test: 1.4117 acc_test: 0.6950 time: 0.1128s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1953 acc_val: 0.5000 loss_test: 1.4388 acc_test: 0.6970 time: 0.1486s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2458 acc_val: 0.5067 loss_test: 1.4807 acc_test: 0.6970 time: 0.1031s
Optimization Finished!
Total time elapsed: 56.1710s, best testing performance  0.701000, minimun loss  1.023988
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7879 acc_train: 0.1833 loss_val: 1.8048 acc_val: 0.1467 loss_test: 1.6814 acc_test: 0.4690 time: 0.1885s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.6943 acc_val: 0.4267 loss_test: 1.1496 acc_test: 0.6630 time: 0.1364s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8570 acc_val: 0.4367 loss_test: 1.2118 acc_test: 0.6670 time: 0.1081s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9137 acc_val: 0.4533 loss_test: 1.2519 acc_test: 0.6820 time: 0.1065s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9671 acc_val: 0.4533 loss_test: 1.2964 acc_test: 0.6880 time: 0.1146s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.4633 loss_test: 1.3375 acc_test: 0.6950 time: 0.1020s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0926 acc_val: 0.4933 loss_test: 1.3763 acc_test: 0.6960 time: 0.1466s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1300 acc_val: 0.4933 loss_test: 1.4106 acc_test: 0.6900 time: 0.1113s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1730 acc_val: 0.4933 loss_test: 1.4497 acc_test: 0.6930 time: 0.1068s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2291 acc_val: 0.5067 loss_test: 1.4854 acc_test: 0.6950 time: 0.1008s
Optimization Finished!
Total time elapsed: 63.1713s, best testing performance  0.698000, minimun loss  1.019323
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8133 acc_train: 0.1167 loss_val: 1.8318 acc_val: 0.0933 loss_test: 1.7047 acc_test: 0.4070 time: 0.1284s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7702 acc_val: 0.4067 loss_test: 1.1586 acc_test: 0.6520 time: 0.0924s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8377 acc_val: 0.4400 loss_test: 1.1968 acc_test: 0.6680 time: 0.0888s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8773 acc_val: 0.4400 loss_test: 1.2371 acc_test: 0.6790 time: 0.0889s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9638 acc_val: 0.4567 loss_test: 1.2772 acc_test: 0.6880 time: 0.0917s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0189 acc_val: 0.4600 loss_test: 1.3108 acc_test: 0.6900 time: 0.1265s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1057 acc_val: 0.4700 loss_test: 1.3543 acc_test: 0.6920 time: 0.1370s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1099 acc_val: 0.4900 loss_test: 1.3833 acc_test: 0.6940 time: 0.1081s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1341 acc_val: 0.4833 loss_test: 1.4078 acc_test: 0.6930 time: 0.1147s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1647 acc_val: 0.4933 loss_test: 1.4375 acc_test: 0.6980 time: 0.1330s
Optimization Finished!
Total time elapsed: 55.4306s, best testing performance  0.699000, minimun loss  1.020172
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7854 acc_train: 0.1833 loss_val: 1.8185 acc_val: 0.1300 loss_test: 1.6540 acc_test: 0.5040 time: 0.1666s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7095 acc_val: 0.4233 loss_test: 1.1909 acc_test: 0.6620 time: 0.1414s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7472 acc_val: 0.4567 loss_test: 1.2188 acc_test: 0.6800 time: 0.1222s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8274 acc_val: 0.4400 loss_test: 1.2753 acc_test: 0.6780 time: 0.1257s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9336 acc_val: 0.4467 loss_test: 1.3356 acc_test: 0.6850 time: 0.0960s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0298 acc_val: 0.4600 loss_test: 1.3720 acc_test: 0.6970 time: 0.0960s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1359 acc_val: 0.4867 loss_test: 1.4132 acc_test: 0.6950 time: 0.1231s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2035 acc_val: 0.4800 loss_test: 1.4522 acc_test: 0.6890 time: 0.1372s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2738 acc_val: 0.4867 loss_test: 1.4801 acc_test: 0.6910 time: 0.1429s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2886 acc_val: 0.4867 loss_test: 1.4969 acc_test: 0.6920 time: 0.1420s
Optimization Finished!
Total time elapsed: 63.0629s, best testing performance  0.697000, minimun loss  1.024947
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1750 loss_val: 1.8085 acc_val: 0.1300 loss_test: 1.6675 acc_test: 0.5040 time: 0.1119s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7578 acc_val: 0.4367 loss_test: 1.1729 acc_test: 0.6690 time: 0.0926s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7718 acc_val: 0.4567 loss_test: 1.1966 acc_test: 0.6820 time: 0.0881s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8501 acc_val: 0.4700 loss_test: 1.2536 acc_test: 0.6870 time: 0.0893s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9616 acc_val: 0.4733 loss_test: 1.2999 acc_test: 0.6920 time: 0.0901s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0261 acc_val: 0.4800 loss_test: 1.3352 acc_test: 0.6950 time: 0.1289s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0482 acc_val: 0.4933 loss_test: 1.3626 acc_test: 0.6960 time: 0.1607s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0937 acc_val: 0.4933 loss_test: 1.3862 acc_test: 0.6960 time: 0.1030s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1091 acc_val: 0.4767 loss_test: 1.4112 acc_test: 0.6980 time: 0.1032s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1322 acc_val: 0.4867 loss_test: 1.4366 acc_test: 0.7020 time: 0.1397s
Optimization Finished!
Total time elapsed: 54.8807s, best testing performance  0.705000, minimun loss  0.995150
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8156 acc_train: 0.1083 loss_val: 1.8207 acc_val: 0.1900 loss_test: 1.7033 acc_test: 0.3270 time: 0.1101s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8612 acc_val: 0.3933 loss_test: 1.1979 acc_test: 0.6610 time: 0.1209s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8631 acc_val: 0.4433 loss_test: 1.2159 acc_test: 0.6750 time: 0.1227s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8392 acc_val: 0.4567 loss_test: 1.2348 acc_test: 0.6760 time: 0.1423s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9116 acc_val: 0.4667 loss_test: 1.2832 acc_test: 0.6890 time: 0.1360s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.4600 loss_test: 1.3462 acc_test: 0.6980 time: 0.1615s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0985 acc_val: 0.4800 loss_test: 1.3709 acc_test: 0.6970 time: 0.1340s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1671 acc_val: 0.4933 loss_test: 1.4000 acc_test: 0.7000 time: 0.1671s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1828 acc_val: 0.4967 loss_test: 1.4216 acc_test: 0.6960 time: 0.1447s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2668 acc_val: 0.4900 loss_test: 1.4634 acc_test: 0.6930 time: 0.1061s
Optimization Finished!
Total time elapsed: 63.6407s, best testing performance  0.702000, minimun loss  1.018484
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7913 acc_train: 0.1417 loss_val: 1.7976 acc_val: 0.1600 loss_test: 1.6729 acc_test: 0.5180 time: 0.1104s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7605 acc_val: 0.4167 loss_test: 1.1785 acc_test: 0.6600 time: 0.0893s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7171 acc_val: 0.4667 loss_test: 1.1840 acc_test: 0.6760 time: 0.0888s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8029 acc_val: 0.4567 loss_test: 1.2336 acc_test: 0.6810 time: 0.0894s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9443 acc_val: 0.4567 loss_test: 1.3061 acc_test: 0.6890 time: 0.0915s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0299 acc_val: 0.4600 loss_test: 1.3451 acc_test: 0.6960 time: 0.1122s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0450 acc_val: 0.4733 loss_test: 1.3726 acc_test: 0.7000 time: 0.1283s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1038 acc_val: 0.4833 loss_test: 1.4067 acc_test: 0.6950 time: 0.1030s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1530 acc_val: 0.4967 loss_test: 1.4415 acc_test: 0.6990 time: 0.1257s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2151 acc_val: 0.4967 loss_test: 1.4820 acc_test: 0.6980 time: 0.1163s
Optimization Finished!
Total time elapsed: 54.6702s, best testing performance  0.703000, minimun loss  0.979432
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7821 acc_train: 0.1917 loss_val: 1.8051 acc_val: 0.1300 loss_test: 1.6743 acc_test: 0.4780 time: 0.1352s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7305 acc_val: 0.4500 loss_test: 1.1685 acc_test: 0.6660 time: 0.1258s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8270 acc_val: 0.4533 loss_test: 1.2187 acc_test: 0.6750 time: 0.1093s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9797 acc_val: 0.4367 loss_test: 1.2913 acc_test: 0.6730 time: 0.1189s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0145 acc_val: 0.4533 loss_test: 1.3308 acc_test: 0.6820 time: 0.1177s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0342 acc_val: 0.4733 loss_test: 1.3589 acc_test: 0.6920 time: 0.1441s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0640 acc_val: 0.4800 loss_test: 1.3828 acc_test: 0.6930 time: 0.1469s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0662 acc_val: 0.5167 loss_test: 1.4019 acc_test: 0.6980 time: 0.1158s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1344 acc_val: 0.5100 loss_test: 1.4432 acc_test: 0.6970 time: 0.1276s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1457 acc_val: 0.5100 loss_test: 1.4605 acc_test: 0.7020 time: 0.1560s
Optimization Finished!
Total time elapsed: 62.8225s, best testing performance  0.704000, minimun loss  0.998876
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8045 acc_train: 0.0750 loss_val: 1.8202 acc_val: 0.1900 loss_test: 1.6841 acc_test: 0.3730 time: 0.1101s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.9222 acc_val: 0.3767 loss_test: 1.2341 acc_test: 0.6530 time: 0.0867s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9224 acc_val: 0.4200 loss_test: 1.2416 acc_test: 0.6730 time: 0.0920s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 2.0432 acc_val: 0.4300 loss_test: 1.2930 acc_test: 0.6760 time: 0.0892s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0659 acc_val: 0.4467 loss_test: 1.3207 acc_test: 0.6850 time: 0.0885s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1105 acc_val: 0.4567 loss_test: 1.3570 acc_test: 0.6900 time: 0.0912s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1572 acc_val: 0.4700 loss_test: 1.3908 acc_test: 0.6920 time: 0.1357s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2167 acc_val: 0.4933 loss_test: 1.4287 acc_test: 0.6920 time: 0.1204s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2469 acc_val: 0.5067 loss_test: 1.4570 acc_test: 0.6900 time: 0.1412s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2947 acc_val: 0.5033 loss_test: 1.4883 acc_test: 0.6900 time: 0.1237s
Optimization Finished!
Total time elapsed: 53.4620s, best testing performance  0.696000, minimun loss  1.043359
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7930 acc_train: 0.1750 loss_val: 1.7930 acc_val: 0.1900 loss_test: 1.6896 acc_test: 0.5200 time: 0.1360s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8338 acc_val: 0.4300 loss_test: 1.1819 acc_test: 0.6650 time: 0.1336s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8550 acc_val: 0.4567 loss_test: 1.1987 acc_test: 0.6740 time: 0.1198s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9222 acc_val: 0.4433 loss_test: 1.2430 acc_test: 0.6850 time: 0.1272s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0105 acc_val: 0.4767 loss_test: 1.2940 acc_test: 0.6900 time: 0.1276s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0567 acc_val: 0.4833 loss_test: 1.3334 acc_test: 0.6930 time: 0.1287s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0868 acc_val: 0.4967 loss_test: 1.3686 acc_test: 0.6950 time: 0.1426s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1240 acc_val: 0.4967 loss_test: 1.4008 acc_test: 0.6940 time: 0.1071s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1578 acc_val: 0.4967 loss_test: 1.4243 acc_test: 0.6950 time: 0.1221s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1526 acc_val: 0.5000 loss_test: 1.4511 acc_test: 0.6990 time: 0.1378s
Optimization Finished!
Total time elapsed: 63.6589s, best testing performance  0.700000, minimun loss  1.010188
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8091 acc_train: 0.1000 loss_val: 1.8107 acc_val: 0.1200 loss_test: 1.6687 acc_test: 0.4980 time: 0.1422s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8020 acc_val: 0.4100 loss_test: 1.1776 acc_test: 0.6570 time: 0.0866s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8261 acc_val: 0.4633 loss_test: 1.2032 acc_test: 0.6740 time: 0.0918s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9200 acc_val: 0.4467 loss_test: 1.2611 acc_test: 0.6790 time: 0.0896s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9610 acc_val: 0.4700 loss_test: 1.2973 acc_test: 0.6930 time: 0.0882s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0517 acc_val: 0.4800 loss_test: 1.3412 acc_test: 0.6900 time: 0.0894s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1342 acc_val: 0.4767 loss_test: 1.3876 acc_test: 0.6910 time: 0.1232s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1624 acc_val: 0.4900 loss_test: 1.4123 acc_test: 0.6870 time: 0.1445s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.5033 loss_test: 1.4443 acc_test: 0.6920 time: 0.1386s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2209 acc_val: 0.5067 loss_test: 1.4635 acc_test: 0.6930 time: 0.1470s
Optimization Finished!
Total time elapsed: 52.1068s, best testing performance  0.696000, minimun loss  1.005458
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7946 acc_train: 0.1917 loss_val: 1.7936 acc_val: 0.1533 loss_test: 1.6738 acc_test: 0.5280 time: 0.1035s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7368 acc_val: 0.4400 loss_test: 1.1518 acc_test: 0.6600 time: 0.1087s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7861 acc_val: 0.4533 loss_test: 1.1849 acc_test: 0.6790 time: 0.1450s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8867 acc_val: 0.4467 loss_test: 1.2398 acc_test: 0.6820 time: 0.1372s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9743 acc_val: 0.4600 loss_test: 1.2980 acc_test: 0.6900 time: 0.1348s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9976 acc_val: 0.4733 loss_test: 1.3291 acc_test: 0.6900 time: 0.1421s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0695 acc_val: 0.5000 loss_test: 1.3755 acc_test: 0.6920 time: 0.1236s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0644 acc_val: 0.5133 loss_test: 1.4037 acc_test: 0.6980 time: 0.1968s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1245 acc_val: 0.5100 loss_test: 1.4439 acc_test: 0.6960 time: 0.1078s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1562 acc_val: 0.5100 loss_test: 1.4747 acc_test: 0.6950 time: 0.1235s
Optimization Finished!
Total time elapsed: 63.3789s, best testing performance  0.702000, minimun loss  0.999617
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8070 acc_train: 0.1083 loss_val: 1.8277 acc_val: 0.0533 loss_test: 1.6721 acc_test: 0.3680 time: 0.1114s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8265 acc_val: 0.3867 loss_test: 1.1911 acc_test: 0.6540 time: 0.0869s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8772 acc_val: 0.4267 loss_test: 1.2185 acc_test: 0.6700 time: 0.0863s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9242 acc_val: 0.4367 loss_test: 1.2575 acc_test: 0.6810 time: 0.0891s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9987 acc_val: 0.4400 loss_test: 1.3037 acc_test: 0.6870 time: 0.0893s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0208 acc_val: 0.4667 loss_test: 1.3281 acc_test: 0.6920 time: 0.0888s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1011 acc_val: 0.4667 loss_test: 1.3746 acc_test: 0.6920 time: 0.0907s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1329 acc_val: 0.4900 loss_test: 1.4063 acc_test: 0.6930 time: 0.1735s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1916 acc_val: 0.4800 loss_test: 1.4473 acc_test: 0.6900 time: 0.1579s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1908 acc_val: 0.5000 loss_test: 1.4622 acc_test: 0.6990 time: 0.1146s
Optimization Finished!
Total time elapsed: 50.8333s, best testing performance  0.702000, minimun loss  1.002982
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8022 acc_train: 0.1000 loss_val: 1.8165 acc_val: 0.0800 loss_test: 1.6733 acc_test: 0.4570 time: 0.1185s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7792 acc_val: 0.3833 loss_test: 1.1714 acc_test: 0.6530 time: 0.1143s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7890 acc_val: 0.4400 loss_test: 1.1853 acc_test: 0.6730 time: 0.1234s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8762 acc_val: 0.4433 loss_test: 1.2329 acc_test: 0.6920 time: 0.1202s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9015 acc_val: 0.4700 loss_test: 1.2615 acc_test: 0.6970 time: 0.1339s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9456 acc_val: 0.4867 loss_test: 1.3045 acc_test: 0.6960 time: 0.1074s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9879 acc_val: 0.4900 loss_test: 1.3404 acc_test: 0.6970 time: 0.1302s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0366 acc_val: 0.5033 loss_test: 1.3795 acc_test: 0.6990 time: 0.1241s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0501 acc_val: 0.5167 loss_test: 1.4013 acc_test: 0.6990 time: 0.1310s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0898 acc_val: 0.5167 loss_test: 1.4343 acc_test: 0.6950 time: 0.1190s
Optimization Finished!
Total time elapsed: 63.1926s, best testing performance  0.704000, minimun loss  1.016955
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8144 acc_train: 0.0917 loss_val: 1.7964 acc_val: 0.1067 loss_test: 1.6860 acc_test: 0.4110 time: 0.1119s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7621 acc_val: 0.4033 loss_test: 1.1337 acc_test: 0.6620 time: 0.0866s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7389 acc_val: 0.4367 loss_test: 1.1458 acc_test: 0.6830 time: 0.0931s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8194 acc_val: 0.4500 loss_test: 1.1997 acc_test: 0.6920 time: 0.0885s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9054 acc_val: 0.4667 loss_test: 1.2541 acc_test: 0.6930 time: 0.0888s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9794 acc_val: 0.4833 loss_test: 1.3048 acc_test: 0.6940 time: 0.0890s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0491 acc_val: 0.4933 loss_test: 1.3546 acc_test: 0.6970 time: 0.0898s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1165 acc_val: 0.4967 loss_test: 1.4022 acc_test: 0.6930 time: 0.0912s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1439 acc_val: 0.5033 loss_test: 1.4387 acc_test: 0.6960 time: 0.1430s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1794 acc_val: 0.4900 loss_test: 1.4735 acc_test: 0.6960 time: 0.1351s
Optimization Finished!
Total time elapsed: 50.2025s, best testing performance  0.700000, minimun loss  0.989188
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8062 acc_train: 0.1750 loss_val: 1.8103 acc_val: 0.1200 loss_test: 1.6938 acc_test: 0.5130 time: 0.1227s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8216 acc_val: 0.3900 loss_test: 1.1811 acc_test: 0.6570 time: 0.1310s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8744 acc_val: 0.4200 loss_test: 1.2099 acc_test: 0.6800 time: 0.1418s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9732 acc_val: 0.4367 loss_test: 1.2600 acc_test: 0.6870 time: 0.1196s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0093 acc_val: 0.4600 loss_test: 1.2971 acc_test: 0.6920 time: 0.1435s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0741 acc_val: 0.4633 loss_test: 1.3449 acc_test: 0.6910 time: 0.1449s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1261 acc_val: 0.4800 loss_test: 1.3887 acc_test: 0.6930 time: 0.1035s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1617 acc_val: 0.5033 loss_test: 1.4260 acc_test: 0.6920 time: 0.1047s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1743 acc_val: 0.5067 loss_test: 1.4627 acc_test: 0.6940 time: 0.1426s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2025 acc_val: 0.5000 loss_test: 1.4961 acc_test: 0.6930 time: 0.1305s
Optimization Finished!
Total time elapsed: 63.9654s, best testing performance  0.697000, minimun loss  1.042229
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7854 acc_train: 0.1667 loss_val: 1.8001 acc_val: 0.1433 loss_test: 1.6824 acc_test: 0.4740 time: 0.1464s
Epoch: 0051 loss_train: 0.0134 acc_train: 1.0000 loss_val: 1.7443 acc_val: 0.3933 loss_test: 1.1486 acc_test: 0.6620 time: 0.0879s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8071 acc_val: 0.4367 loss_test: 1.1856 acc_test: 0.6740 time: 0.0881s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8827 acc_val: 0.4300 loss_test: 1.2310 acc_test: 0.6850 time: 0.0866s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0096 acc_val: 0.4400 loss_test: 1.2875 acc_test: 0.6910 time: 0.0874s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0710 acc_val: 0.4600 loss_test: 1.3244 acc_test: 0.6920 time: 0.0926s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1089 acc_val: 0.4833 loss_test: 1.3602 acc_test: 0.6950 time: 0.0898s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1171 acc_val: 0.4900 loss_test: 1.3828 acc_test: 0.6960 time: 0.0891s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1514 acc_val: 0.4933 loss_test: 1.4170 acc_test: 0.6950 time: 0.1311s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1803 acc_val: 0.4900 loss_test: 1.4426 acc_test: 0.6980 time: 0.1112s
Optimization Finished!
Total time elapsed: 49.9991s, best testing performance  0.704000, minimun loss  1.027595
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8069 acc_train: 0.1333 loss_val: 1.8234 acc_val: 0.1333 loss_test: 1.6950 acc_test: 0.4010 time: 0.1303s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.9773 acc_val: 0.3533 loss_test: 1.2136 acc_test: 0.6450 time: 0.1552s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.9348 acc_val: 0.3967 loss_test: 1.2103 acc_test: 0.6730 time: 0.1228s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9375 acc_val: 0.4433 loss_test: 1.2346 acc_test: 0.6860 time: 0.1611s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0009 acc_val: 0.4600 loss_test: 1.2798 acc_test: 0.6860 time: 0.1137s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0417 acc_val: 0.4733 loss_test: 1.3185 acc_test: 0.6890 time: 0.1496s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0752 acc_val: 0.4900 loss_test: 1.3568 acc_test: 0.6930 time: 0.1040s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0471 acc_val: 0.5167 loss_test: 1.3811 acc_test: 0.6940 time: 0.1227s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1200 acc_val: 0.5100 loss_test: 1.4205 acc_test: 0.6950 time: 0.1343s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1449 acc_val: 0.5200 loss_test: 1.4508 acc_test: 0.6940 time: 0.1788s
Optimization Finished!
Total time elapsed: 63.6024s, best testing performance  0.700000, minimun loss  1.021502
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7928 acc_train: 0.1333 loss_val: 1.7870 acc_val: 0.1800 loss_test: 1.6911 acc_test: 0.4530 time: 0.1468s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8924 acc_val: 0.3833 loss_test: 1.2053 acc_test: 0.6550 time: 0.1153s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8895 acc_val: 0.4033 loss_test: 1.2224 acc_test: 0.6720 time: 0.0871s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9381 acc_val: 0.4233 loss_test: 1.2587 acc_test: 0.6880 time: 0.0870s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9562 acc_val: 0.4600 loss_test: 1.2830 acc_test: 0.6900 time: 0.0876s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.4967 loss_test: 1.3138 acc_test: 0.6920 time: 0.0930s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9856 acc_val: 0.5067 loss_test: 1.3399 acc_test: 0.6950 time: 0.0923s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0373 acc_val: 0.5133 loss_test: 1.3738 acc_test: 0.6960 time: 0.0889s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0974 acc_val: 0.5133 loss_test: 1.4074 acc_test: 0.7000 time: 0.0918s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1605 acc_val: 0.5067 loss_test: 1.4401 acc_test: 0.7020 time: 0.0922s
Optimization Finished!
Total time elapsed: 48.6956s, best testing performance  0.706000, minimun loss  1.036810
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7798 acc_train: 0.2000 loss_val: 1.8045 acc_val: 0.0933 loss_test: 1.6653 acc_test: 0.3970 time: 0.1855s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7557 acc_val: 0.4033 loss_test: 1.1611 acc_test: 0.6530 time: 0.1168s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7960 acc_val: 0.4100 loss_test: 1.1900 acc_test: 0.6750 time: 0.1046s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9023 acc_val: 0.4367 loss_test: 1.2427 acc_test: 0.6820 time: 0.1204s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9347 acc_val: 0.4633 loss_test: 1.2760 acc_test: 0.6880 time: 0.1499s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9871 acc_val: 0.4733 loss_test: 1.3120 acc_test: 0.6950 time: 0.1217s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0217 acc_val: 0.4767 loss_test: 1.3486 acc_test: 0.6970 time: 0.1385s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0569 acc_val: 0.5100 loss_test: 1.3777 acc_test: 0.6950 time: 0.1019s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0933 acc_val: 0.5100 loss_test: 1.4048 acc_test: 0.6990 time: 0.1439s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0640 acc_val: 0.5167 loss_test: 1.4234 acc_test: 0.6960 time: 0.1160s
Optimization Finished!
Total time elapsed: 64.1451s, best testing performance  0.701000, minimun loss  1.003518
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7912 acc_train: 0.1917 loss_val: 1.7713 acc_val: 0.2300 loss_test: 1.6731 acc_test: 0.4810 time: 0.1308s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7216 acc_val: 0.3967 loss_test: 1.1479 acc_test: 0.6670 time: 0.1250s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8308 acc_val: 0.4200 loss_test: 1.1965 acc_test: 0.6820 time: 0.1068s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9352 acc_val: 0.4233 loss_test: 1.2486 acc_test: 0.6940 time: 0.1104s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0271 acc_val: 0.4533 loss_test: 1.3006 acc_test: 0.6920 time: 0.1003s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0574 acc_val: 0.4600 loss_test: 1.3369 acc_test: 0.6920 time: 0.1548s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0942 acc_val: 0.4700 loss_test: 1.3743 acc_test: 0.6990 time: 0.1431s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1219 acc_val: 0.5000 loss_test: 1.4083 acc_test: 0.6990 time: 0.0872s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1879 acc_val: 0.4967 loss_test: 1.4539 acc_test: 0.6990 time: 0.0887s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2109 acc_val: 0.5100 loss_test: 1.4789 acc_test: 0.7010 time: 0.0904s
Optimization Finished!
Total time elapsed: 55.9689s, best testing performance  0.702000, minimun loss  1.016743
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7949 acc_train: 0.1750 loss_val: 1.8101 acc_val: 0.1500 loss_test: 1.6812 acc_test: 0.4830 time: 0.1137s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8738 acc_val: 0.3767 loss_test: 1.1814 acc_test: 0.6460 time: 0.1125s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8493 acc_val: 0.4100 loss_test: 1.1875 acc_test: 0.6710 time: 0.1583s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9099 acc_val: 0.4267 loss_test: 1.2339 acc_test: 0.6830 time: 0.1459s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9924 acc_val: 0.4400 loss_test: 1.2837 acc_test: 0.6930 time: 0.1658s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0262 acc_val: 0.4533 loss_test: 1.3174 acc_test: 0.6950 time: 0.1303s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0204 acc_val: 0.4767 loss_test: 1.3434 acc_test: 0.6940 time: 0.1077s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0456 acc_val: 0.5033 loss_test: 1.3755 acc_test: 0.6980 time: 0.1409s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1077 acc_val: 0.5100 loss_test: 1.4148 acc_test: 0.6940 time: 0.1130s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1449 acc_val: 0.5133 loss_test: 1.4476 acc_test: 0.6990 time: 0.1363s
Optimization Finished!
Total time elapsed: 64.2373s, best testing performance  0.703000, minimun loss  1.006108
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 6, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7900 acc_train: 0.1333 loss_val: 1.8109 acc_val: 0.0833 loss_test: 1.6527 acc_test: 0.3610 time: 0.1255s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8617 acc_val: 0.3800 loss_test: 1.1920 acc_test: 0.6520 time: 0.1306s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8251 acc_val: 0.4300 loss_test: 1.2003 acc_test: 0.6760 time: 0.1176s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8747 acc_val: 0.4467 loss_test: 1.2479 acc_test: 0.6920 time: 0.1429s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9574 acc_val: 0.4500 loss_test: 1.2963 acc_test: 0.6940 time: 0.1038s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0250 acc_val: 0.4700 loss_test: 1.3392 acc_test: 0.6960 time: 0.1375s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0953 acc_val: 0.4767 loss_test: 1.3834 acc_test: 0.6970 time: 0.1407s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1840 acc_val: 0.4867 loss_test: 1.4418 acc_test: 0.7020 time: 0.1136s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2187 acc_val: 0.5000 loss_test: 1.4792 acc_test: 0.7020 time: 0.0981s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2242 acc_val: 0.5067 loss_test: 1.5087 acc_test: 0.6980 time: 0.1279s
Optimization Finished!
Total time elapsed: 63.7828s, best testing performance  0.706000, minimun loss  1.003396
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7837 acc_train: 0.2083 loss_val: 1.8161 acc_val: 0.1400 loss_test: 1.6614 acc_test: 0.5320 time: 0.1309s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8042 acc_val: 0.3700 loss_test: 1.1571 acc_test: 0.6540 time: 0.0943s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7224 acc_val: 0.4433 loss_test: 1.1405 acc_test: 0.6790 time: 0.0944s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7956 acc_val: 0.4700 loss_test: 1.1999 acc_test: 0.6860 time: 0.0961s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9768 acc_val: 0.4600 loss_test: 1.2799 acc_test: 0.6830 time: 0.0967s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4767 loss_test: 1.3369 acc_test: 0.6920 time: 0.1152s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1185 acc_val: 0.4900 loss_test: 1.3657 acc_test: 0.6920 time: 0.1245s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1336 acc_val: 0.5000 loss_test: 1.3966 acc_test: 0.6980 time: 0.1167s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1976 acc_val: 0.5000 loss_test: 1.4329 acc_test: 0.6980 time: 0.1365s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2494 acc_val: 0.5000 loss_test: 1.4670 acc_test: 0.6990 time: 0.1453s
Optimization Finished!
Total time elapsed: 59.9812s, best testing performance  0.701000, minimun loss  0.980095
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7822 acc_train: 0.2583 loss_val: 1.8452 acc_val: 0.1000 loss_test: 1.6623 acc_test: 0.4130 time: 0.2042s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.6601 acc_val: 0.3967 loss_test: 1.1066 acc_test: 0.6690 time: 0.1231s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7092 acc_val: 0.4533 loss_test: 1.1404 acc_test: 0.6770 time: 0.1515s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8400 acc_val: 0.4467 loss_test: 1.2173 acc_test: 0.6720 time: 0.1572s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9549 acc_val: 0.4633 loss_test: 1.2811 acc_test: 0.6840 time: 0.1573s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0562 acc_val: 0.4800 loss_test: 1.3353 acc_test: 0.6880 time: 0.1099s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0536 acc_val: 0.4933 loss_test: 1.3639 acc_test: 0.6930 time: 0.1106s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0841 acc_val: 0.5133 loss_test: 1.3948 acc_test: 0.6980 time: 0.1109s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1377 acc_val: 0.5100 loss_test: 1.4323 acc_test: 0.7000 time: 0.1310s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1577 acc_val: 0.5067 loss_test: 1.4576 acc_test: 0.6990 time: 0.1753s
Optimization Finished!
Total time elapsed: 67.9096s, best testing performance  0.703000, minimun loss  0.987778
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7810 acc_train: 0.2000 loss_val: 1.8073 acc_val: 0.1500 loss_test: 1.6637 acc_test: 0.4880 time: 0.1222s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7213 acc_val: 0.4000 loss_test: 1.1489 acc_test: 0.6640 time: 0.0930s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7162 acc_val: 0.4600 loss_test: 1.1370 acc_test: 0.6840 time: 0.0971s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8245 acc_val: 0.4700 loss_test: 1.2062 acc_test: 0.6740 time: 0.0950s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9991 acc_val: 0.4467 loss_test: 1.3089 acc_test: 0.6780 time: 0.0987s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0656 acc_val: 0.4767 loss_test: 1.3502 acc_test: 0.6930 time: 0.0992s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1561 acc_val: 0.4900 loss_test: 1.3909 acc_test: 0.6990 time: 0.0960s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1209 acc_val: 0.5000 loss_test: 1.4079 acc_test: 0.6940 time: 0.0972s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1731 acc_val: 0.5000 loss_test: 1.4355 acc_test: 0.6980 time: 0.1311s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1948 acc_val: 0.5067 loss_test: 1.4673 acc_test: 0.6940 time: 0.1433s
Optimization Finished!
Total time elapsed: 53.9664s, best testing performance  0.700000, minimun loss  1.017613
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7788 acc_train: 0.1667 loss_val: 1.8315 acc_val: 0.1833 loss_test: 1.6420 acc_test: 0.5510 time: 0.1414s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8381 acc_val: 0.3767 loss_test: 1.1715 acc_test: 0.6540 time: 0.1468s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8293 acc_val: 0.4100 loss_test: 1.1806 acc_test: 0.6690 time: 0.1202s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8581 acc_val: 0.4333 loss_test: 1.2224 acc_test: 0.6770 time: 0.1113s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9440 acc_val: 0.4667 loss_test: 1.2759 acc_test: 0.6840 time: 0.1251s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0160 acc_val: 0.4733 loss_test: 1.3212 acc_test: 0.6920 time: 0.1281s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0131 acc_val: 0.4800 loss_test: 1.3472 acc_test: 0.6920 time: 0.1462s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1214 acc_val: 0.4933 loss_test: 1.4002 acc_test: 0.6970 time: 0.1242s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1195 acc_val: 0.5000 loss_test: 1.4235 acc_test: 0.7000 time: 0.1708s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1413 acc_val: 0.5067 loss_test: 1.4477 acc_test: 0.7040 time: 0.1638s
Optimization Finished!
Total time elapsed: 68.0487s, best testing performance  0.705000, minimun loss  0.991863
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7898 acc_train: 0.1167 loss_val: 1.8243 acc_val: 0.1700 loss_test: 1.6645 acc_test: 0.4890 time: 0.1052s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8319 acc_val: 0.3633 loss_test: 1.1796 acc_test: 0.6580 time: 0.1266s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8039 acc_val: 0.4300 loss_test: 1.1743 acc_test: 0.6790 time: 0.1269s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8710 acc_val: 0.4433 loss_test: 1.2274 acc_test: 0.6690 time: 0.0926s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9887 acc_val: 0.4667 loss_test: 1.3030 acc_test: 0.6830 time: 0.0935s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0404 acc_val: 0.4733 loss_test: 1.3410 acc_test: 0.6940 time: 0.0925s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0725 acc_val: 0.4967 loss_test: 1.3720 acc_test: 0.6960 time: 0.0957s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1093 acc_val: 0.5100 loss_test: 1.4011 acc_test: 0.6950 time: 0.0985s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1251 acc_val: 0.5033 loss_test: 1.4310 acc_test: 0.6960 time: 0.0953s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.5133 loss_test: 1.4542 acc_test: 0.6960 time: 0.0975s
Optimization Finished!
Total time elapsed: 53.1307s, best testing performance  0.701000, minimun loss  1.012396
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7915 acc_train: 0.1583 loss_val: 1.8063 acc_val: 0.1200 loss_test: 1.6543 acc_test: 0.5050 time: 0.1525s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9166 acc_val: 0.3867 loss_test: 1.2044 acc_test: 0.6530 time: 0.1323s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.9074 acc_val: 0.4200 loss_test: 1.2080 acc_test: 0.6690 time: 0.1582s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9906 acc_val: 0.4167 loss_test: 1.2551 acc_test: 0.6780 time: 0.1061s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0955 acc_val: 0.4367 loss_test: 1.3165 acc_test: 0.6790 time: 0.1184s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.1105 acc_val: 0.4667 loss_test: 1.3446 acc_test: 0.6870 time: 0.1254s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1323 acc_val: 0.4833 loss_test: 1.3719 acc_test: 0.6880 time: 0.1485s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1510 acc_val: 0.4933 loss_test: 1.3976 acc_test: 0.6910 time: 0.1043s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1765 acc_val: 0.5000 loss_test: 1.4243 acc_test: 0.6950 time: 0.1183s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2058 acc_val: 0.5000 loss_test: 1.4457 acc_test: 0.6940 time: 0.1163s
Optimization Finished!
Total time elapsed: 67.8810s, best testing performance  0.696000, minimun loss  1.003395
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1417 loss_val: 1.7976 acc_val: 0.1767 loss_test: 1.6781 acc_test: 0.4540 time: 0.1644s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7574 acc_val: 0.3900 loss_test: 1.1604 acc_test: 0.6620 time: 0.1703s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.6963 acc_val: 0.4433 loss_test: 1.1468 acc_test: 0.6860 time: 0.1561s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8094 acc_val: 0.4600 loss_test: 1.2056 acc_test: 0.6910 time: 0.1191s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9117 acc_val: 0.4633 loss_test: 1.2660 acc_test: 0.6870 time: 0.1327s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9669 acc_val: 0.4867 loss_test: 1.3096 acc_test: 0.6920 time: 0.1213s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0455 acc_val: 0.4867 loss_test: 1.3584 acc_test: 0.6950 time: 0.0927s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1193 acc_val: 0.4967 loss_test: 1.3966 acc_test: 0.6940 time: 0.0938s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1330 acc_val: 0.5100 loss_test: 1.4252 acc_test: 0.6910 time: 0.0930s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1723 acc_val: 0.5100 loss_test: 1.4559 acc_test: 0.6960 time: 0.0956s
Optimization Finished!
Total time elapsed: 59.1162s, best testing performance  0.697000, minimun loss  1.006795
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7845 acc_train: 0.1833 loss_val: 1.8148 acc_val: 0.1633 loss_test: 1.6781 acc_test: 0.5100 time: 0.1274s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8831 acc_val: 0.3600 loss_test: 1.1787 acc_test: 0.6530 time: 0.1587s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8554 acc_val: 0.4200 loss_test: 1.1800 acc_test: 0.6740 time: 0.1182s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9013 acc_val: 0.4367 loss_test: 1.2132 acc_test: 0.6780 time: 0.1215s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9535 acc_val: 0.4733 loss_test: 1.2740 acc_test: 0.6840 time: 0.1506s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0320 acc_val: 0.4900 loss_test: 1.3266 acc_test: 0.6910 time: 0.1555s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0898 acc_val: 0.4833 loss_test: 1.3706 acc_test: 0.6940 time: 0.1122s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.5000 loss_test: 1.3975 acc_test: 0.6960 time: 0.1573s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1482 acc_val: 0.5067 loss_test: 1.4306 acc_test: 0.6970 time: 0.1180s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1708 acc_val: 0.5067 loss_test: 1.4518 acc_test: 0.7000 time: 0.1290s
Optimization Finished!
Total time elapsed: 68.7923s, best testing performance  0.702000, minimun loss  0.999415
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8024 acc_train: 0.1500 loss_val: 1.8398 acc_val: 0.1167 loss_test: 1.6802 acc_test: 0.4650 time: 0.1845s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7615 acc_val: 0.4000 loss_test: 1.1389 acc_test: 0.6590 time: 0.1537s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7597 acc_val: 0.4433 loss_test: 1.1452 acc_test: 0.6830 time: 0.1414s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8389 acc_val: 0.4400 loss_test: 1.1962 acc_test: 0.6850 time: 0.1244s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9431 acc_val: 0.4733 loss_test: 1.2676 acc_test: 0.6910 time: 0.1102s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0380 acc_val: 0.4800 loss_test: 1.3241 acc_test: 0.6890 time: 0.1245s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0631 acc_val: 0.4967 loss_test: 1.3601 acc_test: 0.6930 time: 0.1101s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1148 acc_val: 0.5000 loss_test: 1.3906 acc_test: 0.6940 time: 0.1090s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.5000 loss_test: 1.4248 acc_test: 0.6970 time: 0.1211s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1490 acc_val: 0.5133 loss_test: 1.4434 acc_test: 0.6970 time: 0.0925s
Optimization Finished!
Total time elapsed: 65.3835s, best testing performance  0.700000, minimun loss  0.994206
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7886 acc_train: 0.1500 loss_val: 1.8093 acc_val: 0.1400 loss_test: 1.6685 acc_test: 0.4710 time: 0.1353s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.6965 acc_val: 0.4000 loss_test: 1.1339 acc_test: 0.6640 time: 0.0955s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7318 acc_val: 0.4433 loss_test: 1.1621 acc_test: 0.6840 time: 0.0964s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8412 acc_val: 0.4400 loss_test: 1.2269 acc_test: 0.6880 time: 0.1155s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9391 acc_val: 0.4700 loss_test: 1.2889 acc_test: 0.6900 time: 0.1297s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9828 acc_val: 0.4967 loss_test: 1.3314 acc_test: 0.6940 time: 0.1199s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0734 acc_val: 0.5033 loss_test: 1.3800 acc_test: 0.6940 time: 0.1482s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1228 acc_val: 0.5000 loss_test: 1.4158 acc_test: 0.6980 time: 0.1430s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1664 acc_val: 0.5067 loss_test: 1.4524 acc_test: 0.6970 time: 0.1106s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1957 acc_val: 0.4967 loss_test: 1.4716 acc_test: 0.6980 time: 0.1203s
Optimization Finished!
Total time elapsed: 64.3753s, best testing performance  0.701000, minimun loss  1.016176
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8073 acc_train: 0.1083 loss_val: 1.7835 acc_val: 0.1500 loss_test: 1.6896 acc_test: 0.4340 time: 0.1350s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8111 acc_val: 0.3733 loss_test: 1.1831 acc_test: 0.6500 time: 0.1188s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8394 acc_val: 0.4067 loss_test: 1.2050 acc_test: 0.6640 time: 0.1313s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9704 acc_val: 0.4133 loss_test: 1.2788 acc_test: 0.6650 time: 0.1448s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0616 acc_val: 0.4333 loss_test: 1.3278 acc_test: 0.6800 time: 0.1385s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.4633 loss_test: 1.3692 acc_test: 0.6900 time: 0.1605s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1010 acc_val: 0.4833 loss_test: 1.3849 acc_test: 0.6960 time: 0.1267s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1397 acc_val: 0.4900 loss_test: 1.4169 acc_test: 0.6950 time: 0.1511s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2054 acc_val: 0.4933 loss_test: 1.4528 acc_test: 0.6940 time: 0.1344s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1889 acc_val: 0.5067 loss_test: 1.4669 acc_test: 0.6980 time: 0.1270s
Optimization Finished!
Total time elapsed: 68.0398s, best testing performance  0.703000, minimun loss  0.977887
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7866 acc_train: 0.2417 loss_val: 1.8063 acc_val: 0.1967 loss_test: 1.6663 acc_test: 0.4660 time: 0.1282s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.3767 loss_test: 1.1819 acc_test: 0.6570 time: 0.0948s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8160 acc_val: 0.4300 loss_test: 1.1953 acc_test: 0.6700 time: 0.0943s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9116 acc_val: 0.4233 loss_test: 1.2516 acc_test: 0.6680 time: 0.0985s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0147 acc_val: 0.4500 loss_test: 1.3099 acc_test: 0.6850 time: 0.0953s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0397 acc_val: 0.4800 loss_test: 1.3458 acc_test: 0.6900 time: 0.0967s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1023 acc_val: 0.4867 loss_test: 1.3849 acc_test: 0.6940 time: 0.1067s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1594 acc_val: 0.4900 loss_test: 1.4172 acc_test: 0.6970 time: 0.1073s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1492 acc_val: 0.5033 loss_test: 1.4384 acc_test: 0.6940 time: 0.1215s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2069 acc_val: 0.5067 loss_test: 1.4630 acc_test: 0.6950 time: 0.1150s
Optimization Finished!
Total time elapsed: 57.8639s, best testing performance  0.700000, minimun loss  0.993011
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7984 acc_train: 0.1083 loss_val: 1.8100 acc_val: 0.1800 loss_test: 1.6893 acc_test: 0.4910 time: 0.1693s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8692 acc_val: 0.3500 loss_test: 1.1983 acc_test: 0.6460 time: 0.1443s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7831 acc_val: 0.4233 loss_test: 1.1856 acc_test: 0.6690 time: 0.1476s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8291 acc_val: 0.4367 loss_test: 1.2256 acc_test: 0.6710 time: 0.1799s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9339 acc_val: 0.4600 loss_test: 1.2838 acc_test: 0.6800 time: 0.1037s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0564 acc_val: 0.4800 loss_test: 1.3440 acc_test: 0.6890 time: 0.1273s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1282 acc_val: 0.4833 loss_test: 1.3825 acc_test: 0.6930 time: 0.1122s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1177 acc_val: 0.5000 loss_test: 1.4029 acc_test: 0.6980 time: 0.1401s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1355 acc_val: 0.5033 loss_test: 1.4276 acc_test: 0.6980 time: 0.1280s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2022 acc_val: 0.5067 loss_test: 1.4621 acc_test: 0.6960 time: 0.1588s
Optimization Finished!
Total time elapsed: 69.3135s, best testing performance  0.702000, minimun loss  0.986393
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8013 acc_train: 0.1833 loss_val: 1.8261 acc_val: 0.1200 loss_test: 1.6900 acc_test: 0.3700 time: 0.1616s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7284 acc_val: 0.3900 loss_test: 1.1517 acc_test: 0.6610 time: 0.0918s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8182 acc_val: 0.4367 loss_test: 1.1870 acc_test: 0.6770 time: 0.0923s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8941 acc_val: 0.4633 loss_test: 1.2424 acc_test: 0.6850 time: 0.0923s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0209 acc_val: 0.4700 loss_test: 1.3095 acc_test: 0.6980 time: 0.0938s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0596 acc_val: 0.4933 loss_test: 1.3482 acc_test: 0.6980 time: 0.0978s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0761 acc_val: 0.5067 loss_test: 1.3843 acc_test: 0.7000 time: 0.0988s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1056 acc_val: 0.5067 loss_test: 1.4092 acc_test: 0.6970 time: 0.0951s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1613 acc_val: 0.5000 loss_test: 1.4319 acc_test: 0.7000 time: 0.0969s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1854 acc_val: 0.5067 loss_test: 1.4592 acc_test: 0.7000 time: 0.1214s
Optimization Finished!
Total time elapsed: 52.4046s, best testing performance  0.703000, minimun loss  0.988129
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7815 acc_train: 0.2000 loss_val: 1.7745 acc_val: 0.2000 loss_test: 1.6774 acc_test: 0.5460 time: 0.1168s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7916 acc_val: 0.3733 loss_test: 1.1628 acc_test: 0.6550 time: 0.1139s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7957 acc_val: 0.4367 loss_test: 1.1752 acc_test: 0.6750 time: 0.1342s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8555 acc_val: 0.4333 loss_test: 1.2198 acc_test: 0.6770 time: 0.1314s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8235 acc_val: 0.4533 loss_test: 1.2513 acc_test: 0.6880 time: 0.1432s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9447 acc_val: 0.4700 loss_test: 1.3118 acc_test: 0.6950 time: 0.1101s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0399 acc_val: 0.5033 loss_test: 1.3712 acc_test: 0.6970 time: 0.1563s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0868 acc_val: 0.5000 loss_test: 1.4039 acc_test: 0.6950 time: 0.1202s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1283 acc_val: 0.5133 loss_test: 1.4366 acc_test: 0.7020 time: 0.1380s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1961 acc_val: 0.5033 loss_test: 1.4731 acc_test: 0.7030 time: 0.1276s
Optimization Finished!
Total time elapsed: 68.3369s, best testing performance  0.705000, minimun loss  0.986920
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8213 acc_train: 0.1000 loss_val: 1.8018 acc_val: 0.2100 loss_test: 1.6826 acc_test: 0.4160 time: 0.1604s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.6499 acc_val: 0.4333 loss_test: 1.1525 acc_test: 0.6690 time: 0.1170s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.6664 acc_val: 0.4700 loss_test: 1.1720 acc_test: 0.6900 time: 0.1212s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7465 acc_val: 0.4700 loss_test: 1.2199 acc_test: 0.6930 time: 0.1629s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8804 acc_val: 0.4833 loss_test: 1.2809 acc_test: 0.6980 time: 0.0928s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9738 acc_val: 0.4900 loss_test: 1.3295 acc_test: 0.6940 time: 0.0940s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0222 acc_val: 0.4967 loss_test: 1.3627 acc_test: 0.6920 time: 0.0921s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0690 acc_val: 0.5033 loss_test: 1.3969 acc_test: 0.6940 time: 0.0971s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1050 acc_val: 0.5133 loss_test: 1.4287 acc_test: 0.6960 time: 0.0956s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1388 acc_val: 0.5033 loss_test: 1.4627 acc_test: 0.6980 time: 0.0946s
Optimization Finished!
Total time elapsed: 55.1579s, best testing performance  0.701000, minimun loss  1.005904
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7948 acc_train: 0.1417 loss_val: 1.8010 acc_val: 0.1200 loss_test: 1.6766 acc_test: 0.4890 time: 0.1299s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8130 acc_val: 0.3733 loss_test: 1.2000 acc_test: 0.6490 time: 0.1215s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7889 acc_val: 0.4433 loss_test: 1.2032 acc_test: 0.6690 time: 0.1475s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9344 acc_val: 0.4433 loss_test: 1.2694 acc_test: 0.6720 time: 0.1164s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0635 acc_val: 0.4633 loss_test: 1.3286 acc_test: 0.6850 time: 0.1202s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0983 acc_val: 0.4733 loss_test: 1.3602 acc_test: 0.6890 time: 0.1636s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1345 acc_val: 0.4967 loss_test: 1.3957 acc_test: 0.6890 time: 0.1062s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1713 acc_val: 0.4967 loss_test: 1.4225 acc_test: 0.6920 time: 0.1234s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1794 acc_val: 0.4967 loss_test: 1.4483 acc_test: 0.6930 time: 0.1372s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2301 acc_val: 0.5033 loss_test: 1.4751 acc_test: 0.6970 time: 0.1268s
Optimization Finished!
Total time elapsed: 68.1765s, best testing performance  0.697000, minimun loss  1.004687
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7998 acc_train: 0.1667 loss_val: 1.8069 acc_val: 0.0633 loss_test: 1.6800 acc_test: 0.3390 time: 0.1675s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7743 acc_val: 0.3833 loss_test: 1.1857 acc_test: 0.6460 time: 0.1446s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8314 acc_val: 0.4100 loss_test: 1.2159 acc_test: 0.6630 time: 0.1101s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9336 acc_val: 0.4233 loss_test: 1.2729 acc_test: 0.6720 time: 0.1546s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9810 acc_val: 0.4433 loss_test: 1.3057 acc_test: 0.6830 time: 0.1913s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0439 acc_val: 0.4733 loss_test: 1.3449 acc_test: 0.6860 time: 0.1036s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0708 acc_val: 0.4867 loss_test: 1.3744 acc_test: 0.6950 time: 0.1355s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1083 acc_val: 0.4900 loss_test: 1.4051 acc_test: 0.6930 time: 0.1303s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1565 acc_val: 0.4933 loss_test: 1.4332 acc_test: 0.6950 time: 0.0931s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1388 acc_val: 0.5100 loss_test: 1.4456 acc_test: 0.6990 time: 0.0927s
Optimization Finished!
Total time elapsed: 62.6804s, best testing performance  0.701000, minimun loss  1.006189
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.1917 loss_val: 1.8045 acc_val: 0.1767 loss_test: 1.6564 acc_test: 0.5080 time: 0.1408s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8613 acc_val: 0.3600 loss_test: 1.2144 acc_test: 0.6520 time: 0.1643s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7855 acc_val: 0.4433 loss_test: 1.2135 acc_test: 0.6630 time: 0.1695s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8537 acc_val: 0.4567 loss_test: 1.2586 acc_test: 0.6790 time: 0.1262s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9054 acc_val: 0.4867 loss_test: 1.2896 acc_test: 0.6920 time: 0.1240s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0069 acc_val: 0.4833 loss_test: 1.3360 acc_test: 0.6930 time: 0.1463s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0845 acc_val: 0.4967 loss_test: 1.3788 acc_test: 0.6930 time: 0.1682s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1088 acc_val: 0.5100 loss_test: 1.4114 acc_test: 0.6940 time: 0.1249s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1275 acc_val: 0.5033 loss_test: 1.4413 acc_test: 0.6970 time: 0.1443s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1644 acc_val: 0.5067 loss_test: 1.4723 acc_test: 0.6960 time: 0.1409s
Optimization Finished!
Total time elapsed: 68.4561s, best testing performance  0.702000, minimun loss  1.008707
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8145 acc_train: 0.0833 loss_val: 1.7978 acc_val: 0.1233 loss_test: 1.6759 acc_test: 0.4700 time: 0.1040s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7691 acc_val: 0.3967 loss_test: 1.1760 acc_test: 0.6600 time: 0.1159s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7753 acc_val: 0.4567 loss_test: 1.2021 acc_test: 0.6740 time: 0.1412s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8388 acc_val: 0.4533 loss_test: 1.2473 acc_test: 0.6800 time: 0.1198s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9358 acc_val: 0.4700 loss_test: 1.2985 acc_test: 0.6890 time: 0.1806s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9976 acc_val: 0.4833 loss_test: 1.3390 acc_test: 0.6880 time: 0.1215s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0784 acc_val: 0.4767 loss_test: 1.3775 acc_test: 0.6900 time: 0.1561s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1114 acc_val: 0.5000 loss_test: 1.4130 acc_test: 0.6940 time: 0.1168s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1617 acc_val: 0.5067 loss_test: 1.4503 acc_test: 0.6910 time: 0.1632s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2215 acc_val: 0.5033 loss_test: 1.4776 acc_test: 0.6960 time: 0.1329s
Optimization Finished!
Total time elapsed: 67.3935s, best testing performance  0.701000, minimun loss  1.006837
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8048 acc_train: 0.1167 loss_val: 1.8142 acc_val: 0.1733 loss_test: 1.7008 acc_test: 0.4810 time: 0.1306s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8722 acc_val: 0.3700 loss_test: 1.2268 acc_test: 0.6400 time: 0.0986s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7839 acc_val: 0.4300 loss_test: 1.2069 acc_test: 0.6630 time: 0.0948s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.7964 acc_val: 0.4667 loss_test: 1.2420 acc_test: 0.6810 time: 0.0966s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8815 acc_val: 0.4800 loss_test: 1.2954 acc_test: 0.6920 time: 0.1061s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9772 acc_val: 0.4933 loss_test: 1.3384 acc_test: 0.6960 time: 0.1244s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0296 acc_val: 0.4967 loss_test: 1.3669 acc_test: 0.6960 time: 0.1504s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0765 acc_val: 0.5133 loss_test: 1.3922 acc_test: 0.6950 time: 0.1655s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1773 acc_val: 0.5033 loss_test: 1.4348 acc_test: 0.6940 time: 0.1058s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1674 acc_val: 0.5133 loss_test: 1.4471 acc_test: 0.6960 time: 0.1120s
Optimization Finished!
Total time elapsed: 61.6270s, best testing performance  0.700000, minimun loss  1.016066
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8102 acc_train: 0.1167 loss_val: 1.7967 acc_val: 0.1500 loss_test: 1.6766 acc_test: 0.5180 time: 0.1352s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7662 acc_val: 0.4133 loss_test: 1.1542 acc_test: 0.6600 time: 0.1420s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8059 acc_val: 0.4567 loss_test: 1.1856 acc_test: 0.6650 time: 0.1214s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8617 acc_val: 0.4567 loss_test: 1.2318 acc_test: 0.6760 time: 0.1152s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9775 acc_val: 0.4667 loss_test: 1.2824 acc_test: 0.6890 time: 0.1443s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0651 acc_val: 0.4733 loss_test: 1.3275 acc_test: 0.6950 time: 0.1405s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1051 acc_val: 0.4767 loss_test: 1.3620 acc_test: 0.6940 time: 0.1205s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1377 acc_val: 0.4967 loss_test: 1.3902 acc_test: 0.6980 time: 0.1466s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1335 acc_val: 0.5067 loss_test: 1.4099 acc_test: 0.6960 time: 0.1252s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1832 acc_val: 0.5133 loss_test: 1.4442 acc_test: 0.7000 time: 0.1320s
Optimization Finished!
Total time elapsed: 68.9318s, best testing performance  0.704000, minimun loss  0.985750
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7968 acc_train: 0.1833 loss_val: 1.8010 acc_val: 0.1033 loss_test: 1.6772 acc_test: 0.4570 time: 0.1498s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8809 acc_val: 0.3733 loss_test: 1.2072 acc_test: 0.6510 time: 0.0923s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7638 acc_val: 0.4400 loss_test: 1.1885 acc_test: 0.6680 time: 0.0992s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.7624 acc_val: 0.4700 loss_test: 1.2137 acc_test: 0.6840 time: 0.0948s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.7929 acc_val: 0.4867 loss_test: 1.2597 acc_test: 0.6870 time: 0.0944s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9510 acc_val: 0.4767 loss_test: 1.3302 acc_test: 0.6990 time: 0.0956s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.4967 loss_test: 1.3743 acc_test: 0.6950 time: 0.0973s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1102 acc_val: 0.4833 loss_test: 1.4122 acc_test: 0.6970 time: 0.1148s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1219 acc_val: 0.5067 loss_test: 1.4447 acc_test: 0.6960 time: 0.1282s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1834 acc_val: 0.5100 loss_test: 1.4858 acc_test: 0.7030 time: 0.1579s
Optimization Finished!
Total time elapsed: 56.2832s, best testing performance  0.704000, minimun loss  0.992749
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7750 acc_train: 0.2417 loss_val: 1.8287 acc_val: 0.0900 loss_test: 1.6671 acc_test: 0.4600 time: 0.1621s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7200 acc_val: 0.4200 loss_test: 1.1533 acc_test: 0.6580 time: 0.1708s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8245 acc_val: 0.4367 loss_test: 1.2041 acc_test: 0.6690 time: 0.1442s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8777 acc_val: 0.4567 loss_test: 1.2435 acc_test: 0.6870 time: 0.1260s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9808 acc_val: 0.4700 loss_test: 1.3028 acc_test: 0.6930 time: 0.1633s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0300 acc_val: 0.4900 loss_test: 1.3436 acc_test: 0.6900 time: 0.1542s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0531 acc_val: 0.4967 loss_test: 1.3788 acc_test: 0.6930 time: 0.1497s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1517 acc_val: 0.4900 loss_test: 1.4308 acc_test: 0.6950 time: 0.1465s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2015 acc_val: 0.5033 loss_test: 1.4689 acc_test: 0.6970 time: 0.1679s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2206 acc_val: 0.5133 loss_test: 1.4987 acc_test: 0.6990 time: 0.1131s
Optimization Finished!
Total time elapsed: 68.6629s, best testing performance  0.701000, minimun loss  0.983094
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7888 acc_train: 0.1833 loss_val: 1.8162 acc_val: 0.0733 loss_test: 1.6728 acc_test: 0.4250 time: 0.1225s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7027 acc_val: 0.4267 loss_test: 1.1555 acc_test: 0.6590 time: 0.1362s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7408 acc_val: 0.4500 loss_test: 1.1920 acc_test: 0.6710 time: 0.0926s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7923 acc_val: 0.4600 loss_test: 1.2361 acc_test: 0.6790 time: 0.0925s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.8603 acc_val: 0.4733 loss_test: 1.2805 acc_test: 0.6910 time: 0.0928s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9986 acc_val: 0.4767 loss_test: 1.3343 acc_test: 0.6930 time: 0.0959s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0602 acc_val: 0.4833 loss_test: 1.3714 acc_test: 0.6940 time: 0.0962s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4967 loss_test: 1.4042 acc_test: 0.6950 time: 0.0954s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1262 acc_val: 0.5033 loss_test: 1.4373 acc_test: 0.7000 time: 0.0965s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1728 acc_val: 0.5033 loss_test: 1.4752 acc_test: 0.7000 time: 0.0970s
Optimization Finished!
Total time elapsed: 51.7040s, best testing performance  0.703000, minimun loss  0.988525
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7963 acc_train: 0.1917 loss_val: 1.8015 acc_val: 0.1667 loss_test: 1.6776 acc_test: 0.4650 time: 0.1040s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8126 acc_val: 0.3900 loss_test: 1.1624 acc_test: 0.6540 time: 0.1453s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8047 acc_val: 0.4467 loss_test: 1.1750 acc_test: 0.6720 time: 0.1243s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9245 acc_val: 0.4433 loss_test: 1.2392 acc_test: 0.6820 time: 0.1229s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0124 acc_val: 0.4500 loss_test: 1.2916 acc_test: 0.6910 time: 0.1217s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.4600 loss_test: 1.3342 acc_test: 0.6910 time: 0.1197s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.4833 loss_test: 1.3656 acc_test: 0.6910 time: 0.1210s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1088 acc_val: 0.5067 loss_test: 1.3983 acc_test: 0.6960 time: 0.1576s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1600 acc_val: 0.5033 loss_test: 1.4308 acc_test: 0.6940 time: 0.1259s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1853 acc_val: 0.5167 loss_test: 1.4595 acc_test: 0.6960 time: 0.1131s
Optimization Finished!
Total time elapsed: 68.3324s, best testing performance  0.698000, minimun loss  0.987496
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7989 acc_train: 0.1333 loss_val: 1.8376 acc_val: 0.1067 loss_test: 1.6832 acc_test: 0.4420 time: 0.1742s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.6763 acc_val: 0.4333 loss_test: 1.1588 acc_test: 0.6660 time: 0.1342s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8659 acc_val: 0.4333 loss_test: 1.2248 acc_test: 0.6700 time: 0.1442s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9380 acc_val: 0.4367 loss_test: 1.2682 acc_test: 0.6810 time: 0.1064s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0053 acc_val: 0.4567 loss_test: 1.3010 acc_test: 0.6880 time: 0.1162s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0297 acc_val: 0.4700 loss_test: 1.3288 acc_test: 0.6910 time: 0.1436s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0876 acc_val: 0.4867 loss_test: 1.3658 acc_test: 0.6920 time: 0.0969s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1252 acc_val: 0.4933 loss_test: 1.3903 acc_test: 0.6920 time: 0.0928s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.5067 loss_test: 1.4149 acc_test: 0.6920 time: 0.0951s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1437 acc_val: 0.5000 loss_test: 1.4417 acc_test: 0.6940 time: 0.0955s
Optimization Finished!
Total time elapsed: 57.7477s, best testing performance  0.698000, minimun loss  1.023738
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8189 acc_train: 0.1083 loss_val: 1.8212 acc_val: 0.0600 loss_test: 1.7009 acc_test: 0.4200 time: 0.1419s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7167 acc_val: 0.4400 loss_test: 1.1143 acc_test: 0.6690 time: 0.1219s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8152 acc_val: 0.4367 loss_test: 1.1644 acc_test: 0.6750 time: 0.1279s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9098 acc_val: 0.4467 loss_test: 1.2155 acc_test: 0.6920 time: 0.1601s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0057 acc_val: 0.4600 loss_test: 1.2761 acc_test: 0.6950 time: 0.1472s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0444 acc_val: 0.4833 loss_test: 1.3165 acc_test: 0.6940 time: 0.1241s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0622 acc_val: 0.4900 loss_test: 1.3507 acc_test: 0.6990 time: 0.1228s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0954 acc_val: 0.5000 loss_test: 1.3899 acc_test: 0.7000 time: 0.1321s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1271 acc_val: 0.5033 loss_test: 1.4211 acc_test: 0.7000 time: 0.1416s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1371 acc_val: 0.5000 loss_test: 1.4472 acc_test: 0.7010 time: 0.1467s
Optimization Finished!
Total time elapsed: 68.5112s, best testing performance  0.703000, minimun loss  0.982600
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7805 acc_train: 0.2000 loss_val: 1.7851 acc_val: 0.2033 loss_test: 1.6641 acc_test: 0.5360 time: 0.1255s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7029 acc_val: 0.4333 loss_test: 1.1475 acc_test: 0.6660 time: 0.1210s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7296 acc_val: 0.4533 loss_test: 1.1796 acc_test: 0.6810 time: 0.1412s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8225 acc_val: 0.4700 loss_test: 1.2289 acc_test: 0.6880 time: 0.1541s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9466 acc_val: 0.4633 loss_test: 1.2835 acc_test: 0.6910 time: 0.1625s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0061 acc_val: 0.4833 loss_test: 1.3269 acc_test: 0.6940 time: 0.1510s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0281 acc_val: 0.4933 loss_test: 1.3578 acc_test: 0.6950 time: 0.1247s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0731 acc_val: 0.5033 loss_test: 1.3940 acc_test: 0.6960 time: 0.1231s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1103 acc_val: 0.5100 loss_test: 1.4265 acc_test: 0.6930 time: 0.0932s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1214 acc_val: 0.5133 loss_test: 1.4516 acc_test: 0.6980 time: 0.0931s
Optimization Finished!
Total time elapsed: 64.0644s, best testing performance  0.699000, minimun loss  1.010391
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7898 acc_train: 0.1500 loss_val: 1.8096 acc_val: 0.1500 loss_test: 1.6643 acc_test: 0.4950 time: 0.1414s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8725 acc_val: 0.3867 loss_test: 1.2002 acc_test: 0.6540 time: 0.0973s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8831 acc_val: 0.4300 loss_test: 1.2173 acc_test: 0.6680 time: 0.1397s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9086 acc_val: 0.4433 loss_test: 1.2504 acc_test: 0.6840 time: 0.1371s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9885 acc_val: 0.4600 loss_test: 1.2955 acc_test: 0.6870 time: 0.1276s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0446 acc_val: 0.4667 loss_test: 1.3328 acc_test: 0.6920 time: 0.1248s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0879 acc_val: 0.4800 loss_test: 1.3724 acc_test: 0.6910 time: 0.1692s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1622 acc_val: 0.4867 loss_test: 1.4091 acc_test: 0.6930 time: 0.1357s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1846 acc_val: 0.5000 loss_test: 1.4414 acc_test: 0.6940 time: 0.1658s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2200 acc_val: 0.5133 loss_test: 1.4662 acc_test: 0.6930 time: 0.1187s
Optimization Finished!
Total time elapsed: 65.7023s, best testing performance  0.699000, minimun loss  1.003384
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8070 acc_train: 0.1750 loss_val: 1.8008 acc_val: 0.1567 loss_test: 1.6886 acc_test: 0.5040 time: 0.1600s
Epoch: 0051 loss_train: 0.0136 acc_train: 1.0000 loss_val: 1.8059 acc_val: 0.3867 loss_test: 1.1624 acc_test: 0.6570 time: 0.1109s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8453 acc_val: 0.4167 loss_test: 1.1854 acc_test: 0.6790 time: 0.1147s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8485 acc_val: 0.4433 loss_test: 1.2142 acc_test: 0.6870 time: 0.1406s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9475 acc_val: 0.4533 loss_test: 1.2699 acc_test: 0.6900 time: 0.1143s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9917 acc_val: 0.4633 loss_test: 1.3121 acc_test: 0.6930 time: 0.1111s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0402 acc_val: 0.4833 loss_test: 1.3509 acc_test: 0.6950 time: 0.1051s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0719 acc_val: 0.4967 loss_test: 1.3859 acc_test: 0.6940 time: 0.1119s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1129 acc_val: 0.4967 loss_test: 1.4201 acc_test: 0.6950 time: 0.1429s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1479 acc_val: 0.5067 loss_test: 1.4515 acc_test: 0.6940 time: 0.1168s
Optimization Finished!
Total time elapsed: 68.2367s, best testing performance  0.699000, minimun loss  1.020586
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8005 acc_train: 0.1167 loss_val: 1.7872 acc_val: 0.1367 loss_test: 1.6810 acc_test: 0.4540 time: 0.1347s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.8146 acc_val: 0.3867 loss_test: 1.1716 acc_test: 0.6540 time: 0.0953s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8095 acc_val: 0.4467 loss_test: 1.1761 acc_test: 0.6740 time: 0.0944s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8746 acc_val: 0.4500 loss_test: 1.2182 acc_test: 0.6910 time: 0.0993s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9332 acc_val: 0.4567 loss_test: 1.2604 acc_test: 0.6910 time: 0.0968s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9944 acc_val: 0.4733 loss_test: 1.3019 acc_test: 0.6950 time: 0.1365s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0401 acc_val: 0.4900 loss_test: 1.3389 acc_test: 0.6960 time: 0.1191s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0628 acc_val: 0.4967 loss_test: 1.3686 acc_test: 0.6950 time: 0.1740s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0964 acc_val: 0.5100 loss_test: 1.4026 acc_test: 0.6950 time: 0.1341s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1316 acc_val: 0.5133 loss_test: 1.4320 acc_test: 0.6990 time: 0.1555s
Optimization Finished!
Total time elapsed: 59.3609s, best testing performance  0.700000, minimun loss  1.012536
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8013 acc_train: 0.1667 loss_val: 1.8112 acc_val: 0.1333 loss_test: 1.6677 acc_test: 0.5020 time: 0.1080s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.7478 acc_val: 0.4067 loss_test: 1.1517 acc_test: 0.6520 time: 0.1079s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8078 acc_val: 0.4367 loss_test: 1.1763 acc_test: 0.6700 time: 0.1384s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9371 acc_val: 0.4433 loss_test: 1.2531 acc_test: 0.6760 time: 0.1445s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0167 acc_val: 0.4567 loss_test: 1.2954 acc_test: 0.6810 time: 0.1456s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0491 acc_val: 0.4767 loss_test: 1.3356 acc_test: 0.6850 time: 0.1261s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1003 acc_val: 0.4867 loss_test: 1.3741 acc_test: 0.6910 time: 0.1153s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1338 acc_val: 0.5000 loss_test: 1.4166 acc_test: 0.6880 time: 0.1450s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1719 acc_val: 0.5067 loss_test: 1.4520 acc_test: 0.6880 time: 0.1504s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2071 acc_val: 0.4967 loss_test: 1.4910 acc_test: 0.6860 time: 0.1007s
Optimization Finished!
Total time elapsed: 68.5312s, best testing performance  0.692000, minimun loss  1.007037
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7735 acc_train: 0.3083 loss_val: 1.7875 acc_val: 0.2300 loss_test: 1.6633 acc_test: 0.5520 time: 0.1080s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.7860 acc_val: 0.3967 loss_test: 1.1518 acc_test: 0.6630 time: 0.0929s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8872 acc_val: 0.4267 loss_test: 1.1972 acc_test: 0.6780 time: 0.0923s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9279 acc_val: 0.4333 loss_test: 1.2396 acc_test: 0.6860 time: 0.0947s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9734 acc_val: 0.4600 loss_test: 1.2727 acc_test: 0.6890 time: 0.0957s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9824 acc_val: 0.4867 loss_test: 1.3035 acc_test: 0.6910 time: 0.0954s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0296 acc_val: 0.5000 loss_test: 1.3477 acc_test: 0.6930 time: 0.0957s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0479 acc_val: 0.4933 loss_test: 1.3760 acc_test: 0.6940 time: 0.0971s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0815 acc_val: 0.5067 loss_test: 1.4123 acc_test: 0.6940 time: 0.1215s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1191 acc_val: 0.5167 loss_test: 1.4473 acc_test: 0.6940 time: 0.1485s
Optimization Finished!
Total time elapsed: 53.1882s, best testing performance  0.699000, minimun loss  1.010529
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8098 acc_train: 0.0917 loss_val: 1.8007 acc_val: 0.1467 loss_test: 1.6753 acc_test: 0.4840 time: 0.1262s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.7403 acc_val: 0.4233 loss_test: 1.1440 acc_test: 0.6640 time: 0.1502s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7380 acc_val: 0.4500 loss_test: 1.1644 acc_test: 0.6830 time: 0.1125s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8296 acc_val: 0.4767 loss_test: 1.2225 acc_test: 0.6940 time: 0.1513s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9354 acc_val: 0.4800 loss_test: 1.2749 acc_test: 0.6880 time: 0.1211s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9720 acc_val: 0.4933 loss_test: 1.3093 acc_test: 0.6930 time: 0.1515s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0487 acc_val: 0.5067 loss_test: 1.3543 acc_test: 0.6930 time: 0.1440s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0882 acc_val: 0.5100 loss_test: 1.3863 acc_test: 0.6960 time: 0.1551s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1471 acc_val: 0.5067 loss_test: 1.4256 acc_test: 0.6950 time: 0.1135s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1838 acc_val: 0.5067 loss_test: 1.4564 acc_test: 0.6940 time: 0.1405s
Optimization Finished!
Total time elapsed: 68.1245s, best testing performance  0.698000, minimun loss  1.022026
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7836 acc_train: 0.2333 loss_val: 1.7790 acc_val: 0.2467 loss_test: 1.6814 acc_test: 0.5070 time: 0.1391s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8938 acc_val: 0.3767 loss_test: 1.2065 acc_test: 0.6570 time: 0.1169s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8596 acc_val: 0.4433 loss_test: 1.2104 acc_test: 0.6660 time: 0.1186s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8432 acc_val: 0.4500 loss_test: 1.2351 acc_test: 0.6860 time: 0.1185s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9255 acc_val: 0.4767 loss_test: 1.2747 acc_test: 0.6970 time: 0.0925s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9506 acc_val: 0.4800 loss_test: 1.3116 acc_test: 0.6920 time: 0.0919s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0240 acc_val: 0.4967 loss_test: 1.3482 acc_test: 0.6960 time: 0.0948s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0386 acc_val: 0.5067 loss_test: 1.3719 acc_test: 0.6950 time: 0.0950s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0897 acc_val: 0.5100 loss_test: 1.4118 acc_test: 0.6990 time: 0.0943s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1081 acc_val: 0.5100 loss_test: 1.4364 acc_test: 0.6930 time: 0.0988s
Optimization Finished!
Total time elapsed: 53.5087s, best testing performance  0.700000, minimun loss  1.007332
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7972 acc_train: 0.1500 loss_val: 1.8278 acc_val: 0.1567 loss_test: 1.7016 acc_test: 0.4560 time: 0.1598s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.5791 acc_val: 0.4500 loss_test: 1.1007 acc_test: 0.6810 time: 0.1513s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7235 acc_val: 0.4600 loss_test: 1.1611 acc_test: 0.6800 time: 0.1248s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8483 acc_val: 0.4467 loss_test: 1.2273 acc_test: 0.6840 time: 0.1420s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9407 acc_val: 0.4700 loss_test: 1.2757 acc_test: 0.6900 time: 0.1133s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0017 acc_val: 0.4833 loss_test: 1.3122 acc_test: 0.6960 time: 0.1170s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0527 acc_val: 0.5000 loss_test: 1.3491 acc_test: 0.6960 time: 0.1374s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0800 acc_val: 0.5100 loss_test: 1.3840 acc_test: 0.7000 time: 0.1289s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1224 acc_val: 0.5100 loss_test: 1.4122 acc_test: 0.7030 time: 0.1036s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1216 acc_val: 0.5133 loss_test: 1.4340 acc_test: 0.7020 time: 0.1325s
Optimization Finished!
Total time elapsed: 68.1054s, best testing performance  0.705000, minimun loss  0.995166
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7849 acc_train: 0.1917 loss_val: 1.8333 acc_val: 0.1667 loss_test: 1.6665 acc_test: 0.5470 time: 0.1405s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.9071 acc_val: 0.3767 loss_test: 1.2104 acc_test: 0.6550 time: 0.1464s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8581 acc_val: 0.4367 loss_test: 1.2125 acc_test: 0.6680 time: 0.1023s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9160 acc_val: 0.4400 loss_test: 1.2582 acc_test: 0.6810 time: 0.1139s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9838 acc_val: 0.4533 loss_test: 1.2944 acc_test: 0.6960 time: 0.1324s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0324 acc_val: 0.4700 loss_test: 1.3299 acc_test: 0.6950 time: 0.1180s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0605 acc_val: 0.4833 loss_test: 1.3622 acc_test: 0.6920 time: 0.1497s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1683 acc_val: 0.4833 loss_test: 1.4087 acc_test: 0.6930 time: 0.0937s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1637 acc_val: 0.5033 loss_test: 1.4368 acc_test: 0.6950 time: 0.0941s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1997 acc_val: 0.4967 loss_test: 1.4664 acc_test: 0.6930 time: 0.0943s
Optimization Finished!
Total time elapsed: 61.1434s, best testing performance  0.699000, minimun loss  1.004458
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8062 acc_train: 0.1333 loss_val: 1.8044 acc_val: 0.1367 loss_test: 1.6950 acc_test: 0.4520 time: 0.1622s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7119 acc_val: 0.4067 loss_test: 1.1457 acc_test: 0.6610 time: 0.1555s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7648 acc_val: 0.4500 loss_test: 1.1779 acc_test: 0.6710 time: 0.1316s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8627 acc_val: 0.4433 loss_test: 1.2333 acc_test: 0.6940 time: 0.1065s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9871 acc_val: 0.4633 loss_test: 1.2812 acc_test: 0.6890 time: 0.1449s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0516 acc_val: 0.4700 loss_test: 1.3200 acc_test: 0.6890 time: 0.1476s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0591 acc_val: 0.4867 loss_test: 1.3458 acc_test: 0.6950 time: 0.1016s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0917 acc_val: 0.5000 loss_test: 1.3784 acc_test: 0.6960 time: 0.1318s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1126 acc_val: 0.5033 loss_test: 1.4006 acc_test: 0.7000 time: 0.1408s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1515 acc_val: 0.4967 loss_test: 1.4250 acc_test: 0.7010 time: 0.1310s
Optimization Finished!
Total time elapsed: 68.0269s, best testing performance  0.705000, minimun loss  1.003338
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1583 loss_val: 1.8055 acc_val: 0.2067 loss_test: 1.6725 acc_test: 0.5390 time: 0.1790s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7867 acc_val: 0.4033 loss_test: 1.1574 acc_test: 0.6560 time: 0.1363s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8047 acc_val: 0.4500 loss_test: 1.1864 acc_test: 0.6710 time: 0.1388s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9027 acc_val: 0.4533 loss_test: 1.2548 acc_test: 0.6770 time: 0.1442s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9681 acc_val: 0.4600 loss_test: 1.2950 acc_test: 0.6880 time: 0.1197s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0074 acc_val: 0.4733 loss_test: 1.3265 acc_test: 0.6970 time: 0.1191s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0419 acc_val: 0.4900 loss_test: 1.3659 acc_test: 0.6990 time: 0.1195s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.5000 loss_test: 1.4114 acc_test: 0.6980 time: 0.1610s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1467 acc_val: 0.5167 loss_test: 1.4583 acc_test: 0.7000 time: 0.1136s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1645 acc_val: 0.5167 loss_test: 1.4914 acc_test: 0.6990 time: 0.1164s
Optimization Finished!
Total time elapsed: 66.8349s, best testing performance  0.702000, minimun loss  0.986988
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8172 acc_train: 0.0667 loss_val: 1.8166 acc_val: 0.1167 loss_test: 1.6713 acc_test: 0.4930 time: 0.1399s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8562 acc_val: 0.3867 loss_test: 1.1906 acc_test: 0.6480 time: 0.0990s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8752 acc_val: 0.4167 loss_test: 1.2139 acc_test: 0.6640 time: 0.0949s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9152 acc_val: 0.4333 loss_test: 1.2572 acc_test: 0.6790 time: 0.0966s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9374 acc_val: 0.4533 loss_test: 1.2832 acc_test: 0.6880 time: 0.1295s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0266 acc_val: 0.4700 loss_test: 1.3259 acc_test: 0.6920 time: 0.1326s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0644 acc_val: 0.4800 loss_test: 1.3618 acc_test: 0.6940 time: 0.1305s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0964 acc_val: 0.4967 loss_test: 1.3941 acc_test: 0.6960 time: 0.1201s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1779 acc_val: 0.4967 loss_test: 1.4391 acc_test: 0.6940 time: 0.1096s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1680 acc_val: 0.5100 loss_test: 1.4578 acc_test: 0.6960 time: 0.1616s
Optimization Finished!
Total time elapsed: 61.8673s, best testing performance  0.700000, minimun loss  0.994225
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8047 acc_train: 0.1333 loss_val: 1.8271 acc_val: 0.0967 loss_test: 1.6895 acc_test: 0.3770 time: 0.1161s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8404 acc_val: 0.3733 loss_test: 1.1974 acc_test: 0.6470 time: 0.1349s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8382 acc_val: 0.4233 loss_test: 1.1992 acc_test: 0.6750 time: 0.1390s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9094 acc_val: 0.4400 loss_test: 1.2482 acc_test: 0.6930 time: 0.1483s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9773 acc_val: 0.4667 loss_test: 1.2870 acc_test: 0.6960 time: 0.1485s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0347 acc_val: 0.4733 loss_test: 1.3269 acc_test: 0.6940 time: 0.1450s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0552 acc_val: 0.4900 loss_test: 1.3586 acc_test: 0.6960 time: 0.1363s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0902 acc_val: 0.5000 loss_test: 1.3906 acc_test: 0.6950 time: 0.1233s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1233 acc_val: 0.5000 loss_test: 1.4205 acc_test: 0.6980 time: 0.1235s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1212 acc_val: 0.5067 loss_test: 1.4450 acc_test: 0.6950 time: 0.1674s
Optimization Finished!
Total time elapsed: 67.7452s, best testing performance  0.701000, minimun loss  1.007221
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7793 acc_train: 0.2250 loss_val: 1.7782 acc_val: 0.1833 loss_test: 1.6692 acc_test: 0.5440 time: 0.1233s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.8273 acc_val: 0.4033 loss_test: 1.1812 acc_test: 0.6540 time: 0.0927s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7383 acc_val: 0.4700 loss_test: 1.1717 acc_test: 0.6820 time: 0.0951s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.7554 acc_val: 0.4667 loss_test: 1.2104 acc_test: 0.6930 time: 0.0947s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8771 acc_val: 0.4867 loss_test: 1.2685 acc_test: 0.6940 time: 0.0942s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9575 acc_val: 0.4900 loss_test: 1.3193 acc_test: 0.6950 time: 0.0957s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0507 acc_val: 0.4933 loss_test: 1.3689 acc_test: 0.6970 time: 0.0972s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0890 acc_val: 0.5133 loss_test: 1.4147 acc_test: 0.6970 time: 0.1519s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1223 acc_val: 0.5133 loss_test: 1.4500 acc_test: 0.7010 time: 0.1304s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1820 acc_val: 0.5067 loss_test: 1.4921 acc_test: 0.7010 time: 0.1143s
Optimization Finished!
Total time elapsed: 56.0102s, best testing performance  0.703000, minimun loss  1.004840
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7975 acc_train: 0.1250 loss_val: 1.8041 acc_val: 0.1033 loss_test: 1.6943 acc_test: 0.4770 time: 0.1597s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8020 acc_val: 0.4333 loss_test: 1.1644 acc_test: 0.6660 time: 0.1598s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8346 acc_val: 0.4600 loss_test: 1.1928 acc_test: 0.6820 time: 0.1265s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8568 acc_val: 0.4533 loss_test: 1.2223 acc_test: 0.6890 time: 0.1592s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9638 acc_val: 0.4667 loss_test: 1.2739 acc_test: 0.6910 time: 0.1207s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0049 acc_val: 0.4833 loss_test: 1.3124 acc_test: 0.6920 time: 0.1109s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0572 acc_val: 0.4900 loss_test: 1.3529 acc_test: 0.6950 time: 0.1617s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0545 acc_val: 0.4933 loss_test: 1.3707 acc_test: 0.6940 time: 0.1270s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0576 acc_val: 0.5033 loss_test: 1.3975 acc_test: 0.6940 time: 0.1087s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1139 acc_val: 0.4933 loss_test: 1.4317 acc_test: 0.6960 time: 0.1475s
Optimization Finished!
Total time elapsed: 68.4880s, best testing performance  0.701000, minimun loss  1.008539
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7983 acc_train: 0.1083 loss_val: 1.7920 acc_val: 0.2133 loss_test: 1.6713 acc_test: 0.5580 time: 0.1234s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7668 acc_val: 0.3967 loss_test: 1.1676 acc_test: 0.6550 time: 0.1466s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8123 acc_val: 0.4300 loss_test: 1.1999 acc_test: 0.6640 time: 0.0930s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8573 acc_val: 0.4533 loss_test: 1.2411 acc_test: 0.6850 time: 0.0920s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9788 acc_val: 0.4633 loss_test: 1.2909 acc_test: 0.6920 time: 0.0981s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0330 acc_val: 0.4767 loss_test: 1.3325 acc_test: 0.6890 time: 0.0953s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1107 acc_val: 0.4867 loss_test: 1.3815 acc_test: 0.6940 time: 0.0992s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1799 acc_val: 0.4967 loss_test: 1.4316 acc_test: 0.6940 time: 0.0983s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2478 acc_val: 0.5000 loss_test: 1.4791 acc_test: 0.6930 time: 0.0959s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2719 acc_val: 0.5033 loss_test: 1.5097 acc_test: 0.6940 time: 0.0974s
Optimization Finished!
Total time elapsed: 51.7522s, best testing performance  0.699000, minimun loss  1.015548
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8171 acc_train: 0.0750 loss_val: 1.8179 acc_val: 0.1467 loss_test: 1.6867 acc_test: 0.4510 time: 0.1440s
Epoch: 0051 loss_train: 0.0130 acc_train: 1.0000 loss_val: 1.7777 acc_val: 0.4000 loss_test: 1.1513 acc_test: 0.6590 time: 0.1627s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8454 acc_val: 0.4567 loss_test: 1.1844 acc_test: 0.6800 time: 0.1338s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9726 acc_val: 0.4533 loss_test: 1.2487 acc_test: 0.6880 time: 0.1378s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0370 acc_val: 0.4533 loss_test: 1.2961 acc_test: 0.6850 time: 0.1423s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0891 acc_val: 0.4700 loss_test: 1.3494 acc_test: 0.6880 time: 0.1528s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1340 acc_val: 0.4800 loss_test: 1.3957 acc_test: 0.6900 time: 0.1135s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1898 acc_val: 0.4900 loss_test: 1.4493 acc_test: 0.6910 time: 0.1389s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2131 acc_val: 0.4967 loss_test: 1.4870 acc_test: 0.6940 time: 0.1234s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2434 acc_val: 0.5067 loss_test: 1.5220 acc_test: 0.6940 time: 0.1393s
Optimization Finished!
Total time elapsed: 67.8193s, best testing performance  0.696000, minimun loss  1.008371
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.1083 loss_val: 1.7988 acc_val: 0.1533 loss_test: 1.6704 acc_test: 0.4980 time: 0.1427s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8045 acc_val: 0.4000 loss_test: 1.1628 acc_test: 0.6530 time: 0.1408s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8649 acc_val: 0.4233 loss_test: 1.1917 acc_test: 0.6770 time: 0.1136s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9247 acc_val: 0.4400 loss_test: 1.2364 acc_test: 0.6850 time: 0.1560s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0128 acc_val: 0.4533 loss_test: 1.2844 acc_test: 0.6850 time: 0.1561s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0555 acc_val: 0.4667 loss_test: 1.3326 acc_test: 0.6870 time: 0.0947s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4867 loss_test: 1.3745 acc_test: 0.6960 time: 0.0927s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1213 acc_val: 0.5067 loss_test: 1.4082 acc_test: 0.6970 time: 0.0924s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1668 acc_val: 0.5067 loss_test: 1.4498 acc_test: 0.6960 time: 0.0952s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2229 acc_val: 0.5133 loss_test: 1.4874 acc_test: 0.6980 time: 0.0955s
Optimization Finished!
Total time elapsed: 57.5290s, best testing performance  0.699000, minimun loss  0.992482
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7873 acc_train: 0.2083 loss_val: 1.8114 acc_val: 0.0833 loss_test: 1.6703 acc_test: 0.4200 time: 0.1305s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8106 acc_val: 0.3900 loss_test: 1.1803 acc_test: 0.6520 time: 0.1721s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8412 acc_val: 0.4267 loss_test: 1.2003 acc_test: 0.6700 time: 0.1596s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8502 acc_val: 0.4467 loss_test: 1.2317 acc_test: 0.6780 time: 0.1518s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9441 acc_val: 0.4633 loss_test: 1.2809 acc_test: 0.6860 time: 0.1096s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9869 acc_val: 0.4667 loss_test: 1.3198 acc_test: 0.6910 time: 0.1617s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0517 acc_val: 0.4867 loss_test: 1.3602 acc_test: 0.6920 time: 0.1090s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0921 acc_val: 0.4967 loss_test: 1.3936 acc_test: 0.6990 time: 0.1456s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1143 acc_val: 0.5067 loss_test: 1.4193 acc_test: 0.6970 time: 0.1162s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1439 acc_val: 0.5100 loss_test: 1.4476 acc_test: 0.7000 time: 0.1488s
Optimization Finished!
Total time elapsed: 68.2830s, best testing performance  0.702000, minimun loss  1.012812
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7895 acc_train: 0.1750 loss_val: 1.7934 acc_val: 0.1767 loss_test: 1.6810 acc_test: 0.5300 time: 0.1235s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7593 acc_val: 0.4100 loss_test: 1.1553 acc_test: 0.6580 time: 0.1471s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8400 acc_val: 0.4300 loss_test: 1.1918 acc_test: 0.6770 time: 0.1334s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9155 acc_val: 0.4433 loss_test: 1.2442 acc_test: 0.6820 time: 0.1417s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9796 acc_val: 0.4667 loss_test: 1.2971 acc_test: 0.6890 time: 0.1660s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0212 acc_val: 0.4900 loss_test: 1.3350 acc_test: 0.6920 time: 0.1577s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0577 acc_val: 0.5033 loss_test: 1.3768 acc_test: 0.6940 time: 0.1365s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1215 acc_val: 0.5033 loss_test: 1.4250 acc_test: 0.6950 time: 0.1132s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1811 acc_val: 0.5033 loss_test: 1.4648 acc_test: 0.6990 time: 0.0935s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2378 acc_val: 0.5000 loss_test: 1.5053 acc_test: 0.6980 time: 0.0941s
Optimization Finished!
Total time elapsed: 63.4883s, best testing performance  0.702000, minimun loss  1.010422
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7701 acc_train: 0.3083 loss_val: 1.8028 acc_val: 0.1633 loss_test: 1.6550 acc_test: 0.5110 time: 0.1382s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7345 acc_val: 0.4300 loss_test: 1.1485 acc_test: 0.6610 time: 0.0969s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7555 acc_val: 0.4600 loss_test: 1.1708 acc_test: 0.6890 time: 0.1688s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8466 acc_val: 0.4600 loss_test: 1.2217 acc_test: 0.6890 time: 0.1065s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9498 acc_val: 0.4700 loss_test: 1.2772 acc_test: 0.6900 time: 0.1075s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0090 acc_val: 0.4733 loss_test: 1.3226 acc_test: 0.6960 time: 0.1660s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0387 acc_val: 0.4933 loss_test: 1.3600 acc_test: 0.6960 time: 0.1450s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0783 acc_val: 0.5000 loss_test: 1.3926 acc_test: 0.7020 time: 0.1499s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1115 acc_val: 0.5000 loss_test: 1.4274 acc_test: 0.7000 time: 0.1516s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1252 acc_val: 0.5033 loss_test: 1.4520 acc_test: 0.6960 time: 0.1136s
Optimization Finished!
Total time elapsed: 65.3619s, best testing performance  0.704000, minimun loss  0.996829
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.1917 loss_val: 1.7960 acc_val: 0.1667 loss_test: 1.6592 acc_test: 0.5110 time: 0.1559s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8684 acc_val: 0.3633 loss_test: 1.1894 acc_test: 0.6570 time: 0.1103s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8192 acc_val: 0.4167 loss_test: 1.1917 acc_test: 0.6690 time: 0.1269s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8754 acc_val: 0.4300 loss_test: 1.2329 acc_test: 0.6820 time: 0.1182s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9945 acc_val: 0.4533 loss_test: 1.2913 acc_test: 0.6910 time: 0.1208s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0539 acc_val: 0.4600 loss_test: 1.3330 acc_test: 0.6930 time: 0.1362s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0708 acc_val: 0.4733 loss_test: 1.3645 acc_test: 0.6930 time: 0.1398s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1299 acc_val: 0.4967 loss_test: 1.4087 acc_test: 0.6960 time: 0.1181s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1705 acc_val: 0.5033 loss_test: 1.4433 acc_test: 0.6970 time: 0.1149s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2265 acc_val: 0.5067 loss_test: 1.4822 acc_test: 0.6970 time: 0.1180s
Optimization Finished!
Total time elapsed: 67.6651s, best testing performance  0.701000, minimun loss  1.009610
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7830 acc_train: 0.2083 loss_val: 1.7962 acc_val: 0.1800 loss_test: 1.6612 acc_test: 0.5170 time: 0.1375s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8939 acc_val: 0.3667 loss_test: 1.1812 acc_test: 0.6610 time: 0.0951s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8790 acc_val: 0.4100 loss_test: 1.1950 acc_test: 0.6710 time: 0.0949s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9675 acc_val: 0.4233 loss_test: 1.2462 acc_test: 0.6910 time: 0.0952s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0642 acc_val: 0.4500 loss_test: 1.2994 acc_test: 0.6940 time: 0.0987s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0973 acc_val: 0.4533 loss_test: 1.3365 acc_test: 0.6970 time: 0.1169s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1535 acc_val: 0.4733 loss_test: 1.3825 acc_test: 0.6940 time: 0.1932s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1987 acc_val: 0.4967 loss_test: 1.4234 acc_test: 0.6930 time: 0.1080s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2176 acc_val: 0.5067 loss_test: 1.4565 acc_test: 0.6890 time: 0.1377s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2354 acc_val: 0.5000 loss_test: 1.4839 acc_test: 0.6920 time: 0.1444s
Optimization Finished!
Total time elapsed: 60.0650s, best testing performance  0.701000, minimun loss  1.013405
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7935 acc_train: 0.1833 loss_val: 1.7991 acc_val: 0.1733 loss_test: 1.6753 acc_test: 0.4770 time: 0.1363s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8313 acc_val: 0.3767 loss_test: 1.1713 acc_test: 0.6520 time: 0.1913s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7929 acc_val: 0.4233 loss_test: 1.1746 acc_test: 0.6820 time: 0.1323s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8558 acc_val: 0.4467 loss_test: 1.2216 acc_test: 0.6870 time: 0.1176s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9405 acc_val: 0.4533 loss_test: 1.2705 acc_test: 0.6940 time: 0.1624s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9746 acc_val: 0.4700 loss_test: 1.3078 acc_test: 0.6970 time: 0.1419s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0182 acc_val: 0.4800 loss_test: 1.3420 acc_test: 0.6960 time: 0.1173s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0763 acc_val: 0.4900 loss_test: 1.3834 acc_test: 0.6990 time: 0.1346s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1143 acc_val: 0.4900 loss_test: 1.4164 acc_test: 0.6990 time: 0.1860s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.4967 loss_test: 1.4420 acc_test: 0.7000 time: 0.1456s
Optimization Finished!
Total time elapsed: 68.0157s, best testing performance  0.704000, minimun loss  1.000409
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7799 acc_train: 0.1833 loss_val: 1.8214 acc_val: 0.0967 loss_test: 1.6627 acc_test: 0.4290 time: 0.1300s
Epoch: 0051 loss_train: 0.0126 acc_train: 1.0000 loss_val: 1.9413 acc_val: 0.3433 loss_test: 1.2069 acc_test: 0.6440 time: 0.0925s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8969 acc_val: 0.4167 loss_test: 1.2115 acc_test: 0.6710 time: 0.0920s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9477 acc_val: 0.4367 loss_test: 1.2511 acc_test: 0.6760 time: 0.0947s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0094 acc_val: 0.4533 loss_test: 1.2865 acc_test: 0.6890 time: 0.0947s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0733 acc_val: 0.4600 loss_test: 1.3309 acc_test: 0.6890 time: 0.0945s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.4567 loss_test: 1.3625 acc_test: 0.6910 time: 0.0957s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1593 acc_val: 0.4833 loss_test: 1.4001 acc_test: 0.6940 time: 0.0970s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1922 acc_val: 0.4900 loss_test: 1.4329 acc_test: 0.6960 time: 0.1081s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2134 acc_val: 0.5033 loss_test: 1.4566 acc_test: 0.6950 time: 0.1480s
Optimization Finished!
Total time elapsed: 52.7862s, best testing performance  0.698000, minimun loss  0.999197
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 7, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7927 acc_train: 0.1250 loss_val: 1.8176 acc_val: 0.1300 loss_test: 1.6773 acc_test: 0.5090 time: 0.1872s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8244 acc_val: 0.3833 loss_test: 1.1873 acc_test: 0.6570 time: 0.0936s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8757 acc_val: 0.3933 loss_test: 1.2189 acc_test: 0.6690 time: 0.1294s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9120 acc_val: 0.4233 loss_test: 1.2557 acc_test: 0.6820 time: 0.1423s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9787 acc_val: 0.4500 loss_test: 1.2947 acc_test: 0.6880 time: 0.1304s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0182 acc_val: 0.4633 loss_test: 1.3279 acc_test: 0.6930 time: 0.1102s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0710 acc_val: 0.4767 loss_test: 1.3603 acc_test: 0.6920 time: 0.1062s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1071 acc_val: 0.4933 loss_test: 1.3879 acc_test: 0.6930 time: 0.1143s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1789 acc_val: 0.4867 loss_test: 1.4240 acc_test: 0.6900 time: 0.1476s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1673 acc_val: 0.4900 loss_test: 1.4314 acc_test: 0.6950 time: 0.1286s
Optimization Finished!
Total time elapsed: 67.7924s, best testing performance  0.696000, minimun loss  1.016567
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7899 acc_train: 0.2000 loss_val: 1.8353 acc_val: 0.1333 loss_test: 1.6809 acc_test: 0.4300 time: 0.1665s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7935 acc_val: 0.3900 loss_test: 1.1548 acc_test: 0.6700 time: 0.1400s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7868 acc_val: 0.4500 loss_test: 1.1568 acc_test: 0.6850 time: 0.1577s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8446 acc_val: 0.4600 loss_test: 1.2062 acc_test: 0.6810 time: 0.1001s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9670 acc_val: 0.4567 loss_test: 1.2779 acc_test: 0.6840 time: 0.1038s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0179 acc_val: 0.4833 loss_test: 1.3157 acc_test: 0.6910 time: 0.1029s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1133 acc_val: 0.4933 loss_test: 1.3715 acc_test: 0.6910 time: 0.1020s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1158 acc_val: 0.4967 loss_test: 1.3971 acc_test: 0.6970 time: 0.1022s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1788 acc_val: 0.5000 loss_test: 1.4394 acc_test: 0.6940 time: 0.1013s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2652 acc_val: 0.5067 loss_test: 1.4752 acc_test: 0.6970 time: 0.1055s
Optimization Finished!
Total time elapsed: 57.5608s, best testing performance  0.700000, minimun loss  1.014025
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7922 acc_train: 0.1500 loss_val: 1.7945 acc_val: 0.1833 loss_test: 1.6721 acc_test: 0.5000 time: 0.1171s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7625 acc_val: 0.3933 loss_test: 1.1275 acc_test: 0.6640 time: 0.1719s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7993 acc_val: 0.4233 loss_test: 1.1548 acc_test: 0.6790 time: 0.1144s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8749 acc_val: 0.4433 loss_test: 1.2158 acc_test: 0.6750 time: 0.1643s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9732 acc_val: 0.4500 loss_test: 1.2774 acc_test: 0.6850 time: 0.1179s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.4733 loss_test: 1.3078 acc_test: 0.6950 time: 0.1194s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0509 acc_val: 0.4833 loss_test: 1.3561 acc_test: 0.6930 time: 0.1765s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1108 acc_val: 0.5067 loss_test: 1.3995 acc_test: 0.6940 time: 0.1759s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1328 acc_val: 0.5033 loss_test: 1.4246 acc_test: 0.6950 time: 0.1221s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1926 acc_val: 0.4967 loss_test: 1.4569 acc_test: 0.6910 time: 0.1663s
Optimization Finished!
Total time elapsed: 72.5716s, best testing performance  0.698000, minimun loss  0.996787
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7908 acc_train: 0.2000 loss_val: 1.7736 acc_val: 0.2700 loss_test: 1.6821 acc_test: 0.4500 time: 0.1313s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.6956 acc_val: 0.3800 loss_test: 1.1203 acc_test: 0.6510 time: 0.1295s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7235 acc_val: 0.4367 loss_test: 1.1404 acc_test: 0.6760 time: 0.1162s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8057 acc_val: 0.4600 loss_test: 1.1931 acc_test: 0.6860 time: 0.1550s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8885 acc_val: 0.4700 loss_test: 1.2600 acc_test: 0.6900 time: 0.0992s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9506 acc_val: 0.4900 loss_test: 1.3037 acc_test: 0.6950 time: 0.0984s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 1.9949 acc_val: 0.5000 loss_test: 1.3464 acc_test: 0.6940 time: 0.0992s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0618 acc_val: 0.5100 loss_test: 1.3792 acc_test: 0.6970 time: 0.1012s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1296 acc_val: 0.5100 loss_test: 1.4208 acc_test: 0.7020 time: 0.1026s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1646 acc_val: 0.5100 loss_test: 1.4495 acc_test: 0.6990 time: 0.1063s
Optimization Finished!
Total time elapsed: 59.1507s, best testing performance  0.706000, minimun loss  0.989167
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7852 acc_train: 0.1667 loss_val: 1.8048 acc_val: 0.1467 loss_test: 1.6596 acc_test: 0.5160 time: 0.1303s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7872 acc_val: 0.3800 loss_test: 1.1451 acc_test: 0.6650 time: 0.1430s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8090 acc_val: 0.4200 loss_test: 1.1677 acc_test: 0.6740 time: 0.1187s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9072 acc_val: 0.4500 loss_test: 1.2322 acc_test: 0.6820 time: 0.1337s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9597 acc_val: 0.4800 loss_test: 1.2894 acc_test: 0.6880 time: 0.1625s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0171 acc_val: 0.4900 loss_test: 1.3331 acc_test: 0.6940 time: 0.1341s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0525 acc_val: 0.5000 loss_test: 1.3722 acc_test: 0.6930 time: 0.1482s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0980 acc_val: 0.5033 loss_test: 1.4095 acc_test: 0.6920 time: 0.1610s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.5133 loss_test: 1.4402 acc_test: 0.6990 time: 0.1246s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1257 acc_val: 0.5100 loss_test: 1.4735 acc_test: 0.6950 time: 0.1456s
Optimization Finished!
Total time elapsed: 72.7215s, best testing performance  0.701000, minimun loss  0.993257
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8032 acc_train: 0.1000 loss_val: 1.7913 acc_val: 0.1867 loss_test: 1.6964 acc_test: 0.4680 time: 0.1389s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8074 acc_val: 0.3933 loss_test: 1.1592 acc_test: 0.6660 time: 0.1853s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7669 acc_val: 0.4367 loss_test: 1.1473 acc_test: 0.6840 time: 0.1565s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8533 acc_val: 0.4567 loss_test: 1.2014 acc_test: 0.6770 time: 0.1266s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9788 acc_val: 0.4667 loss_test: 1.2799 acc_test: 0.6840 time: 0.1713s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9895 acc_val: 0.4933 loss_test: 1.3120 acc_test: 0.6930 time: 0.1548s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0258 acc_val: 0.4967 loss_test: 1.3553 acc_test: 0.6960 time: 0.1007s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0605 acc_val: 0.5100 loss_test: 1.3850 acc_test: 0.6970 time: 0.1011s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0872 acc_val: 0.5167 loss_test: 1.4174 acc_test: 0.6980 time: 0.0983s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1839 acc_val: 0.5167 loss_test: 1.4693 acc_test: 0.6970 time: 0.1025s
Optimization Finished!
Total time elapsed: 64.2347s, best testing performance  0.702000, minimun loss  1.010788
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1333 loss_val: 1.8028 acc_val: 0.1833 loss_test: 1.6761 acc_test: 0.4930 time: 0.1480s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8222 acc_val: 0.3700 loss_test: 1.1673 acc_test: 0.6560 time: 0.1450s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8359 acc_val: 0.4200 loss_test: 1.1842 acc_test: 0.6760 time: 0.1648s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9073 acc_val: 0.4533 loss_test: 1.2349 acc_test: 0.6840 time: 0.1691s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9629 acc_val: 0.4733 loss_test: 1.2831 acc_test: 0.6920 time: 0.1617s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0057 acc_val: 0.4933 loss_test: 1.3192 acc_test: 0.6980 time: 0.1708s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0667 acc_val: 0.4967 loss_test: 1.3627 acc_test: 0.6950 time: 0.1467s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1307 acc_val: 0.5000 loss_test: 1.4056 acc_test: 0.6950 time: 0.1284s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1935 acc_val: 0.5033 loss_test: 1.4442 acc_test: 0.6960 time: 0.1180s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2298 acc_val: 0.5133 loss_test: 1.4747 acc_test: 0.6940 time: 0.1458s
Optimization Finished!
Total time elapsed: 72.6057s, best testing performance  0.701000, minimun loss  1.007360
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7794 acc_train: 0.2083 loss_val: 1.8501 acc_val: 0.1233 loss_test: 1.6762 acc_test: 0.5020 time: 0.1581s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8157 acc_val: 0.3967 loss_test: 1.1408 acc_test: 0.6580 time: 0.1761s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8308 acc_val: 0.4200 loss_test: 1.1573 acc_test: 0.6810 time: 0.1518s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9506 acc_val: 0.4367 loss_test: 1.2232 acc_test: 0.6840 time: 0.1265s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0586 acc_val: 0.4633 loss_test: 1.2964 acc_test: 0.6920 time: 0.1470s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0886 acc_val: 0.4800 loss_test: 1.3402 acc_test: 0.6890 time: 0.1277s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.4967 loss_test: 1.3712 acc_test: 0.6940 time: 0.1543s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1465 acc_val: 0.5000 loss_test: 1.4079 acc_test: 0.6900 time: 0.1291s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1494 acc_val: 0.5067 loss_test: 1.4305 acc_test: 0.6960 time: 0.0992s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2036 acc_val: 0.5100 loss_test: 1.4672 acc_test: 0.6960 time: 0.1012s
Optimization Finished!
Total time elapsed: 66.7932s, best testing performance  0.703000, minimun loss  0.988799
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8068 acc_train: 0.1333 loss_val: 1.8048 acc_val: 0.1967 loss_test: 1.6947 acc_test: 0.4940 time: 0.1518s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.6921 acc_val: 0.4100 loss_test: 1.1265 acc_test: 0.6650 time: 0.1221s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7705 acc_val: 0.4300 loss_test: 1.1608 acc_test: 0.6840 time: 0.1395s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9444 acc_val: 0.4500 loss_test: 1.2369 acc_test: 0.6870 time: 0.1454s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0121 acc_val: 0.4633 loss_test: 1.2819 acc_test: 0.6880 time: 0.1597s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0435 acc_val: 0.4933 loss_test: 1.3218 acc_test: 0.6900 time: 0.1528s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0664 acc_val: 0.4967 loss_test: 1.3527 acc_test: 0.6930 time: 0.1223s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1045 acc_val: 0.5033 loss_test: 1.3874 acc_test: 0.6950 time: 0.1312s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1382 acc_val: 0.4933 loss_test: 1.4205 acc_test: 0.6950 time: 0.1601s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1698 acc_val: 0.5033 loss_test: 1.4488 acc_test: 0.6980 time: 0.1655s
Optimization Finished!
Total time elapsed: 71.7483s, best testing performance  0.702000, minimun loss  0.996645
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7803 acc_train: 0.1750 loss_val: 1.7926 acc_val: 0.1900 loss_test: 1.6745 acc_test: 0.5440 time: 0.1312s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8236 acc_val: 0.3800 loss_test: 1.1557 acc_test: 0.6580 time: 0.1652s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7997 acc_val: 0.4200 loss_test: 1.1596 acc_test: 0.6800 time: 0.1632s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8670 acc_val: 0.4500 loss_test: 1.2047 acc_test: 0.6930 time: 0.1493s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9385 acc_val: 0.4700 loss_test: 1.2558 acc_test: 0.6890 time: 0.1267s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9879 acc_val: 0.4833 loss_test: 1.2999 acc_test: 0.6920 time: 0.1166s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0071 acc_val: 0.4967 loss_test: 1.3346 acc_test: 0.6920 time: 0.1303s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0534 acc_val: 0.5133 loss_test: 1.3726 acc_test: 0.6970 time: 0.1654s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0856 acc_val: 0.5133 loss_test: 1.4053 acc_test: 0.7020 time: 0.1468s
Epoch: 0451 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1065 acc_val: 0.5100 loss_test: 1.4354 acc_test: 0.7000 time: 0.0995s
Optimization Finished!
Total time elapsed: 69.8038s, best testing performance  0.704000, minimun loss  0.995807
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8005 acc_train: 0.1917 loss_val: 1.8124 acc_val: 0.1467 loss_test: 1.6786 acc_test: 0.4690 time: 0.1532s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7748 acc_val: 0.3967 loss_test: 1.1522 acc_test: 0.6580 time: 0.1019s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7813 acc_val: 0.4200 loss_test: 1.1675 acc_test: 0.6740 time: 0.1047s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8660 acc_val: 0.4200 loss_test: 1.2217 acc_test: 0.6810 time: 0.1275s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9127 acc_val: 0.4667 loss_test: 1.2701 acc_test: 0.6880 time: 0.1512s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9721 acc_val: 0.4700 loss_test: 1.3148 acc_test: 0.6920 time: 0.1310s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0243 acc_val: 0.4833 loss_test: 1.3569 acc_test: 0.6930 time: 0.1646s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0531 acc_val: 0.5000 loss_test: 1.3875 acc_test: 0.6970 time: 0.1240s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.5033 loss_test: 1.4189 acc_test: 0.7000 time: 0.1570s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1573 acc_val: 0.5033 loss_test: 1.4534 acc_test: 0.7020 time: 0.1244s
Optimization Finished!
Total time elapsed: 67.6891s, best testing performance  0.702000, minimun loss  0.994996
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1000 loss_val: 1.8071 acc_val: 0.1033 loss_test: 1.6645 acc_test: 0.4920 time: 0.1816s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7757 acc_val: 0.3600 loss_test: 1.1767 acc_test: 0.6510 time: 0.1189s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7214 acc_val: 0.4333 loss_test: 1.1735 acc_test: 0.6720 time: 0.1248s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.7876 acc_val: 0.4467 loss_test: 1.2218 acc_test: 0.6770 time: 0.1637s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8951 acc_val: 0.4767 loss_test: 1.2766 acc_test: 0.6900 time: 0.1334s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9800 acc_val: 0.4800 loss_test: 1.3201 acc_test: 0.6920 time: 0.1267s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0164 acc_val: 0.5067 loss_test: 1.3540 acc_test: 0.6910 time: 0.1439s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0747 acc_val: 0.4967 loss_test: 1.3874 acc_test: 0.6950 time: 0.1351s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1300 acc_val: 0.5067 loss_test: 1.4178 acc_test: 0.6970 time: 0.1448s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1588 acc_val: 0.5100 loss_test: 1.4456 acc_test: 0.6950 time: 0.1627s
Optimization Finished!
Total time elapsed: 72.0984s, best testing performance  0.700000, minimun loss  1.005810
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8060 acc_train: 0.0583 loss_val: 1.8150 acc_val: 0.1900 loss_test: 1.6767 acc_test: 0.4920 time: 0.1499s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.6482 acc_val: 0.4167 loss_test: 1.1202 acc_test: 0.6680 time: 0.1029s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7346 acc_val: 0.4300 loss_test: 1.1633 acc_test: 0.6730 time: 0.1022s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8742 acc_val: 0.4667 loss_test: 1.2334 acc_test: 0.6750 time: 0.1037s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9721 acc_val: 0.4700 loss_test: 1.2854 acc_test: 0.6920 time: 0.1630s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0172 acc_val: 0.4800 loss_test: 1.3263 acc_test: 0.6930 time: 0.1233s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0331 acc_val: 0.4933 loss_test: 1.3545 acc_test: 0.6940 time: 0.1391s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0817 acc_val: 0.5033 loss_test: 1.3880 acc_test: 0.6960 time: 0.1239s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0945 acc_val: 0.5067 loss_test: 1.4209 acc_test: 0.6920 time: 0.1209s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1247 acc_val: 0.5067 loss_test: 1.4473 acc_test: 0.6950 time: 0.1275s
Optimization Finished!
Total time elapsed: 65.3135s, best testing performance  0.700000, minimun loss  1.009152
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8121 acc_train: 0.1500 loss_val: 1.8181 acc_val: 0.1933 loss_test: 1.6885 acc_test: 0.4510 time: 0.1372s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7111 acc_val: 0.3933 loss_test: 1.1366 acc_test: 0.6650 time: 0.1188s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7078 acc_val: 0.4533 loss_test: 1.1523 acc_test: 0.6790 time: 0.1477s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8799 acc_val: 0.4633 loss_test: 1.2278 acc_test: 0.6800 time: 0.1317s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9652 acc_val: 0.4600 loss_test: 1.2827 acc_test: 0.6870 time: 0.1422s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0273 acc_val: 0.4767 loss_test: 1.3270 acc_test: 0.6890 time: 0.1890s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1211 acc_val: 0.4800 loss_test: 1.3743 acc_test: 0.6900 time: 0.1264s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1736 acc_val: 0.4933 loss_test: 1.4221 acc_test: 0.6900 time: 0.1854s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1940 acc_val: 0.5033 loss_test: 1.4551 acc_test: 0.6940 time: 0.1226s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2250 acc_val: 0.5067 loss_test: 1.4865 acc_test: 0.6930 time: 0.1221s
Optimization Finished!
Total time elapsed: 72.5129s, best testing performance  0.695000, minimun loss  1.005876
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7954 acc_train: 0.1417 loss_val: 1.8226 acc_val: 0.0733 loss_test: 1.6675 acc_test: 0.3640 time: 0.1717s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6775 acc_val: 0.4067 loss_test: 1.1272 acc_test: 0.6600 time: 0.1001s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7426 acc_val: 0.4200 loss_test: 1.1628 acc_test: 0.6800 time: 0.1022s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9006 acc_val: 0.4300 loss_test: 1.2352 acc_test: 0.6810 time: 0.1054s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9624 acc_val: 0.4467 loss_test: 1.2787 acc_test: 0.6850 time: 0.1017s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0187 acc_val: 0.4733 loss_test: 1.3212 acc_test: 0.6870 time: 0.1027s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0383 acc_val: 0.4833 loss_test: 1.3563 acc_test: 0.6900 time: 0.1621s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0791 acc_val: 0.5033 loss_test: 1.3872 acc_test: 0.6920 time: 0.1948s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1152 acc_val: 0.4967 loss_test: 1.4229 acc_test: 0.6920 time: 0.1648s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1607 acc_val: 0.5133 loss_test: 1.4552 acc_test: 0.6960 time: 0.1293s
Optimization Finished!
Total time elapsed: 62.0710s, best testing performance  0.700000, minimun loss  0.988279
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7972 acc_train: 0.1667 loss_val: 1.7856 acc_val: 0.1833 loss_test: 1.6805 acc_test: 0.5340 time: 0.1437s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7714 acc_val: 0.4033 loss_test: 1.1555 acc_test: 0.6610 time: 0.1127s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7973 acc_val: 0.4333 loss_test: 1.1804 acc_test: 0.6740 time: 0.1820s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8718 acc_val: 0.4633 loss_test: 1.2267 acc_test: 0.6870 time: 0.1166s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9238 acc_val: 0.4800 loss_test: 1.2705 acc_test: 0.6930 time: 0.1706s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9602 acc_val: 0.5000 loss_test: 1.3057 acc_test: 0.6970 time: 0.1385s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9970 acc_val: 0.5100 loss_test: 1.3449 acc_test: 0.6980 time: 0.1231s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0456 acc_val: 0.5100 loss_test: 1.3874 acc_test: 0.6970 time: 0.1412s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0920 acc_val: 0.5133 loss_test: 1.4253 acc_test: 0.7040 time: 0.1570s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.5100 loss_test: 1.4607 acc_test: 0.7040 time: 0.1314s
Optimization Finished!
Total time elapsed: 72.1573s, best testing performance  0.706000, minimun loss  0.991046
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8274 acc_train: 0.0750 loss_val: 1.8309 acc_val: 0.0833 loss_test: 1.7101 acc_test: 0.4080 time: 0.1415s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.6643 acc_val: 0.4167 loss_test: 1.1276 acc_test: 0.6760 time: 0.0993s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7788 acc_val: 0.4400 loss_test: 1.1811 acc_test: 0.6730 time: 0.1005s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9058 acc_val: 0.4400 loss_test: 1.2484 acc_test: 0.6840 time: 0.1025s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0389 acc_val: 0.4600 loss_test: 1.3144 acc_test: 0.6870 time: 0.1011s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1290 acc_val: 0.4733 loss_test: 1.3609 acc_test: 0.6900 time: 0.1020s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1824 acc_val: 0.4900 loss_test: 1.4046 acc_test: 0.6920 time: 0.1039s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2017 acc_val: 0.5000 loss_test: 1.4463 acc_test: 0.6930 time: 0.1480s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2134 acc_val: 0.5133 loss_test: 1.4811 acc_test: 0.6930 time: 0.1374s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2492 acc_val: 0.5167 loss_test: 1.5147 acc_test: 0.6950 time: 0.1529s
Optimization Finished!
Total time elapsed: 58.8688s, best testing performance  0.697000, minimun loss  0.972811
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7827 acc_train: 0.1583 loss_val: 1.7880 acc_val: 0.1667 loss_test: 1.6754 acc_test: 0.5200 time: 0.1559s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.9005 acc_val: 0.3567 loss_test: 1.1965 acc_test: 0.6490 time: 0.1505s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8333 acc_val: 0.4233 loss_test: 1.1904 acc_test: 0.6710 time: 0.1653s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 2.0099 acc_val: 0.4133 loss_test: 1.2736 acc_test: 0.6820 time: 0.1554s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0105 acc_val: 0.4600 loss_test: 1.2947 acc_test: 0.6920 time: 0.1617s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0438 acc_val: 0.4767 loss_test: 1.3353 acc_test: 0.6940 time: 0.1302s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0393 acc_val: 0.4933 loss_test: 1.3648 acc_test: 0.6980 time: 0.1584s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0668 acc_val: 0.5167 loss_test: 1.3940 acc_test: 0.6990 time: 0.1736s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0968 acc_val: 0.5133 loss_test: 1.4224 acc_test: 0.7000 time: 0.1381s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1188 acc_val: 0.5167 loss_test: 1.4482 acc_test: 0.6980 time: 0.1597s
Optimization Finished!
Total time elapsed: 73.3881s, best testing performance  0.703000, minimun loss  0.993874
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7752 acc_train: 0.1500 loss_val: 1.7913 acc_val: 0.1067 loss_test: 1.6846 acc_test: 0.4610 time: 0.1512s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7952 acc_val: 0.3967 loss_test: 1.1947 acc_test: 0.6570 time: 0.0997s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8331 acc_val: 0.4500 loss_test: 1.2125 acc_test: 0.6730 time: 0.0991s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9103 acc_val: 0.4600 loss_test: 1.2681 acc_test: 0.6810 time: 0.0982s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9889 acc_val: 0.4633 loss_test: 1.3144 acc_test: 0.6900 time: 0.1026s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0123 acc_val: 0.4933 loss_test: 1.3452 acc_test: 0.6870 time: 0.1024s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0859 acc_val: 0.4967 loss_test: 1.3839 acc_test: 0.6920 time: 0.1016s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1440 acc_val: 0.5000 loss_test: 1.4178 acc_test: 0.6950 time: 0.1012s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1666 acc_val: 0.5000 loss_test: 1.4413 acc_test: 0.6960 time: 0.1033s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2166 acc_val: 0.5067 loss_test: 1.4696 acc_test: 0.6930 time: 0.1474s
Optimization Finished!
Total time elapsed: 56.3014s, best testing performance  0.698000, minimun loss  0.997324
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7968 acc_train: 0.1667 loss_val: 1.8196 acc_val: 0.1067 loss_test: 1.6967 acc_test: 0.4410 time: 0.1466s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9556 acc_val: 0.3633 loss_test: 1.2226 acc_test: 0.6600 time: 0.1167s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8605 acc_val: 0.4333 loss_test: 1.2073 acc_test: 0.6750 time: 0.1518s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9379 acc_val: 0.4367 loss_test: 1.2573 acc_test: 0.6860 time: 0.1692s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0277 acc_val: 0.4633 loss_test: 1.3107 acc_test: 0.6850 time: 0.1307s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0422 acc_val: 0.4833 loss_test: 1.3409 acc_test: 0.6910 time: 0.1611s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0913 acc_val: 0.4933 loss_test: 1.3811 acc_test: 0.6900 time: 0.1557s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1217 acc_val: 0.4967 loss_test: 1.4091 acc_test: 0.6940 time: 0.1475s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1486 acc_val: 0.5133 loss_test: 1.4324 acc_test: 0.6950 time: 0.1226s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2208 acc_val: 0.5067 loss_test: 1.4684 acc_test: 0.6970 time: 0.1125s
Optimization Finished!
Total time elapsed: 72.1784s, best testing performance  0.699000, minimun loss  0.997562
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.1000 loss_val: 1.8353 acc_val: 0.1700 loss_test: 1.6818 acc_test: 0.4250 time: 0.1396s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8119 acc_val: 0.3900 loss_test: 1.1781 acc_test: 0.6580 time: 0.1434s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8016 acc_val: 0.4600 loss_test: 1.1883 acc_test: 0.6780 time: 0.1299s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9270 acc_val: 0.4367 loss_test: 1.2609 acc_test: 0.6780 time: 0.0991s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9988 acc_val: 0.4533 loss_test: 1.3132 acc_test: 0.6860 time: 0.1002s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0309 acc_val: 0.4733 loss_test: 1.3474 acc_test: 0.6890 time: 0.0982s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0924 acc_val: 0.4800 loss_test: 1.3900 acc_test: 0.6900 time: 0.1037s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1378 acc_val: 0.4867 loss_test: 1.4225 acc_test: 0.6950 time: 0.1017s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1459 acc_val: 0.4967 loss_test: 1.4493 acc_test: 0.6970 time: 0.1018s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2244 acc_val: 0.5000 loss_test: 1.4827 acc_test: 0.6990 time: 0.1025s
Optimization Finished!
Total time elapsed: 57.1610s, best testing performance  0.700000, minimun loss  1.014369
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8025 acc_train: 0.1417 loss_val: 1.8197 acc_val: 0.1967 loss_test: 1.7009 acc_test: 0.3980 time: 0.1434s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8520 acc_val: 0.3667 loss_test: 1.1859 acc_test: 0.6540 time: 0.1250s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8438 acc_val: 0.4367 loss_test: 1.1930 acc_test: 0.6690 time: 0.1305s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.9032 acc_val: 0.4567 loss_test: 1.2321 acc_test: 0.6810 time: 0.1265s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9937 acc_val: 0.4633 loss_test: 1.2806 acc_test: 0.6860 time: 0.1327s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0343 acc_val: 0.4800 loss_test: 1.3141 acc_test: 0.6890 time: 0.1495s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0851 acc_val: 0.4933 loss_test: 1.3551 acc_test: 0.6930 time: 0.1615s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1073 acc_val: 0.5033 loss_test: 1.3825 acc_test: 0.6930 time: 0.1262s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1611 acc_val: 0.5067 loss_test: 1.4209 acc_test: 0.6940 time: 0.1613s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2001 acc_val: 0.5200 loss_test: 1.4500 acc_test: 0.6950 time: 0.1645s
Optimization Finished!
Total time elapsed: 71.9804s, best testing performance  0.697000, minimun loss  1.035944
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7682 acc_train: 0.2500 loss_val: 1.7981 acc_val: 0.0933 loss_test: 1.6617 acc_test: 0.4670 time: 0.1778s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8523 acc_val: 0.3933 loss_test: 1.1626 acc_test: 0.6610 time: 0.1658s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8420 acc_val: 0.4400 loss_test: 1.1778 acc_test: 0.6710 time: 0.1224s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8571 acc_val: 0.4433 loss_test: 1.2110 acc_test: 0.6900 time: 0.1199s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9503 acc_val: 0.4533 loss_test: 1.2566 acc_test: 0.6910 time: 0.1203s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0274 acc_val: 0.4667 loss_test: 1.3063 acc_test: 0.6940 time: 0.0995s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.4933 loss_test: 1.3487 acc_test: 0.6950 time: 0.1000s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1387 acc_val: 0.4933 loss_test: 1.3878 acc_test: 0.6980 time: 0.1006s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1824 acc_val: 0.4933 loss_test: 1.4239 acc_test: 0.6980 time: 0.1060s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2226 acc_val: 0.5100 loss_test: 1.4571 acc_test: 0.6940 time: 0.1009s
Optimization Finished!
Total time elapsed: 59.6739s, best testing performance  0.700000, minimun loss  0.993171
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8202 acc_train: 0.0750 loss_val: 1.8033 acc_val: 0.1567 loss_test: 1.6858 acc_test: 0.5000 time: 0.1725s
Epoch: 0051 loss_train: 0.0133 acc_train: 1.0000 loss_val: 1.7771 acc_val: 0.3767 loss_test: 1.1555 acc_test: 0.6550 time: 0.1509s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7634 acc_val: 0.4467 loss_test: 1.1683 acc_test: 0.6710 time: 0.1536s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.7828 acc_val: 0.4567 loss_test: 1.2069 acc_test: 0.6830 time: 0.1609s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8635 acc_val: 0.4733 loss_test: 1.2567 acc_test: 0.6890 time: 0.1536s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9603 acc_val: 0.4767 loss_test: 1.3086 acc_test: 0.6930 time: 0.1193s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0115 acc_val: 0.4900 loss_test: 1.3549 acc_test: 0.6940 time: 0.1168s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0903 acc_val: 0.5067 loss_test: 1.4066 acc_test: 0.6950 time: 0.1121s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1155 acc_val: 0.5100 loss_test: 1.4409 acc_test: 0.6940 time: 0.1462s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1587 acc_val: 0.5067 loss_test: 1.4780 acc_test: 0.6940 time: 0.1688s
Optimization Finished!
Total time elapsed: 72.3127s, best testing performance  0.697000, minimun loss  1.014293
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7739 acc_train: 0.2250 loss_val: 1.7886 acc_val: 0.1033 loss_test: 1.6650 acc_test: 0.4640 time: 0.1246s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7275 acc_val: 0.4267 loss_test: 1.1304 acc_test: 0.6650 time: 0.1270s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7485 acc_val: 0.4400 loss_test: 1.1580 acc_test: 0.6730 time: 0.1152s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8170 acc_val: 0.4467 loss_test: 1.2057 acc_test: 0.6860 time: 0.1554s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9010 acc_val: 0.4667 loss_test: 1.2494 acc_test: 0.6890 time: 0.1183s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9240 acc_val: 0.4833 loss_test: 1.2879 acc_test: 0.6910 time: 0.1149s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9673 acc_val: 0.5000 loss_test: 1.3323 acc_test: 0.6960 time: 0.1189s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0179 acc_val: 0.5167 loss_test: 1.3704 acc_test: 0.6950 time: 0.0990s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0192 acc_val: 0.5133 loss_test: 1.4022 acc_test: 0.7000 time: 0.1003s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0711 acc_val: 0.5133 loss_test: 1.4389 acc_test: 0.6960 time: 0.1023s
Optimization Finished!
Total time elapsed: 64.4096s, best testing performance  0.701000, minimun loss  0.999988
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8031 acc_train: 0.1250 loss_val: 1.8089 acc_val: 0.0933 loss_test: 1.6867 acc_test: 0.4940 time: 0.1770s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7205 acc_val: 0.4300 loss_test: 1.1575 acc_test: 0.6620 time: 0.1466s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8289 acc_val: 0.4267 loss_test: 1.2002 acc_test: 0.6710 time: 0.1385s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8984 acc_val: 0.4400 loss_test: 1.2416 acc_test: 0.6760 time: 0.1487s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9829 acc_val: 0.4567 loss_test: 1.2849 acc_test: 0.6850 time: 0.1314s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0314 acc_val: 0.4767 loss_test: 1.3231 acc_test: 0.6900 time: 0.1669s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0915 acc_val: 0.4933 loss_test: 1.3652 acc_test: 0.6950 time: 0.1899s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1509 acc_val: 0.4967 loss_test: 1.4032 acc_test: 0.6970 time: 0.1390s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2178 acc_val: 0.5033 loss_test: 1.4462 acc_test: 0.7000 time: 0.1713s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.2969 acc_val: 0.4933 loss_test: 1.4898 acc_test: 0.6980 time: 0.1197s
Optimization Finished!
Total time elapsed: 72.6657s, best testing performance  0.702000, minimun loss  1.023602
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7923 acc_train: 0.1917 loss_val: 1.7837 acc_val: 0.2200 loss_test: 1.7189 acc_test: 0.4450 time: 0.1292s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8352 acc_val: 0.3833 loss_test: 1.1896 acc_test: 0.6490 time: 0.1362s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8374 acc_val: 0.4400 loss_test: 1.2015 acc_test: 0.6630 time: 0.1402s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9741 acc_val: 0.4133 loss_test: 1.2674 acc_test: 0.6740 time: 0.1303s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0527 acc_val: 0.4500 loss_test: 1.3214 acc_test: 0.6880 time: 0.1748s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0896 acc_val: 0.4733 loss_test: 1.3519 acc_test: 0.6890 time: 0.1329s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1143 acc_val: 0.4900 loss_test: 1.3831 acc_test: 0.6920 time: 0.1310s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1937 acc_val: 0.4967 loss_test: 1.4246 acc_test: 0.6950 time: 0.1717s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2252 acc_val: 0.5033 loss_test: 1.4529 acc_test: 0.6930 time: 0.0995s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2342 acc_val: 0.5067 loss_test: 1.4772 acc_test: 0.6980 time: 0.0993s
Optimization Finished!
Total time elapsed: 67.5251s, best testing performance  0.700000, minimun loss  0.980568
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7738 acc_train: 0.2917 loss_val: 1.7978 acc_val: 0.2133 loss_test: 1.6903 acc_test: 0.5130 time: 0.1473s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9293 acc_val: 0.3633 loss_test: 1.2322 acc_test: 0.6390 time: 0.1028s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9156 acc_val: 0.4233 loss_test: 1.2375 acc_test: 0.6570 time: 0.1581s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9705 acc_val: 0.4267 loss_test: 1.2843 acc_test: 0.6720 time: 0.1369s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9951 acc_val: 0.4433 loss_test: 1.3080 acc_test: 0.6880 time: 0.1600s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0434 acc_val: 0.4600 loss_test: 1.3434 acc_test: 0.6920 time: 0.1725s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.4933 loss_test: 1.3698 acc_test: 0.6920 time: 0.1457s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0462 acc_val: 0.5100 loss_test: 1.3889 acc_test: 0.6970 time: 0.1186s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0602 acc_val: 0.5133 loss_test: 1.4125 acc_test: 0.6990 time: 0.1252s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0705 acc_val: 0.5133 loss_test: 1.4299 acc_test: 0.6960 time: 0.1672s
Optimization Finished!
Total time elapsed: 70.0942s, best testing performance  0.700000, minimun loss  1.006227
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8010 acc_train: 0.1667 loss_val: 1.7880 acc_val: 0.1867 loss_test: 1.7263 acc_test: 0.4580 time: 0.1646s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7836 acc_val: 0.4167 loss_test: 1.1819 acc_test: 0.6590 time: 0.1694s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8076 acc_val: 0.4433 loss_test: 1.2008 acc_test: 0.6750 time: 0.1700s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9080 acc_val: 0.4300 loss_test: 1.2552 acc_test: 0.6800 time: 0.1498s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9811 acc_val: 0.4667 loss_test: 1.3000 acc_test: 0.6880 time: 0.1597s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0349 acc_val: 0.4733 loss_test: 1.3394 acc_test: 0.6950 time: 0.1145s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0986 acc_val: 0.4800 loss_test: 1.3783 acc_test: 0.6960 time: 0.1527s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1455 acc_val: 0.4967 loss_test: 1.4118 acc_test: 0.6930 time: 0.2084s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1787 acc_val: 0.5067 loss_test: 1.4446 acc_test: 0.6960 time: 0.1343s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2200 acc_val: 0.5067 loss_test: 1.4796 acc_test: 0.6930 time: 0.1222s
Optimization Finished!
Total time elapsed: 71.6334s, best testing performance  0.696000, minimun loss  0.992940
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7964 acc_train: 0.1750 loss_val: 1.8092 acc_val: 0.1400 loss_test: 1.7202 acc_test: 0.4370 time: 0.1467s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7559 acc_val: 0.4233 loss_test: 1.1929 acc_test: 0.6580 time: 0.1022s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8186 acc_val: 0.4533 loss_test: 1.2191 acc_test: 0.6660 time: 0.1023s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8843 acc_val: 0.4433 loss_test: 1.2713 acc_test: 0.6720 time: 0.1659s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0225 acc_val: 0.4500 loss_test: 1.3271 acc_test: 0.6870 time: 0.1401s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0377 acc_val: 0.4700 loss_test: 1.3478 acc_test: 0.6870 time: 0.1553s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0669 acc_val: 0.4967 loss_test: 1.3806 acc_test: 0.6930 time: 0.1317s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1476 acc_val: 0.4967 loss_test: 1.4204 acc_test: 0.6940 time: 0.1548s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1935 acc_val: 0.4967 loss_test: 1.4507 acc_test: 0.6960 time: 0.1341s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2376 acc_val: 0.5033 loss_test: 1.4861 acc_test: 0.6990 time: 0.1409s
Optimization Finished!
Total time elapsed: 67.6386s, best testing performance  0.703000, minimun loss  1.014443
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7895 acc_train: 0.2083 loss_val: 1.8094 acc_val: 0.1767 loss_test: 1.6984 acc_test: 0.5280 time: 0.1374s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8466 acc_val: 0.3700 loss_test: 1.2051 acc_test: 0.6400 time: 0.1411s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8892 acc_val: 0.4233 loss_test: 1.2256 acc_test: 0.6570 time: 0.1179s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9818 acc_val: 0.4300 loss_test: 1.2889 acc_test: 0.6700 time: 0.1612s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0297 acc_val: 0.4433 loss_test: 1.3204 acc_test: 0.6860 time: 0.1295s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0189 acc_val: 0.4700 loss_test: 1.3380 acc_test: 0.6910 time: 0.1185s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0557 acc_val: 0.4967 loss_test: 1.3720 acc_test: 0.6930 time: 0.1375s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0949 acc_val: 0.5000 loss_test: 1.4038 acc_test: 0.6970 time: 0.1297s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1177 acc_val: 0.5167 loss_test: 1.4378 acc_test: 0.6940 time: 0.2013s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1320 acc_val: 0.4967 loss_test: 1.4594 acc_test: 0.6960 time: 0.1471s
Optimization Finished!
Total time elapsed: 72.5973s, best testing performance  0.700000, minimun loss  1.008452
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7972 acc_train: 0.1667 loss_val: 1.8206 acc_val: 0.0900 loss_test: 1.6851 acc_test: 0.4690 time: 0.1460s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7351 acc_val: 0.3933 loss_test: 1.1467 acc_test: 0.6600 time: 0.1022s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7778 acc_val: 0.4333 loss_test: 1.1788 acc_test: 0.6800 time: 0.1058s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8752 acc_val: 0.4667 loss_test: 1.2354 acc_test: 0.6920 time: 0.1019s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9615 acc_val: 0.4600 loss_test: 1.2789 acc_test: 0.6890 time: 0.1474s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0034 acc_val: 0.4733 loss_test: 1.3162 acc_test: 0.6940 time: 0.1724s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.4867 loss_test: 1.3537 acc_test: 0.6910 time: 0.1320s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1254 acc_val: 0.4967 loss_test: 1.3949 acc_test: 0.6950 time: 0.1359s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1255 acc_val: 0.4967 loss_test: 1.4091 acc_test: 0.6940 time: 0.1449s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1789 acc_val: 0.4967 loss_test: 1.4479 acc_test: 0.6970 time: 0.1627s
Optimization Finished!
Total time elapsed: 64.1473s, best testing performance  0.701000, minimun loss  1.015065
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8173 acc_train: 0.1083 loss_val: 1.8003 acc_val: 0.2000 loss_test: 1.6988 acc_test: 0.5310 time: 0.1812s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.9093 acc_val: 0.3933 loss_test: 1.2025 acc_test: 0.6600 time: 0.1665s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.9460 acc_val: 0.4267 loss_test: 1.2365 acc_test: 0.6700 time: 0.1116s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9572 acc_val: 0.4367 loss_test: 1.2645 acc_test: 0.6880 time: 0.1419s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0384 acc_val: 0.4600 loss_test: 1.3129 acc_test: 0.6880 time: 0.1205s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0659 acc_val: 0.4767 loss_test: 1.3511 acc_test: 0.6910 time: 0.1535s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1250 acc_val: 0.4700 loss_test: 1.3982 acc_test: 0.6900 time: 0.1094s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1472 acc_val: 0.4867 loss_test: 1.4331 acc_test: 0.6990 time: 0.1655s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1489 acc_val: 0.4900 loss_test: 1.4681 acc_test: 0.6940 time: 0.1298s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1690 acc_val: 0.5067 loss_test: 1.4977 acc_test: 0.6960 time: 0.1414s
Optimization Finished!
Total time elapsed: 72.3995s, best testing performance  0.704000, minimun loss  1.013439
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7947 acc_train: 0.1500 loss_val: 1.8025 acc_val: 0.0867 loss_test: 1.6737 acc_test: 0.3640 time: 0.1463s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8169 acc_val: 0.4233 loss_test: 1.1700 acc_test: 0.6540 time: 0.1009s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8422 acc_val: 0.4367 loss_test: 1.1932 acc_test: 0.6790 time: 0.1020s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8782 acc_val: 0.4600 loss_test: 1.2374 acc_test: 0.6890 time: 0.1020s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9983 acc_val: 0.4533 loss_test: 1.2972 acc_test: 0.6830 time: 0.1066s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0665 acc_val: 0.4667 loss_test: 1.3425 acc_test: 0.6830 time: 0.1037s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0851 acc_val: 0.4700 loss_test: 1.3766 acc_test: 0.6900 time: 0.1464s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1383 acc_val: 0.4833 loss_test: 1.4153 acc_test: 0.6870 time: 0.1272s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1754 acc_val: 0.4967 loss_test: 1.4503 acc_test: 0.6890 time: 0.1500s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1923 acc_val: 0.5000 loss_test: 1.4764 acc_test: 0.6890 time: 0.1718s
Optimization Finished!
Total time elapsed: 60.9198s, best testing performance  0.692000, minimun loss  0.991384
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8036 acc_train: 0.0917 loss_val: 1.8359 acc_val: 0.1100 loss_test: 1.6776 acc_test: 0.3910 time: 0.1748s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8136 acc_val: 0.4167 loss_test: 1.1612 acc_test: 0.6660 time: 0.1381s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8497 acc_val: 0.4300 loss_test: 1.1946 acc_test: 0.6800 time: 0.1534s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9266 acc_val: 0.4567 loss_test: 1.2439 acc_test: 0.6880 time: 0.1788s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0318 acc_val: 0.4567 loss_test: 1.3013 acc_test: 0.6880 time: 0.1212s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0965 acc_val: 0.4667 loss_test: 1.3473 acc_test: 0.6920 time: 0.1754s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1369 acc_val: 0.4767 loss_test: 1.3887 acc_test: 0.6930 time: 0.1597s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1777 acc_val: 0.5067 loss_test: 1.4282 acc_test: 0.6940 time: 0.1490s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1970 acc_val: 0.5100 loss_test: 1.4596 acc_test: 0.6960 time: 0.1536s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2553 acc_val: 0.5100 loss_test: 1.5008 acc_test: 0.6940 time: 0.1266s
Optimization Finished!
Total time elapsed: 72.8233s, best testing performance  0.699000, minimun loss  1.001140
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7852 acc_train: 0.2000 loss_val: 1.7933 acc_val: 0.1100 loss_test: 1.6828 acc_test: 0.4750 time: 0.1437s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7837 acc_val: 0.4167 loss_test: 1.1718 acc_test: 0.6490 time: 0.0991s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8490 acc_val: 0.4367 loss_test: 1.2042 acc_test: 0.6660 time: 0.0987s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8909 acc_val: 0.4400 loss_test: 1.2467 acc_test: 0.6800 time: 0.1012s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9825 acc_val: 0.4533 loss_test: 1.2973 acc_test: 0.6830 time: 0.1010s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0043 acc_val: 0.4733 loss_test: 1.3250 acc_test: 0.6930 time: 0.1019s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0404 acc_val: 0.4933 loss_test: 1.3617 acc_test: 0.6960 time: 0.1032s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0946 acc_val: 0.4967 loss_test: 1.3987 acc_test: 0.6940 time: 0.1048s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1091 acc_val: 0.5067 loss_test: 1.4303 acc_test: 0.6970 time: 0.1538s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1362 acc_val: 0.5033 loss_test: 1.4591 acc_test: 0.6930 time: 0.1507s
Optimization Finished!
Total time elapsed: 56.8023s, best testing performance  0.701000, minimun loss  0.996603
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1167 loss_val: 1.8012 acc_val: 0.1000 loss_test: 1.6939 acc_test: 0.4230 time: 0.1582s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8559 acc_val: 0.3800 loss_test: 1.1827 acc_test: 0.6580 time: 0.1124s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8701 acc_val: 0.4233 loss_test: 1.1988 acc_test: 0.6650 time: 0.1512s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8969 acc_val: 0.4400 loss_test: 1.2433 acc_test: 0.6830 time: 0.1620s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9564 acc_val: 0.4533 loss_test: 1.2909 acc_test: 0.6900 time: 0.1282s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0013 acc_val: 0.4800 loss_test: 1.3429 acc_test: 0.6900 time: 0.1210s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0758 acc_val: 0.4767 loss_test: 1.4011 acc_test: 0.6950 time: 0.2066s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1271 acc_val: 0.4933 loss_test: 1.4490 acc_test: 0.7010 time: 0.1513s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1711 acc_val: 0.4967 loss_test: 1.4919 acc_test: 0.7020 time: 0.1110s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.2512 acc_val: 0.5000 loss_test: 1.5368 acc_test: 0.7000 time: 0.1495s
Optimization Finished!
Total time elapsed: 72.2407s, best testing performance  0.705000, minimun loss  1.015192
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8028 acc_train: 0.1583 loss_val: 1.8137 acc_val: 0.1733 loss_test: 1.6760 acc_test: 0.4330 time: 0.1902s
Epoch: 0051 loss_train: 0.0140 acc_train: 1.0000 loss_val: 1.7733 acc_val: 0.3967 loss_test: 1.1562 acc_test: 0.6620 time: 0.1396s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8828 acc_val: 0.4300 loss_test: 1.1974 acc_test: 0.6720 time: 0.0994s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9447 acc_val: 0.4433 loss_test: 1.2368 acc_test: 0.6850 time: 0.1000s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0032 acc_val: 0.4500 loss_test: 1.2760 acc_test: 0.6890 time: 0.1001s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0416 acc_val: 0.4700 loss_test: 1.3137 acc_test: 0.6890 time: 0.1009s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0785 acc_val: 0.4800 loss_test: 1.3531 acc_test: 0.6930 time: 0.1030s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0807 acc_val: 0.4967 loss_test: 1.3821 acc_test: 0.6960 time: 0.1018s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1373 acc_val: 0.5033 loss_test: 1.4272 acc_test: 0.6950 time: 0.1018s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1542 acc_val: 0.5100 loss_test: 1.4596 acc_test: 0.6950 time: 0.1598s
Optimization Finished!
Total time elapsed: 57.3982s, best testing performance  0.699000, minimun loss  1.028280
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7996 acc_train: 0.1417 loss_val: 1.7909 acc_val: 0.1700 loss_test: 1.6869 acc_test: 0.5040 time: 0.1428s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8568 acc_val: 0.3933 loss_test: 1.1953 acc_test: 0.6540 time: 0.1744s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8507 acc_val: 0.4367 loss_test: 1.1971 acc_test: 0.6730 time: 0.1445s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8963 acc_val: 0.4433 loss_test: 1.2330 acc_test: 0.6830 time: 0.1489s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9589 acc_val: 0.4600 loss_test: 1.2726 acc_test: 0.6880 time: 0.1499s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0195 acc_val: 0.4767 loss_test: 1.3148 acc_test: 0.6950 time: 0.1537s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0824 acc_val: 0.4900 loss_test: 1.3597 acc_test: 0.6940 time: 0.1266s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1100 acc_val: 0.4933 loss_test: 1.3922 acc_test: 0.7010 time: 0.1321s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1692 acc_val: 0.5000 loss_test: 1.4308 acc_test: 0.6970 time: 0.1459s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2172 acc_val: 0.5033 loss_test: 1.4648 acc_test: 0.7010 time: 0.1547s
Optimization Finished!
Total time elapsed: 72.6358s, best testing performance  0.703000, minimun loss  1.024264
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8004 acc_train: 0.1583 loss_val: 1.8283 acc_val: 0.0533 loss_test: 1.6832 acc_test: 0.3500 time: 0.1283s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7816 acc_val: 0.4167 loss_test: 1.1495 acc_test: 0.6560 time: 0.1365s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8191 acc_val: 0.4300 loss_test: 1.1764 acc_test: 0.6630 time: 0.1158s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9055 acc_val: 0.4367 loss_test: 1.2298 acc_test: 0.6780 time: 0.1739s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9860 acc_val: 0.4600 loss_test: 1.2782 acc_test: 0.6850 time: 0.0992s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0446 acc_val: 0.4633 loss_test: 1.3218 acc_test: 0.6910 time: 0.0988s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1034 acc_val: 0.4733 loss_test: 1.3664 acc_test: 0.6910 time: 0.1015s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1413 acc_val: 0.4900 loss_test: 1.4076 acc_test: 0.6930 time: 0.1012s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1429 acc_val: 0.5033 loss_test: 1.4383 acc_test: 0.7010 time: 0.1028s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1741 acc_val: 0.5067 loss_test: 1.4786 acc_test: 0.7040 time: 0.1034s
Optimization Finished!
Total time elapsed: 57.5449s, best testing performance  0.705000, minimun loss  0.997312
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7964 acc_train: 0.1417 loss_val: 1.8357 acc_val: 0.1167 loss_test: 1.6959 acc_test: 0.4570 time: 0.1525s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8720 acc_val: 0.3700 loss_test: 1.2017 acc_test: 0.6570 time: 0.1691s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9048 acc_val: 0.4033 loss_test: 1.2110 acc_test: 0.6700 time: 0.1957s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.9429 acc_val: 0.4333 loss_test: 1.2428 acc_test: 0.6840 time: 0.1220s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9882 acc_val: 0.4500 loss_test: 1.2816 acc_test: 0.6880 time: 0.1625s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0229 acc_val: 0.4767 loss_test: 1.3172 acc_test: 0.6890 time: 0.1401s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0605 acc_val: 0.4900 loss_test: 1.3505 acc_test: 0.6920 time: 0.1211s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1005 acc_val: 0.5000 loss_test: 1.3829 acc_test: 0.6980 time: 0.1315s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1587 acc_val: 0.5033 loss_test: 1.4196 acc_test: 0.6930 time: 0.1502s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2039 acc_val: 0.5133 loss_test: 1.4518 acc_test: 0.6970 time: 0.1516s
Optimization Finished!
Total time elapsed: 72.2544s, best testing performance  0.701000, minimun loss  1.035853
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.1917 loss_val: 1.7762 acc_val: 0.1867 loss_test: 1.6735 acc_test: 0.5190 time: 0.1393s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.5676 acc_val: 0.4700 loss_test: 1.1152 acc_test: 0.6770 time: 0.1507s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.5830 acc_val: 0.5067 loss_test: 1.1378 acc_test: 0.6890 time: 0.1238s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.7233 acc_val: 0.4700 loss_test: 1.2085 acc_test: 0.6910 time: 0.1438s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.8643 acc_val: 0.4633 loss_test: 1.2686 acc_test: 0.6930 time: 0.1203s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9552 acc_val: 0.4767 loss_test: 1.3141 acc_test: 0.6930 time: 0.1443s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0226 acc_val: 0.4967 loss_test: 1.3509 acc_test: 0.6920 time: 0.0991s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0556 acc_val: 0.5033 loss_test: 1.3800 acc_test: 0.6940 time: 0.0981s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1076 acc_val: 0.5067 loss_test: 1.4116 acc_test: 0.6950 time: 0.1040s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1344 acc_val: 0.5100 loss_test: 1.4431 acc_test: 0.6990 time: 0.1022s
Optimization Finished!
Total time elapsed: 61.2842s, best testing performance  0.701000, minimun loss  1.008558
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8030 acc_train: 0.0833 loss_val: 1.8260 acc_val: 0.1933 loss_test: 1.6727 acc_test: 0.4700 time: 0.1193s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8205 acc_val: 0.4067 loss_test: 1.1839 acc_test: 0.6550 time: 0.1452s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8425 acc_val: 0.4300 loss_test: 1.2090 acc_test: 0.6710 time: 0.1394s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9475 acc_val: 0.4367 loss_test: 1.2672 acc_test: 0.6820 time: 0.1575s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0204 acc_val: 0.4600 loss_test: 1.3150 acc_test: 0.6860 time: 0.1559s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0767 acc_val: 0.4867 loss_test: 1.3602 acc_test: 0.6920 time: 0.1424s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1319 acc_val: 0.4867 loss_test: 1.4063 acc_test: 0.6980 time: 0.1510s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1551 acc_val: 0.5033 loss_test: 1.4507 acc_test: 0.7030 time: 0.1482s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2204 acc_val: 0.5067 loss_test: 1.4963 acc_test: 0.6990 time: 0.1167s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2221 acc_val: 0.5067 loss_test: 1.5244 acc_test: 0.6980 time: 0.1583s
Optimization Finished!
Total time elapsed: 72.2962s, best testing performance  0.705000, minimun loss  1.023593
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7909 acc_train: 0.1750 loss_val: 1.7926 acc_val: 0.1700 loss_test: 1.6805 acc_test: 0.5200 time: 0.1352s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7628 acc_val: 0.4133 loss_test: 1.1671 acc_test: 0.6550 time: 0.1435s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8018 acc_val: 0.4400 loss_test: 1.2037 acc_test: 0.6670 time: 0.1335s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8880 acc_val: 0.4467 loss_test: 1.2507 acc_test: 0.6850 time: 0.1303s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9982 acc_val: 0.4567 loss_test: 1.2943 acc_test: 0.6870 time: 0.1780s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0627 acc_val: 0.4733 loss_test: 1.3352 acc_test: 0.6890 time: 0.1639s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1231 acc_val: 0.4833 loss_test: 1.3727 acc_test: 0.6890 time: 0.1308s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1556 acc_val: 0.5067 loss_test: 1.4022 acc_test: 0.6950 time: 0.1451s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1815 acc_val: 0.5033 loss_test: 1.4300 acc_test: 0.6950 time: 0.0994s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2468 acc_val: 0.5067 loss_test: 1.4688 acc_test: 0.6920 time: 0.0996s
Optimization Finished!
Total time elapsed: 66.1878s, best testing performance  0.698000, minimun loss  0.997339
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7776 acc_train: 0.2833 loss_val: 1.8039 acc_val: 0.1600 loss_test: 1.6580 acc_test: 0.5280 time: 0.1438s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8264 acc_val: 0.4133 loss_test: 1.2052 acc_test: 0.6570 time: 0.1403s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8761 acc_val: 0.4433 loss_test: 1.2304 acc_test: 0.6710 time: 0.1402s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9594 acc_val: 0.4400 loss_test: 1.2809 acc_test: 0.6820 time: 0.1249s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9929 acc_val: 0.4633 loss_test: 1.3092 acc_test: 0.6900 time: 0.2350s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0055 acc_val: 0.4800 loss_test: 1.3429 acc_test: 0.6940 time: 0.1430s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0505 acc_val: 0.4933 loss_test: 1.3784 acc_test: 0.6950 time: 0.1569s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0709 acc_val: 0.4967 loss_test: 1.4083 acc_test: 0.7030 time: 0.1222s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1102 acc_val: 0.5000 loss_test: 1.4406 acc_test: 0.6970 time: 0.1612s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1209 acc_val: 0.5167 loss_test: 1.4619 acc_test: 0.7040 time: 0.1646s
Optimization Finished!
Total time elapsed: 72.5151s, best testing performance  0.706000, minimun loss  1.026168
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7768 acc_train: 0.2167 loss_val: 1.8113 acc_val: 0.1533 loss_test: 1.6570 acc_test: 0.5530 time: 0.1989s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7688 acc_val: 0.4200 loss_test: 1.1596 acc_test: 0.6550 time: 0.2166s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7859 acc_val: 0.4333 loss_test: 1.1871 acc_test: 0.6800 time: 0.1201s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8285 acc_val: 0.4433 loss_test: 1.2301 acc_test: 0.6870 time: 0.1350s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9451 acc_val: 0.4600 loss_test: 1.2818 acc_test: 0.6880 time: 0.1735s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0316 acc_val: 0.4467 loss_test: 1.3293 acc_test: 0.6910 time: 0.1190s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0550 acc_val: 0.4567 loss_test: 1.3564 acc_test: 0.6940 time: 0.1320s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1064 acc_val: 0.4867 loss_test: 1.3994 acc_test: 0.6980 time: 0.1624s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1292 acc_val: 0.4900 loss_test: 1.4240 acc_test: 0.7000 time: 0.1262s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1843 acc_val: 0.4900 loss_test: 1.4700 acc_test: 0.6990 time: 0.0997s
Optimization Finished!
Total time elapsed: 68.6333s, best testing performance  0.704000, minimun loss  1.000376
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7845 acc_train: 0.2000 loss_val: 1.8121 acc_val: 0.2000 loss_test: 1.6590 acc_test: 0.4300 time: 0.1490s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8204 acc_val: 0.3967 loss_test: 1.1768 acc_test: 0.6580 time: 0.1038s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8142 acc_val: 0.4400 loss_test: 1.1889 acc_test: 0.6740 time: 0.1426s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8795 acc_val: 0.4533 loss_test: 1.2360 acc_test: 0.6870 time: 0.1201s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9902 acc_val: 0.4533 loss_test: 1.2820 acc_test: 0.6920 time: 0.1226s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0282 acc_val: 0.4700 loss_test: 1.3199 acc_test: 0.6960 time: 0.1678s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0879 acc_val: 0.4800 loss_test: 1.3597 acc_test: 0.6960 time: 0.1501s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0577 acc_val: 0.5000 loss_test: 1.3831 acc_test: 0.7020 time: 0.1250s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.5000 loss_test: 1.4186 acc_test: 0.7030 time: 0.1380s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1357 acc_val: 0.5033 loss_test: 1.4442 acc_test: 0.7050 time: 0.1295s
Optimization Finished!
Total time elapsed: 69.4264s, best testing performance  0.707000, minimun loss  0.989326
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7737 acc_train: 0.3000 loss_val: 1.8364 acc_val: 0.0833 loss_test: 1.6800 acc_test: 0.4540 time: 0.1679s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8195 acc_val: 0.3967 loss_test: 1.1818 acc_test: 0.6550 time: 0.1622s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8343 acc_val: 0.4433 loss_test: 1.1984 acc_test: 0.6770 time: 0.1464s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8888 acc_val: 0.4433 loss_test: 1.2340 acc_test: 0.6860 time: 0.1317s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9331 acc_val: 0.4767 loss_test: 1.2713 acc_test: 0.6900 time: 0.1284s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0067 acc_val: 0.4733 loss_test: 1.3160 acc_test: 0.6910 time: 0.1357s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0756 acc_val: 0.4900 loss_test: 1.3587 acc_test: 0.6930 time: 0.1542s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1121 acc_val: 0.5067 loss_test: 1.3916 acc_test: 0.6940 time: 0.1421s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1196 acc_val: 0.5000 loss_test: 1.4218 acc_test: 0.6980 time: 0.1389s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1690 acc_val: 0.5067 loss_test: 1.4548 acc_test: 0.6940 time: 0.1219s
Optimization Finished!
Total time elapsed: 71.8240s, best testing performance  0.700000, minimun loss  1.025435
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7847 acc_train: 0.2917 loss_val: 1.8279 acc_val: 0.1300 loss_test: 1.6769 acc_test: 0.4820 time: 0.1462s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7570 acc_val: 0.4267 loss_test: 1.1817 acc_test: 0.6570 time: 0.1054s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8020 acc_val: 0.4400 loss_test: 1.2063 acc_test: 0.6750 time: 0.1021s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.8456 acc_val: 0.4633 loss_test: 1.2409 acc_test: 0.6860 time: 0.1807s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9540 acc_val: 0.4600 loss_test: 1.2875 acc_test: 0.6880 time: 0.1517s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0018 acc_val: 0.4867 loss_test: 1.3246 acc_test: 0.6890 time: 0.1288s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0666 acc_val: 0.4900 loss_test: 1.3639 acc_test: 0.6930 time: 0.1391s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1242 acc_val: 0.5000 loss_test: 1.3964 acc_test: 0.6910 time: 0.1697s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1211 acc_val: 0.4833 loss_test: 1.4163 acc_test: 0.6940 time: 0.1504s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1432 acc_val: 0.5067 loss_test: 1.4418 acc_test: 0.6960 time: 0.1497s
Optimization Finished!
Total time elapsed: 66.1755s, best testing performance  0.702000, minimun loss  1.023673
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7993 acc_train: 0.1417 loss_val: 1.7912 acc_val: 0.2000 loss_test: 1.6807 acc_test: 0.4940 time: 0.1409s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8455 acc_val: 0.3700 loss_test: 1.2032 acc_test: 0.6510 time: 0.1368s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8797 acc_val: 0.4233 loss_test: 1.2285 acc_test: 0.6640 time: 0.1266s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9658 acc_val: 0.4333 loss_test: 1.2759 acc_test: 0.6780 time: 0.1165s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9881 acc_val: 0.4467 loss_test: 1.2979 acc_test: 0.6860 time: 0.1484s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0277 acc_val: 0.4733 loss_test: 1.3324 acc_test: 0.6900 time: 0.1497s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0671 acc_val: 0.4967 loss_test: 1.3679 acc_test: 0.6960 time: 0.1363s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1033 acc_val: 0.5067 loss_test: 1.4017 acc_test: 0.6940 time: 0.1996s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1171 acc_val: 0.4967 loss_test: 1.4259 acc_test: 0.6960 time: 0.1489s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1501 acc_val: 0.5000 loss_test: 1.4546 acc_test: 0.6990 time: 0.1234s
Optimization Finished!
Total time elapsed: 71.9924s, best testing performance  0.701000, minimun loss  1.015936
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7832 acc_train: 0.2083 loss_val: 1.7926 acc_val: 0.2167 loss_test: 1.6798 acc_test: 0.5120 time: 0.1501s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7556 acc_val: 0.3967 loss_test: 1.1626 acc_test: 0.6590 time: 0.1026s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7351 acc_val: 0.4600 loss_test: 1.1791 acc_test: 0.6810 time: 0.1009s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8094 acc_val: 0.4700 loss_test: 1.2301 acc_test: 0.6890 time: 0.1057s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9205 acc_val: 0.4833 loss_test: 1.2823 acc_test: 0.6950 time: 0.1037s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9361 acc_val: 0.5067 loss_test: 1.3147 acc_test: 0.6930 time: 0.1192s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9874 acc_val: 0.5133 loss_test: 1.3517 acc_test: 0.6970 time: 0.1222s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0098 acc_val: 0.5133 loss_test: 1.3835 acc_test: 0.7030 time: 0.1201s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0218 acc_val: 0.5200 loss_test: 1.4115 acc_test: 0.6990 time: 0.1770s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0697 acc_val: 0.5300 loss_test: 1.4399 acc_test: 0.7000 time: 0.1988s
Optimization Finished!
Total time elapsed: 62.9197s, best testing performance  0.706000, minimun loss  1.005417
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7722 acc_train: 0.2750 loss_val: 1.7943 acc_val: 0.1533 loss_test: 1.6419 acc_test: 0.5280 time: 0.1591s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6982 acc_val: 0.4067 loss_test: 1.1536 acc_test: 0.6680 time: 0.1683s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7275 acc_val: 0.4533 loss_test: 1.1851 acc_test: 0.6860 time: 0.1201s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8036 acc_val: 0.4667 loss_test: 1.2502 acc_test: 0.6890 time: 0.1931s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0019 acc_val: 0.4633 loss_test: 1.3291 acc_test: 0.6860 time: 0.1246s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0496 acc_val: 0.4600 loss_test: 1.3603 acc_test: 0.7000 time: 0.1545s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0895 acc_val: 0.4900 loss_test: 1.3855 acc_test: 0.6970 time: 0.1247s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1307 acc_val: 0.5100 loss_test: 1.4160 acc_test: 0.6920 time: 0.1603s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1611 acc_val: 0.5067 loss_test: 1.4446 acc_test: 0.6930 time: 0.1645s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1583 acc_val: 0.5133 loss_test: 1.4651 acc_test: 0.6970 time: 0.1160s
Optimization Finished!
Total time elapsed: 72.0725s, best testing performance  0.701000, minimun loss  0.981654
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7835 acc_train: 0.1667 loss_val: 1.8025 acc_val: 0.1500 loss_test: 1.6707 acc_test: 0.4530 time: 0.1302s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9544 acc_val: 0.3733 loss_test: 1.2297 acc_test: 0.6450 time: 0.0983s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9104 acc_val: 0.4300 loss_test: 1.2382 acc_test: 0.6680 time: 0.1036s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9459 acc_val: 0.4500 loss_test: 1.2808 acc_test: 0.6830 time: 0.1017s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0455 acc_val: 0.4567 loss_test: 1.3271 acc_test: 0.6930 time: 0.1009s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1260 acc_val: 0.4733 loss_test: 1.3608 acc_test: 0.6930 time: 0.1035s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1278 acc_val: 0.4733 loss_test: 1.3868 acc_test: 0.6940 time: 0.1496s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.4967 loss_test: 1.4101 acc_test: 0.6960 time: 0.1412s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1659 acc_val: 0.5000 loss_test: 1.4442 acc_test: 0.6920 time: 0.1850s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2144 acc_val: 0.5000 loss_test: 1.4800 acc_test: 0.6930 time: 0.1150s
Optimization Finished!
Total time elapsed: 59.9554s, best testing performance  0.701000, minimun loss  1.007642
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7872 acc_train: 0.1583 loss_val: 1.8260 acc_val: 0.1000 loss_test: 1.6810 acc_test: 0.4480 time: 0.1476s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8699 acc_val: 0.3967 loss_test: 1.1875 acc_test: 0.6520 time: 0.1867s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8259 acc_val: 0.4400 loss_test: 1.2025 acc_test: 0.6770 time: 0.1609s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9161 acc_val: 0.4467 loss_test: 1.2617 acc_test: 0.6790 time: 0.1468s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9783 acc_val: 0.4667 loss_test: 1.3015 acc_test: 0.6970 time: 0.1872s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0775 acc_val: 0.4567 loss_test: 1.3489 acc_test: 0.6940 time: 0.1214s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0929 acc_val: 0.4800 loss_test: 1.3767 acc_test: 0.7000 time: 0.1395s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0982 acc_val: 0.4967 loss_test: 1.4003 acc_test: 0.7030 time: 0.1461s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1575 acc_val: 0.4933 loss_test: 1.4410 acc_test: 0.6970 time: 0.1347s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1601 acc_val: 0.5067 loss_test: 1.4605 acc_test: 0.6970 time: 0.1156s
Optimization Finished!
Total time elapsed: 72.4061s, best testing performance  0.704000, minimun loss  1.007888
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7911 acc_train: 0.1583 loss_val: 1.8109 acc_val: 0.0767 loss_test: 1.6569 acc_test: 0.3970 time: 0.1546s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 2.0715 acc_val: 0.3333 loss_test: 1.2692 acc_test: 0.6440 time: 0.0986s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9270 acc_val: 0.4067 loss_test: 1.2517 acc_test: 0.6670 time: 0.0989s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9144 acc_val: 0.4333 loss_test: 1.2817 acc_test: 0.6780 time: 0.1009s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0681 acc_val: 0.4500 loss_test: 1.3441 acc_test: 0.6900 time: 0.1014s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1093 acc_val: 0.4667 loss_test: 1.3724 acc_test: 0.6930 time: 0.1032s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1664 acc_val: 0.4900 loss_test: 1.4025 acc_test: 0.6960 time: 0.1067s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2050 acc_val: 0.5033 loss_test: 1.4256 acc_test: 0.6950 time: 0.1036s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2423 acc_val: 0.5100 loss_test: 1.4555 acc_test: 0.6960 time: 0.2050s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2648 acc_val: 0.5100 loss_test: 1.4734 acc_test: 0.6980 time: 0.1665s
Optimization Finished!
Total time elapsed: 56.6835s, best testing performance  0.701000, minimun loss  1.019482
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 8, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7963 acc_train: 0.1333 loss_val: 1.8037 acc_val: 0.1633 loss_test: 1.6625 acc_test: 0.5300 time: 0.1938s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7618 acc_val: 0.4333 loss_test: 1.1567 acc_test: 0.6680 time: 0.1235s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8179 acc_val: 0.4600 loss_test: 1.2043 acc_test: 0.6870 time: 0.1221s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9164 acc_val: 0.4467 loss_test: 1.2735 acc_test: 0.6830 time: 0.1415s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0488 acc_val: 0.4600 loss_test: 1.3217 acc_test: 0.6910 time: 0.1667s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1106 acc_val: 0.4767 loss_test: 1.3697 acc_test: 0.6920 time: 0.1279s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1099 acc_val: 0.4900 loss_test: 1.3892 acc_test: 0.6950 time: 0.1705s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1429 acc_val: 0.5000 loss_test: 1.4238 acc_test: 0.6960 time: 0.1154s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1770 acc_val: 0.5033 loss_test: 1.4524 acc_test: 0.6990 time: 0.1669s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1710 acc_val: 0.5100 loss_test: 1.4733 acc_test: 0.6990 time: 0.1714s
Optimization Finished!
Total time elapsed: 72.2491s, best testing performance  0.704000, minimun loss  0.986803
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7807 acc_train: 0.2917 loss_val: 1.8034 acc_val: 0.1933 loss_test: 1.6446 acc_test: 0.5260 time: 0.1675s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8958 acc_val: 0.3567 loss_test: 1.1972 acc_test: 0.6600 time: 0.1652s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8632 acc_val: 0.3967 loss_test: 1.1973 acc_test: 0.6710 time: 0.1237s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9412 acc_val: 0.4300 loss_test: 1.2625 acc_test: 0.6670 time: 0.1050s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0239 acc_val: 0.4533 loss_test: 1.3100 acc_test: 0.6830 time: 0.1043s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4667 loss_test: 1.3589 acc_test: 0.6860 time: 0.1068s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1108 acc_val: 0.4767 loss_test: 1.3862 acc_test: 0.6920 time: 0.1078s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1690 acc_val: 0.5000 loss_test: 1.4271 acc_test: 0.6920 time: 0.1084s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1765 acc_val: 0.5167 loss_test: 1.4545 acc_test: 0.6970 time: 0.1105s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2431 acc_val: 0.5133 loss_test: 1.4897 acc_test: 0.6950 time: 0.1522s
Optimization Finished!
Total time elapsed: 62.0887s, best testing performance  0.699000, minimun loss  0.994684
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8086 acc_train: 0.1000 loss_val: 1.7906 acc_val: 0.1567 loss_test: 1.6725 acc_test: 0.4870 time: 0.1818s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.9541 acc_val: 0.3467 loss_test: 1.2065 acc_test: 0.6490 time: 0.1477s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7906 acc_val: 0.4300 loss_test: 1.1628 acc_test: 0.6700 time: 0.1838s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8848 acc_val: 0.4267 loss_test: 1.2232 acc_test: 0.6710 time: 0.1748s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0157 acc_val: 0.4467 loss_test: 1.2921 acc_test: 0.6840 time: 0.1453s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0798 acc_val: 0.4767 loss_test: 1.3419 acc_test: 0.6880 time: 0.1301s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1010 acc_val: 0.4867 loss_test: 1.3743 acc_test: 0.6920 time: 0.1848s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1428 acc_val: 0.5000 loss_test: 1.4021 acc_test: 0.6960 time: 0.1321s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1952 acc_val: 0.4900 loss_test: 1.4420 acc_test: 0.6940 time: 0.1749s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2427 acc_val: 0.4933 loss_test: 1.4768 acc_test: 0.6960 time: 0.1964s
Optimization Finished!
Total time elapsed: 76.9886s, best testing performance  0.702000, minimun loss  1.007838
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7973 acc_train: 0.1500 loss_val: 1.8103 acc_val: 0.1600 loss_test: 1.6813 acc_test: 0.4710 time: 0.1575s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8810 acc_val: 0.3633 loss_test: 1.1804 acc_test: 0.6550 time: 0.1327s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7592 acc_val: 0.4533 loss_test: 1.1323 acc_test: 0.6780 time: 0.1055s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8123 acc_val: 0.4633 loss_test: 1.1842 acc_test: 0.6810 time: 0.1055s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9858 acc_val: 0.4500 loss_test: 1.2697 acc_test: 0.6900 time: 0.1041s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0765 acc_val: 0.4767 loss_test: 1.3243 acc_test: 0.6930 time: 0.1067s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0551 acc_val: 0.4900 loss_test: 1.3441 acc_test: 0.6940 time: 0.1126s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0931 acc_val: 0.5100 loss_test: 1.3878 acc_test: 0.6940 time: 0.1126s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1443 acc_val: 0.5033 loss_test: 1.4209 acc_test: 0.6940 time: 0.1090s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2282 acc_val: 0.4933 loss_test: 1.4607 acc_test: 0.6910 time: 0.1488s
Optimization Finished!
Total time elapsed: 61.0949s, best testing performance  0.701000, minimun loss  1.016171
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7980 acc_train: 0.1250 loss_val: 1.7913 acc_val: 0.1900 loss_test: 1.6727 acc_test: 0.5390 time: 0.1715s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7985 acc_val: 0.3867 loss_test: 1.1612 acc_test: 0.6620 time: 0.1317s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7259 acc_val: 0.4533 loss_test: 1.1395 acc_test: 0.6730 time: 0.1691s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.7912 acc_val: 0.4700 loss_test: 1.1972 acc_test: 0.6750 time: 0.1444s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9669 acc_val: 0.4600 loss_test: 1.2858 acc_test: 0.6860 time: 0.1304s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0575 acc_val: 0.4700 loss_test: 1.3407 acc_test: 0.6900 time: 0.1459s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0916 acc_val: 0.4867 loss_test: 1.3728 acc_test: 0.6930 time: 0.1335s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1230 acc_val: 0.5000 loss_test: 1.4021 acc_test: 0.6940 time: 0.1403s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1575 acc_val: 0.5100 loss_test: 1.4292 acc_test: 0.6960 time: 0.1611s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1682 acc_val: 0.5033 loss_test: 1.4492 acc_test: 0.6950 time: 0.1548s
Optimization Finished!
Total time elapsed: 77.2027s, best testing performance  0.700000, minimun loss  0.976998
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7878 acc_train: 0.1417 loss_val: 1.8028 acc_val: 0.1900 loss_test: 1.6569 acc_test: 0.5180 time: 0.1618s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.9758 acc_val: 0.3700 loss_test: 1.2205 acc_test: 0.6580 time: 0.1770s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8456 acc_val: 0.4233 loss_test: 1.1792 acc_test: 0.6700 time: 0.1225s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9186 acc_val: 0.4433 loss_test: 1.2370 acc_test: 0.6750 time: 0.1099s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0328 acc_val: 0.4533 loss_test: 1.3019 acc_test: 0.6830 time: 0.1046s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0668 acc_val: 0.4833 loss_test: 1.3391 acc_test: 0.6900 time: 0.1109s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0547 acc_val: 0.5000 loss_test: 1.3657 acc_test: 0.6940 time: 0.1121s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0864 acc_val: 0.5000 loss_test: 1.3951 acc_test: 0.6940 time: 0.1090s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1520 acc_val: 0.5133 loss_test: 1.4322 acc_test: 0.6970 time: 0.1126s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1804 acc_val: 0.5100 loss_test: 1.4539 acc_test: 0.7000 time: 0.1088s
Optimization Finished!
Total time elapsed: 59.3424s, best testing performance  0.702000, minimun loss  1.009786
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7933 acc_train: 0.1250 loss_val: 1.8156 acc_val: 0.1967 loss_test: 1.6827 acc_test: 0.4680 time: 0.1557s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8151 acc_val: 0.3900 loss_test: 1.1702 acc_test: 0.6590 time: 0.1425s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8013 acc_val: 0.4267 loss_test: 1.1809 acc_test: 0.6790 time: 0.1921s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8798 acc_val: 0.4367 loss_test: 1.2281 acc_test: 0.6900 time: 0.2111s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9568 acc_val: 0.4733 loss_test: 1.2772 acc_test: 0.6880 time: 0.1598s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0321 acc_val: 0.4900 loss_test: 1.3258 acc_test: 0.6900 time: 0.1837s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0482 acc_val: 0.5033 loss_test: 1.3527 acc_test: 0.6940 time: 0.1280s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1052 acc_val: 0.5067 loss_test: 1.3926 acc_test: 0.6990 time: 0.1680s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1257 acc_val: 0.5133 loss_test: 1.4186 acc_test: 0.6990 time: 0.1466s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1768 acc_val: 0.5000 loss_test: 1.4563 acc_test: 0.6990 time: 0.1927s
Optimization Finished!
Total time elapsed: 77.6473s, best testing performance  0.701000, minimun loss  1.017001
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7861 acc_train: 0.1750 loss_val: 1.7940 acc_val: 0.1400 loss_test: 1.6764 acc_test: 0.4910 time: 0.1761s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7192 acc_val: 0.4067 loss_test: 1.1169 acc_test: 0.6650 time: 0.1428s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7272 acc_val: 0.4367 loss_test: 1.1366 acc_test: 0.6790 time: 0.1564s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8446 acc_val: 0.4400 loss_test: 1.2052 acc_test: 0.6860 time: 0.1436s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9337 acc_val: 0.4600 loss_test: 1.2634 acc_test: 0.6900 time: 0.1725s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0141 acc_val: 0.4700 loss_test: 1.3161 acc_test: 0.6900 time: 0.1284s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0610 acc_val: 0.4867 loss_test: 1.3528 acc_test: 0.6950 time: 0.1057s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1122 acc_val: 0.4900 loss_test: 1.3906 acc_test: 0.6930 time: 0.1095s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1714 acc_val: 0.4933 loss_test: 1.4262 acc_test: 0.6910 time: 0.1048s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2096 acc_val: 0.4933 loss_test: 1.4610 acc_test: 0.6930 time: 0.1134s
Optimization Finished!
Total time elapsed: 67.8139s, best testing performance  0.697000, minimun loss  0.979632
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7963 acc_train: 0.1583 loss_val: 1.7836 acc_val: 0.2033 loss_test: 1.6944 acc_test: 0.4840 time: 0.1568s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6715 acc_val: 0.4067 loss_test: 1.1208 acc_test: 0.6620 time: 0.1536s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7483 acc_val: 0.4267 loss_test: 1.1585 acc_test: 0.6810 time: 0.1699s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8181 acc_val: 0.4533 loss_test: 1.2139 acc_test: 0.6860 time: 0.1252s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8896 acc_val: 0.4767 loss_test: 1.2695 acc_test: 0.6900 time: 0.1381s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9808 acc_val: 0.4900 loss_test: 1.3216 acc_test: 0.6870 time: 0.1463s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0747 acc_val: 0.4933 loss_test: 1.3746 acc_test: 0.6910 time: 0.1829s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1171 acc_val: 0.4967 loss_test: 1.4181 acc_test: 0.6910 time: 0.2050s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1863 acc_val: 0.4967 loss_test: 1.4627 acc_test: 0.6950 time: 0.1696s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2638 acc_val: 0.5000 loss_test: 1.5051 acc_test: 0.6970 time: 0.1299s
Optimization Finished!
Total time elapsed: 77.7573s, best testing performance  0.700000, minimun loss  0.992721
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7779 acc_train: 0.2000 loss_val: 1.7930 acc_val: 0.1267 loss_test: 1.6673 acc_test: 0.4900 time: 0.1659s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8014 acc_val: 0.3667 loss_test: 1.1675 acc_test: 0.6550 time: 0.1316s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8443 acc_val: 0.4167 loss_test: 1.1924 acc_test: 0.6770 time: 0.1743s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9180 acc_val: 0.4400 loss_test: 1.2442 acc_test: 0.6860 time: 0.1390s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9645 acc_val: 0.4733 loss_test: 1.2880 acc_test: 0.6870 time: 0.1424s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0140 acc_val: 0.4933 loss_test: 1.3311 acc_test: 0.6920 time: 0.1647s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0311 acc_val: 0.4967 loss_test: 1.3619 acc_test: 0.6980 time: 0.1256s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0617 acc_val: 0.5033 loss_test: 1.3950 acc_test: 0.6980 time: 0.1766s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0888 acc_val: 0.5033 loss_test: 1.4287 acc_test: 0.7000 time: 0.1383s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1187 acc_val: 0.5133 loss_test: 1.4621 acc_test: 0.7020 time: 0.1654s
Optimization Finished!
Total time elapsed: 76.6392s, best testing performance  0.703000, minimun loss  0.995528
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1917 loss_val: 1.7978 acc_val: 0.1567 loss_test: 1.6821 acc_test: 0.4640 time: 0.1549s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8039 acc_val: 0.3633 loss_test: 1.1578 acc_test: 0.6520 time: 0.1115s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8233 acc_val: 0.4233 loss_test: 1.1722 acc_test: 0.6760 time: 0.1078s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9223 acc_val: 0.4400 loss_test: 1.2276 acc_test: 0.6880 time: 0.1113s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9956 acc_val: 0.4567 loss_test: 1.2812 acc_test: 0.6830 time: 0.1248s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0256 acc_val: 0.4867 loss_test: 1.3211 acc_test: 0.6910 time: 0.1517s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0499 acc_val: 0.5067 loss_test: 1.3569 acc_test: 0.6920 time: 0.1765s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1071 acc_val: 0.4967 loss_test: 1.4007 acc_test: 0.6930 time: 0.1758s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1636 acc_val: 0.5033 loss_test: 1.4340 acc_test: 0.6950 time: 0.1720s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2082 acc_val: 0.5033 loss_test: 1.4676 acc_test: 0.6960 time: 0.1760s
Optimization Finished!
Total time elapsed: 69.9292s, best testing performance  0.698000, minimun loss  0.990726
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7947 acc_train: 0.1667 loss_val: 1.8277 acc_val: 0.1767 loss_test: 1.6405 acc_test: 0.5700 time: 0.1721s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7935 acc_val: 0.3933 loss_test: 1.1537 acc_test: 0.6580 time: 0.1378s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7520 acc_val: 0.4467 loss_test: 1.1663 acc_test: 0.6770 time: 0.1552s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8052 acc_val: 0.4767 loss_test: 1.2134 acc_test: 0.6730 time: 0.1520s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9059 acc_val: 0.4733 loss_test: 1.2829 acc_test: 0.6860 time: 0.1492s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0677 acc_val: 0.4800 loss_test: 1.3455 acc_test: 0.6900 time: 0.1503s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1335 acc_val: 0.5100 loss_test: 1.3857 acc_test: 0.6910 time: 0.1576s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2104 acc_val: 0.4967 loss_test: 1.4211 acc_test: 0.6930 time: 0.1317s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2246 acc_val: 0.5067 loss_test: 1.4432 acc_test: 0.6930 time: 0.1407s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2203 acc_val: 0.5133 loss_test: 1.4656 acc_test: 0.6970 time: 0.1433s
Optimization Finished!
Total time elapsed: 77.1322s, best testing performance  0.702000, minimun loss  0.963597
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7944 acc_train: 0.1500 loss_val: 1.8129 acc_val: 0.1300 loss_test: 1.6434 acc_test: 0.5000 time: 0.1415s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8347 acc_val: 0.3867 loss_test: 1.1867 acc_test: 0.6650 time: 0.1049s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8146 acc_val: 0.4133 loss_test: 1.1934 acc_test: 0.6770 time: 0.1077s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8377 acc_val: 0.4600 loss_test: 1.2293 acc_test: 0.6820 time: 0.1086s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0215 acc_val: 0.4567 loss_test: 1.3194 acc_test: 0.6900 time: 0.1072s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0934 acc_val: 0.4767 loss_test: 1.3676 acc_test: 0.6940 time: 0.1125s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1357 acc_val: 0.4967 loss_test: 1.3987 acc_test: 0.6950 time: 0.1091s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1755 acc_val: 0.5000 loss_test: 1.4290 acc_test: 0.6930 time: 0.1111s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1826 acc_val: 0.5100 loss_test: 1.4415 acc_test: 0.6960 time: 0.1211s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2193 acc_val: 0.5033 loss_test: 1.4596 acc_test: 0.6960 time: 0.1326s
Optimization Finished!
Total time elapsed: 60.5303s, best testing performance  0.699000, minimun loss  0.994579
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1750 loss_val: 1.8110 acc_val: 0.0667 loss_test: 1.6508 acc_test: 0.4210 time: 0.1453s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6860 acc_val: 0.4133 loss_test: 1.1390 acc_test: 0.6540 time: 0.1691s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.6799 acc_val: 0.4500 loss_test: 1.1599 acc_test: 0.6730 time: 0.1709s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.6724 acc_val: 0.4733 loss_test: 1.1859 acc_test: 0.6780 time: 0.1422s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.8006 acc_val: 0.4733 loss_test: 1.2724 acc_test: 0.6870 time: 0.1683s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9914 acc_val: 0.4900 loss_test: 1.3544 acc_test: 0.6980 time: 0.1316s
Epoch: 0301 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0663 acc_val: 0.5133 loss_test: 1.3924 acc_test: 0.6960 time: 0.1485s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1672 acc_val: 0.5133 loss_test: 1.4439 acc_test: 0.6950 time: 0.1794s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1766 acc_val: 0.5133 loss_test: 1.4615 acc_test: 0.7020 time: 0.1654s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.2131 acc_val: 0.5033 loss_test: 1.4974 acc_test: 0.6990 time: 0.1694s
Optimization Finished!
Total time elapsed: 77.7538s, best testing performance  0.707000, minimun loss  0.977979
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8010 acc_train: 0.1167 loss_val: 1.8192 acc_val: 0.1533 loss_test: 1.6612 acc_test: 0.5130 time: 0.1775s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7174 acc_val: 0.3767 loss_test: 1.1481 acc_test: 0.6630 time: 0.1316s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7224 acc_val: 0.4233 loss_test: 1.1638 acc_test: 0.6790 time: 0.1422s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.7268 acc_val: 0.4600 loss_test: 1.1861 acc_test: 0.6860 time: 0.1753s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8424 acc_val: 0.4700 loss_test: 1.2554 acc_test: 0.6870 time: 0.1054s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0089 acc_val: 0.4767 loss_test: 1.3324 acc_test: 0.6920 time: 0.1072s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0496 acc_val: 0.5000 loss_test: 1.3661 acc_test: 0.6990 time: 0.1073s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0702 acc_val: 0.5100 loss_test: 1.3933 acc_test: 0.6940 time: 0.1092s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1259 acc_val: 0.5167 loss_test: 1.4191 acc_test: 0.6960 time: 0.1134s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.5133 loss_test: 1.4573 acc_test: 0.6960 time: 0.1125s
Optimization Finished!
Total time elapsed: 62.1591s, best testing performance  0.703000, minimun loss  0.984246
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7855 acc_train: 0.1667 loss_val: 1.8073 acc_val: 0.1133 loss_test: 1.6608 acc_test: 0.5080 time: 0.1745s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7951 acc_val: 0.4000 loss_test: 1.1844 acc_test: 0.6610 time: 0.1620s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7669 acc_val: 0.4467 loss_test: 1.1868 acc_test: 0.6800 time: 0.1834s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7856 acc_val: 0.4667 loss_test: 1.2190 acc_test: 0.6830 time: 0.1810s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9518 acc_val: 0.4867 loss_test: 1.2981 acc_test: 0.6940 time: 0.1697s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0265 acc_val: 0.4900 loss_test: 1.3449 acc_test: 0.6950 time: 0.1701s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0647 acc_val: 0.5033 loss_test: 1.3724 acc_test: 0.6960 time: 0.1319s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1187 acc_val: 0.5133 loss_test: 1.4067 acc_test: 0.6950 time: 0.1269s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1590 acc_val: 0.5133 loss_test: 1.4394 acc_test: 0.6930 time: 0.1864s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1582 acc_val: 0.5167 loss_test: 1.4533 acc_test: 0.6940 time: 0.1405s
Optimization Finished!
Total time elapsed: 77.9714s, best testing performance  0.701000, minimun loss  1.009995
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7858 acc_train: 0.2000 loss_val: 1.7745 acc_val: 0.1500 loss_test: 1.6542 acc_test: 0.5210 time: 0.1582s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7807 acc_val: 0.3900 loss_test: 1.1893 acc_test: 0.6570 time: 0.1431s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7529 acc_val: 0.4567 loss_test: 1.1915 acc_test: 0.6780 time: 0.1285s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8505 acc_val: 0.4533 loss_test: 1.2495 acc_test: 0.6840 time: 0.1625s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9400 acc_val: 0.4733 loss_test: 1.2973 acc_test: 0.6870 time: 0.1265s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0213 acc_val: 0.4733 loss_test: 1.3409 acc_test: 0.6940 time: 0.1481s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1319 acc_val: 0.4733 loss_test: 1.3874 acc_test: 0.6920 time: 0.1200s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1157 acc_val: 0.5000 loss_test: 1.4090 acc_test: 0.6910 time: 0.1420s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1852 acc_val: 0.5067 loss_test: 1.4473 acc_test: 0.6930 time: 0.1061s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2362 acc_val: 0.5033 loss_test: 1.4785 acc_test: 0.6960 time: 0.1056s
Optimization Finished!
Total time elapsed: 71.3727s, best testing performance  0.702000, minimun loss  1.011214
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8115 acc_train: 0.1083 loss_val: 1.8024 acc_val: 0.1333 loss_test: 1.6896 acc_test: 0.4780 time: 0.1569s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7065 acc_val: 0.4133 loss_test: 1.1580 acc_test: 0.6650 time: 0.1104s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7108 acc_val: 0.4733 loss_test: 1.1702 acc_test: 0.6880 time: 0.1764s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8572 acc_val: 0.4767 loss_test: 1.2489 acc_test: 0.6850 time: 0.1749s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0290 acc_val: 0.4667 loss_test: 1.3183 acc_test: 0.6910 time: 0.1493s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0936 acc_val: 0.4800 loss_test: 1.3506 acc_test: 0.6930 time: 0.1411s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1351 acc_val: 0.4900 loss_test: 1.3751 acc_test: 0.6960 time: 0.1623s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.2049 acc_val: 0.4933 loss_test: 1.4152 acc_test: 0.6960 time: 0.1821s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2296 acc_val: 0.4900 loss_test: 1.4422 acc_test: 0.6960 time: 0.1931s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2419 acc_val: 0.4900 loss_test: 1.4640 acc_test: 0.6980 time: 0.1240s
Optimization Finished!
Total time elapsed: 75.0944s, best testing performance  0.701000, minimun loss  0.997916
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7821 acc_train: 0.2500 loss_val: 1.8017 acc_val: 0.2333 loss_test: 1.6703 acc_test: 0.5390 time: 0.1543s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6953 acc_val: 0.4433 loss_test: 1.1221 acc_test: 0.6680 time: 0.1182s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7725 acc_val: 0.4500 loss_test: 1.1590 acc_test: 0.6850 time: 0.1513s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8708 acc_val: 0.4500 loss_test: 1.2190 acc_test: 0.6860 time: 0.1913s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9858 acc_val: 0.4600 loss_test: 1.2793 acc_test: 0.6930 time: 0.1899s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0112 acc_val: 0.4867 loss_test: 1.3180 acc_test: 0.6930 time: 0.1286s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0013 acc_val: 0.5067 loss_test: 1.3392 acc_test: 0.6940 time: 0.1666s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0423 acc_val: 0.5133 loss_test: 1.3752 acc_test: 0.6960 time: 0.1535s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0541 acc_val: 0.5167 loss_test: 1.4001 acc_test: 0.6960 time: 0.1698s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0993 acc_val: 0.5200 loss_test: 1.4260 acc_test: 0.6970 time: 0.1588s
Optimization Finished!
Total time elapsed: 77.2449s, best testing performance  0.699000, minimun loss  0.989836
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8006 acc_train: 0.1667 loss_val: 1.8154 acc_val: 0.1500 loss_test: 1.6718 acc_test: 0.4970 time: 0.1534s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.8142 acc_val: 0.3933 loss_test: 1.1520 acc_test: 0.6600 time: 0.1081s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8985 acc_val: 0.4367 loss_test: 1.1961 acc_test: 0.6780 time: 0.1064s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9912 acc_val: 0.4433 loss_test: 1.2523 acc_test: 0.6870 time: 0.1121s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0741 acc_val: 0.4467 loss_test: 1.3024 acc_test: 0.6910 time: 0.1080s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0968 acc_val: 0.4667 loss_test: 1.3421 acc_test: 0.6930 time: 0.1098s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1152 acc_val: 0.4733 loss_test: 1.3750 acc_test: 0.6940 time: 0.1642s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1138 acc_val: 0.5000 loss_test: 1.4022 acc_test: 0.6940 time: 0.2012s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1407 acc_val: 0.4967 loss_test: 1.4329 acc_test: 0.6950 time: 0.1477s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1323 acc_val: 0.5100 loss_test: 1.4475 acc_test: 0.7000 time: 0.1602s
Optimization Finished!
Total time elapsed: 66.5660s, best testing performance  0.702000, minimun loss  0.975155
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8106 acc_train: 0.0750 loss_val: 1.8259 acc_val: 0.1500 loss_test: 1.6892 acc_test: 0.4650 time: 0.1636s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7619 acc_val: 0.4167 loss_test: 1.1529 acc_test: 0.6690 time: 0.1490s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8137 acc_val: 0.4367 loss_test: 1.1875 acc_test: 0.6790 time: 0.1595s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9122 acc_val: 0.4533 loss_test: 1.2520 acc_test: 0.6840 time: 0.1570s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9779 acc_val: 0.4633 loss_test: 1.2989 acc_test: 0.6870 time: 0.1460s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0119 acc_val: 0.4867 loss_test: 1.3352 acc_test: 0.6920 time: 0.1486s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0736 acc_val: 0.5000 loss_test: 1.3725 acc_test: 0.6960 time: 0.1366s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0583 acc_val: 0.5033 loss_test: 1.3918 acc_test: 0.6950 time: 0.1627s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0984 acc_val: 0.5200 loss_test: 1.4253 acc_test: 0.6950 time: 0.1590s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1162 acc_val: 0.5133 loss_test: 1.4450 acc_test: 0.6960 time: 0.1395s
Optimization Finished!
Total time elapsed: 76.8827s, best testing performance  0.702000, minimun loss  0.980663
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7835 acc_train: 0.1500 loss_val: 1.7868 acc_val: 0.1300 loss_test: 1.6719 acc_test: 0.4960 time: 0.1660s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.6543 acc_val: 0.4700 loss_test: 1.1330 acc_test: 0.6700 time: 0.1702s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7061 acc_val: 0.4967 loss_test: 1.1694 acc_test: 0.6910 time: 0.1053s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8051 acc_val: 0.4867 loss_test: 1.2322 acc_test: 0.6860 time: 0.1054s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9495 acc_val: 0.4767 loss_test: 1.2957 acc_test: 0.6930 time: 0.1092s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9965 acc_val: 0.4867 loss_test: 1.3320 acc_test: 0.6910 time: 0.1122s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.4967 loss_test: 1.3704 acc_test: 0.6950 time: 0.1107s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0848 acc_val: 0.5100 loss_test: 1.4014 acc_test: 0.6970 time: 0.1097s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1326 acc_val: 0.5100 loss_test: 1.4403 acc_test: 0.6980 time: 0.1090s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1794 acc_val: 0.5067 loss_test: 1.4665 acc_test: 0.6980 time: 0.1116s
Optimization Finished!
Total time elapsed: 59.9033s, best testing performance  0.702000, minimun loss  0.988946
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1417 loss_val: 1.8152 acc_val: 0.1967 loss_test: 1.6703 acc_test: 0.5290 time: 0.1570s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7323 acc_val: 0.4067 loss_test: 1.1729 acc_test: 0.6620 time: 0.1407s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7667 acc_val: 0.4667 loss_test: 1.2038 acc_test: 0.6730 time: 0.1824s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8783 acc_val: 0.4467 loss_test: 1.2706 acc_test: 0.6830 time: 0.1845s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9810 acc_val: 0.4567 loss_test: 1.3160 acc_test: 0.6900 time: 0.1872s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0530 acc_val: 0.4567 loss_test: 1.3506 acc_test: 0.6940 time: 0.1865s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0783 acc_val: 0.4900 loss_test: 1.3817 acc_test: 0.6970 time: 0.1281s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1542 acc_val: 0.4933 loss_test: 1.4238 acc_test: 0.6950 time: 0.1540s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1875 acc_val: 0.5033 loss_test: 1.4555 acc_test: 0.6960 time: 0.1779s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2028 acc_val: 0.5000 loss_test: 1.4773 acc_test: 0.6970 time: 0.1824s
Optimization Finished!
Total time elapsed: 77.8090s, best testing performance  0.699000, minimun loss  1.004174
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7922 acc_train: 0.1333 loss_val: 1.8088 acc_val: 0.1567 loss_test: 1.6750 acc_test: 0.4890 time: 0.1535s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9185 acc_val: 0.3933 loss_test: 1.2087 acc_test: 0.6610 time: 0.1577s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9221 acc_val: 0.4467 loss_test: 1.2237 acc_test: 0.6800 time: 0.1558s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 2.0062 acc_val: 0.4433 loss_test: 1.2799 acc_test: 0.6820 time: 0.1339s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0287 acc_val: 0.4667 loss_test: 1.3116 acc_test: 0.6900 time: 0.1531s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0742 acc_val: 0.4767 loss_test: 1.3504 acc_test: 0.6920 time: 0.1598s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0829 acc_val: 0.5000 loss_test: 1.3813 acc_test: 0.6970 time: 0.1064s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1109 acc_val: 0.5000 loss_test: 1.4143 acc_test: 0.7000 time: 0.1087s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1447 acc_val: 0.5167 loss_test: 1.4450 acc_test: 0.7000 time: 0.1104s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1724 acc_val: 0.5100 loss_test: 1.4661 acc_test: 0.7050 time: 0.1085s
Optimization Finished!
Total time elapsed: 66.0187s, best testing performance  0.707000, minimun loss  0.988667
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7920 acc_train: 0.1333 loss_val: 1.8008 acc_val: 0.0867 loss_test: 1.6838 acc_test: 0.3640 time: 0.1622s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6855 acc_val: 0.4233 loss_test: 1.1250 acc_test: 0.6590 time: 0.1788s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7655 acc_val: 0.4533 loss_test: 1.1657 acc_test: 0.6790 time: 0.1580s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8894 acc_val: 0.4467 loss_test: 1.2301 acc_test: 0.6840 time: 0.1285s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9761 acc_val: 0.4667 loss_test: 1.2783 acc_test: 0.6920 time: 0.1407s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0311 acc_val: 0.4767 loss_test: 1.3215 acc_test: 0.6920 time: 0.1314s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0639 acc_val: 0.4867 loss_test: 1.3597 acc_test: 0.6940 time: 0.1775s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.4900 loss_test: 1.3963 acc_test: 0.6920 time: 0.1672s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1275 acc_val: 0.5100 loss_test: 1.4272 acc_test: 0.6950 time: 0.1469s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1464 acc_val: 0.5067 loss_test: 1.4573 acc_test: 0.6960 time: 0.1760s
Optimization Finished!
Total time elapsed: 77.4757s, best testing performance  0.699000, minimun loss  0.968391
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7885 acc_train: 0.1333 loss_val: 1.8056 acc_val: 0.0500 loss_test: 1.6696 acc_test: 0.3470 time: 0.1373s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.6555 acc_val: 0.4300 loss_test: 1.1082 acc_test: 0.6650 time: 0.1789s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7480 acc_val: 0.4533 loss_test: 1.1495 acc_test: 0.6830 time: 0.1400s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8143 acc_val: 0.4733 loss_test: 1.2062 acc_test: 0.6900 time: 0.1696s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9923 acc_val: 0.4667 loss_test: 1.2740 acc_test: 0.6950 time: 0.1930s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0813 acc_val: 0.4733 loss_test: 1.3240 acc_test: 0.6910 time: 0.1338s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1414 acc_val: 0.4800 loss_test: 1.3678 acc_test: 0.6960 time: 0.1414s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1415 acc_val: 0.5000 loss_test: 1.3924 acc_test: 0.6960 time: 0.1736s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1758 acc_val: 0.4967 loss_test: 1.4211 acc_test: 0.6970 time: 0.1252s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2105 acc_val: 0.5033 loss_test: 1.4460 acc_test: 0.6950 time: 0.1738s
Optimization Finished!
Total time elapsed: 75.9071s, best testing performance  0.700000, minimun loss  0.972835
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7926 acc_train: 0.1417 loss_val: 1.7967 acc_val: 0.1167 loss_test: 1.6703 acc_test: 0.4780 time: 0.1523s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7975 acc_val: 0.3867 loss_test: 1.1603 acc_test: 0.6580 time: 0.1073s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8720 acc_val: 0.4167 loss_test: 1.1935 acc_test: 0.6720 time: 0.1086s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9254 acc_val: 0.4300 loss_test: 1.2363 acc_test: 0.6790 time: 0.1103s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9786 acc_val: 0.4467 loss_test: 1.2763 acc_test: 0.6850 time: 0.1316s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0405 acc_val: 0.4600 loss_test: 1.3206 acc_test: 0.6920 time: 0.1843s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0858 acc_val: 0.4767 loss_test: 1.3625 acc_test: 0.6900 time: 0.1710s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1213 acc_val: 0.4967 loss_test: 1.4002 acc_test: 0.6920 time: 0.1399s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1598 acc_val: 0.5033 loss_test: 1.4333 acc_test: 0.6940 time: 0.1843s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2033 acc_val: 0.5000 loss_test: 1.4665 acc_test: 0.6940 time: 0.1312s
Optimization Finished!
Total time elapsed: 70.3597s, best testing performance  0.694000, minimun loss  1.005749
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7780 acc_train: 0.2083 loss_val: 1.8058 acc_val: 0.0933 loss_test: 1.6698 acc_test: 0.4160 time: 0.2241s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.7582 acc_val: 0.4233 loss_test: 1.1539 acc_test: 0.6660 time: 0.1195s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8123 acc_val: 0.4233 loss_test: 1.1814 acc_test: 0.6860 time: 0.1914s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8331 acc_val: 0.4533 loss_test: 1.2184 acc_test: 0.6910 time: 0.1942s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9379 acc_val: 0.4633 loss_test: 1.2722 acc_test: 0.6880 time: 0.1812s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9934 acc_val: 0.4767 loss_test: 1.3197 acc_test: 0.6920 time: 0.1191s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0354 acc_val: 0.4900 loss_test: 1.3577 acc_test: 0.6930 time: 0.1436s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4933 loss_test: 1.4007 acc_test: 0.6950 time: 0.1794s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1464 acc_val: 0.5033 loss_test: 1.4389 acc_test: 0.6940 time: 0.1695s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1800 acc_val: 0.5033 loss_test: 1.4684 acc_test: 0.6980 time: 0.1474s
Optimization Finished!
Total time elapsed: 77.4204s, best testing performance  0.704000, minimun loss  1.011446
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7780 acc_train: 0.1833 loss_val: 1.8166 acc_val: 0.1667 loss_test: 1.6557 acc_test: 0.5510 time: 0.1475s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.9643 acc_val: 0.3500 loss_test: 1.2275 acc_test: 0.6470 time: 0.1061s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 2.0028 acc_val: 0.4067 loss_test: 1.2416 acc_test: 0.6600 time: 0.1073s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9908 acc_val: 0.4333 loss_test: 1.2564 acc_test: 0.6840 time: 0.1128s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0497 acc_val: 0.4467 loss_test: 1.2948 acc_test: 0.6850 time: 0.1070s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0577 acc_val: 0.4833 loss_test: 1.3234 acc_test: 0.6900 time: 0.1096s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1130 acc_val: 0.5033 loss_test: 1.3610 acc_test: 0.6920 time: 0.1088s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1477 acc_val: 0.5100 loss_test: 1.3937 acc_test: 0.6910 time: 0.1102s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2035 acc_val: 0.5100 loss_test: 1.4264 acc_test: 0.6920 time: 0.1435s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2314 acc_val: 0.5133 loss_test: 1.4578 acc_test: 0.6910 time: 0.1332s
Optimization Finished!
Total time elapsed: 61.4196s, best testing performance  0.695000, minimun loss  1.045644
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7971 acc_train: 0.1667 loss_val: 1.7818 acc_val: 0.2067 loss_test: 1.6964 acc_test: 0.5040 time: 0.2053s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8673 acc_val: 0.3767 loss_test: 1.1863 acc_test: 0.6530 time: 0.1370s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8662 acc_val: 0.4367 loss_test: 1.1962 acc_test: 0.6680 time: 0.1923s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8856 acc_val: 0.4533 loss_test: 1.2279 acc_test: 0.6880 time: 0.1713s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9159 acc_val: 0.4600 loss_test: 1.2674 acc_test: 0.6920 time: 0.1398s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9473 acc_val: 0.4833 loss_test: 1.3074 acc_test: 0.6940 time: 0.1229s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0374 acc_val: 0.4900 loss_test: 1.3630 acc_test: 0.6900 time: 0.1850s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0780 acc_val: 0.4967 loss_test: 1.4092 acc_test: 0.6900 time: 0.1396s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1354 acc_val: 0.5033 loss_test: 1.4567 acc_test: 0.6930 time: 0.1610s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2101 acc_val: 0.5033 loss_test: 1.5046 acc_test: 0.6910 time: 0.1768s
Optimization Finished!
Total time elapsed: 77.8006s, best testing performance  0.696000, minimun loss  1.019587
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.1583 loss_val: 1.7936 acc_val: 0.2167 loss_test: 1.6847 acc_test: 0.5110 time: 0.2206s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8587 acc_val: 0.3967 loss_test: 1.1719 acc_test: 0.6540 time: 0.1469s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.9306 acc_val: 0.4200 loss_test: 1.2075 acc_test: 0.6690 time: 0.1714s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9452 acc_val: 0.4333 loss_test: 1.2381 acc_test: 0.6830 time: 0.1526s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9991 acc_val: 0.4533 loss_test: 1.2810 acc_test: 0.6890 time: 0.1050s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0579 acc_val: 0.4733 loss_test: 1.3251 acc_test: 0.6900 time: 0.1046s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1098 acc_val: 0.4833 loss_test: 1.3654 acc_test: 0.6910 time: 0.1122s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1594 acc_val: 0.4967 loss_test: 1.4054 acc_test: 0.6940 time: 0.1086s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1994 acc_val: 0.5000 loss_test: 1.4407 acc_test: 0.6980 time: 0.1076s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2670 acc_val: 0.4967 loss_test: 1.4743 acc_test: 0.7010 time: 0.1079s
Optimization Finished!
Total time elapsed: 61.8108s, best testing performance  0.703000, minimun loss  1.018662
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7874 acc_train: 0.1083 loss_val: 1.7929 acc_val: 0.1900 loss_test: 1.6631 acc_test: 0.5560 time: 0.1793s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8645 acc_val: 0.4333 loss_test: 1.1925 acc_test: 0.6570 time: 0.1414s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8235 acc_val: 0.4733 loss_test: 1.2022 acc_test: 0.6760 time: 0.1594s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8922 acc_val: 0.4500 loss_test: 1.2611 acc_test: 0.6750 time: 0.1664s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0256 acc_val: 0.4467 loss_test: 1.3155 acc_test: 0.6850 time: 0.1989s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0710 acc_val: 0.4700 loss_test: 1.3474 acc_test: 0.6890 time: 0.1732s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0926 acc_val: 0.5033 loss_test: 1.3721 acc_test: 0.6930 time: 0.1553s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0946 acc_val: 0.5100 loss_test: 1.3982 acc_test: 0.6930 time: 0.1372s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1152 acc_val: 0.5000 loss_test: 1.4291 acc_test: 0.7000 time: 0.1571s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1285 acc_val: 0.5133 loss_test: 1.4532 acc_test: 0.6990 time: 0.1766s
Optimization Finished!
Total time elapsed: 78.4874s, best testing performance  0.701000, minimun loss  0.980584
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8060 acc_train: 0.0667 loss_val: 1.7994 acc_val: 0.1700 loss_test: 1.6640 acc_test: 0.5550 time: 0.1946s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7842 acc_val: 0.4067 loss_test: 1.1793 acc_test: 0.6570 time: 0.1476s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7328 acc_val: 0.4700 loss_test: 1.1894 acc_test: 0.6810 time: 0.1608s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.6864 acc_val: 0.4867 loss_test: 1.2127 acc_test: 0.6910 time: 0.1599s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.8869 acc_val: 0.4733 loss_test: 1.3076 acc_test: 0.6840 time: 0.1336s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0509 acc_val: 0.4733 loss_test: 1.3628 acc_test: 0.6900 time: 0.1881s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1477 acc_val: 0.4933 loss_test: 1.4016 acc_test: 0.6930 time: 0.1769s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1721 acc_val: 0.5033 loss_test: 1.4232 acc_test: 0.6960 time: 0.1067s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2324 acc_val: 0.5100 loss_test: 1.4591 acc_test: 0.6970 time: 0.1053s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2539 acc_val: 0.5000 loss_test: 1.4845 acc_test: 0.6930 time: 0.1056s
Optimization Finished!
Total time elapsed: 69.8990s, best testing performance  0.700000, minimun loss  0.979147
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7883 acc_train: 0.1667 loss_val: 1.7997 acc_val: 0.1300 loss_test: 1.6774 acc_test: 0.5060 time: 0.1588s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9285 acc_val: 0.3867 loss_test: 1.2207 acc_test: 0.6460 time: 0.1485s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8276 acc_val: 0.4667 loss_test: 1.2137 acc_test: 0.6710 time: 0.1527s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8691 acc_val: 0.4833 loss_test: 1.2672 acc_test: 0.6760 time: 0.1215s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0613 acc_val: 0.4400 loss_test: 1.3349 acc_test: 0.6850 time: 0.1413s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1335 acc_val: 0.4700 loss_test: 1.3752 acc_test: 0.6940 time: 0.1472s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1842 acc_val: 0.4833 loss_test: 1.4015 acc_test: 0.6920 time: 0.1416s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1672 acc_val: 0.5067 loss_test: 1.4223 acc_test: 0.6950 time: 0.1775s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1972 acc_val: 0.4967 loss_test: 1.4462 acc_test: 0.6960 time: 0.1757s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2227 acc_val: 0.5100 loss_test: 1.4719 acc_test: 0.6950 time: 0.1763s
Optimization Finished!
Total time elapsed: 78.1203s, best testing performance  0.700000, minimun loss  0.992064
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8120 acc_train: 0.1083 loss_val: 1.8116 acc_val: 0.1833 loss_test: 1.6849 acc_test: 0.5100 time: 0.1598s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7118 acc_val: 0.4600 loss_test: 1.1743 acc_test: 0.6650 time: 0.1899s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7483 acc_val: 0.4900 loss_test: 1.1980 acc_test: 0.6790 time: 0.1263s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.7432 acc_val: 0.5000 loss_test: 1.2319 acc_test: 0.6850 time: 0.1709s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9371 acc_val: 0.4833 loss_test: 1.3118 acc_test: 0.6950 time: 0.1290s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0137 acc_val: 0.4800 loss_test: 1.3487 acc_test: 0.6980 time: 0.1273s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1426 acc_val: 0.4933 loss_test: 1.4036 acc_test: 0.6940 time: 0.1628s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1731 acc_val: 0.4967 loss_test: 1.4280 acc_test: 0.6950 time: 0.1749s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2127 acc_val: 0.5000 loss_test: 1.4619 acc_test: 0.6990 time: 0.1675s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2701 acc_val: 0.5067 loss_test: 1.4885 acc_test: 0.6940 time: 0.1458s
Optimization Finished!
Total time elapsed: 77.7505s, best testing performance  0.700000, minimun loss  1.003692
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8032 acc_train: 0.1333 loss_val: 1.8232 acc_val: 0.1267 loss_test: 1.6724 acc_test: 0.4870 time: 0.1564s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8016 acc_val: 0.4000 loss_test: 1.1762 acc_test: 0.6540 time: 0.1221s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7954 acc_val: 0.4700 loss_test: 1.1937 acc_test: 0.6720 time: 0.1123s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7860 acc_val: 0.4833 loss_test: 1.2317 acc_test: 0.6810 time: 0.1084s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9613 acc_val: 0.4633 loss_test: 1.3086 acc_test: 0.6840 time: 0.1669s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1006 acc_val: 0.4533 loss_test: 1.3627 acc_test: 0.6890 time: 0.1360s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0980 acc_val: 0.4867 loss_test: 1.3836 acc_test: 0.6890 time: 0.1794s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1474 acc_val: 0.5000 loss_test: 1.4186 acc_test: 0.6940 time: 0.1217s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1397 acc_val: 0.5033 loss_test: 1.4361 acc_test: 0.6960 time: 0.1387s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1719 acc_val: 0.5033 loss_test: 1.4580 acc_test: 0.6930 time: 0.1674s
Optimization Finished!
Total time elapsed: 68.9563s, best testing performance  0.700000, minimun loss  0.980741
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8169 acc_train: 0.1000 loss_val: 1.7962 acc_val: 0.1367 loss_test: 1.6943 acc_test: 0.5100 time: 0.1789s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7645 acc_val: 0.3933 loss_test: 1.1680 acc_test: 0.6470 time: 0.1962s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8444 acc_val: 0.4267 loss_test: 1.2033 acc_test: 0.6690 time: 0.1480s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9352 acc_val: 0.4400 loss_test: 1.2463 acc_test: 0.6830 time: 0.1730s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9701 acc_val: 0.4600 loss_test: 1.2803 acc_test: 0.6880 time: 0.2192s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9981 acc_val: 0.4733 loss_test: 1.3146 acc_test: 0.6930 time: 0.1271s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0665 acc_val: 0.4800 loss_test: 1.3532 acc_test: 0.6930 time: 0.1439s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0772 acc_val: 0.4933 loss_test: 1.3822 acc_test: 0.6980 time: 0.1977s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1040 acc_val: 0.5033 loss_test: 1.4097 acc_test: 0.7020 time: 0.1595s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1554 acc_val: 0.5000 loss_test: 1.4454 acc_test: 0.6950 time: 0.1449s
Optimization Finished!
Total time elapsed: 77.7539s, best testing performance  0.703000, minimun loss  0.990192
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7890 acc_train: 0.1917 loss_val: 1.8126 acc_val: 0.1000 loss_test: 1.6753 acc_test: 0.4000 time: 0.1292s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7968 acc_val: 0.3933 loss_test: 1.1732 acc_test: 0.6630 time: 0.1057s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8331 acc_val: 0.4467 loss_test: 1.1944 acc_test: 0.6780 time: 0.1046s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9704 acc_val: 0.4433 loss_test: 1.2584 acc_test: 0.6780 time: 0.1074s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0335 acc_val: 0.4633 loss_test: 1.2967 acc_test: 0.6860 time: 0.1105s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0907 acc_val: 0.4667 loss_test: 1.3365 acc_test: 0.6880 time: 0.1076s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1263 acc_val: 0.4733 loss_test: 1.3703 acc_test: 0.6920 time: 0.1140s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1612 acc_val: 0.4967 loss_test: 1.4081 acc_test: 0.6910 time: 0.1142s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1691 acc_val: 0.5033 loss_test: 1.4278 acc_test: 0.6960 time: 0.1467s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1953 acc_val: 0.5067 loss_test: 1.4577 acc_test: 0.6950 time: 0.1838s
Optimization Finished!
Total time elapsed: 59.7598s, best testing performance  0.699000, minimun loss  0.983980
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1167 loss_val: 1.8259 acc_val: 0.1600 loss_test: 1.6798 acc_test: 0.5390 time: 0.2034s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8084 acc_val: 0.4100 loss_test: 1.1812 acc_test: 0.6540 time: 0.1737s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8337 acc_val: 0.4467 loss_test: 1.2092 acc_test: 0.6700 time: 0.1492s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9491 acc_val: 0.4633 loss_test: 1.2662 acc_test: 0.6820 time: 0.1334s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0659 acc_val: 0.4467 loss_test: 1.3245 acc_test: 0.6870 time: 0.1436s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0907 acc_val: 0.4600 loss_test: 1.3528 acc_test: 0.6910 time: 0.1818s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1136 acc_val: 0.4733 loss_test: 1.3831 acc_test: 0.6910 time: 0.1241s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1376 acc_val: 0.4967 loss_test: 1.4168 acc_test: 0.6930 time: 0.1662s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1746 acc_val: 0.5033 loss_test: 1.4536 acc_test: 0.6920 time: 0.1201s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1724 acc_val: 0.5067 loss_test: 1.4730 acc_test: 0.6970 time: 0.1909s
Optimization Finished!
Total time elapsed: 77.8022s, best testing performance  0.700000, minimun loss  0.994761
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7877 acc_train: 0.2000 loss_val: 1.8053 acc_val: 0.1333 loss_test: 1.6511 acc_test: 0.5020 time: 0.1646s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8294 acc_val: 0.3833 loss_test: 1.1892 acc_test: 0.6480 time: 0.1330s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8656 acc_val: 0.4367 loss_test: 1.2215 acc_test: 0.6640 time: 0.1628s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9500 acc_val: 0.4400 loss_test: 1.2705 acc_test: 0.6750 time: 0.1384s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0249 acc_val: 0.4533 loss_test: 1.3119 acc_test: 0.6870 time: 0.1709s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1296 acc_val: 0.4700 loss_test: 1.3587 acc_test: 0.6910 time: 0.1054s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.2077 acc_val: 0.4700 loss_test: 1.4092 acc_test: 0.6880 time: 0.1054s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2450 acc_val: 0.4767 loss_test: 1.4503 acc_test: 0.6880 time: 0.1084s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2723 acc_val: 0.4867 loss_test: 1.4897 acc_test: 0.6870 time: 0.1093s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2725 acc_val: 0.4800 loss_test: 1.5181 acc_test: 0.6890 time: 0.1092s
Optimization Finished!
Total time elapsed: 64.0208s, best testing performance  0.693000, minimun loss  0.991011
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7818 acc_train: 0.2333 loss_val: 1.7817 acc_val: 0.2267 loss_test: 1.6615 acc_test: 0.5600 time: 0.1793s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8152 acc_val: 0.4100 loss_test: 1.1946 acc_test: 0.6500 time: 0.1667s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8100 acc_val: 0.4633 loss_test: 1.2126 acc_test: 0.6730 time: 0.1382s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9176 acc_val: 0.4700 loss_test: 1.2714 acc_test: 0.6810 time: 0.1611s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0281 acc_val: 0.4567 loss_test: 1.3199 acc_test: 0.6890 time: 0.1643s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0512 acc_val: 0.4667 loss_test: 1.3472 acc_test: 0.6900 time: 0.1596s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0785 acc_val: 0.4767 loss_test: 1.3787 acc_test: 0.6930 time: 0.1281s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1299 acc_val: 0.4933 loss_test: 1.4149 acc_test: 0.6930 time: 0.1356s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1648 acc_val: 0.5033 loss_test: 1.4425 acc_test: 0.6910 time: 0.1729s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1607 acc_val: 0.5100 loss_test: 1.4604 acc_test: 0.6960 time: 0.1734s
Optimization Finished!
Total time elapsed: 76.7391s, best testing performance  0.698000, minimun loss  0.997010
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.0917 loss_val: 1.8493 acc_val: 0.1067 loss_test: 1.6766 acc_test: 0.4820 time: 0.1808s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8162 acc_val: 0.4100 loss_test: 1.1830 acc_test: 0.6600 time: 0.2168s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8639 acc_val: 0.4433 loss_test: 1.2059 acc_test: 0.6790 time: 0.1375s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9181 acc_val: 0.4567 loss_test: 1.2441 acc_test: 0.6880 time: 0.1347s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9744 acc_val: 0.4500 loss_test: 1.2840 acc_test: 0.6900 time: 0.1944s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0476 acc_val: 0.4667 loss_test: 1.3273 acc_test: 0.6900 time: 0.1660s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0879 acc_val: 0.4867 loss_test: 1.3648 acc_test: 0.6940 time: 0.1226s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1058 acc_val: 0.4800 loss_test: 1.3912 acc_test: 0.6950 time: 0.1286s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1628 acc_val: 0.4833 loss_test: 1.4265 acc_test: 0.6930 time: 0.1634s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1922 acc_val: 0.4933 loss_test: 1.4567 acc_test: 0.6960 time: 0.1052s
Optimization Finished!
Total time elapsed: 73.2616s, best testing performance  0.701000, minimun loss  1.018229
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7890 acc_train: 0.1750 loss_val: 1.7947 acc_val: 0.1767 loss_test: 1.6912 acc_test: 0.5000 time: 0.1754s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7977 acc_val: 0.4133 loss_test: 1.2027 acc_test: 0.6550 time: 0.1086s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8449 acc_val: 0.4367 loss_test: 1.2291 acc_test: 0.6740 time: 0.1126s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8969 acc_val: 0.4600 loss_test: 1.2678 acc_test: 0.6840 time: 0.1189s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9753 acc_val: 0.4667 loss_test: 1.3113 acc_test: 0.6890 time: 0.1559s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0218 acc_val: 0.4733 loss_test: 1.3489 acc_test: 0.6900 time: 0.2029s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0470 acc_val: 0.4933 loss_test: 1.3878 acc_test: 0.6950 time: 0.1589s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0753 acc_val: 0.5133 loss_test: 1.4225 acc_test: 0.6970 time: 0.2262s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.5133 loss_test: 1.4597 acc_test: 0.6950 time: 0.1642s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1633 acc_val: 0.5067 loss_test: 1.4941 acc_test: 0.6970 time: 0.1797s
Optimization Finished!
Total time elapsed: 72.3187s, best testing performance  0.702000, minimun loss  1.042710
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8023 acc_train: 0.1167 loss_val: 1.8082 acc_val: 0.1300 loss_test: 1.6627 acc_test: 0.5130 time: 0.1745s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8004 acc_val: 0.4133 loss_test: 1.1996 acc_test: 0.6490 time: 0.1242s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8146 acc_val: 0.4567 loss_test: 1.2164 acc_test: 0.6690 time: 0.1655s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9268 acc_val: 0.4500 loss_test: 1.2680 acc_test: 0.6800 time: 0.1556s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0176 acc_val: 0.4567 loss_test: 1.3170 acc_test: 0.6870 time: 0.1716s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0570 acc_val: 0.4767 loss_test: 1.3563 acc_test: 0.6930 time: 0.1365s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1001 acc_val: 0.4800 loss_test: 1.3912 acc_test: 0.6920 time: 0.1443s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1359 acc_val: 0.4900 loss_test: 1.4252 acc_test: 0.6930 time: 0.1527s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1474 acc_val: 0.4933 loss_test: 1.4526 acc_test: 0.6990 time: 0.1346s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1664 acc_val: 0.5067 loss_test: 1.4790 acc_test: 0.6990 time: 0.1482s
Optimization Finished!
Total time elapsed: 78.1751s, best testing performance  0.702000, minimun loss  1.007545
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1083 loss_val: 1.7883 acc_val: 0.1967 loss_test: 1.6651 acc_test: 0.5200 time: 0.1646s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.8446 acc_val: 0.4100 loss_test: 1.2259 acc_test: 0.6520 time: 0.1071s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8295 acc_val: 0.4500 loss_test: 1.2289 acc_test: 0.6720 time: 0.1066s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8881 acc_val: 0.4600 loss_test: 1.2664 acc_test: 0.6860 time: 0.1072s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9623 acc_val: 0.4633 loss_test: 1.3097 acc_test: 0.6900 time: 0.1108s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0204 acc_val: 0.4733 loss_test: 1.3490 acc_test: 0.6920 time: 0.1084s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0443 acc_val: 0.4900 loss_test: 1.3836 acc_test: 0.6980 time: 0.1106s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0934 acc_val: 0.5000 loss_test: 1.4260 acc_test: 0.7020 time: 0.1798s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1760 acc_val: 0.4967 loss_test: 1.4737 acc_test: 0.6980 time: 0.1988s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2132 acc_val: 0.5100 loss_test: 1.5174 acc_test: 0.6990 time: 0.1695s
Optimization Finished!
Total time elapsed: 62.7430s, best testing performance  0.705000, minimun loss  1.024628
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7830 acc_train: 0.1417 loss_val: 1.7799 acc_val: 0.2267 loss_test: 1.6857 acc_test: 0.5050 time: 0.1920s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8884 acc_val: 0.3900 loss_test: 1.1877 acc_test: 0.6500 time: 0.1556s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8716 acc_val: 0.4367 loss_test: 1.1968 acc_test: 0.6680 time: 0.1653s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9475 acc_val: 0.4433 loss_test: 1.2422 acc_test: 0.6800 time: 0.1661s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0420 acc_val: 0.4567 loss_test: 1.2926 acc_test: 0.6870 time: 0.2067s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0410 acc_val: 0.4733 loss_test: 1.3216 acc_test: 0.6920 time: 0.1353s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0591 acc_val: 0.4900 loss_test: 1.3579 acc_test: 0.6950 time: 0.1716s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1266 acc_val: 0.5033 loss_test: 1.4039 acc_test: 0.6910 time: 0.1697s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1397 acc_val: 0.5100 loss_test: 1.4309 acc_test: 0.6960 time: 0.1370s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1961 acc_val: 0.5000 loss_test: 1.4678 acc_test: 0.6970 time: 0.1498s
Optimization Finished!
Total time elapsed: 77.0842s, best testing performance  0.699000, minimun loss  1.017449
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7947 acc_train: 0.1333 loss_val: 1.7779 acc_val: 0.1700 loss_test: 1.6702 acc_test: 0.5440 time: 0.1372s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7443 acc_val: 0.4167 loss_test: 1.1805 acc_test: 0.6520 time: 0.1843s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7622 acc_val: 0.4533 loss_test: 1.1923 acc_test: 0.6800 time: 0.1633s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8733 acc_val: 0.4700 loss_test: 1.2513 acc_test: 0.6960 time: 0.1059s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9585 acc_val: 0.4767 loss_test: 1.2950 acc_test: 0.6970 time: 0.1062s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0336 acc_val: 0.4867 loss_test: 1.3380 acc_test: 0.6960 time: 0.1052s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0812 acc_val: 0.4933 loss_test: 1.3757 acc_test: 0.6940 time: 0.1092s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1309 acc_val: 0.5067 loss_test: 1.4144 acc_test: 0.6910 time: 0.1097s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1424 acc_val: 0.5033 loss_test: 1.4392 acc_test: 0.6960 time: 0.1080s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1730 acc_val: 0.4967 loss_test: 1.4674 acc_test: 0.6990 time: 0.1080s
Optimization Finished!
Total time elapsed: 60.5723s, best testing performance  0.703000, minimun loss  1.001920
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7880 acc_train: 0.2000 loss_val: 1.8135 acc_val: 0.1767 loss_test: 1.6840 acc_test: 0.5070 time: 0.2245s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8143 acc_val: 0.4067 loss_test: 1.2070 acc_test: 0.6470 time: 0.1241s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7933 acc_val: 0.4400 loss_test: 1.2153 acc_test: 0.6670 time: 0.1607s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8671 acc_val: 0.4600 loss_test: 1.2609 acc_test: 0.6850 time: 0.1998s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9786 acc_val: 0.4633 loss_test: 1.3096 acc_test: 0.6870 time: 0.1643s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0416 acc_val: 0.4900 loss_test: 1.3431 acc_test: 0.6940 time: 0.1332s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1186 acc_val: 0.4933 loss_test: 1.3886 acc_test: 0.6930 time: 0.1722s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1420 acc_val: 0.5033 loss_test: 1.4192 acc_test: 0.6930 time: 0.1316s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1843 acc_val: 0.5067 loss_test: 1.4422 acc_test: 0.6930 time: 0.1752s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2218 acc_val: 0.5133 loss_test: 1.4658 acc_test: 0.6940 time: 0.1734s
Optimization Finished!
Total time elapsed: 77.8549s, best testing performance  0.701000, minimun loss  0.997977
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7873 acc_train: 0.1833 loss_val: 1.8489 acc_val: 0.0533 loss_test: 1.6769 acc_test: 0.3470 time: 0.1784s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8440 acc_val: 0.4067 loss_test: 1.2123 acc_test: 0.6510 time: 0.1589s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9694 acc_val: 0.4133 loss_test: 1.2613 acc_test: 0.6670 time: 0.1720s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9675 acc_val: 0.4433 loss_test: 1.2823 acc_test: 0.6810 time: 0.2002s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0126 acc_val: 0.4600 loss_test: 1.3147 acc_test: 0.6900 time: 0.1493s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.4700 loss_test: 1.3519 acc_test: 0.6930 time: 0.1284s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0903 acc_val: 0.4933 loss_test: 1.3781 acc_test: 0.6920 time: 0.1486s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1072 acc_val: 0.5067 loss_test: 1.4045 acc_test: 0.6960 time: 0.1655s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1500 acc_val: 0.5067 loss_test: 1.4336 acc_test: 0.6980 time: 0.1060s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1889 acc_val: 0.5067 loss_test: 1.4625 acc_test: 0.7000 time: 0.1052s
Optimization Finished!
Total time elapsed: 70.2090s, best testing performance  0.705000, minimun loss  0.989641
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7917 acc_train: 0.2417 loss_val: 1.8084 acc_val: 0.1667 loss_test: 1.6575 acc_test: 0.5100 time: 0.1605s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7608 acc_val: 0.4200 loss_test: 1.1852 acc_test: 0.6670 time: 0.1940s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8317 acc_val: 0.4300 loss_test: 1.2266 acc_test: 0.6770 time: 0.1732s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9234 acc_val: 0.4367 loss_test: 1.2827 acc_test: 0.6850 time: 0.1638s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0229 acc_val: 0.4700 loss_test: 1.3270 acc_test: 0.6940 time: 0.1315s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0808 acc_val: 0.4833 loss_test: 1.3622 acc_test: 0.6950 time: 0.1472s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1334 acc_val: 0.4967 loss_test: 1.3964 acc_test: 0.6940 time: 0.1362s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1649 acc_val: 0.5033 loss_test: 1.4296 acc_test: 0.6970 time: 0.1772s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1806 acc_val: 0.5100 loss_test: 1.4573 acc_test: 0.6960 time: 0.1584s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2251 acc_val: 0.5133 loss_test: 1.4867 acc_test: 0.6970 time: 0.1519s
Optimization Finished!
Total time elapsed: 75.4276s, best testing performance  0.701000, minimun loss  1.015323
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7904 acc_train: 0.2333 loss_val: 1.8234 acc_val: 0.1200 loss_test: 1.6599 acc_test: 0.4710 time: 0.1629s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8393 acc_val: 0.3933 loss_test: 1.2082 acc_test: 0.6480 time: 0.1371s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8146 acc_val: 0.4400 loss_test: 1.2130 acc_test: 0.6690 time: 0.1704s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9069 acc_val: 0.4367 loss_test: 1.2617 acc_test: 0.6870 time: 0.2018s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0334 acc_val: 0.4433 loss_test: 1.3142 acc_test: 0.6880 time: 0.1694s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.4600 loss_test: 1.3495 acc_test: 0.6910 time: 0.1860s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1437 acc_val: 0.4800 loss_test: 1.3926 acc_test: 0.6930 time: 0.1553s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2007 acc_val: 0.4967 loss_test: 1.4320 acc_test: 0.6950 time: 0.1157s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2228 acc_val: 0.4867 loss_test: 1.4608 acc_test: 0.6950 time: 0.1367s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2389 acc_val: 0.4967 loss_test: 1.4812 acc_test: 0.6940 time: 0.1343s
Optimization Finished!
Total time elapsed: 77.4919s, best testing performance  0.698000, minimun loss  0.992909
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7877 acc_train: 0.1417 loss_val: 1.8268 acc_val: 0.0700 loss_test: 1.6801 acc_test: 0.4230 time: 0.1477s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.9282 acc_val: 0.3667 loss_test: 1.2041 acc_test: 0.6490 time: 0.1096s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9191 acc_val: 0.4200 loss_test: 1.2213 acc_test: 0.6690 time: 0.1146s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9998 acc_val: 0.4400 loss_test: 1.2663 acc_test: 0.6840 time: 0.1129s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0751 acc_val: 0.4567 loss_test: 1.3091 acc_test: 0.6880 time: 0.1096s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.4700 loss_test: 1.3495 acc_test: 0.6880 time: 0.1514s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1185 acc_val: 0.4833 loss_test: 1.3751 acc_test: 0.6930 time: 0.1513s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2211 acc_val: 0.4867 loss_test: 1.4264 acc_test: 0.6920 time: 0.1594s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2185 acc_val: 0.5067 loss_test: 1.4491 acc_test: 0.6940 time: 0.1791s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2253 acc_val: 0.5067 loss_test: 1.4759 acc_test: 0.6920 time: 0.1276s
Optimization Finished!
Total time elapsed: 66.7716s, best testing performance  0.697000, minimun loss  1.019681
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7949 acc_train: 0.0917 loss_val: 1.7921 acc_val: 0.1967 loss_test: 1.6785 acc_test: 0.4990 time: 0.1313s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7619 acc_val: 0.4000 loss_test: 1.1614 acc_test: 0.6540 time: 0.1458s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8806 acc_val: 0.4267 loss_test: 1.2108 acc_test: 0.6690 time: 0.1419s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9268 acc_val: 0.4400 loss_test: 1.2471 acc_test: 0.6880 time: 0.1589s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9594 acc_val: 0.4533 loss_test: 1.2771 acc_test: 0.6860 time: 0.2162s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0062 acc_val: 0.4733 loss_test: 1.3137 acc_test: 0.6920 time: 0.1302s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0352 acc_val: 0.4933 loss_test: 1.3457 acc_test: 0.6940 time: 0.1385s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0732 acc_val: 0.5067 loss_test: 1.3813 acc_test: 0.6940 time: 0.1534s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1032 acc_val: 0.5100 loss_test: 1.4095 acc_test: 0.6950 time: 0.1284s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.5133 loss_test: 1.4284 acc_test: 0.6920 time: 0.1401s
Optimization Finished!
Total time elapsed: 76.8979s, best testing performance  0.699000, minimun loss  1.013474
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8041 acc_train: 0.1000 loss_val: 1.8179 acc_val: 0.1400 loss_test: 1.7079 acc_test: 0.4770 time: 0.1861s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7315 acc_val: 0.3967 loss_test: 1.1561 acc_test: 0.6620 time: 0.2006s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7996 acc_val: 0.4333 loss_test: 1.1919 acc_test: 0.6740 time: 0.1069s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9054 acc_val: 0.4533 loss_test: 1.2528 acc_test: 0.6870 time: 0.1066s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9743 acc_val: 0.4700 loss_test: 1.2915 acc_test: 0.6920 time: 0.1080s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0130 acc_val: 0.4833 loss_test: 1.3308 acc_test: 0.6880 time: 0.1074s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0844 acc_val: 0.4833 loss_test: 1.3739 acc_test: 0.6920 time: 0.1065s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1248 acc_val: 0.5000 loss_test: 1.4084 acc_test: 0.6940 time: 0.1083s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1618 acc_val: 0.5000 loss_test: 1.4408 acc_test: 0.6950 time: 0.1107s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1994 acc_val: 0.5033 loss_test: 1.4732 acc_test: 0.6980 time: 0.1257s
Optimization Finished!
Total time elapsed: 60.5680s, best testing performance  0.700000, minimun loss  1.007613
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7823 acc_train: 0.2167 loss_val: 1.8165 acc_val: 0.1533 loss_test: 1.6605 acc_test: 0.5140 time: 0.1745s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8202 acc_val: 0.3633 loss_test: 1.1999 acc_test: 0.6480 time: 0.1956s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8061 acc_val: 0.4267 loss_test: 1.2048 acc_test: 0.6690 time: 0.1505s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4500 loss_test: 1.2496 acc_test: 0.6840 time: 0.1441s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9230 acc_val: 0.4700 loss_test: 1.2831 acc_test: 0.6910 time: 0.1859s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0194 acc_val: 0.4700 loss_test: 1.3297 acc_test: 0.6880 time: 0.1621s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0845 acc_val: 0.4767 loss_test: 1.3690 acc_test: 0.6900 time: 0.1248s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1115 acc_val: 0.5000 loss_test: 1.4012 acc_test: 0.6890 time: 0.1213s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1859 acc_val: 0.5000 loss_test: 1.4386 acc_test: 0.6890 time: 0.1643s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2030 acc_val: 0.5033 loss_test: 1.4655 acc_test: 0.6930 time: 0.1361s
Optimization Finished!
Total time elapsed: 78.0593s, best testing performance  0.696000, minimun loss  1.024636
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 9, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7868 acc_train: 0.1583 loss_val: 1.7964 acc_val: 0.2033 loss_test: 1.6822 acc_test: 0.4620 time: 0.1816s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8132 acc_val: 0.3933 loss_test: 1.1914 acc_test: 0.6580 time: 0.1547s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8430 acc_val: 0.4333 loss_test: 1.2169 acc_test: 0.6720 time: 0.1302s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9055 acc_val: 0.4500 loss_test: 1.2549 acc_test: 0.6850 time: 0.1569s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9639 acc_val: 0.4600 loss_test: 1.2920 acc_test: 0.6870 time: 0.1584s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9859 acc_val: 0.4833 loss_test: 1.3262 acc_test: 0.6930 time: 0.1050s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0288 acc_val: 0.4967 loss_test: 1.3591 acc_test: 0.6910 time: 0.1057s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0973 acc_val: 0.5033 loss_test: 1.4051 acc_test: 0.6960 time: 0.1117s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1319 acc_val: 0.5133 loss_test: 1.4369 acc_test: 0.7000 time: 0.1086s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1682 acc_val: 0.5100 loss_test: 1.4636 acc_test: 0.6990 time: 0.1145s
Optimization Finished!
Total time elapsed: 64.2554s, best testing performance  0.703000, minimun loss  1.030389
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7863 acc_train: 0.2167 loss_val: 1.7973 acc_val: 0.1700 loss_test: 1.6638 acc_test: 0.5030 time: 0.6409s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7754 acc_val: 0.3867 loss_test: 1.1381 acc_test: 0.6680 time: 0.0898s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.6997 acc_val: 0.4400 loss_test: 1.1162 acc_test: 0.6800 time: 0.0920s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8071 acc_val: 0.4533 loss_test: 1.1899 acc_test: 0.6840 time: 0.0901s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9826 acc_val: 0.4700 loss_test: 1.2804 acc_test: 0.6890 time: 0.0898s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0488 acc_val: 0.4800 loss_test: 1.3314 acc_test: 0.6910 time: 0.0950s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1029 acc_val: 0.4967 loss_test: 1.3738 acc_test: 0.6960 time: 0.0920s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1353 acc_val: 0.5000 loss_test: 1.4072 acc_test: 0.6990 time: 0.0924s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1502 acc_val: 0.5067 loss_test: 1.4341 acc_test: 0.6990 time: 0.0904s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2108 acc_val: 0.5133 loss_test: 1.4690 acc_test: 0.6960 time: 0.0907s
Optimization Finished!
Total time elapsed: 46.4246s, best testing performance  0.701000, minimun loss  0.987904
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7962 acc_train: 0.1333 loss_val: 1.8037 acc_val: 0.1833 loss_test: 1.6896 acc_test: 0.5020 time: 0.1516s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8016 acc_val: 0.4133 loss_test: 1.1488 acc_test: 0.6650 time: 0.0951s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8323 acc_val: 0.4533 loss_test: 1.1816 acc_test: 0.6770 time: 0.0902s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9396 acc_val: 0.4567 loss_test: 1.2479 acc_test: 0.6810 time: 0.0901s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9908 acc_val: 0.4733 loss_test: 1.2950 acc_test: 0.6900 time: 0.0909s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0121 acc_val: 0.4967 loss_test: 1.3286 acc_test: 0.6990 time: 0.0904s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0440 acc_val: 0.5100 loss_test: 1.3625 acc_test: 0.6950 time: 0.0914s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0951 acc_val: 0.5067 loss_test: 1.3930 acc_test: 0.6960 time: 0.0910s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1034 acc_val: 0.5067 loss_test: 1.4134 acc_test: 0.6990 time: 0.0916s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1518 acc_val: 0.5067 loss_test: 1.4469 acc_test: 0.6980 time: 0.0904s
Optimization Finished!
Total time elapsed: 45.7942s, best testing performance  0.701000, minimun loss  1.009742
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1000 loss_val: 1.8117 acc_val: 0.2133 loss_test: 1.6774 acc_test: 0.5110 time: 0.1682s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.9015 acc_val: 0.3800 loss_test: 1.1729 acc_test: 0.6680 time: 0.0902s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9255 acc_val: 0.4200 loss_test: 1.1942 acc_test: 0.6740 time: 0.0900s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 2.0178 acc_val: 0.4333 loss_test: 1.2548 acc_test: 0.6750 time: 0.0902s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0518 acc_val: 0.4667 loss_test: 1.3023 acc_test: 0.6850 time: 0.0897s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1064 acc_val: 0.4667 loss_test: 1.3549 acc_test: 0.6920 time: 0.0911s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1427 acc_val: 0.4800 loss_test: 1.3956 acc_test: 0.6950 time: 0.0908s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1653 acc_val: 0.5000 loss_test: 1.4339 acc_test: 0.6990 time: 0.0909s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2377 acc_val: 0.4967 loss_test: 1.4766 acc_test: 0.6990 time: 0.0903s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2616 acc_val: 0.5067 loss_test: 1.5049 acc_test: 0.7030 time: 0.0920s
Optimization Finished!
Total time elapsed: 45.7724s, best testing performance  0.705000, minimun loss  0.993286
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7761 acc_train: 0.1917 loss_val: 1.8087 acc_val: 0.1133 loss_test: 1.6577 acc_test: 0.4600 time: 0.1505s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8580 acc_val: 0.3733 loss_test: 1.1877 acc_test: 0.6640 time: 0.0897s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8192 acc_val: 0.4267 loss_test: 1.1789 acc_test: 0.6770 time: 0.0902s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9468 acc_val: 0.4500 loss_test: 1.2408 acc_test: 0.6780 time: 0.0906s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0251 acc_val: 0.4667 loss_test: 1.2923 acc_test: 0.6870 time: 0.0897s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0706 acc_val: 0.4800 loss_test: 1.3359 acc_test: 0.6900 time: 0.0901s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1219 acc_val: 0.4900 loss_test: 1.3764 acc_test: 0.6920 time: 0.0924s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1436 acc_val: 0.5033 loss_test: 1.4005 acc_test: 0.6900 time: 0.0922s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1259 acc_val: 0.5100 loss_test: 1.4240 acc_test: 0.6930 time: 0.0913s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1638 acc_val: 0.5067 loss_test: 1.4479 acc_test: 0.6930 time: 0.0915s
Optimization Finished!
Total time elapsed: 45.8799s, best testing performance  0.696000, minimun loss  1.009489
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7777 acc_train: 0.3083 loss_val: 1.8005 acc_val: 0.1367 loss_test: 1.6798 acc_test: 0.4320 time: 0.1466s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7803 acc_val: 0.4167 loss_test: 1.1411 acc_test: 0.6650 time: 0.0899s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7507 acc_val: 0.4533 loss_test: 1.1520 acc_test: 0.6830 time: 0.0899s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8800 acc_val: 0.4633 loss_test: 1.2271 acc_test: 0.6840 time: 0.0903s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9567 acc_val: 0.4633 loss_test: 1.2859 acc_test: 0.6900 time: 0.0915s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0335 acc_val: 0.4733 loss_test: 1.3416 acc_test: 0.6890 time: 0.0920s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0583 acc_val: 0.4933 loss_test: 1.3782 acc_test: 0.6890 time: 0.0944s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1032 acc_val: 0.5100 loss_test: 1.4183 acc_test: 0.6970 time: 0.0901s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1673 acc_val: 0.5067 loss_test: 1.4647 acc_test: 0.6960 time: 0.0913s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1839 acc_val: 0.5100 loss_test: 1.4985 acc_test: 0.6990 time: 0.0906s
Optimization Finished!
Total time elapsed: 45.7762s, best testing performance  0.702000, minimun loss  0.993277
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8010 acc_train: 0.1167 loss_val: 1.8082 acc_val: 0.1300 loss_test: 1.6875 acc_test: 0.4880 time: 0.1462s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.7360 acc_val: 0.3867 loss_test: 1.1430 acc_test: 0.6610 time: 0.0959s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8437 acc_val: 0.4167 loss_test: 1.1924 acc_test: 0.6780 time: 0.0904s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.9360 acc_val: 0.4333 loss_test: 1.2425 acc_test: 0.6800 time: 0.0900s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0161 acc_val: 0.4533 loss_test: 1.2978 acc_test: 0.6850 time: 0.0901s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0290 acc_val: 0.4833 loss_test: 1.3291 acc_test: 0.6930 time: 0.0896s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0773 acc_val: 0.5000 loss_test: 1.3672 acc_test: 0.6910 time: 0.0912s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1027 acc_val: 0.4967 loss_test: 1.4002 acc_test: 0.6980 time: 0.0915s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1088 acc_val: 0.5100 loss_test: 1.4230 acc_test: 0.7000 time: 0.0943s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1490 acc_val: 0.5233 loss_test: 1.4566 acc_test: 0.7020 time: 0.0935s
Optimization Finished!
Total time elapsed: 46.1245s, best testing performance  0.704000, minimun loss  1.001513
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7939 acc_train: 0.1000 loss_val: 1.8153 acc_val: 0.1867 loss_test: 1.6653 acc_test: 0.5000 time: 0.1241s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7659 acc_val: 0.3933 loss_test: 1.1424 acc_test: 0.6620 time: 0.0903s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8006 acc_val: 0.4133 loss_test: 1.1671 acc_test: 0.6810 time: 0.0903s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8653 acc_val: 0.4467 loss_test: 1.2203 acc_test: 0.6930 time: 0.0899s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9645 acc_val: 0.4700 loss_test: 1.2834 acc_test: 0.6870 time: 0.0899s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0072 acc_val: 0.4867 loss_test: 1.3309 acc_test: 0.6950 time: 0.0899s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0335 acc_val: 0.4900 loss_test: 1.3642 acc_test: 0.6910 time: 0.0925s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0732 acc_val: 0.5033 loss_test: 1.4047 acc_test: 0.6980 time: 0.0924s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1290 acc_val: 0.5033 loss_test: 1.4494 acc_test: 0.6970 time: 0.0917s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1755 acc_val: 0.4967 loss_test: 1.4883 acc_test: 0.6960 time: 0.0926s
Optimization Finished!
Total time elapsed: 45.7620s, best testing performance  0.701000, minimun loss  0.997895
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7966 acc_train: 0.1500 loss_val: 1.7860 acc_val: 0.2100 loss_test: 1.6867 acc_test: 0.5270 time: 0.1562s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8179 acc_val: 0.3733 loss_test: 1.1623 acc_test: 0.6580 time: 0.0904s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7750 acc_val: 0.4233 loss_test: 1.1679 acc_test: 0.6780 time: 0.0947s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8366 acc_val: 0.4433 loss_test: 1.2079 acc_test: 0.6870 time: 0.0915s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9269 acc_val: 0.4633 loss_test: 1.2646 acc_test: 0.6900 time: 0.0903s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0031 acc_val: 0.4733 loss_test: 1.3110 acc_test: 0.6940 time: 0.1034s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4900 loss_test: 1.3493 acc_test: 0.6960 time: 0.0923s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1015 acc_val: 0.5033 loss_test: 1.3748 acc_test: 0.6930 time: 0.0923s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1760 acc_val: 0.5033 loss_test: 1.4213 acc_test: 0.6910 time: 0.0908s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2236 acc_val: 0.5000 loss_test: 1.4496 acc_test: 0.6920 time: 0.0909s
Optimization Finished!
Total time elapsed: 46.0035s, best testing performance  0.697000, minimun loss  0.999129
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7918 acc_train: 0.1333 loss_val: 1.8055 acc_val: 0.1600 loss_test: 1.6669 acc_test: 0.5170 time: 0.1481s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8037 acc_val: 0.3767 loss_test: 1.1403 acc_test: 0.6600 time: 0.0902s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8027 acc_val: 0.4100 loss_test: 1.1553 acc_test: 0.6750 time: 0.0910s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9440 acc_val: 0.4267 loss_test: 1.2252 acc_test: 0.6840 time: 0.0901s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0201 acc_val: 0.4567 loss_test: 1.2792 acc_test: 0.6860 time: 0.0906s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0673 acc_val: 0.4667 loss_test: 1.3252 acc_test: 0.6930 time: 0.0905s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1181 acc_val: 0.4900 loss_test: 1.3653 acc_test: 0.6920 time: 0.0911s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1229 acc_val: 0.5033 loss_test: 1.3920 acc_test: 0.6950 time: 0.0906s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2000 acc_val: 0.5067 loss_test: 1.4347 acc_test: 0.6930 time: 0.0907s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2324 acc_val: 0.5000 loss_test: 1.4621 acc_test: 0.6960 time: 0.0919s
Optimization Finished!
Total time elapsed: 45.8029s, best testing performance  0.697000, minimun loss  0.995270
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7990 acc_train: 0.1417 loss_val: 1.7854 acc_val: 0.1600 loss_test: 1.6623 acc_test: 0.4690 time: 0.1492s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.9518 acc_val: 0.3533 loss_test: 1.1947 acc_test: 0.6560 time: 0.0944s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.9894 acc_val: 0.4000 loss_test: 1.2172 acc_test: 0.6700 time: 0.0906s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 2.0144 acc_val: 0.4200 loss_test: 1.2480 acc_test: 0.6770 time: 0.0913s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0650 acc_val: 0.4500 loss_test: 1.2949 acc_test: 0.6880 time: 0.0898s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0869 acc_val: 0.4633 loss_test: 1.3281 acc_test: 0.6890 time: 0.0896s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1201 acc_val: 0.4800 loss_test: 1.3616 acc_test: 0.6900 time: 0.0934s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1428 acc_val: 0.5000 loss_test: 1.3991 acc_test: 0.6960 time: 0.0910s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1481 acc_val: 0.5067 loss_test: 1.4216 acc_test: 0.6960 time: 0.0901s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1897 acc_val: 0.5100 loss_test: 1.4584 acc_test: 0.6970 time: 0.0911s
Optimization Finished!
Total time elapsed: 45.8014s, best testing performance  0.700000, minimun loss  0.997006
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8122 acc_train: 0.0917 loss_val: 1.8417 acc_val: 0.0533 loss_test: 1.6863 acc_test: 0.3680 time: 0.1295s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 2.0735 acc_val: 0.3233 loss_test: 1.3061 acc_test: 0.6350 time: 0.0937s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8955 acc_val: 0.4033 loss_test: 1.2595 acc_test: 0.6650 time: 0.0940s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8536 acc_val: 0.4700 loss_test: 1.2680 acc_test: 0.6840 time: 0.0902s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9327 acc_val: 0.4767 loss_test: 1.3173 acc_test: 0.6890 time: 0.0899s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0070 acc_val: 0.4833 loss_test: 1.3602 acc_test: 0.6930 time: 0.0902s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0523 acc_val: 0.5033 loss_test: 1.3929 acc_test: 0.6960 time: 0.0902s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0456 acc_val: 0.5100 loss_test: 1.4114 acc_test: 0.7000 time: 0.0923s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1107 acc_val: 0.5167 loss_test: 1.4454 acc_test: 0.6940 time: 0.0922s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1445 acc_val: 0.5100 loss_test: 1.4740 acc_test: 0.6930 time: 0.0921s
Optimization Finished!
Total time elapsed: 45.9545s, best testing performance  0.702000, minimun loss  1.067458
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7997 acc_train: 0.2000 loss_val: 1.7908 acc_val: 0.1633 loss_test: 1.7048 acc_test: 0.4730 time: 0.1244s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9019 acc_val: 0.3367 loss_test: 1.2113 acc_test: 0.6430 time: 0.0955s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7799 acc_val: 0.4100 loss_test: 1.1846 acc_test: 0.6670 time: 0.0904s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.7817 acc_val: 0.4367 loss_test: 1.2059 acc_test: 0.6730 time: 0.0912s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9277 acc_val: 0.4600 loss_test: 1.2835 acc_test: 0.6870 time: 0.0922s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0502 acc_val: 0.4767 loss_test: 1.3478 acc_test: 0.6920 time: 0.0901s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0804 acc_val: 0.4800 loss_test: 1.3790 acc_test: 0.6910 time: 0.0926s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1094 acc_val: 0.4967 loss_test: 1.4076 acc_test: 0.6960 time: 0.0916s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1645 acc_val: 0.5000 loss_test: 1.4440 acc_test: 0.6940 time: 0.0911s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1937 acc_val: 0.5133 loss_test: 1.4684 acc_test: 0.6940 time: 0.0969s
Optimization Finished!
Total time elapsed: 45.8541s, best testing performance  0.699000, minimun loss  0.983657
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7940 acc_train: 0.1750 loss_val: 1.7849 acc_val: 0.1133 loss_test: 1.7026 acc_test: 0.3980 time: 0.1236s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9670 acc_val: 0.3400 loss_test: 1.2286 acc_test: 0.6510 time: 0.0898s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8176 acc_val: 0.4367 loss_test: 1.1995 acc_test: 0.6690 time: 0.0899s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9888 acc_val: 0.4400 loss_test: 1.2793 acc_test: 0.6810 time: 0.0913s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0686 acc_val: 0.4567 loss_test: 1.3248 acc_test: 0.6860 time: 0.0916s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0851 acc_val: 0.4633 loss_test: 1.3526 acc_test: 0.6940 time: 0.0899s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1500 acc_val: 0.4767 loss_test: 1.3901 acc_test: 0.6940 time: 0.0904s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1353 acc_val: 0.4967 loss_test: 1.4087 acc_test: 0.6960 time: 0.1045s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2032 acc_val: 0.4967 loss_test: 1.4500 acc_test: 0.6990 time: 0.0913s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2295 acc_val: 0.5033 loss_test: 1.4742 acc_test: 0.6980 time: 0.0917s
Optimization Finished!
Total time elapsed: 45.7439s, best testing performance  0.701000, minimun loss  1.042765
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7936 acc_train: 0.1583 loss_val: 1.7848 acc_val: 0.1900 loss_test: 1.7004 acc_test: 0.4730 time: 0.1179s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8474 acc_val: 0.3933 loss_test: 1.1921 acc_test: 0.6650 time: 0.0907s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8803 acc_val: 0.4200 loss_test: 1.2083 acc_test: 0.6630 time: 0.0918s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9519 acc_val: 0.4433 loss_test: 1.2581 acc_test: 0.6830 time: 0.0910s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0250 acc_val: 0.4600 loss_test: 1.3111 acc_test: 0.6900 time: 0.0906s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0551 acc_val: 0.4800 loss_test: 1.3506 acc_test: 0.6890 time: 0.0897s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1041 acc_val: 0.5000 loss_test: 1.3833 acc_test: 0.6940 time: 0.0912s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1460 acc_val: 0.5033 loss_test: 1.4171 acc_test: 0.6950 time: 0.0940s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1519 acc_val: 0.5100 loss_test: 1.4380 acc_test: 0.6940 time: 0.0914s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2158 acc_val: 0.5133 loss_test: 1.4740 acc_test: 0.6960 time: 0.0902s
Optimization Finished!
Total time elapsed: 45.9660s, best testing performance  0.699000, minimun loss  1.031949
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7819 acc_train: 0.2417 loss_val: 1.8472 acc_val: 0.1067 loss_test: 1.6874 acc_test: 0.4260 time: 0.1236s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.9931 acc_val: 0.3200 loss_test: 1.2626 acc_test: 0.6380 time: 0.0906s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7881 acc_val: 0.4300 loss_test: 1.2143 acc_test: 0.6680 time: 0.0911s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8223 acc_val: 0.4667 loss_test: 1.2514 acc_test: 0.6800 time: 0.0906s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9255 acc_val: 0.4833 loss_test: 1.3086 acc_test: 0.6910 time: 0.0901s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0197 acc_val: 0.5033 loss_test: 1.3541 acc_test: 0.6930 time: 0.0910s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0546 acc_val: 0.5100 loss_test: 1.3883 acc_test: 0.6930 time: 0.0900s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1053 acc_val: 0.5100 loss_test: 1.4228 acc_test: 0.6940 time: 0.0944s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1310 acc_val: 0.5200 loss_test: 1.4440 acc_test: 0.6940 time: 0.0916s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1434 acc_val: 0.5200 loss_test: 1.4634 acc_test: 0.6980 time: 0.0904s
Optimization Finished!
Total time elapsed: 45.8178s, best testing performance  0.703000, minimun loss  1.028240
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7874 acc_train: 0.1833 loss_val: 1.8117 acc_val: 0.1000 loss_test: 1.6597 acc_test: 0.4610 time: 0.1283s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8401 acc_val: 0.4167 loss_test: 1.1672 acc_test: 0.6740 time: 0.0903s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8431 acc_val: 0.4533 loss_test: 1.1944 acc_test: 0.6870 time: 0.0914s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9012 acc_val: 0.4467 loss_test: 1.2416 acc_test: 0.6840 time: 0.0901s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9934 acc_val: 0.4800 loss_test: 1.2995 acc_test: 0.6940 time: 0.0909s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9919 acc_val: 0.4933 loss_test: 1.3254 acc_test: 0.6950 time: 0.0902s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0237 acc_val: 0.5033 loss_test: 1.3585 acc_test: 0.6950 time: 0.0905s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0644 acc_val: 0.5067 loss_test: 1.3913 acc_test: 0.6950 time: 0.0908s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0937 acc_val: 0.5133 loss_test: 1.4130 acc_test: 0.6960 time: 0.0911s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0946 acc_val: 0.5267 loss_test: 1.4370 acc_test: 0.6950 time: 0.0913s
Optimization Finished!
Total time elapsed: 45.9199s, best testing performance  0.700000, minimun loss  0.978705
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7797 acc_train: 0.2333 loss_val: 1.7800 acc_val: 0.1467 loss_test: 1.6385 acc_test: 0.5620 time: 0.1243s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.6830 acc_val: 0.4133 loss_test: 1.1525 acc_test: 0.6660 time: 0.0899s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7112 acc_val: 0.4567 loss_test: 1.1725 acc_test: 0.6830 time: 0.0916s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8033 acc_val: 0.4667 loss_test: 1.2312 acc_test: 0.6860 time: 0.0936s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9467 acc_val: 0.4700 loss_test: 1.3002 acc_test: 0.6940 time: 0.0897s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0453 acc_val: 0.4800 loss_test: 1.3471 acc_test: 0.6950 time: 0.0922s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0977 acc_val: 0.4900 loss_test: 1.3864 acc_test: 0.6950 time: 0.0914s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1637 acc_val: 0.5000 loss_test: 1.4195 acc_test: 0.6940 time: 0.0906s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1617 acc_val: 0.5033 loss_test: 1.4417 acc_test: 0.6950 time: 0.0903s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1759 acc_val: 0.5133 loss_test: 1.4611 acc_test: 0.7020 time: 0.0907s
Optimization Finished!
Total time elapsed: 45.7326s, best testing performance  0.702000, minimun loss  0.976603
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7944 acc_train: 0.2083 loss_val: 1.8276 acc_val: 0.0633 loss_test: 1.6648 acc_test: 0.3450 time: 0.1254s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8562 acc_val: 0.3967 loss_test: 1.1746 acc_test: 0.6580 time: 0.0908s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8286 acc_val: 0.4467 loss_test: 1.1904 acc_test: 0.6840 time: 0.0897s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8905 acc_val: 0.4533 loss_test: 1.2457 acc_test: 0.6840 time: 0.0899s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0419 acc_val: 0.4767 loss_test: 1.3157 acc_test: 0.6880 time: 0.0898s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0750 acc_val: 0.4800 loss_test: 1.3468 acc_test: 0.6950 time: 0.0901s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1850 acc_val: 0.4967 loss_test: 1.3957 acc_test: 0.6910 time: 0.0951s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1714 acc_val: 0.5100 loss_test: 1.4190 acc_test: 0.6900 time: 0.0916s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2093 acc_val: 0.5133 loss_test: 1.4504 acc_test: 0.6880 time: 0.0927s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2562 acc_val: 0.5100 loss_test: 1.4853 acc_test: 0.6900 time: 0.0908s
Optimization Finished!
Total time elapsed: 45.8002s, best testing performance  0.698000, minimun loss  0.967838
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7888 acc_train: 0.1667 loss_val: 1.7971 acc_val: 0.1367 loss_test: 1.6777 acc_test: 0.4040 time: 0.1307s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7523 acc_val: 0.4133 loss_test: 1.1851 acc_test: 0.6610 time: 0.0902s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7077 acc_val: 0.4633 loss_test: 1.1857 acc_test: 0.6810 time: 0.0899s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8531 acc_val: 0.4633 loss_test: 1.2590 acc_test: 0.6760 time: 0.0910s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0373 acc_val: 0.4533 loss_test: 1.3340 acc_test: 0.6870 time: 0.0901s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0489 acc_val: 0.4833 loss_test: 1.3520 acc_test: 0.6950 time: 0.0901s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0503 acc_val: 0.5000 loss_test: 1.3654 acc_test: 0.6940 time: 0.0920s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1247 acc_val: 0.5033 loss_test: 1.4053 acc_test: 0.6920 time: 0.0915s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1655 acc_val: 0.5067 loss_test: 1.4311 acc_test: 0.6910 time: 0.0910s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2059 acc_val: 0.5067 loss_test: 1.4590 acc_test: 0.6940 time: 0.0913s
Optimization Finished!
Total time elapsed: 46.0364s, best testing performance  0.699000, minimun loss  0.996258
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7699 acc_train: 0.2250 loss_val: 1.7535 acc_val: 0.2600 loss_test: 1.6570 acc_test: 0.5790 time: 0.1376s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7233 acc_val: 0.4467 loss_test: 1.1539 acc_test: 0.6760 time: 0.0906s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7640 acc_val: 0.4667 loss_test: 1.1835 acc_test: 0.6880 time: 0.0896s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9293 acc_val: 0.4567 loss_test: 1.2634 acc_test: 0.6880 time: 0.0901s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9904 acc_val: 0.4767 loss_test: 1.3091 acc_test: 0.6920 time: 0.0903s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0319 acc_val: 0.4933 loss_test: 1.3495 acc_test: 0.6940 time: 0.0899s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0645 acc_val: 0.5033 loss_test: 1.3917 acc_test: 0.6960 time: 0.0944s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0815 acc_val: 0.5067 loss_test: 1.4142 acc_test: 0.6940 time: 0.0917s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1350 acc_val: 0.5067 loss_test: 1.4485 acc_test: 0.6960 time: 0.0914s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1543 acc_val: 0.5000 loss_test: 1.4823 acc_test: 0.6980 time: 0.0908s
Optimization Finished!
Total time elapsed: 45.8681s, best testing performance  0.704000, minimun loss  0.980780
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8118 acc_train: 0.1333 loss_val: 1.8259 acc_val: 0.0567 loss_test: 1.6830 acc_test: 0.3430 time: 0.1252s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7619 acc_val: 0.4233 loss_test: 1.1640 acc_test: 0.6560 time: 0.0908s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8263 acc_val: 0.4533 loss_test: 1.2015 acc_test: 0.6800 time: 0.1072s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9355 acc_val: 0.4500 loss_test: 1.2610 acc_test: 0.6850 time: 0.0896s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0224 acc_val: 0.4633 loss_test: 1.3114 acc_test: 0.6880 time: 0.0905s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0686 acc_val: 0.4767 loss_test: 1.3428 acc_test: 0.6890 time: 0.0912s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0763 acc_val: 0.4900 loss_test: 1.3644 acc_test: 0.6920 time: 0.0913s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1399 acc_val: 0.5000 loss_test: 1.4040 acc_test: 0.6910 time: 0.0910s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1750 acc_val: 0.5067 loss_test: 1.4319 acc_test: 0.6930 time: 0.0913s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2210 acc_val: 0.5033 loss_test: 1.4594 acc_test: 0.6920 time: 0.0908s
Optimization Finished!
Total time elapsed: 45.7776s, best testing performance  0.697000, minimun loss  0.998157
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7812 acc_train: 0.1917 loss_val: 1.7716 acc_val: 0.2167 loss_test: 1.6681 acc_test: 0.5170 time: 0.1351s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7299 acc_val: 0.4467 loss_test: 1.1577 acc_test: 0.6600 time: 0.0904s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7832 acc_val: 0.4600 loss_test: 1.1934 acc_test: 0.6800 time: 0.0898s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8707 acc_val: 0.4667 loss_test: 1.2492 acc_test: 0.6860 time: 0.0902s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9724 acc_val: 0.4733 loss_test: 1.3032 acc_test: 0.6890 time: 0.0911s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0491 acc_val: 0.4800 loss_test: 1.3461 acc_test: 0.6900 time: 0.0900s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1039 acc_val: 0.4967 loss_test: 1.3859 acc_test: 0.6890 time: 0.0911s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1890 acc_val: 0.5000 loss_test: 1.4282 acc_test: 0.6940 time: 0.0910s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2444 acc_val: 0.5000 loss_test: 1.4661 acc_test: 0.6940 time: 0.0917s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2989 acc_val: 0.5000 loss_test: 1.5023 acc_test: 0.6920 time: 0.0941s
Optimization Finished!
Total time elapsed: 45.9566s, best testing performance  0.699000, minimun loss  0.999188
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8034 acc_train: 0.1500 loss_val: 1.8086 acc_val: 0.1033 loss_test: 1.6765 acc_test: 0.4180 time: 0.1244s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7746 acc_val: 0.4167 loss_test: 1.1784 acc_test: 0.6590 time: 0.0903s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8153 acc_val: 0.4400 loss_test: 1.1957 acc_test: 0.6810 time: 0.0904s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9145 acc_val: 0.4467 loss_test: 1.2510 acc_test: 0.6880 time: 0.0916s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0073 acc_val: 0.4633 loss_test: 1.3018 acc_test: 0.6870 time: 0.0925s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4900 loss_test: 1.3388 acc_test: 0.6940 time: 0.0916s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0349 acc_val: 0.5000 loss_test: 1.3677 acc_test: 0.6950 time: 0.0912s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1101 acc_val: 0.5033 loss_test: 1.4120 acc_test: 0.6980 time: 0.0909s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1614 acc_val: 0.5100 loss_test: 1.4453 acc_test: 0.7030 time: 0.0915s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1750 acc_val: 0.5067 loss_test: 1.4780 acc_test: 0.7010 time: 0.1104s
Optimization Finished!
Total time elapsed: 46.0067s, best testing performance  0.704000, minimun loss  1.008785
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7914 acc_train: 0.1917 loss_val: 1.7923 acc_val: 0.1667 loss_test: 1.6767 acc_test: 0.5460 time: 0.1212s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.7195 acc_val: 0.4333 loss_test: 1.1381 acc_test: 0.6610 time: 0.0899s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7942 acc_val: 0.4633 loss_test: 1.1751 acc_test: 0.6800 time: 0.0920s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8994 acc_val: 0.4567 loss_test: 1.2419 acc_test: 0.6870 time: 0.0903s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9889 acc_val: 0.4700 loss_test: 1.2916 acc_test: 0.6920 time: 0.0904s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0694 acc_val: 0.4867 loss_test: 1.3414 acc_test: 0.6950 time: 0.0899s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1009 acc_val: 0.4967 loss_test: 1.3773 acc_test: 0.6910 time: 0.0909s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1343 acc_val: 0.5000 loss_test: 1.4160 acc_test: 0.6910 time: 0.0906s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1612 acc_val: 0.5100 loss_test: 1.4379 acc_test: 0.6980 time: 0.0903s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1771 acc_val: 0.5100 loss_test: 1.4665 acc_test: 0.6960 time: 0.0917s
Optimization Finished!
Total time elapsed: 45.7012s, best testing performance  0.702000, minimun loss  0.991242
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.1417 loss_val: 1.7808 acc_val: 0.2267 loss_test: 1.6755 acc_test: 0.5190 time: 0.1240s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8065 acc_val: 0.3967 loss_test: 1.1920 acc_test: 0.6540 time: 0.0901s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8486 acc_val: 0.4333 loss_test: 1.2203 acc_test: 0.6640 time: 0.0918s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9422 acc_val: 0.4400 loss_test: 1.2689 acc_test: 0.6810 time: 0.0921s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9894 acc_val: 0.4667 loss_test: 1.3058 acc_test: 0.6850 time: 0.0905s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0318 acc_val: 0.4767 loss_test: 1.3393 acc_test: 0.6870 time: 0.0908s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0312 acc_val: 0.5033 loss_test: 1.3665 acc_test: 0.6920 time: 0.0921s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0926 acc_val: 0.5100 loss_test: 1.4064 acc_test: 0.6940 time: 0.0907s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1372 acc_val: 0.5067 loss_test: 1.4335 acc_test: 0.7000 time: 0.0903s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1564 acc_val: 0.5067 loss_test: 1.4638 acc_test: 0.6970 time: 0.0918s
Optimization Finished!
Total time elapsed: 45.8208s, best testing performance  0.700000, minimun loss  1.005186
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7965 acc_train: 0.1417 loss_val: 1.7905 acc_val: 0.2367 loss_test: 1.6665 acc_test: 0.5610 time: 0.1262s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8240 acc_val: 0.4033 loss_test: 1.1848 acc_test: 0.6540 time: 0.0907s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7487 acc_val: 0.4733 loss_test: 1.1833 acc_test: 0.6830 time: 0.0920s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.7958 acc_val: 0.4933 loss_test: 1.2334 acc_test: 0.6780 time: 0.0914s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9056 acc_val: 0.4800 loss_test: 1.2964 acc_test: 0.6890 time: 0.0910s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0145 acc_val: 0.4700 loss_test: 1.3379 acc_test: 0.6930 time: 0.0907s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0888 acc_val: 0.4833 loss_test: 1.3723 acc_test: 0.6920 time: 0.0907s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.5000 loss_test: 1.4076 acc_test: 0.6920 time: 0.0916s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2505 acc_val: 0.5000 loss_test: 1.4494 acc_test: 0.6930 time: 0.0910s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2946 acc_val: 0.4967 loss_test: 1.4786 acc_test: 0.6950 time: 0.0921s
Optimization Finished!
Total time elapsed: 45.8544s, best testing performance  0.701000, minimun loss  0.977569
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7979 acc_train: 0.1583 loss_val: 1.8061 acc_val: 0.2067 loss_test: 1.6646 acc_test: 0.5140 time: 0.1273s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8807 acc_val: 0.4000 loss_test: 1.2150 acc_test: 0.6550 time: 0.1016s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8809 acc_val: 0.4433 loss_test: 1.2271 acc_test: 0.6750 time: 0.0916s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9636 acc_val: 0.4667 loss_test: 1.2817 acc_test: 0.6770 time: 0.0922s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4567 loss_test: 1.3404 acc_test: 0.6920 time: 0.0901s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1298 acc_val: 0.4733 loss_test: 1.3715 acc_test: 0.6930 time: 0.0906s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1701 acc_val: 0.5033 loss_test: 1.3984 acc_test: 0.6900 time: 0.0909s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1533 acc_val: 0.5100 loss_test: 1.4173 acc_test: 0.7000 time: 0.0909s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2078 acc_val: 0.5133 loss_test: 1.4531 acc_test: 0.6990 time: 0.0939s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1802 acc_val: 0.5067 loss_test: 1.4597 acc_test: 0.7010 time: 0.0915s
Optimization Finished!
Total time elapsed: 45.7433s, best testing performance  0.702000, minimun loss  0.976704
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7964 acc_train: 0.1583 loss_val: 1.7962 acc_val: 0.2067 loss_test: 1.6728 acc_test: 0.5020 time: 0.1328s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.6796 acc_val: 0.4567 loss_test: 1.1513 acc_test: 0.6740 time: 0.0900s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7224 acc_val: 0.4933 loss_test: 1.1809 acc_test: 0.6800 time: 0.0909s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8772 acc_val: 0.4833 loss_test: 1.2577 acc_test: 0.6820 time: 0.0903s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0172 acc_val: 0.4667 loss_test: 1.3139 acc_test: 0.6940 time: 0.0898s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0609 acc_val: 0.4733 loss_test: 1.3497 acc_test: 0.6920 time: 0.0945s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0986 acc_val: 0.5033 loss_test: 1.3832 acc_test: 0.6930 time: 0.0913s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1004 acc_val: 0.5067 loss_test: 1.4148 acc_test: 0.6980 time: 0.0916s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1641 acc_val: 0.5067 loss_test: 1.4435 acc_test: 0.6940 time: 0.0913s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1849 acc_val: 0.5100 loss_test: 1.4707 acc_test: 0.6940 time: 0.0912s
Optimization Finished!
Total time elapsed: 45.8580s, best testing performance  0.700000, minimun loss  0.975380
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.2083 loss_val: 1.7765 acc_val: 0.2300 loss_test: 1.6277 acc_test: 0.5620 time: 0.1192s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7988 acc_val: 0.4233 loss_test: 1.1655 acc_test: 0.6580 time: 0.0901s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8344 acc_val: 0.4700 loss_test: 1.1988 acc_test: 0.6770 time: 0.0903s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9642 acc_val: 0.4733 loss_test: 1.2720 acc_test: 0.6860 time: 0.0897s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0808 acc_val: 0.4500 loss_test: 1.3322 acc_test: 0.6870 time: 0.0908s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1290 acc_val: 0.4567 loss_test: 1.3579 acc_test: 0.6930 time: 0.0915s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1480 acc_val: 0.4733 loss_test: 1.3875 acc_test: 0.6920 time: 0.0948s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1501 acc_val: 0.5033 loss_test: 1.4156 acc_test: 0.6940 time: 0.0913s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1310 acc_val: 0.5000 loss_test: 1.4310 acc_test: 0.6960 time: 0.0914s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1924 acc_val: 0.5000 loss_test: 1.4665 acc_test: 0.7000 time: 0.0919s
Optimization Finished!
Total time elapsed: 45.8435s, best testing performance  0.700000, minimun loss  0.966062
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8004 acc_train: 0.1250 loss_val: 1.7979 acc_val: 0.1967 loss_test: 1.6694 acc_test: 0.4540 time: 0.1169s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8153 acc_val: 0.4000 loss_test: 1.1907 acc_test: 0.6590 time: 0.0898s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8016 acc_val: 0.4567 loss_test: 1.2131 acc_test: 0.6800 time: 0.0903s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9652 acc_val: 0.4667 loss_test: 1.2993 acc_test: 0.6730 time: 0.0904s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1072 acc_val: 0.4700 loss_test: 1.3597 acc_test: 0.6860 time: 0.0915s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1015 acc_val: 0.4767 loss_test: 1.3834 acc_test: 0.6900 time: 0.0898s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1348 acc_val: 0.5100 loss_test: 1.4246 acc_test: 0.6910 time: 0.0911s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1761 acc_val: 0.5133 loss_test: 1.4710 acc_test: 0.6920 time: 0.0908s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2254 acc_val: 0.5133 loss_test: 1.5096 acc_test: 0.6960 time: 0.0919s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2808 acc_val: 0.5167 loss_test: 1.5520 acc_test: 0.6990 time: 0.0910s
Optimization Finished!
Total time elapsed: 45.8525s, best testing performance  0.700000, minimun loss  0.987408
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7966 acc_train: 0.1333 loss_val: 1.8083 acc_val: 0.1333 loss_test: 1.6744 acc_test: 0.5420 time: 0.1679s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.7419 acc_val: 0.4267 loss_test: 1.1419 acc_test: 0.6640 time: 0.0903s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.9247 acc_val: 0.4200 loss_test: 1.2137 acc_test: 0.6680 time: 0.0946s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9732 acc_val: 0.4400 loss_test: 1.2487 acc_test: 0.6800 time: 0.0900s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0307 acc_val: 0.4600 loss_test: 1.2870 acc_test: 0.6890 time: 0.0913s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0521 acc_val: 0.4733 loss_test: 1.3245 acc_test: 0.6850 time: 0.0904s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1040 acc_val: 0.4833 loss_test: 1.3633 acc_test: 0.6900 time: 0.0912s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1481 acc_val: 0.5033 loss_test: 1.4066 acc_test: 0.6930 time: 0.0929s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1913 acc_val: 0.5133 loss_test: 1.4380 acc_test: 0.6920 time: 0.0919s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2380 acc_val: 0.5067 loss_test: 1.4749 acc_test: 0.6910 time: 0.0963s
Optimization Finished!
Total time elapsed: 46.0088s, best testing performance  0.697000, minimun loss  0.987544
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7954 acc_train: 0.1583 loss_val: 1.7879 acc_val: 0.2433 loss_test: 1.6881 acc_test: 0.5170 time: 0.1601s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.6759 acc_val: 0.4300 loss_test: 1.1223 acc_test: 0.6650 time: 0.0910s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8716 acc_val: 0.4333 loss_test: 1.2004 acc_test: 0.6730 time: 0.0914s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.4467 loss_test: 1.2561 acc_test: 0.6800 time: 0.0906s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0528 acc_val: 0.4467 loss_test: 1.3017 acc_test: 0.6860 time: 0.0906s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0605 acc_val: 0.4600 loss_test: 1.3302 acc_test: 0.6870 time: 0.0908s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1003 acc_val: 0.4867 loss_test: 1.3673 acc_test: 0.6920 time: 0.0919s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1240 acc_val: 0.4933 loss_test: 1.4010 acc_test: 0.6930 time: 0.0911s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1770 acc_val: 0.5067 loss_test: 1.4402 acc_test: 0.6960 time: 0.0905s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1963 acc_val: 0.5033 loss_test: 1.4751 acc_test: 0.6980 time: 0.0921s
Optimization Finished!
Total time elapsed: 46.1290s, best testing performance  0.699000, minimun loss  0.986651
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8099 acc_train: 0.1167 loss_val: 1.7915 acc_val: 0.2033 loss_test: 1.7023 acc_test: 0.4710 time: 0.1301s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.8876 acc_val: 0.3533 loss_test: 1.2036 acc_test: 0.6380 time: 0.0903s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.9102 acc_val: 0.4333 loss_test: 1.2163 acc_test: 0.6660 time: 0.0986s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9415 acc_val: 0.4533 loss_test: 1.2452 acc_test: 0.6850 time: 0.0929s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9813 acc_val: 0.4667 loss_test: 1.2840 acc_test: 0.6890 time: 0.0905s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0078 acc_val: 0.4833 loss_test: 1.3180 acc_test: 0.6890 time: 0.0908s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0541 acc_val: 0.5000 loss_test: 1.3571 acc_test: 0.6930 time: 0.0902s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0476 acc_val: 0.5133 loss_test: 1.3782 acc_test: 0.7000 time: 0.0900s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1217 acc_val: 0.5200 loss_test: 1.4186 acc_test: 0.7000 time: 0.1038s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1354 acc_val: 0.5133 loss_test: 1.4483 acc_test: 0.7010 time: 0.0913s
Optimization Finished!
Total time elapsed: 45.8175s, best testing performance  0.705000, minimun loss  1.010440
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8047 acc_train: 0.1083 loss_val: 1.7911 acc_val: 0.1333 loss_test: 1.6707 acc_test: 0.5320 time: 0.1389s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8584 acc_val: 0.4000 loss_test: 1.1914 acc_test: 0.6460 time: 0.0912s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.9341 acc_val: 0.4233 loss_test: 1.2253 acc_test: 0.6650 time: 0.0902s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.9936 acc_val: 0.4400 loss_test: 1.2630 acc_test: 0.6810 time: 0.0952s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0406 acc_val: 0.4500 loss_test: 1.2968 acc_test: 0.6850 time: 0.0911s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0786 acc_val: 0.4567 loss_test: 1.3309 acc_test: 0.6860 time: 0.0909s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0971 acc_val: 0.4867 loss_test: 1.3594 acc_test: 0.6860 time: 0.0904s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1302 acc_val: 0.4867 loss_test: 1.3904 acc_test: 0.6880 time: 0.0912s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1807 acc_val: 0.4900 loss_test: 1.4276 acc_test: 0.6900 time: 0.0914s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1946 acc_val: 0.4900 loss_test: 1.4514 acc_test: 0.6880 time: 0.0932s
Optimization Finished!
Total time elapsed: 45.8229s, best testing performance  0.693000, minimun loss  1.010185
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8015 acc_train: 0.1000 loss_val: 1.8161 acc_val: 0.0633 loss_test: 1.6772 acc_test: 0.3830 time: 0.1457s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7353 acc_val: 0.3933 loss_test: 1.1805 acc_test: 0.6430 time: 0.0900s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7655 acc_val: 0.4467 loss_test: 1.2030 acc_test: 0.6670 time: 0.0905s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8622 acc_val: 0.4500 loss_test: 1.2518 acc_test: 0.6830 time: 0.0906s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9275 acc_val: 0.4733 loss_test: 1.2834 acc_test: 0.6930 time: 0.0916s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9671 acc_val: 0.4733 loss_test: 1.3156 acc_test: 0.6950 time: 0.0903s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0187 acc_val: 0.4933 loss_test: 1.3516 acc_test: 0.6960 time: 0.0916s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0583 acc_val: 0.5067 loss_test: 1.3848 acc_test: 0.6940 time: 0.0915s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1089 acc_val: 0.5100 loss_test: 1.4156 acc_test: 0.6960 time: 0.0902s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1374 acc_val: 0.5133 loss_test: 1.4427 acc_test: 0.6960 time: 0.0930s
Optimization Finished!
Total time elapsed: 46.0713s, best testing performance  0.699000, minimun loss  1.026035
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8084 acc_train: 0.1250 loss_val: 1.8169 acc_val: 0.1433 loss_test: 1.7034 acc_test: 0.4250 time: 0.1261s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8468 acc_val: 0.3767 loss_test: 1.1893 acc_test: 0.6540 time: 0.0900s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8268 acc_val: 0.4400 loss_test: 1.2063 acc_test: 0.6740 time: 0.0910s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8427 acc_val: 0.4533 loss_test: 1.2387 acc_test: 0.6930 time: 0.0912s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9563 acc_val: 0.4667 loss_test: 1.2924 acc_test: 0.6890 time: 0.0904s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9878 acc_val: 0.4833 loss_test: 1.3253 acc_test: 0.6900 time: 0.0924s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0259 acc_val: 0.5000 loss_test: 1.3604 acc_test: 0.6920 time: 0.0905s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0827 acc_val: 0.5167 loss_test: 1.4022 acc_test: 0.6960 time: 0.0907s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1295 acc_val: 0.5067 loss_test: 1.4361 acc_test: 0.6940 time: 0.0908s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1729 acc_val: 0.5167 loss_test: 1.4659 acc_test: 0.6950 time: 0.0919s
Optimization Finished!
Total time elapsed: 45.8097s, best testing performance  0.703000, minimun loss  1.004584
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7959 acc_train: 0.1917 loss_val: 1.8032 acc_val: 0.1500 loss_test: 1.6751 acc_test: 0.5230 time: 0.1468s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7639 acc_val: 0.3933 loss_test: 1.1882 acc_test: 0.6510 time: 0.0902s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7354 acc_val: 0.4567 loss_test: 1.1990 acc_test: 0.6700 time: 0.0899s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8132 acc_val: 0.4800 loss_test: 1.2460 acc_test: 0.6810 time: 0.0906s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9321 acc_val: 0.4767 loss_test: 1.2969 acc_test: 0.6900 time: 0.0916s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0196 acc_val: 0.4833 loss_test: 1.3423 acc_test: 0.6980 time: 0.0925s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0723 acc_val: 0.4867 loss_test: 1.3830 acc_test: 0.6940 time: 0.1030s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1154 acc_val: 0.4900 loss_test: 1.4141 acc_test: 0.6950 time: 0.0908s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1551 acc_val: 0.5033 loss_test: 1.4470 acc_test: 0.6940 time: 0.0922s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2100 acc_val: 0.5033 loss_test: 1.4808 acc_test: 0.6960 time: 0.0909s
Optimization Finished!
Total time elapsed: 45.9248s, best testing performance  0.699000, minimun loss  1.000316
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8099 acc_train: 0.1000 loss_val: 1.8297 acc_val: 0.1433 loss_test: 1.6798 acc_test: 0.4760 time: 0.1323s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.7311 acc_val: 0.4067 loss_test: 1.1462 acc_test: 0.6570 time: 0.0903s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8598 acc_val: 0.4267 loss_test: 1.2069 acc_test: 0.6610 time: 0.0905s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8871 acc_val: 0.4500 loss_test: 1.2376 acc_test: 0.6780 time: 0.0904s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9610 acc_val: 0.4633 loss_test: 1.2753 acc_test: 0.6880 time: 0.0906s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0182 acc_val: 0.4667 loss_test: 1.3116 acc_test: 0.6920 time: 0.0904s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0485 acc_val: 0.4867 loss_test: 1.3435 acc_test: 0.6950 time: 0.0918s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1187 acc_val: 0.4967 loss_test: 1.3832 acc_test: 0.6920 time: 0.0923s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1327 acc_val: 0.4967 loss_test: 1.4118 acc_test: 0.6920 time: 0.0911s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1777 acc_val: 0.5033 loss_test: 1.4413 acc_test: 0.6960 time: 0.0922s
Optimization Finished!
Total time elapsed: 45.9487s, best testing performance  0.701000, minimun loss  0.986221
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.1833 loss_val: 1.8012 acc_val: 0.1867 loss_test: 1.6753 acc_test: 0.4800 time: 0.1377s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8244 acc_val: 0.3967 loss_test: 1.1697 acc_test: 0.6570 time: 0.0904s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8102 acc_val: 0.4333 loss_test: 1.1924 acc_test: 0.6730 time: 0.1040s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8535 acc_val: 0.4567 loss_test: 1.2297 acc_test: 0.6840 time: 0.0910s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9288 acc_val: 0.4600 loss_test: 1.2790 acc_test: 0.6890 time: 0.0916s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0058 acc_val: 0.4733 loss_test: 1.3283 acc_test: 0.6930 time: 0.0914s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0246 acc_val: 0.4933 loss_test: 1.3645 acc_test: 0.6930 time: 0.0966s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.4933 loss_test: 1.4075 acc_test: 0.7000 time: 0.0912s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1403 acc_val: 0.5100 loss_test: 1.4428 acc_test: 0.6980 time: 0.1048s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1827 acc_val: 0.5100 loss_test: 1.4753 acc_test: 0.6990 time: 0.0914s
Optimization Finished!
Total time elapsed: 45.9574s, best testing performance  0.703000, minimun loss  1.001357
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8061 acc_train: 0.0833 loss_val: 1.7926 acc_val: 0.2167 loss_test: 1.7047 acc_test: 0.4130 time: 0.1312s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8888 acc_val: 0.3767 loss_test: 1.2182 acc_test: 0.6500 time: 0.0918s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8264 acc_val: 0.4400 loss_test: 1.2175 acc_test: 0.6690 time: 0.0894s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8755 acc_val: 0.4600 loss_test: 1.2565 acc_test: 0.6800 time: 0.0904s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9324 acc_val: 0.4767 loss_test: 1.2998 acc_test: 0.6920 time: 0.0904s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9707 acc_val: 0.4900 loss_test: 1.3430 acc_test: 0.6910 time: 0.0900s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0425 acc_val: 0.4933 loss_test: 1.3916 acc_test: 0.6980 time: 0.0973s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0812 acc_val: 0.5100 loss_test: 1.4360 acc_test: 0.7010 time: 0.0904s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1549 acc_val: 0.5000 loss_test: 1.4863 acc_test: 0.7000 time: 0.0906s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2229 acc_val: 0.5033 loss_test: 1.5363 acc_test: 0.6960 time: 0.0942s
Optimization Finished!
Total time elapsed: 45.8639s, best testing performance  0.704000, minimun loss  1.017292
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7971 acc_train: 0.1167 loss_val: 1.7999 acc_val: 0.2100 loss_test: 1.6755 acc_test: 0.5040 time: 0.1314s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6623 acc_val: 0.4300 loss_test: 1.1657 acc_test: 0.6620 time: 0.0901s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8123 acc_val: 0.4400 loss_test: 1.2330 acc_test: 0.6570 time: 0.0902s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9332 acc_val: 0.4167 loss_test: 1.2916 acc_test: 0.6570 time: 0.0893s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0431 acc_val: 0.4333 loss_test: 1.3307 acc_test: 0.6890 time: 0.0945s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1109 acc_val: 0.4700 loss_test: 1.3585 acc_test: 0.6970 time: 0.0898s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1200 acc_val: 0.4900 loss_test: 1.3772 acc_test: 0.6980 time: 0.0911s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1624 acc_val: 0.5067 loss_test: 1.4099 acc_test: 0.7000 time: 0.0925s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2040 acc_val: 0.5067 loss_test: 1.4410 acc_test: 0.7040 time: 0.0918s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2146 acc_val: 0.5033 loss_test: 1.4666 acc_test: 0.7040 time: 0.0908s
Optimization Finished!
Total time elapsed: 45.8367s, best testing performance  0.708000, minimun loss  1.007936
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7868 acc_train: 0.1917 loss_val: 1.7999 acc_val: 0.1800 loss_test: 1.6634 acc_test: 0.4900 time: 0.1478s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.6373 acc_val: 0.4300 loss_test: 1.1561 acc_test: 0.6660 time: 0.1002s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7218 acc_val: 0.4300 loss_test: 1.2086 acc_test: 0.6690 time: 0.0911s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8239 acc_val: 0.4467 loss_test: 1.2650 acc_test: 0.6840 time: 0.0904s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9497 acc_val: 0.4567 loss_test: 1.3138 acc_test: 0.6900 time: 0.0928s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0389 acc_val: 0.4833 loss_test: 1.3641 acc_test: 0.6920 time: 0.0916s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0795 acc_val: 0.5000 loss_test: 1.3938 acc_test: 0.6930 time: 0.0908s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1280 acc_val: 0.5067 loss_test: 1.4288 acc_test: 0.6970 time: 0.0965s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1850 acc_val: 0.5133 loss_test: 1.4617 acc_test: 0.6980 time: 0.0923s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2206 acc_val: 0.5133 loss_test: 1.4825 acc_test: 0.7010 time: 0.1037s
Optimization Finished!
Total time elapsed: 46.0459s, best testing performance  0.701000, minimun loss  0.973823
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7857 acc_train: 0.2167 loss_val: 1.7856 acc_val: 0.2100 loss_test: 1.6541 acc_test: 0.5400 time: 0.1659s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.6306 acc_val: 0.4467 loss_test: 1.1506 acc_test: 0.6670 time: 0.0900s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.6900 acc_val: 0.4600 loss_test: 1.1892 acc_test: 0.6790 time: 0.0905s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.7757 acc_val: 0.4500 loss_test: 1.2500 acc_test: 0.6830 time: 0.0902s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.8992 acc_val: 0.4700 loss_test: 1.2984 acc_test: 0.6920 time: 0.1017s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9803 acc_val: 0.4833 loss_test: 1.3414 acc_test: 0.6900 time: 0.0917s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1028 acc_val: 0.4900 loss_test: 1.3879 acc_test: 0.6950 time: 0.0913s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1605 acc_val: 0.4933 loss_test: 1.4246 acc_test: 0.6970 time: 0.0921s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2148 acc_val: 0.4967 loss_test: 1.4602 acc_test: 0.6970 time: 0.0907s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2454 acc_val: 0.5067 loss_test: 1.4907 acc_test: 0.7020 time: 0.0907s
Optimization Finished!
Total time elapsed: 45.9194s, best testing performance  0.704000, minimun loss  0.978375
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7997 acc_train: 0.1583 loss_val: 1.8238 acc_val: 0.0933 loss_test: 1.6760 acc_test: 0.4980 time: 0.1494s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7882 acc_val: 0.4000 loss_test: 1.1889 acc_test: 0.6460 time: 0.0899s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8637 acc_val: 0.4333 loss_test: 1.2365 acc_test: 0.6590 time: 0.0907s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9514 acc_val: 0.4267 loss_test: 1.2938 acc_test: 0.6660 time: 0.0923s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0249 acc_val: 0.4400 loss_test: 1.3269 acc_test: 0.6840 time: 0.0908s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0887 acc_val: 0.4633 loss_test: 1.3563 acc_test: 0.6920 time: 0.0905s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4900 loss_test: 1.3754 acc_test: 0.6920 time: 0.0915s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1190 acc_val: 0.5000 loss_test: 1.4024 acc_test: 0.6930 time: 0.0917s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1073 acc_val: 0.5067 loss_test: 1.4176 acc_test: 0.6970 time: 0.0910s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1450 acc_val: 0.5133 loss_test: 1.4493 acc_test: 0.7020 time: 0.0904s
Optimization Finished!
Total time elapsed: 45.9804s, best testing performance  0.704000, minimun loss  0.999819
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.2167 loss_val: 1.8006 acc_val: 0.1767 loss_test: 1.6758 acc_test: 0.5490 time: 0.1720s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7132 acc_val: 0.4267 loss_test: 1.1914 acc_test: 0.6520 time: 0.0909s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7182 acc_val: 0.4533 loss_test: 1.2108 acc_test: 0.6700 time: 0.0932s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8136 acc_val: 0.4567 loss_test: 1.2620 acc_test: 0.6870 time: 0.0926s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9442 acc_val: 0.4733 loss_test: 1.3123 acc_test: 0.6950 time: 0.0907s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9980 acc_val: 0.4900 loss_test: 1.3430 acc_test: 0.6970 time: 0.0901s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0763 acc_val: 0.5000 loss_test: 1.3829 acc_test: 0.6980 time: 0.0904s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1076 acc_val: 0.5033 loss_test: 1.4114 acc_test: 0.6980 time: 0.0923s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1370 acc_val: 0.5033 loss_test: 1.4385 acc_test: 0.6960 time: 0.0925s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2133 acc_val: 0.4933 loss_test: 1.4728 acc_test: 0.6980 time: 0.0915s
Optimization Finished!
Total time elapsed: 46.0448s, best testing performance  0.703000, minimun loss  0.996530
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7698 acc_train: 0.2333 loss_val: 1.8026 acc_val: 0.1433 loss_test: 1.6488 acc_test: 0.5200 time: 0.1332s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9280 acc_val: 0.3667 loss_test: 1.2058 acc_test: 0.6590 time: 0.0954s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.9679 acc_val: 0.4167 loss_test: 1.2313 acc_test: 0.6660 time: 0.0907s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 2.0216 acc_val: 0.4367 loss_test: 1.2718 acc_test: 0.6800 time: 0.0901s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.4633 loss_test: 1.3081 acc_test: 0.6840 time: 0.0902s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1234 acc_val: 0.4600 loss_test: 1.3581 acc_test: 0.6890 time: 0.0903s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.4833 loss_test: 1.3829 acc_test: 0.6940 time: 0.1013s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1480 acc_val: 0.5067 loss_test: 1.4204 acc_test: 0.6940 time: 0.0909s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1717 acc_val: 0.5067 loss_test: 1.4512 acc_test: 0.6980 time: 0.0915s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1712 acc_val: 0.5067 loss_test: 1.4730 acc_test: 0.6990 time: 0.0914s
Optimization Finished!
Total time elapsed: 45.7994s, best testing performance  0.702000, minimun loss  0.993212
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8055 acc_train: 0.1250 loss_val: 1.8250 acc_val: 0.1600 loss_test: 1.6922 acc_test: 0.5020 time: 0.1472s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9668 acc_val: 0.3800 loss_test: 1.2222 acc_test: 0.6480 time: 0.0907s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9248 acc_val: 0.4033 loss_test: 1.2243 acc_test: 0.6690 time: 0.0899s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9805 acc_val: 0.4233 loss_test: 1.2669 acc_test: 0.6760 time: 0.0919s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0584 acc_val: 0.4567 loss_test: 1.3132 acc_test: 0.6830 time: 0.0900s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1171 acc_val: 0.4733 loss_test: 1.3544 acc_test: 0.6880 time: 0.0944s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1389 acc_val: 0.4667 loss_test: 1.3924 acc_test: 0.6910 time: 0.0907s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1517 acc_val: 0.4800 loss_test: 1.4274 acc_test: 0.6960 time: 0.1219s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1653 acc_val: 0.5067 loss_test: 1.4645 acc_test: 0.6960 time: 0.0917s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2121 acc_val: 0.5067 loss_test: 1.5121 acc_test: 0.6970 time: 0.0938s
Optimization Finished!
Total time elapsed: 45.8175s, best testing performance  0.699000, minimun loss  1.009874
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7966 acc_train: 0.1500 loss_val: 1.8146 acc_val: 0.1367 loss_test: 1.6815 acc_test: 0.4270 time: 0.1237s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.7427 acc_val: 0.4067 loss_test: 1.1700 acc_test: 0.6460 time: 0.1021s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8226 acc_val: 0.4367 loss_test: 1.1967 acc_test: 0.6710 time: 0.0904s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9330 acc_val: 0.4400 loss_test: 1.2467 acc_test: 0.6870 time: 0.0899s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9955 acc_val: 0.4667 loss_test: 1.2957 acc_test: 0.6910 time: 0.0900s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9947 acc_val: 0.4900 loss_test: 1.3251 acc_test: 0.6950 time: 0.0901s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0145 acc_val: 0.5033 loss_test: 1.3592 acc_test: 0.6970 time: 0.0906s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0293 acc_val: 0.5100 loss_test: 1.3931 acc_test: 0.7030 time: 0.0949s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0825 acc_val: 0.5167 loss_test: 1.4284 acc_test: 0.7010 time: 0.0905s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0969 acc_val: 0.5167 loss_test: 1.4589 acc_test: 0.7030 time: 0.0909s
Optimization Finished!
Total time elapsed: 45.7847s, best testing performance  0.707000, minimun loss  1.001604
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7927 acc_train: 0.1583 loss_val: 1.8215 acc_val: 0.1433 loss_test: 1.6697 acc_test: 0.5130 time: 0.1258s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9776 acc_val: 0.3667 loss_test: 1.2333 acc_test: 0.6530 time: 0.0900s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9532 acc_val: 0.4100 loss_test: 1.2283 acc_test: 0.6690 time: 0.0923s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9551 acc_val: 0.4300 loss_test: 1.2546 acc_test: 0.6800 time: 0.0900s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0073 acc_val: 0.4567 loss_test: 1.2903 acc_test: 0.6830 time: 0.0901s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0520 acc_val: 0.4700 loss_test: 1.3299 acc_test: 0.6910 time: 0.0898s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.4733 loss_test: 1.3659 acc_test: 0.6910 time: 0.0915s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1167 acc_val: 0.5000 loss_test: 1.4016 acc_test: 0.6900 time: 0.0910s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1443 acc_val: 0.5067 loss_test: 1.4320 acc_test: 0.6930 time: 0.0895s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1675 acc_val: 0.5000 loss_test: 1.4577 acc_test: 0.6940 time: 0.0904s
Optimization Finished!
Total time elapsed: 45.6694s, best testing performance  0.697000, minimun loss  1.002974
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7857 acc_train: 0.2000 loss_val: 1.8109 acc_val: 0.1667 loss_test: 1.6700 acc_test: 0.5130 time: 0.1482s
Epoch: 0051 loss_train: 0.0123 acc_train: 1.0000 loss_val: 1.7985 acc_val: 0.3833 loss_test: 1.1880 acc_test: 0.6490 time: 0.0935s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8643 acc_val: 0.4000 loss_test: 1.2196 acc_test: 0.6690 time: 0.0899s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9280 acc_val: 0.4267 loss_test: 1.2555 acc_test: 0.6760 time: 0.0905s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9717 acc_val: 0.4533 loss_test: 1.2927 acc_test: 0.6830 time: 0.0911s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0632 acc_val: 0.4600 loss_test: 1.3420 acc_test: 0.6890 time: 0.0900s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0865 acc_val: 0.4900 loss_test: 1.3759 acc_test: 0.6900 time: 0.0904s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1373 acc_val: 0.4967 loss_test: 1.4186 acc_test: 0.6930 time: 0.0902s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1608 acc_val: 0.5033 loss_test: 1.4491 acc_test: 0.6910 time: 0.0906s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2193 acc_val: 0.4967 loss_test: 1.4893 acc_test: 0.6930 time: 0.0903s
Optimization Finished!
Total time elapsed: 45.6454s, best testing performance  0.698000, minimun loss  1.007863
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7910 acc_train: 0.1500 loss_val: 1.8040 acc_val: 0.1733 loss_test: 1.6731 acc_test: 0.5430 time: 0.1297s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.9050 acc_val: 0.3700 loss_test: 1.2109 acc_test: 0.6430 time: 0.0900s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8303 acc_val: 0.4067 loss_test: 1.2215 acc_test: 0.6640 time: 0.0897s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9569 acc_val: 0.4367 loss_test: 1.2821 acc_test: 0.6840 time: 0.0900s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0212 acc_val: 0.4633 loss_test: 1.3179 acc_test: 0.6880 time: 0.0907s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0768 acc_val: 0.4767 loss_test: 1.3562 acc_test: 0.6920 time: 0.0900s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1064 acc_val: 0.4867 loss_test: 1.3900 acc_test: 0.6940 time: 0.0947s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1465 acc_val: 0.4933 loss_test: 1.4225 acc_test: 0.6890 time: 0.0903s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1775 acc_val: 0.4967 loss_test: 1.4536 acc_test: 0.6910 time: 0.0915s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2029 acc_val: 0.5000 loss_test: 1.4824 acc_test: 0.6940 time: 0.0914s
Optimization Finished!
Total time elapsed: 45.7761s, best testing performance  0.698000, minimun loss  0.999093
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7988 acc_train: 0.1500 loss_val: 1.8041 acc_val: 0.1467 loss_test: 1.6720 acc_test: 0.5010 time: 0.1299s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8979 acc_val: 0.3733 loss_test: 1.1998 acc_test: 0.6510 time: 0.0907s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9032 acc_val: 0.4200 loss_test: 1.2268 acc_test: 0.6620 time: 0.0902s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9960 acc_val: 0.4267 loss_test: 1.2817 acc_test: 0.6770 time: 0.0906s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0266 acc_val: 0.4600 loss_test: 1.3117 acc_test: 0.6910 time: 0.0920s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0882 acc_val: 0.4667 loss_test: 1.3507 acc_test: 0.6930 time: 0.0937s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0653 acc_val: 0.4900 loss_test: 1.3725 acc_test: 0.6930 time: 0.0921s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1406 acc_val: 0.4933 loss_test: 1.4173 acc_test: 0.6970 time: 0.0909s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1376 acc_val: 0.5100 loss_test: 1.4391 acc_test: 0.6990 time: 0.0910s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1643 acc_val: 0.5133 loss_test: 1.4694 acc_test: 0.6970 time: 0.0907s
Optimization Finished!
Total time elapsed: 45.8687s, best testing performance  0.702000, minimun loss  0.998396
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7970 acc_train: 0.1333 loss_val: 1.7849 acc_val: 0.2033 loss_test: 1.6707 acc_test: 0.5450 time: 0.1336s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7219 acc_val: 0.4033 loss_test: 1.1536 acc_test: 0.6610 time: 0.0906s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7169 acc_val: 0.4567 loss_test: 1.1867 acc_test: 0.6810 time: 0.1079s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8698 acc_val: 0.4500 loss_test: 1.2514 acc_test: 0.6840 time: 0.0909s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9628 acc_val: 0.4600 loss_test: 1.3005 acc_test: 0.6900 time: 0.0901s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0447 acc_val: 0.4700 loss_test: 1.3446 acc_test: 0.6910 time: 0.0899s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1359 acc_val: 0.4833 loss_test: 1.3968 acc_test: 0.6940 time: 0.0903s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1895 acc_val: 0.4933 loss_test: 1.4293 acc_test: 0.6950 time: 0.0905s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2236 acc_val: 0.5033 loss_test: 1.4585 acc_test: 0.6930 time: 0.0905s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2497 acc_val: 0.5033 loss_test: 1.4840 acc_test: 0.6960 time: 0.0926s
Optimization Finished!
Total time elapsed: 45.7888s, best testing performance  0.700000, minimun loss  0.992080
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7904 acc_train: 0.1500 loss_val: 1.8081 acc_val: 0.1167 loss_test: 1.6774 acc_test: 0.4350 time: 0.1510s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7843 acc_val: 0.4067 loss_test: 1.1820 acc_test: 0.6600 time: 0.0941s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8297 acc_val: 0.4467 loss_test: 1.2244 acc_test: 0.6690 time: 0.0933s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9448 acc_val: 0.4533 loss_test: 1.2792 acc_test: 0.6870 time: 0.0898s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0009 acc_val: 0.4700 loss_test: 1.3138 acc_test: 0.6940 time: 0.0899s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0494 acc_val: 0.4733 loss_test: 1.3511 acc_test: 0.6900 time: 0.0904s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0861 acc_val: 0.4800 loss_test: 1.3838 acc_test: 0.6930 time: 0.0910s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1047 acc_val: 0.5067 loss_test: 1.4094 acc_test: 0.6940 time: 0.1018s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1718 acc_val: 0.5067 loss_test: 1.4413 acc_test: 0.6910 time: 0.0919s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1940 acc_val: 0.5100 loss_test: 1.4660 acc_test: 0.6940 time: 0.0921s
Optimization Finished!
Total time elapsed: 45.8188s, best testing performance  0.700000, minimun loss  1.014994
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 10, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7958 acc_train: 0.2083 loss_val: 1.7977 acc_val: 0.0933 loss_test: 1.6821 acc_test: 0.4660 time: 0.1202s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.6743 acc_val: 0.3967 loss_test: 1.1491 acc_test: 0.6580 time: 0.0893s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7328 acc_val: 0.4600 loss_test: 1.1922 acc_test: 0.6770 time: 0.0898s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8593 acc_val: 0.4667 loss_test: 1.2528 acc_test: 0.6850 time: 0.0899s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9398 acc_val: 0.4633 loss_test: 1.2931 acc_test: 0.6920 time: 0.0903s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9944 acc_val: 0.4900 loss_test: 1.3261 acc_test: 0.6930 time: 0.0897s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0050 acc_val: 0.5133 loss_test: 1.3581 acc_test: 0.6970 time: 0.0913s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0626 acc_val: 0.5067 loss_test: 1.3985 acc_test: 0.7010 time: 0.0912s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0586 acc_val: 0.5133 loss_test: 1.4338 acc_test: 0.6960 time: 0.0906s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1399 acc_val: 0.5333 loss_test: 1.4835 acc_test: 0.6980 time: 0.0909s
Optimization Finished!
Total time elapsed: 45.7157s, best testing performance  0.703000, minimun loss  1.004419
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7969 acc_train: 0.1333 loss_val: 1.8041 acc_val: 0.1733 loss_test: 1.6864 acc_test: 0.4920 time: 0.1656s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8563 acc_val: 0.3733 loss_test: 1.1649 acc_test: 0.6640 time: 0.1146s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9089 acc_val: 0.4067 loss_test: 1.1725 acc_test: 0.6810 time: 0.1153s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9957 acc_val: 0.4167 loss_test: 1.2298 acc_test: 0.6840 time: 0.1157s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0592 acc_val: 0.4600 loss_test: 1.2997 acc_test: 0.6930 time: 0.1151s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0915 acc_val: 0.4767 loss_test: 1.3519 acc_test: 0.6880 time: 0.1152s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0883 acc_val: 0.5000 loss_test: 1.3787 acc_test: 0.6930 time: 0.1148s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1361 acc_val: 0.5067 loss_test: 1.4178 acc_test: 0.6960 time: 0.1170s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1597 acc_val: 0.5133 loss_test: 1.4439 acc_test: 0.6920 time: 0.1203s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2022 acc_val: 0.5067 loss_test: 1.4712 acc_test: 0.6910 time: 0.1151s
Optimization Finished!
Total time elapsed: 58.9312s, best testing performance  0.698000, minimun loss  1.005489
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7933 acc_train: 0.1500 loss_val: 1.7869 acc_val: 0.1600 loss_test: 1.7069 acc_test: 0.4640 time: 0.1603s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7127 acc_val: 0.3833 loss_test: 1.1061 acc_test: 0.6740 time: 0.1144s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7770 acc_val: 0.4167 loss_test: 1.1416 acc_test: 0.6830 time: 0.1156s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8755 acc_val: 0.4367 loss_test: 1.2129 acc_test: 0.6830 time: 0.1337s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9583 acc_val: 0.4733 loss_test: 1.2858 acc_test: 0.6850 time: 0.1153s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0563 acc_val: 0.4700 loss_test: 1.3490 acc_test: 0.6900 time: 0.1144s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0793 acc_val: 0.4900 loss_test: 1.3979 acc_test: 0.6980 time: 0.1166s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1572 acc_val: 0.5033 loss_test: 1.4451 acc_test: 0.7060 time: 0.1186s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2214 acc_val: 0.4967 loss_test: 1.4916 acc_test: 0.7020 time: 0.1203s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2799 acc_val: 0.5033 loss_test: 1.5305 acc_test: 0.7020 time: 0.1142s
Optimization Finished!
Total time elapsed: 58.9429s, best testing performance  0.707000, minimun loss  0.962551
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8086 acc_train: 0.1000 loss_val: 1.7993 acc_val: 0.1767 loss_test: 1.7228 acc_test: 0.4030 time: 0.1494s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8001 acc_val: 0.3633 loss_test: 1.1471 acc_test: 0.6620 time: 0.1457s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7876 acc_val: 0.4033 loss_test: 1.1289 acc_test: 0.6770 time: 0.1144s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9021 acc_val: 0.4333 loss_test: 1.2184 acc_test: 0.6880 time: 0.1169s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0052 acc_val: 0.4733 loss_test: 1.2994 acc_test: 0.6890 time: 0.1142s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0325 acc_val: 0.4867 loss_test: 1.3342 acc_test: 0.6930 time: 0.1170s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1052 acc_val: 0.4967 loss_test: 1.3771 acc_test: 0.6950 time: 0.1208s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1369 acc_val: 0.4967 loss_test: 1.4096 acc_test: 0.6960 time: 0.1202s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1698 acc_val: 0.5000 loss_test: 1.4352 acc_test: 0.6980 time: 0.1169s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1795 acc_val: 0.5100 loss_test: 1.4567 acc_test: 0.6990 time: 0.1163s
Optimization Finished!
Total time elapsed: 59.0604s, best testing performance  0.702000, minimun loss  0.979465
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7858 acc_train: 0.1917 loss_val: 1.7891 acc_val: 0.1567 loss_test: 1.6798 acc_test: 0.4880 time: 0.1608s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8863 acc_val: 0.3667 loss_test: 1.1844 acc_test: 0.6620 time: 0.1137s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8588 acc_val: 0.4100 loss_test: 1.1745 acc_test: 0.6800 time: 0.1159s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0005 acc_val: 0.4233 loss_test: 1.2497 acc_test: 0.6770 time: 0.1161s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0938 acc_val: 0.4467 loss_test: 1.3268 acc_test: 0.6740 time: 0.1140s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1185 acc_val: 0.4633 loss_test: 1.3672 acc_test: 0.6910 time: 0.1308s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1318 acc_val: 0.4867 loss_test: 1.3987 acc_test: 0.6950 time: 0.1152s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1665 acc_val: 0.4967 loss_test: 1.4299 acc_test: 0.6940 time: 0.1165s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1906 acc_val: 0.5100 loss_test: 1.4547 acc_test: 0.6960 time: 0.1166s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2305 acc_val: 0.5033 loss_test: 1.4848 acc_test: 0.6960 time: 0.1142s
Optimization Finished!
Total time elapsed: 58.8900s, best testing performance  0.699000, minimun loss  0.992859
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7767 acc_train: 0.2583 loss_val: 1.7999 acc_val: 0.1600 loss_test: 1.6640 acc_test: 0.5210 time: 0.1515s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9228 acc_val: 0.3467 loss_test: 1.1886 acc_test: 0.6510 time: 0.1206s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8264 acc_val: 0.4133 loss_test: 1.1570 acc_test: 0.6780 time: 0.1153s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9466 acc_val: 0.4100 loss_test: 1.2214 acc_test: 0.6800 time: 0.1169s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9852 acc_val: 0.4467 loss_test: 1.2690 acc_test: 0.6890 time: 0.1143s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0805 acc_val: 0.4733 loss_test: 1.3355 acc_test: 0.6890 time: 0.1182s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1008 acc_val: 0.4867 loss_test: 1.3706 acc_test: 0.6950 time: 0.1165s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1321 acc_val: 0.4933 loss_test: 1.4117 acc_test: 0.6980 time: 0.1185s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1556 acc_val: 0.5033 loss_test: 1.4396 acc_test: 0.7040 time: 0.1204s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2085 acc_val: 0.5067 loss_test: 1.4706 acc_test: 0.7020 time: 0.1159s
Optimization Finished!
Total time elapsed: 59.0502s, best testing performance  0.708000, minimun loss  0.991420
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7774 acc_train: 0.2917 loss_val: 1.8466 acc_val: 0.0900 loss_test: 1.6704 acc_test: 0.3850 time: 0.1895s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7526 acc_val: 0.3833 loss_test: 1.1562 acc_test: 0.6730 time: 0.1186s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.7679 acc_val: 0.4267 loss_test: 1.1641 acc_test: 0.6820 time: 0.1194s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8390 acc_val: 0.4267 loss_test: 1.2164 acc_test: 0.6820 time: 0.1200s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9480 acc_val: 0.4500 loss_test: 1.2943 acc_test: 0.6910 time: 0.1149s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0604 acc_val: 0.4733 loss_test: 1.3587 acc_test: 0.6930 time: 0.1145s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0419 acc_val: 0.4933 loss_test: 1.3766 acc_test: 0.6990 time: 0.1321s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0754 acc_val: 0.5167 loss_test: 1.4083 acc_test: 0.7010 time: 0.1192s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1187 acc_val: 0.5167 loss_test: 1.4337 acc_test: 0.7040 time: 0.1210s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1562 acc_val: 0.5167 loss_test: 1.4585 acc_test: 0.7040 time: 0.1174s
Optimization Finished!
Total time elapsed: 59.4825s, best testing performance  0.707000, minimun loss  0.989141
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7836 acc_train: 0.2083 loss_val: 1.7834 acc_val: 0.1767 loss_test: 1.6800 acc_test: 0.4800 time: 0.1515s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7451 acc_val: 0.3733 loss_test: 1.1406 acc_test: 0.6710 time: 0.1150s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7424 acc_val: 0.4200 loss_test: 1.1565 acc_test: 0.6890 time: 0.1224s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.4333 loss_test: 1.2212 acc_test: 0.6930 time: 0.1160s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9872 acc_val: 0.4567 loss_test: 1.2998 acc_test: 0.6910 time: 0.1175s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.4833 loss_test: 1.3573 acc_test: 0.6940 time: 0.1168s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1112 acc_val: 0.4967 loss_test: 1.3956 acc_test: 0.6900 time: 0.1161s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1787 acc_val: 0.5067 loss_test: 1.4318 acc_test: 0.6960 time: 0.1330s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2117 acc_val: 0.5133 loss_test: 1.4602 acc_test: 0.6960 time: 0.1219s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2399 acc_val: 0.5100 loss_test: 1.4833 acc_test: 0.6950 time: 0.1196s
Optimization Finished!
Total time elapsed: 59.2634s, best testing performance  0.698000, minimun loss  0.958987
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7925 acc_train: 0.1667 loss_val: 1.7803 acc_val: 0.1900 loss_test: 1.7001 acc_test: 0.5100 time: 0.1788s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8059 acc_val: 0.3600 loss_test: 1.1598 acc_test: 0.6600 time: 0.1139s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7156 acc_val: 0.4167 loss_test: 1.1350 acc_test: 0.6830 time: 0.1144s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.7799 acc_val: 0.4467 loss_test: 1.2035 acc_test: 0.6870 time: 0.1153s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9332 acc_val: 0.4767 loss_test: 1.2986 acc_test: 0.6870 time: 0.1144s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0029 acc_val: 0.4800 loss_test: 1.3515 acc_test: 0.6920 time: 0.1396s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0642 acc_val: 0.4900 loss_test: 1.3984 acc_test: 0.6910 time: 0.1425s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.5033 loss_test: 1.4445 acc_test: 0.6950 time: 0.1467s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2376 acc_val: 0.5033 loss_test: 1.4917 acc_test: 0.6970 time: 0.2285s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2584 acc_val: 0.5100 loss_test: 1.5164 acc_test: 0.6970 time: 0.1871s
Optimization Finished!
Total time elapsed: 74.3556s, best testing performance  0.702000, minimun loss  0.994306
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7799 acc_train: 0.2333 loss_val: 1.7924 acc_val: 0.1533 loss_test: 1.6638 acc_test: 0.5240 time: 0.1961s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8436 acc_val: 0.3467 loss_test: 1.1588 acc_test: 0.6720 time: 0.2066s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7796 acc_val: 0.4167 loss_test: 1.1502 acc_test: 0.6840 time: 0.2041s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8765 acc_val: 0.4200 loss_test: 1.2206 acc_test: 0.6870 time: 0.2510s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0649 acc_val: 0.4600 loss_test: 1.3144 acc_test: 0.6900 time: 0.1986s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1416 acc_val: 0.4733 loss_test: 1.3592 acc_test: 0.6910 time: 0.1393s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1536 acc_val: 0.4833 loss_test: 1.3909 acc_test: 0.6940 time: 0.1389s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1953 acc_val: 0.5000 loss_test: 1.4235 acc_test: 0.6940 time: 0.2176s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2158 acc_val: 0.5000 loss_test: 1.4569 acc_test: 0.6980 time: 0.1821s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2282 acc_val: 0.5000 loss_test: 1.4793 acc_test: 0.6960 time: 0.1970s
Optimization Finished!
Total time elapsed: 90.7396s, best testing performance  0.703000, minimun loss  0.963582
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8075 acc_train: 0.1000 loss_val: 1.8059 acc_val: 0.1233 loss_test: 1.6883 acc_test: 0.4600 time: 0.1824s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6630 acc_val: 0.4300 loss_test: 1.1014 acc_test: 0.6840 time: 0.1892s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7564 acc_val: 0.4267 loss_test: 1.1387 acc_test: 0.6900 time: 0.2076s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8414 acc_val: 0.4433 loss_test: 1.2009 acc_test: 0.6900 time: 0.1600s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0522 acc_val: 0.4467 loss_test: 1.3111 acc_test: 0.6930 time: 0.1392s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0943 acc_val: 0.4733 loss_test: 1.3487 acc_test: 0.6920 time: 0.1390s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1011 acc_val: 0.4900 loss_test: 1.3764 acc_test: 0.6970 time: 0.1989s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1462 acc_val: 0.5033 loss_test: 1.4103 acc_test: 0.6980 time: 0.2244s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1673 acc_val: 0.4967 loss_test: 1.4371 acc_test: 0.6970 time: 0.1758s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1634 acc_val: 0.5067 loss_test: 1.4533 acc_test: 0.7020 time: 0.2130s
Optimization Finished!
Total time elapsed: 91.1146s, best testing performance  0.705000, minimun loss  0.965555
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7942 acc_train: 0.1750 loss_val: 1.7984 acc_val: 0.1500 loss_test: 1.7043 acc_test: 0.4850 time: 0.2133s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7753 acc_val: 0.3967 loss_test: 1.1585 acc_test: 0.6660 time: 0.1922s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7917 acc_val: 0.4367 loss_test: 1.1794 acc_test: 0.6780 time: 0.1968s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9201 acc_val: 0.4533 loss_test: 1.2496 acc_test: 0.6840 time: 0.1904s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0272 acc_val: 0.4733 loss_test: 1.3140 acc_test: 0.6870 time: 0.1404s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0941 acc_val: 0.4667 loss_test: 1.3547 acc_test: 0.6900 time: 0.1382s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.4833 loss_test: 1.3793 acc_test: 0.6930 time: 0.2112s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1222 acc_val: 0.4867 loss_test: 1.4099 acc_test: 0.6980 time: 0.1871s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1688 acc_val: 0.5033 loss_test: 1.4465 acc_test: 0.6980 time: 0.2020s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1971 acc_val: 0.5067 loss_test: 1.4735 acc_test: 0.6990 time: 0.1910s
Optimization Finished!
Total time elapsed: 89.6313s, best testing performance  0.706000, minimun loss  0.965598
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7747 acc_train: 0.2500 loss_val: 1.7903 acc_val: 0.2033 loss_test: 1.6784 acc_test: 0.5250 time: 0.1673s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.9565 acc_val: 0.3467 loss_test: 1.2202 acc_test: 0.6520 time: 0.1764s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7773 acc_val: 0.4300 loss_test: 1.1754 acc_test: 0.6780 time: 0.1767s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9191 acc_val: 0.4500 loss_test: 1.2548 acc_test: 0.6840 time: 0.1382s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9824 acc_val: 0.4667 loss_test: 1.3071 acc_test: 0.6900 time: 0.1388s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0266 acc_val: 0.4800 loss_test: 1.3475 acc_test: 0.6940 time: 0.1885s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0694 acc_val: 0.4967 loss_test: 1.3881 acc_test: 0.6960 time: 0.1832s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0695 acc_val: 0.5067 loss_test: 1.4153 acc_test: 0.6990 time: 0.1919s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1320 acc_val: 0.5067 loss_test: 1.4520 acc_test: 0.7010 time: 0.2229s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1548 acc_val: 0.5167 loss_test: 1.4747 acc_test: 0.7040 time: 0.2098s
Optimization Finished!
Total time elapsed: 88.3198s, best testing performance  0.706000, minimun loss  0.954892
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7965 acc_train: 0.1917 loss_val: 1.8317 acc_val: 0.0833 loss_test: 1.6970 acc_test: 0.4120 time: 0.2046s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 2.0055 acc_val: 0.3467 loss_test: 1.2384 acc_test: 0.6540 time: 0.1887s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9391 acc_val: 0.4033 loss_test: 1.2217 acc_test: 0.6670 time: 0.1866s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 2.0081 acc_val: 0.4267 loss_test: 1.2803 acc_test: 0.6790 time: 0.1394s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1088 acc_val: 0.4500 loss_test: 1.3371 acc_test: 0.6910 time: 0.1433s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1155 acc_val: 0.4800 loss_test: 1.3628 acc_test: 0.6920 time: 0.2242s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1652 acc_val: 0.4967 loss_test: 1.4018 acc_test: 0.6950 time: 0.1928s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2062 acc_val: 0.5000 loss_test: 1.4382 acc_test: 0.6970 time: 0.2147s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2515 acc_val: 0.5000 loss_test: 1.4678 acc_test: 0.6960 time: 0.2011s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2773 acc_val: 0.4967 loss_test: 1.4943 acc_test: 0.6950 time: 0.1394s
Optimization Finished!
Total time elapsed: 88.1617s, best testing performance  0.699000, minimun loss  1.000052
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7865 acc_train: 0.1583 loss_val: 1.8023 acc_val: 0.1867 loss_test: 1.6838 acc_test: 0.4940 time: 0.1658s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9276 acc_val: 0.3533 loss_test: 1.2025 acc_test: 0.6540 time: 0.1845s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8540 acc_val: 0.4133 loss_test: 1.1833 acc_test: 0.6720 time: 0.1724s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9350 acc_val: 0.4133 loss_test: 1.2504 acc_test: 0.6770 time: 0.1390s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.1043 acc_val: 0.4500 loss_test: 1.3332 acc_test: 0.6810 time: 0.1397s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0966 acc_val: 0.4700 loss_test: 1.3589 acc_test: 0.6920 time: 0.2218s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1241 acc_val: 0.4833 loss_test: 1.3860 acc_test: 0.6940 time: 0.1915s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1423 acc_val: 0.5000 loss_test: 1.4142 acc_test: 0.6960 time: 0.1721s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1828 acc_val: 0.5067 loss_test: 1.4458 acc_test: 0.6960 time: 0.1945s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1878 acc_val: 0.5100 loss_test: 1.4616 acc_test: 0.6960 time: 0.1397s
Optimization Finished!
Total time elapsed: 87.0604s, best testing performance  0.700000, minimun loss  0.973794
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7972 acc_train: 0.2000 loss_val: 1.7979 acc_val: 0.1467 loss_test: 1.7045 acc_test: 0.4540 time: 0.2128s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.9416 acc_val: 0.3733 loss_test: 1.2169 acc_test: 0.6580 time: 0.1770s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8604 acc_val: 0.4133 loss_test: 1.1990 acc_test: 0.6750 time: 0.1382s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0532 acc_val: 0.4300 loss_test: 1.2891 acc_test: 0.6790 time: 0.1384s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.4600 loss_test: 1.3276 acc_test: 0.6840 time: 0.1428s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1313 acc_val: 0.4633 loss_test: 1.3707 acc_test: 0.6880 time: 0.2113s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1002 acc_val: 0.4733 loss_test: 1.3865 acc_test: 0.6950 time: 0.1783s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1021 acc_val: 0.4967 loss_test: 1.4097 acc_test: 0.6980 time: 0.1842s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1131 acc_val: 0.5100 loss_test: 1.4332 acc_test: 0.7040 time: 0.1828s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1422 acc_val: 0.5133 loss_test: 1.4575 acc_test: 0.7010 time: 0.1420s
Optimization Finished!
Total time elapsed: 86.5090s, best testing performance  0.709000, minimun loss  0.982712
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1750 loss_val: 1.7715 acc_val: 0.1733 loss_test: 1.6758 acc_test: 0.5030 time: 0.1700s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.6647 acc_val: 0.4200 loss_test: 1.1225 acc_test: 0.6760 time: 0.1753s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7574 acc_val: 0.4267 loss_test: 1.1737 acc_test: 0.6910 time: 0.1397s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8651 acc_val: 0.4533 loss_test: 1.2319 acc_test: 0.6930 time: 0.1479s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.8992 acc_val: 0.4767 loss_test: 1.2722 acc_test: 0.6940 time: 0.1437s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9727 acc_val: 0.4967 loss_test: 1.3233 acc_test: 0.6900 time: 0.2227s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0103 acc_val: 0.5067 loss_test: 1.3591 acc_test: 0.6960 time: 0.2052s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0697 acc_val: 0.5000 loss_test: 1.4013 acc_test: 0.6980 time: 0.1969s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0696 acc_val: 0.5100 loss_test: 1.4261 acc_test: 0.6990 time: 0.2070s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1132 acc_val: 0.5133 loss_test: 1.4581 acc_test: 0.7000 time: 0.1396s
Optimization Finished!
Total time elapsed: 86.0691s, best testing performance  0.701000, minimun loss  0.965609
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7976 acc_train: 0.1583 loss_val: 1.8061 acc_val: 0.1967 loss_test: 1.6941 acc_test: 0.5230 time: 0.2121s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7484 acc_val: 0.4000 loss_test: 1.1477 acc_test: 0.6640 time: 0.2059s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8570 acc_val: 0.4233 loss_test: 1.2016 acc_test: 0.6780 time: 0.1404s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9766 acc_val: 0.4367 loss_test: 1.2631 acc_test: 0.6840 time: 0.1381s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0103 acc_val: 0.4600 loss_test: 1.2981 acc_test: 0.6900 time: 0.1918s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0556 acc_val: 0.4800 loss_test: 1.3392 acc_test: 0.6940 time: 0.1948s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0865 acc_val: 0.4900 loss_test: 1.3723 acc_test: 0.6940 time: 0.1712s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1448 acc_val: 0.4967 loss_test: 1.4137 acc_test: 0.6920 time: 0.1811s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1909 acc_val: 0.4967 loss_test: 1.4442 acc_test: 0.6930 time: 0.1423s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2225 acc_val: 0.4967 loss_test: 1.4690 acc_test: 0.6900 time: 0.1403s
Optimization Finished!
Total time elapsed: 85.1679s, best testing performance  0.698000, minimun loss  0.982597
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7819 acc_train: 0.2667 loss_val: 1.8076 acc_val: 0.1600 loss_test: 1.6690 acc_test: 0.5420 time: 0.1911s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.9457 acc_val: 0.3500 loss_test: 1.2162 acc_test: 0.6560 time: 0.1428s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.9445 acc_val: 0.4133 loss_test: 1.2312 acc_test: 0.6680 time: 0.1391s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9956 acc_val: 0.4467 loss_test: 1.2759 acc_test: 0.6780 time: 0.1390s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0313 acc_val: 0.4600 loss_test: 1.3116 acc_test: 0.6840 time: 0.1879s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0145 acc_val: 0.4833 loss_test: 1.3384 acc_test: 0.6940 time: 0.1831s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0280 acc_val: 0.4967 loss_test: 1.3686 acc_test: 0.6940 time: 0.2406s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0571 acc_val: 0.5033 loss_test: 1.3986 acc_test: 0.6980 time: 0.1898s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0758 acc_val: 0.5133 loss_test: 1.4277 acc_test: 0.6970 time: 0.1419s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1238 acc_val: 0.5167 loss_test: 1.4539 acc_test: 0.6960 time: 0.1393s
Optimization Finished!
Total time elapsed: 84.4768s, best testing performance  0.700000, minimun loss  0.988688
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7846 acc_train: 0.2333 loss_val: 1.7932 acc_val: 0.2100 loss_test: 1.6781 acc_test: 0.5420 time: 0.1793s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.6211 acc_val: 0.4167 loss_test: 1.1257 acc_test: 0.6710 time: 0.1416s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.6828 acc_val: 0.4400 loss_test: 1.1534 acc_test: 0.6830 time: 0.1385s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.7718 acc_val: 0.4700 loss_test: 1.2099 acc_test: 0.6930 time: 0.2034s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.8334 acc_val: 0.4800 loss_test: 1.2621 acc_test: 0.6980 time: 0.1944s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9289 acc_val: 0.5000 loss_test: 1.3156 acc_test: 0.6950 time: 0.1804s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9808 acc_val: 0.5067 loss_test: 1.3499 acc_test: 0.7000 time: 0.1942s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0052 acc_val: 0.5200 loss_test: 1.3803 acc_test: 0.7000 time: 0.1786s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0652 acc_val: 0.5133 loss_test: 1.4139 acc_test: 0.7000 time: 0.1422s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1265 acc_val: 0.5133 loss_test: 1.4415 acc_test: 0.6960 time: 0.1441s
Optimization Finished!
Total time elapsed: 85.1327s, best testing performance  0.704000, minimun loss  0.984842
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7964 acc_train: 0.1750 loss_val: 1.8310 acc_val: 0.0967 loss_test: 1.6704 acc_test: 0.4010 time: 0.1871s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7117 acc_val: 0.4233 loss_test: 1.1481 acc_test: 0.6760 time: 0.1404s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8350 acc_val: 0.4300 loss_test: 1.2057 acc_test: 0.6770 time: 0.1436s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9503 acc_val: 0.4400 loss_test: 1.2737 acc_test: 0.6840 time: 0.1853s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9871 acc_val: 0.4600 loss_test: 1.3095 acc_test: 0.6870 time: 0.2042s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0350 acc_val: 0.4767 loss_test: 1.3544 acc_test: 0.6920 time: 0.2022s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0574 acc_val: 0.4833 loss_test: 1.3815 acc_test: 0.6940 time: 0.1789s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0769 acc_val: 0.5067 loss_test: 1.4083 acc_test: 0.6960 time: 0.1533s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1011 acc_val: 0.5133 loss_test: 1.4438 acc_test: 0.6960 time: 0.1447s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1529 acc_val: 0.5100 loss_test: 1.4726 acc_test: 0.7000 time: 0.3075s
Optimization Finished!
Total time elapsed: 86.9334s, best testing performance  0.700000, minimun loss  0.966810
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8022 acc_train: 0.1000 loss_val: 1.8009 acc_val: 0.1633 loss_test: 1.6776 acc_test: 0.5030 time: 0.1843s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.9157 acc_val: 0.3600 loss_test: 1.1852 acc_test: 0.6600 time: 0.1388s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8976 acc_val: 0.4100 loss_test: 1.1958 acc_test: 0.6730 time: 0.1918s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9493 acc_val: 0.4233 loss_test: 1.2488 acc_test: 0.6810 time: 0.1787s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0971 acc_val: 0.4367 loss_test: 1.3241 acc_test: 0.6870 time: 0.2044s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1248 acc_val: 0.4567 loss_test: 1.3634 acc_test: 0.6910 time: 0.1890s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1709 acc_val: 0.4867 loss_test: 1.4049 acc_test: 0.6940 time: 0.2210s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1740 acc_val: 0.5067 loss_test: 1.4264 acc_test: 0.6950 time: 0.1479s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2166 acc_val: 0.5000 loss_test: 1.4633 acc_test: 0.6990 time: 0.1405s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2147 acc_val: 0.5100 loss_test: 1.4812 acc_test: 0.6980 time: 0.1955s
Optimization Finished!
Total time elapsed: 85.6692s, best testing performance  0.702000, minimun loss  0.975730
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7766 acc_train: 0.2417 loss_val: 1.8218 acc_val: 0.0833 loss_test: 1.6718 acc_test: 0.3710 time: 0.1657s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8161 acc_val: 0.4000 loss_test: 1.1711 acc_test: 0.6570 time: 0.1382s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8932 acc_val: 0.4400 loss_test: 1.2054 acc_test: 0.6820 time: 0.2083s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0216 acc_val: 0.4333 loss_test: 1.2742 acc_test: 0.6880 time: 0.2259s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0549 acc_val: 0.4567 loss_test: 1.3151 acc_test: 0.6940 time: 0.1812s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1001 acc_val: 0.4800 loss_test: 1.3612 acc_test: 0.6950 time: 0.2184s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1594 acc_val: 0.4800 loss_test: 1.4030 acc_test: 0.6940 time: 0.1431s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2084 acc_val: 0.5000 loss_test: 1.4425 acc_test: 0.6930 time: 0.1399s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2605 acc_val: 0.5000 loss_test: 1.4764 acc_test: 0.6980 time: 0.2001s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3248 acc_val: 0.5100 loss_test: 1.5088 acc_test: 0.6970 time: 0.1838s
Optimization Finished!
Total time elapsed: 87.6175s, best testing performance  0.700000, minimun loss  0.961889
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7896 acc_train: 0.2000 loss_val: 1.8269 acc_val: 0.0733 loss_test: 1.6712 acc_test: 0.4630 time: 0.1749s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7939 acc_val: 0.3900 loss_test: 1.1864 acc_test: 0.6570 time: 0.1968s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8492 acc_val: 0.4267 loss_test: 1.2175 acc_test: 0.6730 time: 0.1824s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9187 acc_val: 0.4467 loss_test: 1.2703 acc_test: 0.6860 time: 0.1663s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9293 acc_val: 0.4700 loss_test: 1.3061 acc_test: 0.6940 time: 0.1851s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0205 acc_val: 0.4867 loss_test: 1.3575 acc_test: 0.6930 time: 0.1705s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0493 acc_val: 0.4867 loss_test: 1.3868 acc_test: 0.6940 time: 0.1416s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0849 acc_val: 0.4900 loss_test: 1.4180 acc_test: 0.6990 time: 0.1414s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0871 acc_val: 0.5033 loss_test: 1.4513 acc_test: 0.6990 time: 0.2283s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1624 acc_val: 0.5067 loss_test: 1.4800 acc_test: 0.7000 time: 0.2070s
Optimization Finished!
Total time elapsed: 89.0234s, best testing performance  0.703000, minimun loss  0.962425
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7964 acc_train: 0.1917 loss_val: 1.8223 acc_val: 0.1567 loss_test: 1.6603 acc_test: 0.5100 time: 0.1782s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8342 acc_val: 0.3833 loss_test: 1.1890 acc_test: 0.6650 time: 0.1802s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7750 acc_val: 0.4133 loss_test: 1.1832 acc_test: 0.6790 time: 0.1738s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8980 acc_val: 0.4300 loss_test: 1.2520 acc_test: 0.6870 time: 0.2051s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0365 acc_val: 0.4500 loss_test: 1.3152 acc_test: 0.6870 time: 0.2022s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1021 acc_val: 0.4700 loss_test: 1.3624 acc_test: 0.6850 time: 0.1395s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1790 acc_val: 0.4867 loss_test: 1.4073 acc_test: 0.6880 time: 0.1395s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2265 acc_val: 0.4900 loss_test: 1.4483 acc_test: 0.6920 time: 0.1789s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2236 acc_val: 0.5133 loss_test: 1.4706 acc_test: 0.6940 time: 0.1920s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2581 acc_val: 0.5133 loss_test: 1.5019 acc_test: 0.6970 time: 0.1737s
Optimization Finished!
Total time elapsed: 90.6936s, best testing performance  0.698000, minimun loss  0.974494
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7799 acc_train: 0.2167 loss_val: 1.7915 acc_val: 0.1500 loss_test: 1.6448 acc_test: 0.5240 time: 0.2185s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8043 acc_val: 0.4033 loss_test: 1.1843 acc_test: 0.6650 time: 0.1725s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8487 acc_val: 0.4300 loss_test: 1.2137 acc_test: 0.6830 time: 0.2002s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9658 acc_val: 0.4333 loss_test: 1.2796 acc_test: 0.6840 time: 0.1903s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1063 acc_val: 0.4433 loss_test: 1.3452 acc_test: 0.6900 time: 0.1392s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1340 acc_val: 0.4667 loss_test: 1.3857 acc_test: 0.6900 time: 0.1396s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1812 acc_val: 0.4833 loss_test: 1.4226 acc_test: 0.6920 time: 0.1459s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2254 acc_val: 0.4900 loss_test: 1.4540 acc_test: 0.6920 time: 0.1777s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2281 acc_val: 0.5000 loss_test: 1.4765 acc_test: 0.6950 time: 0.1909s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2380 acc_val: 0.5000 loss_test: 1.4953 acc_test: 0.6930 time: 0.1809s
Optimization Finished!
Total time elapsed: 91.1560s, best testing performance  0.697000, minimun loss  0.959442
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8201 acc_train: 0.0750 loss_val: 1.8010 acc_val: 0.1333 loss_test: 1.6756 acc_test: 0.4620 time: 0.1721s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7780 acc_val: 0.4167 loss_test: 1.1866 acc_test: 0.6640 time: 0.1940s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7836 acc_val: 0.4633 loss_test: 1.2033 acc_test: 0.6740 time: 0.2556s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8701 acc_val: 0.4667 loss_test: 1.2652 acc_test: 0.6780 time: 0.2051s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0556 acc_val: 0.4533 loss_test: 1.3382 acc_test: 0.6900 time: 0.1390s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1475 acc_val: 0.4600 loss_test: 1.3789 acc_test: 0.6910 time: 0.1385s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1578 acc_val: 0.4667 loss_test: 1.4031 acc_test: 0.6940 time: 0.1858s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1848 acc_val: 0.4933 loss_test: 1.4267 acc_test: 0.6960 time: 0.1822s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2141 acc_val: 0.5000 loss_test: 1.4548 acc_test: 0.6980 time: 0.2126s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2318 acc_val: 0.5000 loss_test: 1.4752 acc_test: 0.7010 time: 0.2011s
Optimization Finished!
Total time elapsed: 90.0282s, best testing performance  0.701000, minimun loss  0.987819
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8033 acc_train: 0.1333 loss_val: 1.8011 acc_val: 0.1133 loss_test: 1.6699 acc_test: 0.4600 time: 0.1677s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7716 acc_val: 0.3900 loss_test: 1.1694 acc_test: 0.6640 time: 0.1826s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7671 acc_val: 0.4433 loss_test: 1.1876 acc_test: 0.6750 time: 0.1850s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8359 acc_val: 0.4533 loss_test: 1.2440 acc_test: 0.6770 time: 0.1391s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0162 acc_val: 0.4467 loss_test: 1.3214 acc_test: 0.6850 time: 0.1388s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0422 acc_val: 0.4633 loss_test: 1.3469 acc_test: 0.6950 time: 0.1443s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0394 acc_val: 0.4967 loss_test: 1.3690 acc_test: 0.6980 time: 0.2129s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0542 acc_val: 0.5067 loss_test: 1.3983 acc_test: 0.7010 time: 0.1998s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1043 acc_val: 0.5133 loss_test: 1.4379 acc_test: 0.6980 time: 0.2106s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1084 acc_val: 0.5100 loss_test: 1.4592 acc_test: 0.7020 time: 0.1763s
Optimization Finished!
Total time elapsed: 89.5369s, best testing performance  0.704000, minimun loss  0.960755
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7959 acc_train: 0.2167 loss_val: 1.7767 acc_val: 0.1467 loss_test: 1.6684 acc_test: 0.4460 time: 0.1747s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.6403 acc_val: 0.4100 loss_test: 1.1410 acc_test: 0.6580 time: 0.2699s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.6226 acc_val: 0.4533 loss_test: 1.1552 acc_test: 0.6790 time: 0.2004s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.7326 acc_val: 0.4667 loss_test: 1.2259 acc_test: 0.6850 time: 0.1392s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9216 acc_val: 0.4667 loss_test: 1.3093 acc_test: 0.6890 time: 0.1394s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9777 acc_val: 0.4833 loss_test: 1.3435 acc_test: 0.6890 time: 0.1972s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0545 acc_val: 0.4967 loss_test: 1.3846 acc_test: 0.6950 time: 0.1827s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1024 acc_val: 0.5067 loss_test: 1.4157 acc_test: 0.6960 time: 0.2106s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1430 acc_val: 0.5033 loss_test: 1.4423 acc_test: 0.7010 time: 0.2401s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1574 acc_val: 0.5100 loss_test: 1.4635 acc_test: 0.7010 time: 0.1490s
Optimization Finished!
Total time elapsed: 88.2867s, best testing performance  0.705000, minimun loss  0.959466
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7846 acc_train: 0.1917 loss_val: 1.8016 acc_val: 0.1767 loss_test: 1.6662 acc_test: 0.5010 time: 0.2010s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7542 acc_val: 0.4200 loss_test: 1.1663 acc_test: 0.6690 time: 0.2176s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.6872 acc_val: 0.4900 loss_test: 1.1755 acc_test: 0.6810 time: 0.1908s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8461 acc_val: 0.4667 loss_test: 1.2580 acc_test: 0.6830 time: 0.1391s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9795 acc_val: 0.4633 loss_test: 1.3221 acc_test: 0.6910 time: 0.1388s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0222 acc_val: 0.4733 loss_test: 1.3518 acc_test: 0.6950 time: 0.1927s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0411 acc_val: 0.5000 loss_test: 1.3799 acc_test: 0.6930 time: 0.1903s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0775 acc_val: 0.5033 loss_test: 1.4112 acc_test: 0.6960 time: 0.1979s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1027 acc_val: 0.5133 loss_test: 1.4373 acc_test: 0.6980 time: 0.1793s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1051 acc_val: 0.5200 loss_test: 1.4556 acc_test: 0.7000 time: 0.1403s
Optimization Finished!
Total time elapsed: 87.4457s, best testing performance  0.703000, minimun loss  0.964719
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8002 acc_train: 0.0917 loss_val: 1.8092 acc_val: 0.1367 loss_test: 1.6897 acc_test: 0.4330 time: 0.2177s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.9112 acc_val: 0.3767 loss_test: 1.2063 acc_test: 0.6570 time: 0.1832s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8027 acc_val: 0.4500 loss_test: 1.1949 acc_test: 0.6770 time: 0.1395s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9731 acc_val: 0.4300 loss_test: 1.2756 acc_test: 0.6790 time: 0.1407s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0826 acc_val: 0.4500 loss_test: 1.3296 acc_test: 0.6850 time: 0.1428s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0759 acc_val: 0.4667 loss_test: 1.3565 acc_test: 0.6900 time: 0.1890s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1576 acc_val: 0.4767 loss_test: 1.4053 acc_test: 0.6940 time: 0.1634s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1294 acc_val: 0.5033 loss_test: 1.4208 acc_test: 0.6950 time: 0.2051s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1939 acc_val: 0.5033 loss_test: 1.4594 acc_test: 0.6980 time: 0.2151s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2355 acc_val: 0.5067 loss_test: 1.4888 acc_test: 0.6950 time: 0.1398s
Optimization Finished!
Total time elapsed: 86.4356s, best testing performance  0.701000, minimun loss  0.971665
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8190 acc_train: 0.1083 loss_val: 1.8050 acc_val: 0.1433 loss_test: 1.7128 acc_test: 0.4750 time: 0.1903s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.6330 acc_val: 0.4367 loss_test: 1.1050 acc_test: 0.6740 time: 0.1934s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.7249 acc_val: 0.4567 loss_test: 1.1516 acc_test: 0.6830 time: 0.1390s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8237 acc_val: 0.4733 loss_test: 1.2125 acc_test: 0.6920 time: 0.1388s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9263 acc_val: 0.4700 loss_test: 1.2690 acc_test: 0.6950 time: 0.2190s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9707 acc_val: 0.4967 loss_test: 1.3087 acc_test: 0.6960 time: 0.1976s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9907 acc_val: 0.5067 loss_test: 1.3436 acc_test: 0.6970 time: 0.2244s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0179 acc_val: 0.5100 loss_test: 1.3749 acc_test: 0.7010 time: 0.1816s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0518 acc_val: 0.5100 loss_test: 1.4084 acc_test: 0.7040 time: 0.1406s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0936 acc_val: 0.5100 loss_test: 1.4395 acc_test: 0.7030 time: 0.1457s
Optimization Finished!
Total time elapsed: 85.3954s, best testing performance  0.708000, minimun loss  0.981903
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7814 acc_train: 0.2250 loss_val: 1.7992 acc_val: 0.1800 loss_test: 1.6587 acc_test: 0.5630 time: 0.2195s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.6735 acc_val: 0.4133 loss_test: 1.1411 acc_test: 0.6670 time: 0.1875s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7138 acc_val: 0.4467 loss_test: 1.1732 acc_test: 0.6800 time: 0.1406s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.7938 acc_val: 0.4633 loss_test: 1.2217 acc_test: 0.6920 time: 0.1380s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9217 acc_val: 0.4567 loss_test: 1.2836 acc_test: 0.6910 time: 0.2112s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0073 acc_val: 0.4667 loss_test: 1.3296 acc_test: 0.6930 time: 0.1799s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0680 acc_val: 0.4867 loss_test: 1.3727 acc_test: 0.6940 time: 0.1884s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1193 acc_val: 0.5067 loss_test: 1.4075 acc_test: 0.6940 time: 0.1858s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1408 acc_val: 0.4933 loss_test: 1.4341 acc_test: 0.6920 time: 0.1470s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1776 acc_val: 0.5000 loss_test: 1.4648 acc_test: 0.6950 time: 0.1403s
Optimization Finished!
Total time elapsed: 84.7978s, best testing performance  0.696000, minimun loss  0.975317
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8145 acc_train: 0.1167 loss_val: 1.7927 acc_val: 0.2133 loss_test: 1.6938 acc_test: 0.5120 time: 0.1790s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7209 acc_val: 0.4333 loss_test: 1.1382 acc_test: 0.6730 time: 0.1388s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7303 acc_val: 0.4733 loss_test: 1.1638 acc_test: 0.6790 time: 0.1391s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8550 acc_val: 0.4733 loss_test: 1.2304 acc_test: 0.6940 time: 0.1903s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9095 acc_val: 0.4767 loss_test: 1.2747 acc_test: 0.6970 time: 0.2065s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9608 acc_val: 0.4933 loss_test: 1.3178 acc_test: 0.6960 time: 0.1728s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0261 acc_val: 0.5100 loss_test: 1.3603 acc_test: 0.7020 time: 0.1945s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0669 acc_val: 0.5033 loss_test: 1.3926 acc_test: 0.7030 time: 0.1734s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1123 acc_val: 0.5133 loss_test: 1.4323 acc_test: 0.7020 time: 0.1400s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1310 acc_val: 0.5100 loss_test: 1.4575 acc_test: 0.7050 time: 0.1396s
Optimization Finished!
Total time elapsed: 83.9176s, best testing performance  0.708000, minimun loss  0.986447
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7887 acc_train: 0.0917 loss_val: 1.7901 acc_val: 0.1867 loss_test: 1.6897 acc_test: 0.5180 time: 0.1864s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7123 acc_val: 0.4167 loss_test: 1.1537 acc_test: 0.6690 time: 0.1396s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7911 acc_val: 0.4233 loss_test: 1.1978 acc_test: 0.6770 time: 0.1383s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9120 acc_val: 0.4467 loss_test: 1.2530 acc_test: 0.6880 time: 0.1861s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9663 acc_val: 0.4667 loss_test: 1.2932 acc_test: 0.6910 time: 0.2097s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0033 acc_val: 0.4900 loss_test: 1.3280 acc_test: 0.6960 time: 0.2371s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0797 acc_val: 0.5000 loss_test: 1.3708 acc_test: 0.6920 time: 0.1728s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0850 acc_val: 0.5033 loss_test: 1.3960 acc_test: 0.6940 time: 0.1430s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1278 acc_val: 0.5100 loss_test: 1.4271 acc_test: 0.6980 time: 0.1411s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1556 acc_val: 0.5100 loss_test: 1.4554 acc_test: 0.7000 time: 0.1489s
Optimization Finished!
Total time elapsed: 85.0242s, best testing performance  0.703000, minimun loss  0.987028
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7891 acc_train: 0.2083 loss_val: 1.7972 acc_val: 0.2200 loss_test: 1.6720 acc_test: 0.5170 time: 0.1743s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.6849 acc_val: 0.4267 loss_test: 1.1384 acc_test: 0.6700 time: 0.1390s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7622 acc_val: 0.4467 loss_test: 1.1778 acc_test: 0.6780 time: 0.1471s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8967 acc_val: 0.4567 loss_test: 1.2470 acc_test: 0.6910 time: 0.1808s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9819 acc_val: 0.4567 loss_test: 1.2938 acc_test: 0.6890 time: 0.1743s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0250 acc_val: 0.4867 loss_test: 1.3303 acc_test: 0.6920 time: 0.2075s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0389 acc_val: 0.4967 loss_test: 1.3613 acc_test: 0.6930 time: 0.1941s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1186 acc_val: 0.5067 loss_test: 1.3986 acc_test: 0.6950 time: 0.1903s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.5100 loss_test: 1.4218 acc_test: 0.6960 time: 0.1361s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1564 acc_val: 0.5133 loss_test: 1.4470 acc_test: 0.6950 time: 0.1408s
Optimization Finished!
Total time elapsed: 84.6748s, best testing performance  0.698000, minimun loss  0.998538
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7949 acc_train: 0.1917 loss_val: 1.8448 acc_val: 0.0833 loss_test: 1.6745 acc_test: 0.3920 time: 0.1973s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.6771 acc_val: 0.4367 loss_test: 1.1389 acc_test: 0.6740 time: 0.1433s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7948 acc_val: 0.4700 loss_test: 1.1888 acc_test: 0.6820 time: 0.1387s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9191 acc_val: 0.4600 loss_test: 1.2511 acc_test: 0.6880 time: 0.1463s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0081 acc_val: 0.4667 loss_test: 1.3019 acc_test: 0.6850 time: 0.2185s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0534 acc_val: 0.4700 loss_test: 1.3398 acc_test: 0.6880 time: 0.2084s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1125 acc_val: 0.4800 loss_test: 1.3840 acc_test: 0.6930 time: 0.1745s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1244 acc_val: 0.4900 loss_test: 1.4146 acc_test: 0.6930 time: 0.1867s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1946 acc_val: 0.4967 loss_test: 1.4558 acc_test: 0.6980 time: 0.2083s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2233 acc_val: 0.5000 loss_test: 1.4885 acc_test: 0.6960 time: 0.1425s
Optimization Finished!
Total time elapsed: 86.1461s, best testing performance  0.702000, minimun loss  0.985667
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8073 acc_train: 0.1167 loss_val: 1.8259 acc_val: 0.0700 loss_test: 1.6970 acc_test: 0.4340 time: 0.1873s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7416 acc_val: 0.4267 loss_test: 1.1517 acc_test: 0.6600 time: 0.2330s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8555 acc_val: 0.4333 loss_test: 1.1951 acc_test: 0.6810 time: 0.2057s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9482 acc_val: 0.4500 loss_test: 1.2434 acc_test: 0.6850 time: 0.1390s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0068 acc_val: 0.4633 loss_test: 1.2852 acc_test: 0.6870 time: 0.1392s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0160 acc_val: 0.4833 loss_test: 1.3182 acc_test: 0.6920 time: 0.2548s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0469 acc_val: 0.4933 loss_test: 1.3569 acc_test: 0.6950 time: 0.2018s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0516 acc_val: 0.5133 loss_test: 1.3848 acc_test: 0.6950 time: 0.1847s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0578 acc_val: 0.5167 loss_test: 1.4110 acc_test: 0.7000 time: 0.2014s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.0781 acc_val: 0.5133 loss_test: 1.4412 acc_test: 0.6990 time: 0.2264s
Optimization Finished!
Total time elapsed: 89.4574s, best testing performance  0.705000, minimun loss  0.985330
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7867 acc_train: 0.2083 loss_val: 1.8546 acc_val: 0.0533 loss_test: 1.6689 acc_test: 0.3590 time: 0.1867s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7256 acc_val: 0.4000 loss_test: 1.1595 acc_test: 0.6650 time: 0.1785s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8241 acc_val: 0.4367 loss_test: 1.2025 acc_test: 0.6740 time: 0.2178s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9432 acc_val: 0.4500 loss_test: 1.2599 acc_test: 0.6880 time: 0.2015s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9799 acc_val: 0.4633 loss_test: 1.2967 acc_test: 0.6860 time: 0.1397s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0457 acc_val: 0.4700 loss_test: 1.3401 acc_test: 0.6890 time: 0.1388s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.4867 loss_test: 1.3683 acc_test: 0.6910 time: 0.1463s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0750 acc_val: 0.5200 loss_test: 1.4003 acc_test: 0.6940 time: 0.1772s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1056 acc_val: 0.5033 loss_test: 1.4263 acc_test: 0.6950 time: 0.1750s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1399 acc_val: 0.5100 loss_test: 1.4510 acc_test: 0.6970 time: 0.1781s
Optimization Finished!
Total time elapsed: 90.6496s, best testing performance  0.699000, minimun loss  0.988490
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7970 acc_train: 0.1333 loss_val: 1.8138 acc_val: 0.0900 loss_test: 1.7027 acc_test: 0.4190 time: 0.1701s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7357 acc_val: 0.4133 loss_test: 1.1486 acc_test: 0.6670 time: 0.1804s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8310 acc_val: 0.4633 loss_test: 1.1932 acc_test: 0.6750 time: 0.1935s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9069 acc_val: 0.4600 loss_test: 1.2497 acc_test: 0.6930 time: 0.1905s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9596 acc_val: 0.4633 loss_test: 1.2926 acc_test: 0.6950 time: 0.1825s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9560 acc_val: 0.4867 loss_test: 1.3246 acc_test: 0.6980 time: 0.1394s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 1.9963 acc_val: 0.5100 loss_test: 1.3683 acc_test: 0.6970 time: 0.1456s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0382 acc_val: 0.5100 loss_test: 1.4106 acc_test: 0.7030 time: 0.1494s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0812 acc_val: 0.5233 loss_test: 1.4480 acc_test: 0.7000 time: 0.1840s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1131 acc_val: 0.5267 loss_test: 1.4841 acc_test: 0.6970 time: 0.1728s
Optimization Finished!
Total time elapsed: 90.7663s, best testing performance  0.707000, minimun loss  0.977356
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.1917 loss_val: 1.7926 acc_val: 0.1700 loss_test: 1.6854 acc_test: 0.5240 time: 0.1937s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8738 acc_val: 0.3900 loss_test: 1.1937 acc_test: 0.6610 time: 0.1942s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8879 acc_val: 0.4233 loss_test: 1.2071 acc_test: 0.6780 time: 0.2140s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9601 acc_val: 0.4533 loss_test: 1.2460 acc_test: 0.6820 time: 0.2012s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9679 acc_val: 0.4700 loss_test: 1.2768 acc_test: 0.6880 time: 0.2032s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0169 acc_val: 0.4833 loss_test: 1.3191 acc_test: 0.6950 time: 0.1875s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0487 acc_val: 0.5000 loss_test: 1.3548 acc_test: 0.6970 time: 0.1420s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0930 acc_val: 0.5100 loss_test: 1.3930 acc_test: 0.6990 time: 0.1397s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1327 acc_val: 0.5033 loss_test: 1.4278 acc_test: 0.7010 time: 0.1497s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1638 acc_val: 0.5167 loss_test: 1.4602 acc_test: 0.7010 time: 0.1742s
Optimization Finished!
Total time elapsed: 88.1300s, best testing performance  0.704000, minimun loss  0.992151
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7971 acc_train: 0.1500 loss_val: 1.7906 acc_val: 0.1433 loss_test: 1.6679 acc_test: 0.5020 time: 0.1727s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8546 acc_val: 0.4000 loss_test: 1.1904 acc_test: 0.6570 time: 0.1385s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8175 acc_val: 0.4433 loss_test: 1.2006 acc_test: 0.6710 time: 0.1547s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8927 acc_val: 0.4300 loss_test: 1.2573 acc_test: 0.6800 time: 0.1942s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9976 acc_val: 0.4567 loss_test: 1.3093 acc_test: 0.6910 time: 0.1708s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0394 acc_val: 0.4733 loss_test: 1.3475 acc_test: 0.6910 time: 0.1922s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0902 acc_val: 0.4933 loss_test: 1.3803 acc_test: 0.6950 time: 0.1704s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1421 acc_val: 0.5033 loss_test: 1.4198 acc_test: 0.6980 time: 0.2101s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1551 acc_val: 0.5033 loss_test: 1.4474 acc_test: 0.7020 time: 0.1415s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1892 acc_val: 0.5100 loss_test: 1.4772 acc_test: 0.7020 time: 0.1393s
Optimization Finished!
Total time elapsed: 84.9940s, best testing performance  0.706000, minimun loss  0.985083
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7956 acc_train: 0.1750 loss_val: 1.8082 acc_val: 0.1867 loss_test: 1.6717 acc_test: 0.5210 time: 0.1694s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7886 acc_val: 0.4300 loss_test: 1.1700 acc_test: 0.6610 time: 0.1388s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.9050 acc_val: 0.4467 loss_test: 1.2178 acc_test: 0.6750 time: 0.1438s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 2.0177 acc_val: 0.4400 loss_test: 1.2757 acc_test: 0.6810 time: 0.1482s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0326 acc_val: 0.4500 loss_test: 1.3119 acc_test: 0.6870 time: 0.2077s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0614 acc_val: 0.4733 loss_test: 1.3472 acc_test: 0.6930 time: 0.1948s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0709 acc_val: 0.4867 loss_test: 1.3784 acc_test: 0.6950 time: 0.2046s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1351 acc_val: 0.4933 loss_test: 1.4205 acc_test: 0.6930 time: 0.1925s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1904 acc_val: 0.4967 loss_test: 1.4609 acc_test: 0.6970 time: 0.1925s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2404 acc_val: 0.4933 loss_test: 1.4982 acc_test: 0.6930 time: 0.1409s
Optimization Finished!
Total time elapsed: 85.4560s, best testing performance  0.699000, minimun loss  0.986487
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8071 acc_train: 0.1333 loss_val: 1.8246 acc_val: 0.1800 loss_test: 1.6744 acc_test: 0.5250 time: 0.1790s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7239 acc_val: 0.4300 loss_test: 1.1576 acc_test: 0.6630 time: 0.1886s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7676 acc_val: 0.4433 loss_test: 1.1895 acc_test: 0.6710 time: 0.1784s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9279 acc_val: 0.4400 loss_test: 1.2646 acc_test: 0.6820 time: 0.1391s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0601 acc_val: 0.4600 loss_test: 1.3215 acc_test: 0.6900 time: 0.1393s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0739 acc_val: 0.4767 loss_test: 1.3508 acc_test: 0.6900 time: 0.1796s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1066 acc_val: 0.4833 loss_test: 1.3804 acc_test: 0.6940 time: 0.1908s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0795 acc_val: 0.5000 loss_test: 1.3999 acc_test: 0.6970 time: 0.2196s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1234 acc_val: 0.5067 loss_test: 1.4328 acc_test: 0.7010 time: 0.2002s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1581 acc_val: 0.5100 loss_test: 1.4560 acc_test: 0.6980 time: 0.1932s
Optimization Finished!
Total time elapsed: 88.7446s, best testing performance  0.703000, minimun loss  0.988896
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7949 acc_train: 0.1750 loss_val: 1.8071 acc_val: 0.1767 loss_test: 1.6704 acc_test: 0.5290 time: 0.1769s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7380 acc_val: 0.4267 loss_test: 1.1551 acc_test: 0.6620 time: 0.1852s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8323 acc_val: 0.4400 loss_test: 1.2010 acc_test: 0.6730 time: 0.1782s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9364 acc_val: 0.4467 loss_test: 1.2545 acc_test: 0.6810 time: 0.2155s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0221 acc_val: 0.4667 loss_test: 1.3008 acc_test: 0.6900 time: 0.1424s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0782 acc_val: 0.4567 loss_test: 1.3439 acc_test: 0.6930 time: 0.1393s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1292 acc_val: 0.4767 loss_test: 1.3798 acc_test: 0.6920 time: 0.2083s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1377 acc_val: 0.4967 loss_test: 1.4091 acc_test: 0.6970 time: 0.1981s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1711 acc_val: 0.5100 loss_test: 1.4409 acc_test: 0.6980 time: 0.1710s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2142 acc_val: 0.5067 loss_test: 1.4732 acc_test: 0.6990 time: 0.1944s
Optimization Finished!
Total time elapsed: 89.9423s, best testing performance  0.702000, minimun loss  0.976013
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8081 acc_train: 0.1667 loss_val: 1.8137 acc_val: 0.1967 loss_test: 1.6702 acc_test: 0.4920 time: 0.1988s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7826 acc_val: 0.4267 loss_test: 1.1533 acc_test: 0.6630 time: 0.1889s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7695 acc_val: 0.4500 loss_test: 1.1672 acc_test: 0.6860 time: 0.2075s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8959 acc_val: 0.4500 loss_test: 1.2314 acc_test: 0.6910 time: 0.1979s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9728 acc_val: 0.4567 loss_test: 1.2819 acc_test: 0.6920 time: 0.1842s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0214 acc_val: 0.4800 loss_test: 1.3269 acc_test: 0.6920 time: 0.1402s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4867 loss_test: 1.3601 acc_test: 0.6910 time: 0.1401s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1398 acc_val: 0.4900 loss_test: 1.4034 acc_test: 0.6910 time: 0.1755s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1620 acc_val: 0.4933 loss_test: 1.4338 acc_test: 0.6930 time: 0.1928s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1871 acc_val: 0.5067 loss_test: 1.4552 acc_test: 0.6960 time: 0.1653s
Optimization Finished!
Total time elapsed: 90.6042s, best testing performance  0.697000, minimun loss  0.974537
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7978 acc_train: 0.0750 loss_val: 1.8150 acc_val: 0.1700 loss_test: 1.6933 acc_test: 0.5020 time: 0.1926s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8799 acc_val: 0.3833 loss_test: 1.1839 acc_test: 0.6530 time: 0.1682s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8803 acc_val: 0.4200 loss_test: 1.2025 acc_test: 0.6670 time: 0.1884s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9458 acc_val: 0.4400 loss_test: 1.2442 acc_test: 0.6810 time: 0.2099s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9838 acc_val: 0.4600 loss_test: 1.2779 acc_test: 0.6890 time: 0.1868s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0321 acc_val: 0.4667 loss_test: 1.3145 acc_test: 0.6920 time: 0.1860s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0355 acc_val: 0.4900 loss_test: 1.3431 acc_test: 0.6940 time: 0.1401s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0783 acc_val: 0.5000 loss_test: 1.3736 acc_test: 0.6920 time: 0.1408s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1112 acc_val: 0.5067 loss_test: 1.4058 acc_test: 0.6940 time: 0.1473s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1327 acc_val: 0.5100 loss_test: 1.4281 acc_test: 0.6960 time: 0.1862s
Optimization Finished!
Total time elapsed: 88.3571s, best testing performance  0.699000, minimun loss  0.982418
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8151 acc_train: 0.0833 loss_val: 1.8276 acc_val: 0.1233 loss_test: 1.6863 acc_test: 0.4850 time: 0.1654s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.9122 acc_val: 0.3900 loss_test: 1.1894 acc_test: 0.6610 time: 0.1385s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.9461 acc_val: 0.4100 loss_test: 1.2107 acc_test: 0.6750 time: 0.2053s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.4400 loss_test: 1.2623 acc_test: 0.6800 time: 0.1750s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0704 acc_val: 0.4433 loss_test: 1.3039 acc_test: 0.6870 time: 0.1960s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0945 acc_val: 0.4633 loss_test: 1.3432 acc_test: 0.6920 time: 0.1954s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1304 acc_val: 0.4833 loss_test: 1.3814 acc_test: 0.6910 time: 0.2080s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1475 acc_val: 0.4967 loss_test: 1.4130 acc_test: 0.6920 time: 0.1399s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1702 acc_val: 0.5067 loss_test: 1.4440 acc_test: 0.6930 time: 0.1393s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2047 acc_val: 0.4967 loss_test: 1.4773 acc_test: 0.6970 time: 0.1437s
Optimization Finished!
Total time elapsed: 85.4085s, best testing performance  0.699000, minimun loss  0.999142
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7912 acc_train: 0.1917 loss_val: 1.8166 acc_val: 0.1867 loss_test: 1.6902 acc_test: 0.4820 time: 0.2064s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.9038 acc_val: 0.3933 loss_test: 1.1990 acc_test: 0.6580 time: 0.1394s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.9033 acc_val: 0.4433 loss_test: 1.2092 acc_test: 0.6750 time: 0.1385s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9741 acc_val: 0.4567 loss_test: 1.2603 acc_test: 0.6850 time: 0.1442s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0136 acc_val: 0.4633 loss_test: 1.2955 acc_test: 0.6900 time: 0.1811s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0333 acc_val: 0.4800 loss_test: 1.3298 acc_test: 0.6920 time: 0.1975s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0465 acc_val: 0.5033 loss_test: 1.3628 acc_test: 0.6970 time: 0.2071s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0669 acc_val: 0.5067 loss_test: 1.3956 acc_test: 0.7000 time: 0.1977s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0789 acc_val: 0.5067 loss_test: 1.4244 acc_test: 0.7000 time: 0.1736s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1139 acc_val: 0.5100 loss_test: 1.4593 acc_test: 0.6990 time: 0.1400s
Optimization Finished!
Total time elapsed: 85.2523s, best testing performance  0.706000, minimun loss  1.023247
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8062 acc_train: 0.0917 loss_val: 1.8001 acc_val: 0.1200 loss_test: 1.6813 acc_test: 0.4780 time: 0.1749s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8984 acc_val: 0.3733 loss_test: 1.2004 acc_test: 0.6550 time: 0.2053s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.9153 acc_val: 0.4300 loss_test: 1.2186 acc_test: 0.6680 time: 0.1721s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9494 acc_val: 0.4333 loss_test: 1.2572 acc_test: 0.6770 time: 0.1400s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0145 acc_val: 0.4633 loss_test: 1.3031 acc_test: 0.6840 time: 0.1384s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0233 acc_val: 0.4800 loss_test: 1.3348 acc_test: 0.6940 time: 0.1922s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0695 acc_val: 0.4867 loss_test: 1.3742 acc_test: 0.6950 time: 0.1889s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1136 acc_val: 0.4933 loss_test: 1.4120 acc_test: 0.6940 time: 0.1882s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1557 acc_val: 0.4933 loss_test: 1.4478 acc_test: 0.7030 time: 0.1724s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1839 acc_val: 0.5067 loss_test: 1.4796 acc_test: 0.7060 time: 0.2104s
Optimization Finished!
Total time elapsed: 88.6898s, best testing performance  0.708000, minimun loss  0.987375
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7882 acc_train: 0.1750 loss_val: 1.8043 acc_val: 0.2000 loss_test: 1.6665 acc_test: 0.4850 time: 0.2291s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.9744 acc_val: 0.3667 loss_test: 1.2208 acc_test: 0.6590 time: 0.1932s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.9760 acc_val: 0.4133 loss_test: 1.2266 acc_test: 0.6760 time: 0.1732s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 2.0014 acc_val: 0.4300 loss_test: 1.2605 acc_test: 0.6850 time: 0.1884s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0287 acc_val: 0.4567 loss_test: 1.2959 acc_test: 0.6880 time: 0.1392s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0473 acc_val: 0.4800 loss_test: 1.3318 acc_test: 0.6880 time: 0.1382s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0422 acc_val: 0.4967 loss_test: 1.3594 acc_test: 0.6880 time: 0.1960s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0588 acc_val: 0.5100 loss_test: 1.3911 acc_test: 0.7010 time: 0.2095s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1036 acc_val: 0.5167 loss_test: 1.4330 acc_test: 0.6990 time: 0.2109s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.5167 loss_test: 1.4670 acc_test: 0.7030 time: 0.1780s
Optimization Finished!
Total time elapsed: 89.6244s, best testing performance  0.703000, minimun loss  0.999948
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8036 acc_train: 0.0917 loss_val: 1.7942 acc_val: 0.1167 loss_test: 1.6655 acc_test: 0.4520 time: 0.1839s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9144 acc_val: 0.3767 loss_test: 1.1999 acc_test: 0.6620 time: 0.1820s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9320 acc_val: 0.4200 loss_test: 1.2207 acc_test: 0.6830 time: 0.1737s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 2.0264 acc_val: 0.4333 loss_test: 1.2741 acc_test: 0.6900 time: 0.1731s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0247 acc_val: 0.4633 loss_test: 1.3053 acc_test: 0.6930 time: 0.1930s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0693 acc_val: 0.4733 loss_test: 1.3420 acc_test: 0.6940 time: 0.1388s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0852 acc_val: 0.4867 loss_test: 1.3770 acc_test: 0.6960 time: 0.1419s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1382 acc_val: 0.4933 loss_test: 1.4213 acc_test: 0.6980 time: 0.1452s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1672 acc_val: 0.5033 loss_test: 1.4483 acc_test: 0.7020 time: 0.1931s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2064 acc_val: 0.5100 loss_test: 1.4815 acc_test: 0.6990 time: 0.1921s
Optimization Finished!
Total time elapsed: 90.1672s, best testing performance  0.704000, minimun loss  0.996552
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7944 acc_train: 0.2000 loss_val: 1.7959 acc_val: 0.1767 loss_test: 1.6714 acc_test: 0.5390 time: 0.1593s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9343 acc_val: 0.3767 loss_test: 1.2338 acc_test: 0.6570 time: 0.1932s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9293 acc_val: 0.4167 loss_test: 1.2418 acc_test: 0.6780 time: 0.1894s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9560 acc_val: 0.4500 loss_test: 1.2784 acc_test: 0.6860 time: 0.1865s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9927 acc_val: 0.4567 loss_test: 1.3161 acc_test: 0.6880 time: 0.1965s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0310 acc_val: 0.4833 loss_test: 1.3539 acc_test: 0.6870 time: 0.2042s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0736 acc_val: 0.5033 loss_test: 1.3896 acc_test: 0.6990 time: 0.1412s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1125 acc_val: 0.5067 loss_test: 1.4222 acc_test: 0.6970 time: 0.1417s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1339 acc_val: 0.5100 loss_test: 1.4542 acc_test: 0.6980 time: 0.1447s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1829 acc_val: 0.4933 loss_test: 1.4870 acc_test: 0.6940 time: 0.1898s
Optimization Finished!
Total time elapsed: 88.2095s, best testing performance  0.701000, minimun loss  1.010531
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7887 acc_train: 0.1250 loss_val: 1.8230 acc_val: 0.0600 loss_test: 1.6712 acc_test: 0.3450 time: 0.1806s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.7901 acc_val: 0.3933 loss_test: 1.1825 acc_test: 0.6630 time: 0.1385s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8991 acc_val: 0.4300 loss_test: 1.2296 acc_test: 0.6710 time: 0.1850s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9571 acc_val: 0.4400 loss_test: 1.2704 acc_test: 0.6840 time: 0.1959s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0008 acc_val: 0.4567 loss_test: 1.3042 acc_test: 0.6920 time: 0.1683s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0349 acc_val: 0.4700 loss_test: 1.3389 acc_test: 0.6920 time: 0.1970s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0558 acc_val: 0.4900 loss_test: 1.3655 acc_test: 0.6930 time: 0.1831s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1082 acc_val: 0.4967 loss_test: 1.4015 acc_test: 0.6930 time: 0.2163s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1178 acc_val: 0.5100 loss_test: 1.4255 acc_test: 0.7000 time: 0.1434s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1987 acc_val: 0.5033 loss_test: 1.4635 acc_test: 0.6980 time: 0.1399s
Optimization Finished!
Total time elapsed: 85.0025s, best testing performance  0.703000, minimun loss  1.008110
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8015 acc_train: 0.1417 loss_val: 1.8077 acc_val: 0.1700 loss_test: 1.6890 acc_test: 0.4400 time: 0.1823s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7750 acc_val: 0.4167 loss_test: 1.1864 acc_test: 0.6650 time: 0.1396s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7939 acc_val: 0.4500 loss_test: 1.2123 acc_test: 0.6860 time: 0.1388s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8430 acc_val: 0.4633 loss_test: 1.2626 acc_test: 0.6960 time: 0.1429s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9326 acc_val: 0.4700 loss_test: 1.3073 acc_test: 0.6960 time: 0.1813s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0303 acc_val: 0.4767 loss_test: 1.3549 acc_test: 0.6940 time: 0.1995s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0960 acc_val: 0.4900 loss_test: 1.3929 acc_test: 0.6940 time: 0.1760s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1384 acc_val: 0.4967 loss_test: 1.4220 acc_test: 0.6950 time: 0.1688s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1715 acc_val: 0.5033 loss_test: 1.4532 acc_test: 0.6940 time: 0.2069s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1890 acc_val: 0.5033 loss_test: 1.4745 acc_test: 0.6960 time: 0.1403s
Optimization Finished!
Total time elapsed: 85.8961s, best testing performance  0.700000, minimun loss  1.013159
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 15, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8173 acc_train: 0.0833 loss_val: 1.7820 acc_val: 0.2167 loss_test: 1.6996 acc_test: 0.5310 time: 0.1823s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8117 acc_val: 0.3967 loss_test: 1.1820 acc_test: 0.6460 time: 0.1913s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7692 acc_val: 0.4367 loss_test: 1.1876 acc_test: 0.6830 time: 0.2168s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9521 acc_val: 0.4500 loss_test: 1.2690 acc_test: 0.6870 time: 0.1415s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0056 acc_val: 0.4600 loss_test: 1.3017 acc_test: 0.6910 time: 0.1382s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0236 acc_val: 0.4700 loss_test: 1.3390 acc_test: 0.6930 time: 0.1953s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0713 acc_val: 0.4800 loss_test: 1.3761 acc_test: 0.6940 time: 0.1894s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1196 acc_val: 0.5033 loss_test: 1.4096 acc_test: 0.6960 time: 0.2130s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1348 acc_val: 0.5000 loss_test: 1.4398 acc_test: 0.6950 time: 0.2163s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1632 acc_val: 0.5033 loss_test: 1.4732 acc_test: 0.6940 time: 0.2280s
Optimization Finished!
Total time elapsed: 89.3405s, best testing performance  0.698000, minimun loss  0.998841
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1000 loss_val: 1.8041 acc_val: 0.1133 loss_test: 1.6559 acc_test: 0.4820 time: 0.2174s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8668 acc_val: 0.3700 loss_test: 1.1789 acc_test: 0.6620 time: 0.2231s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8623 acc_val: 0.4133 loss_test: 1.1904 acc_test: 0.6800 time: 0.2292s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9844 acc_val: 0.4400 loss_test: 1.2601 acc_test: 0.6820 time: 0.1714s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0440 acc_val: 0.4767 loss_test: 1.3093 acc_test: 0.6880 time: 0.1793s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0590 acc_val: 0.4833 loss_test: 1.3486 acc_test: 0.6920 time: 0.2415s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1146 acc_val: 0.4800 loss_test: 1.3914 acc_test: 0.6910 time: 0.2118s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1885 acc_val: 0.4900 loss_test: 1.4369 acc_test: 0.6930 time: 0.2361s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2223 acc_val: 0.5067 loss_test: 1.4697 acc_test: 0.6930 time: 0.2411s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2837 acc_val: 0.5067 loss_test: 1.5026 acc_test: 0.6950 time: 0.1717s
Optimization Finished!
Total time elapsed: 106.3192s, best testing performance  0.699000, minimun loss  0.973547
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7995 acc_train: 0.1500 loss_val: 1.8170 acc_val: 0.0800 loss_test: 1.6579 acc_test: 0.4100 time: 0.2253s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8318 acc_val: 0.3933 loss_test: 1.1596 acc_test: 0.6680 time: 0.2180s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8265 acc_val: 0.4167 loss_test: 1.1789 acc_test: 0.6800 time: 0.1702s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9749 acc_val: 0.4167 loss_test: 1.2657 acc_test: 0.6800 time: 0.1748s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0384 acc_val: 0.4467 loss_test: 1.3196 acc_test: 0.6850 time: 0.2404s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0652 acc_val: 0.4733 loss_test: 1.3591 acc_test: 0.6940 time: 0.2161s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1277 acc_val: 0.4800 loss_test: 1.4028 acc_test: 0.6940 time: 0.2410s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1842 acc_val: 0.4967 loss_test: 1.4391 acc_test: 0.6920 time: 0.2432s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2102 acc_val: 0.5033 loss_test: 1.4688 acc_test: 0.6970 time: 0.1738s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2407 acc_val: 0.5100 loss_test: 1.4975 acc_test: 0.6960 time: 0.1758s
Optimization Finished!
Total time elapsed: 104.8727s, best testing performance  0.699000, minimun loss  0.971099
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7898 acc_train: 0.1833 loss_val: 1.8289 acc_val: 0.1833 loss_test: 1.6566 acc_test: 0.4930 time: 0.2052s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8850 acc_val: 0.3633 loss_test: 1.1694 acc_test: 0.6680 time: 0.1742s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9481 acc_val: 0.4067 loss_test: 1.2075 acc_test: 0.6720 time: 0.2427s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.4267 loss_test: 1.2875 acc_test: 0.6790 time: 0.2418s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.1104 acc_val: 0.4600 loss_test: 1.3310 acc_test: 0.6830 time: 0.2130s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1382 acc_val: 0.4700 loss_test: 1.3732 acc_test: 0.6900 time: 0.2934s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1664 acc_val: 0.4900 loss_test: 1.4052 acc_test: 0.6950 time: 0.2514s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2012 acc_val: 0.5033 loss_test: 1.4474 acc_test: 0.6930 time: 0.1723s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2377 acc_val: 0.5000 loss_test: 1.4838 acc_test: 0.7000 time: 0.1792s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2734 acc_val: 0.5033 loss_test: 1.5127 acc_test: 0.6950 time: 0.2378s
Optimization Finished!
Total time elapsed: 104.9004s, best testing performance  0.701000, minimun loss  0.977686
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7935 acc_train: 0.1667 loss_val: 1.8299 acc_val: 0.1233 loss_test: 1.6669 acc_test: 0.4660 time: 0.2371s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8901 acc_val: 0.3600 loss_test: 1.1682 acc_test: 0.6670 time: 0.2206s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8830 acc_val: 0.4000 loss_test: 1.1880 acc_test: 0.6760 time: 0.2359s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 2.0173 acc_val: 0.4033 loss_test: 1.2668 acc_test: 0.6760 time: 0.2323s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0389 acc_val: 0.4400 loss_test: 1.3091 acc_test: 0.6820 time: 0.2340s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0520 acc_val: 0.4733 loss_test: 1.3398 acc_test: 0.6880 time: 0.1705s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0546 acc_val: 0.4867 loss_test: 1.3629 acc_test: 0.6960 time: 0.1723s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1204 acc_val: 0.4967 loss_test: 1.4028 acc_test: 0.6950 time: 0.2453s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1197 acc_val: 0.5067 loss_test: 1.4245 acc_test: 0.7010 time: 0.2119s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1439 acc_val: 0.5133 loss_test: 1.4481 acc_test: 0.7030 time: 0.2124s
Optimization Finished!
Total time elapsed: 109.4784s, best testing performance  0.705000, minimun loss  0.975494
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7990 acc_train: 0.1667 loss_val: 1.8043 acc_val: 0.2233 loss_test: 1.6667 acc_test: 0.4940 time: 0.2988s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8671 acc_val: 0.3467 loss_test: 1.1755 acc_test: 0.6550 time: 0.2517s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8056 acc_val: 0.4233 loss_test: 1.1674 acc_test: 0.6770 time: 0.2347s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9029 acc_val: 0.4233 loss_test: 1.2332 acc_test: 0.6810 time: 0.2230s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0039 acc_val: 0.4567 loss_test: 1.2998 acc_test: 0.6830 time: 0.1709s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0186 acc_val: 0.4733 loss_test: 1.3374 acc_test: 0.6900 time: 0.1698s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0429 acc_val: 0.4900 loss_test: 1.3712 acc_test: 0.6950 time: 0.2253s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1319 acc_val: 0.5000 loss_test: 1.4189 acc_test: 0.7010 time: 0.2338s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1410 acc_val: 0.5100 loss_test: 1.4508 acc_test: 0.7000 time: 0.2373s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1780 acc_val: 0.5167 loss_test: 1.4809 acc_test: 0.7000 time: 0.2150s
Optimization Finished!
Total time elapsed: 110.3750s, best testing performance  0.703000, minimun loss  0.967533
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7905 acc_train: 0.2000 loss_val: 1.7916 acc_val: 0.2200 loss_test: 1.6628 acc_test: 0.5190 time: 0.2788s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8313 acc_val: 0.3733 loss_test: 1.1431 acc_test: 0.6600 time: 0.2318s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8314 acc_val: 0.4067 loss_test: 1.1669 acc_test: 0.6690 time: 0.2373s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9004 acc_val: 0.4167 loss_test: 1.2201 acc_test: 0.6820 time: 0.1708s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0742 acc_val: 0.4433 loss_test: 1.3035 acc_test: 0.6820 time: 0.1685s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0563 acc_val: 0.4700 loss_test: 1.3294 acc_test: 0.6910 time: 0.2956s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.4867 loss_test: 1.3590 acc_test: 0.6940 time: 0.2694s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0872 acc_val: 0.5000 loss_test: 1.3942 acc_test: 0.6950 time: 0.2347s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.5100 loss_test: 1.4192 acc_test: 0.6980 time: 0.2276s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1337 acc_val: 0.5100 loss_test: 1.4544 acc_test: 0.6990 time: 0.1753s
Optimization Finished!
Total time elapsed: 107.4354s, best testing performance  0.701000, minimun loss  0.964100
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7859 acc_train: 0.2000 loss_val: 1.8039 acc_val: 0.1600 loss_test: 1.6642 acc_test: 0.5290 time: 0.2262s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7366 acc_val: 0.3900 loss_test: 1.1364 acc_test: 0.6780 time: 0.2281s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.6854 acc_val: 0.4433 loss_test: 1.1349 acc_test: 0.6850 time: 0.1698s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.7657 acc_val: 0.4467 loss_test: 1.1890 acc_test: 0.6830 time: 0.1701s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9831 acc_val: 0.4533 loss_test: 1.2977 acc_test: 0.6850 time: 0.2191s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0858 acc_val: 0.4800 loss_test: 1.3511 acc_test: 0.6890 time: 0.2662s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1437 acc_val: 0.4933 loss_test: 1.3898 acc_test: 0.6940 time: 0.2412s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1800 acc_val: 0.4933 loss_test: 1.4181 acc_test: 0.6950 time: 0.2259s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2198 acc_val: 0.5033 loss_test: 1.4488 acc_test: 0.6940 time: 0.1757s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2621 acc_val: 0.5133 loss_test: 1.4746 acc_test: 0.6980 time: 0.1709s
Optimization Finished!
Total time elapsed: 105.4792s, best testing performance  0.702000, minimun loss  0.978509
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.1750 loss_val: 1.8145 acc_val: 0.1133 loss_test: 1.6623 acc_test: 0.4770 time: 0.2264s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7730 acc_val: 0.3767 loss_test: 1.1281 acc_test: 0.6710 time: 0.1738s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7770 acc_val: 0.4367 loss_test: 1.1469 acc_test: 0.6840 time: 0.2324s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9608 acc_val: 0.4367 loss_test: 1.2444 acc_test: 0.6840 time: 0.2562s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0377 acc_val: 0.4567 loss_test: 1.3003 acc_test: 0.6850 time: 0.2534s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0640 acc_val: 0.4800 loss_test: 1.3281 acc_test: 0.6920 time: 0.2192s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0934 acc_val: 0.4933 loss_test: 1.3630 acc_test: 0.6940 time: 0.2436s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1111 acc_val: 0.5067 loss_test: 1.3937 acc_test: 0.6980 time: 0.1746s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1524 acc_val: 0.4967 loss_test: 1.4230 acc_test: 0.7000 time: 0.1782s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1644 acc_val: 0.5100 loss_test: 1.4450 acc_test: 0.6990 time: 0.2402s
Optimization Finished!
Total time elapsed: 106.0437s, best testing performance  0.705000, minimun loss  0.951340
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7992 acc_train: 0.1583 loss_val: 1.8519 acc_val: 0.0700 loss_test: 1.6679 acc_test: 0.4190 time: 0.2108s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8443 acc_val: 0.3633 loss_test: 1.1485 acc_test: 0.6640 time: 0.2262s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7944 acc_val: 0.4033 loss_test: 1.1530 acc_test: 0.6830 time: 0.2699s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9233 acc_val: 0.4300 loss_test: 1.2287 acc_test: 0.6870 time: 0.2621s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4533 loss_test: 1.3053 acc_test: 0.6850 time: 0.2222s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.4633 loss_test: 1.3407 acc_test: 0.6870 time: 0.2204s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1314 acc_val: 0.4900 loss_test: 1.3758 acc_test: 0.6930 time: 0.1750s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1480 acc_val: 0.4967 loss_test: 1.4038 acc_test: 0.6940 time: 0.1818s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1465 acc_val: 0.5067 loss_test: 1.4307 acc_test: 0.6940 time: 0.2312s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2042 acc_val: 0.5000 loss_test: 1.4616 acc_test: 0.6970 time: 0.2271s
Optimization Finished!
Total time elapsed: 110.0745s, best testing performance  0.703000, minimun loss  0.959539
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8054 acc_train: 0.1083 loss_val: 1.8109 acc_val: 0.1400 loss_test: 1.6669 acc_test: 0.4800 time: 0.2619s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8243 acc_val: 0.3633 loss_test: 1.1519 acc_test: 0.6650 time: 0.2255s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8656 acc_val: 0.4033 loss_test: 1.1874 acc_test: 0.6820 time: 0.2321s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9894 acc_val: 0.4367 loss_test: 1.2608 acc_test: 0.6830 time: 0.2481s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0682 acc_val: 0.4533 loss_test: 1.3126 acc_test: 0.6870 time: 0.2349s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1177 acc_val: 0.4700 loss_test: 1.3534 acc_test: 0.6910 time: 0.1711s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1270 acc_val: 0.4867 loss_test: 1.3797 acc_test: 0.6930 time: 0.1819s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1553 acc_val: 0.5067 loss_test: 1.4050 acc_test: 0.6980 time: 0.2390s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1838 acc_val: 0.5067 loss_test: 1.4362 acc_test: 0.7020 time: 0.2123s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1920 acc_val: 0.5100 loss_test: 1.4565 acc_test: 0.7000 time: 0.2295s
Optimization Finished!
Total time elapsed: 113.0499s, best testing performance  0.703000, minimun loss  0.965282
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7740 acc_train: 0.2667 loss_val: 1.8305 acc_val: 0.1600 loss_test: 1.6667 acc_test: 0.5060 time: 0.2309s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7084 acc_val: 0.4100 loss_test: 1.1138 acc_test: 0.6720 time: 0.2360s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8065 acc_val: 0.4133 loss_test: 1.1682 acc_test: 0.6860 time: 0.2353s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9627 acc_val: 0.4267 loss_test: 1.2508 acc_test: 0.6850 time: 0.2629s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0338 acc_val: 0.4700 loss_test: 1.3048 acc_test: 0.6910 time: 0.1714s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.4767 loss_test: 1.3444 acc_test: 0.6910 time: 0.1783s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1141 acc_val: 0.4967 loss_test: 1.3768 acc_test: 0.6950 time: 0.2339s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1285 acc_val: 0.5033 loss_test: 1.4070 acc_test: 0.6990 time: 0.2371s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1229 acc_val: 0.5100 loss_test: 1.4264 acc_test: 0.7000 time: 0.2275s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1626 acc_val: 0.5100 loss_test: 1.4597 acc_test: 0.7010 time: 0.2604s
Optimization Finished!
Total time elapsed: 110.4427s, best testing performance  0.704000, minimun loss  0.947178
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.2333 loss_val: 1.8264 acc_val: 0.1000 loss_test: 1.6801 acc_test: 0.4760 time: 0.2205s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.6806 acc_val: 0.4167 loss_test: 1.1110 acc_test: 0.6790 time: 0.2243s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7592 acc_val: 0.4200 loss_test: 1.1620 acc_test: 0.6840 time: 0.2409s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8731 acc_val: 0.4300 loss_test: 1.2371 acc_test: 0.6850 time: 0.1729s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9922 acc_val: 0.4667 loss_test: 1.2971 acc_test: 0.6920 time: 0.1696s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0209 acc_val: 0.4733 loss_test: 1.3345 acc_test: 0.6920 time: 0.2391s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0898 acc_val: 0.5067 loss_test: 1.3765 acc_test: 0.6920 time: 0.2217s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1159 acc_val: 0.5067 loss_test: 1.4044 acc_test: 0.6980 time: 0.2316s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1715 acc_val: 0.5133 loss_test: 1.4407 acc_test: 0.6960 time: 0.2743s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2123 acc_val: 0.5100 loss_test: 1.4665 acc_test: 0.6990 time: 0.1711s
Optimization Finished!
Total time elapsed: 107.5967s, best testing performance  0.701000, minimun loss  0.970894
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7978 acc_train: 0.1000 loss_val: 1.7978 acc_val: 0.1267 loss_test: 1.6662 acc_test: 0.5300 time: 0.2183s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8065 acc_val: 0.3900 loss_test: 1.1580 acc_test: 0.6650 time: 0.2600s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7310 acc_val: 0.4233 loss_test: 1.1577 acc_test: 0.6900 time: 0.1708s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8414 acc_val: 0.4400 loss_test: 1.2339 acc_test: 0.6820 time: 0.1694s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9604 acc_val: 0.4633 loss_test: 1.2975 acc_test: 0.6890 time: 0.2192s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0495 acc_val: 0.4633 loss_test: 1.3519 acc_test: 0.6910 time: 0.2191s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1262 acc_val: 0.4767 loss_test: 1.3930 acc_test: 0.6900 time: 0.2210s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2378 acc_val: 0.4833 loss_test: 1.4465 acc_test: 0.6890 time: 0.2286s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2708 acc_val: 0.4800 loss_test: 1.4762 acc_test: 0.6920 time: 0.1733s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2920 acc_val: 0.4933 loss_test: 1.5008 acc_test: 0.6980 time: 0.1837s
Optimization Finished!
Total time elapsed: 105.3626s, best testing performance  0.698000, minimun loss  0.957931
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7899 acc_train: 0.1917 loss_val: 1.8097 acc_val: 0.1400 loss_test: 1.6775 acc_test: 0.4910 time: 0.2075s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7703 acc_val: 0.3900 loss_test: 1.1664 acc_test: 0.6700 time: 0.1722s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7282 acc_val: 0.4567 loss_test: 1.1604 acc_test: 0.6860 time: 0.1734s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8936 acc_val: 0.4733 loss_test: 1.2453 acc_test: 0.6920 time: 0.2154s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9524 acc_val: 0.4733 loss_test: 1.2868 acc_test: 0.6920 time: 0.2293s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0102 acc_val: 0.4767 loss_test: 1.3302 acc_test: 0.6920 time: 0.2517s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0412 acc_val: 0.4967 loss_test: 1.3636 acc_test: 0.6930 time: 0.2525s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0643 acc_val: 0.5067 loss_test: 1.3917 acc_test: 0.6920 time: 0.2339s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1114 acc_val: 0.5033 loss_test: 1.4263 acc_test: 0.6930 time: 0.1735s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1011 acc_val: 0.5133 loss_test: 1.4427 acc_test: 0.6950 time: 0.1779s
Optimization Finished!
Total time elapsed: 105.8286s, best testing performance  0.699000, minimun loss  0.989094
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7801 acc_train: 0.1750 loss_val: 1.8381 acc_val: 0.0767 loss_test: 1.6570 acc_test: 0.4310 time: 0.1918s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8401 acc_val: 0.3700 loss_test: 1.1847 acc_test: 0.6680 time: 0.1735s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.9018 acc_val: 0.4033 loss_test: 1.2187 acc_test: 0.6830 time: 0.2176s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9943 acc_val: 0.4400 loss_test: 1.2769 acc_test: 0.6850 time: 0.2384s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0811 acc_val: 0.4667 loss_test: 1.3259 acc_test: 0.6840 time: 0.2402s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1185 acc_val: 0.4900 loss_test: 1.3595 acc_test: 0.6920 time: 0.2386s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1309 acc_val: 0.4833 loss_test: 1.3885 acc_test: 0.6980 time: 0.2285s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1551 acc_val: 0.4933 loss_test: 1.4201 acc_test: 0.6990 time: 0.1743s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2059 acc_val: 0.5033 loss_test: 1.4525 acc_test: 0.7010 time: 0.1816s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2105 acc_val: 0.5100 loss_test: 1.4740 acc_test: 0.7000 time: 0.2153s
Optimization Finished!
Total time elapsed: 106.2465s, best testing performance  0.703000, minimun loss  0.974467
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7835 acc_train: 0.1667 loss_val: 1.8254 acc_val: 0.1333 loss_test: 1.6737 acc_test: 0.4890 time: 0.2235s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8003 acc_val: 0.3833 loss_test: 1.1577 acc_test: 0.6620 time: 0.1788s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8707 acc_val: 0.4233 loss_test: 1.2007 acc_test: 0.6690 time: 0.2173s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9506 acc_val: 0.4467 loss_test: 1.2579 acc_test: 0.6830 time: 0.2578s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0257 acc_val: 0.4567 loss_test: 1.3019 acc_test: 0.6840 time: 0.3212s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0743 acc_val: 0.4733 loss_test: 1.3427 acc_test: 0.6890 time: 0.2140s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0955 acc_val: 0.4933 loss_test: 1.3786 acc_test: 0.6930 time: 0.1772s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1249 acc_val: 0.5000 loss_test: 1.4108 acc_test: 0.6920 time: 0.1865s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1308 acc_val: 0.5100 loss_test: 1.4354 acc_test: 0.6900 time: 0.2325s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1324 acc_val: 0.5067 loss_test: 1.4549 acc_test: 0.6900 time: 0.2176s
Optimization Finished!
Total time elapsed: 109.6649s, best testing performance  0.697000, minimun loss  0.980535
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7826 acc_train: 0.2083 loss_val: 1.7983 acc_val: 0.1967 loss_test: 1.6661 acc_test: 0.5570 time: 0.2272s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6839 acc_val: 0.4000 loss_test: 1.1304 acc_test: 0.6680 time: 0.2358s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7764 acc_val: 0.4400 loss_test: 1.1773 acc_test: 0.6840 time: 0.2041s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9098 acc_val: 0.4633 loss_test: 1.2508 acc_test: 0.6860 time: 0.2583s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9975 acc_val: 0.4700 loss_test: 1.3053 acc_test: 0.6900 time: 0.2167s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0327 acc_val: 0.4833 loss_test: 1.3446 acc_test: 0.6940 time: 0.1726s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.5000 loss_test: 1.3787 acc_test: 0.6950 time: 0.1794s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0803 acc_val: 0.5067 loss_test: 1.4105 acc_test: 0.6940 time: 0.2327s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1275 acc_val: 0.5100 loss_test: 1.4397 acc_test: 0.6960 time: 0.2402s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1668 acc_val: 0.5133 loss_test: 1.4721 acc_test: 0.6970 time: 0.2591s
Optimization Finished!
Total time elapsed: 112.6360s, best testing performance  0.702000, minimun loss  0.960470
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7859 acc_train: 0.2417 loss_val: 1.8010 acc_val: 0.1100 loss_test: 1.6640 acc_test: 0.4720 time: 0.2188s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.8579 acc_val: 0.3833 loss_test: 1.1483 acc_test: 0.6650 time: 0.2284s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.9287 acc_val: 0.4000 loss_test: 1.1945 acc_test: 0.6720 time: 0.2425s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9974 acc_val: 0.4300 loss_test: 1.2457 acc_test: 0.6840 time: 0.2312s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0293 acc_val: 0.4600 loss_test: 1.2849 acc_test: 0.6860 time: 0.1704s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0475 acc_val: 0.4667 loss_test: 1.3212 acc_test: 0.6900 time: 0.1778s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0833 acc_val: 0.4833 loss_test: 1.3599 acc_test: 0.6950 time: 0.2440s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1118 acc_val: 0.4933 loss_test: 1.3955 acc_test: 0.6990 time: 0.2930s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1497 acc_val: 0.5000 loss_test: 1.4291 acc_test: 0.6980 time: 0.2152s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1848 acc_val: 0.5067 loss_test: 1.4594 acc_test: 0.6980 time: 0.2357s
Optimization Finished!
Total time elapsed: 110.3635s, best testing performance  0.704000, minimun loss  0.952959
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7840 acc_train: 0.1917 loss_val: 1.7920 acc_val: 0.1700 loss_test: 1.6664 acc_test: 0.5300 time: 0.2467s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7539 acc_val: 0.4233 loss_test: 1.1178 acc_test: 0.6770 time: 0.2234s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8128 acc_val: 0.4433 loss_test: 1.1642 acc_test: 0.6900 time: 0.2473s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9765 acc_val: 0.4467 loss_test: 1.2495 acc_test: 0.6890 time: 0.1712s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0462 acc_val: 0.4500 loss_test: 1.3019 acc_test: 0.6870 time: 0.1700s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0676 acc_val: 0.4867 loss_test: 1.3404 acc_test: 0.6900 time: 0.2326s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1027 acc_val: 0.5067 loss_test: 1.3744 acc_test: 0.6930 time: 0.2456s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1674 acc_val: 0.5033 loss_test: 1.4257 acc_test: 0.6970 time: 0.2173s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1994 acc_val: 0.5033 loss_test: 1.4614 acc_test: 0.6980 time: 0.2357s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2774 acc_val: 0.5000 loss_test: 1.5104 acc_test: 0.6940 time: 0.1722s
Optimization Finished!
Total time elapsed: 107.9560s, best testing performance  0.701000, minimun loss  0.958888
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7813 acc_train: 0.1833 loss_val: 1.8167 acc_val: 0.1567 loss_test: 1.6581 acc_test: 0.4820 time: 0.2372s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8511 acc_val: 0.3633 loss_test: 1.1761 acc_test: 0.6630 time: 0.2447s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8946 acc_val: 0.4033 loss_test: 1.2122 acc_test: 0.6700 time: 0.1708s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9619 acc_val: 0.4200 loss_test: 1.2596 acc_test: 0.6830 time: 0.1712s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0459 acc_val: 0.4400 loss_test: 1.3077 acc_test: 0.6870 time: 0.2143s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0462 acc_val: 0.4700 loss_test: 1.3350 acc_test: 0.6870 time: 0.2548s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0796 acc_val: 0.4933 loss_test: 1.3647 acc_test: 0.6880 time: 0.2377s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0997 acc_val: 0.4900 loss_test: 1.3903 acc_test: 0.6900 time: 0.2488s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1818 acc_val: 0.4933 loss_test: 1.4230 acc_test: 0.6950 time: 0.1763s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2113 acc_val: 0.4833 loss_test: 1.4454 acc_test: 0.6910 time: 0.1702s
Optimization Finished!
Total time elapsed: 106.2939s, best testing performance  0.695000, minimun loss  0.981664
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8170 acc_train: 0.1167 loss_val: 1.7970 acc_val: 0.1700 loss_test: 1.6773 acc_test: 0.5180 time: 0.2312s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.9198 acc_val: 0.3533 loss_test: 1.1884 acc_test: 0.6520 time: 0.1722s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8896 acc_val: 0.3867 loss_test: 1.1901 acc_test: 0.6710 time: 0.1712s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9020 acc_val: 0.4367 loss_test: 1.2252 acc_test: 0.6790 time: 0.2402s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9815 acc_val: 0.4633 loss_test: 1.2761 acc_test: 0.6890 time: 0.2686s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0069 acc_val: 0.4733 loss_test: 1.3168 acc_test: 0.6940 time: 0.2155s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0632 acc_val: 0.4900 loss_test: 1.3613 acc_test: 0.6940 time: 0.2188s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1069 acc_val: 0.5033 loss_test: 1.4103 acc_test: 0.6920 time: 0.1735s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1471 acc_val: 0.5167 loss_test: 1.4433 acc_test: 0.6900 time: 0.1710s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1923 acc_val: 0.5200 loss_test: 1.4810 acc_test: 0.6940 time: 0.2834s
Optimization Finished!
Total time elapsed: 105.5419s, best testing performance  0.699000, minimun loss  0.975786
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7980 acc_train: 0.1417 loss_val: 1.7900 acc_val: 0.1667 loss_test: 1.6867 acc_test: 0.5190 time: 0.1984s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.8122 acc_val: 0.3867 loss_test: 1.1929 acc_test: 0.6630 time: 0.1718s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8407 acc_val: 0.4167 loss_test: 1.2074 acc_test: 0.6740 time: 0.2490s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8880 acc_val: 0.4433 loss_test: 1.2469 acc_test: 0.6790 time: 0.2079s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9635 acc_val: 0.4600 loss_test: 1.2928 acc_test: 0.6860 time: 0.2429s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0321 acc_val: 0.4700 loss_test: 1.3347 acc_test: 0.6900 time: 0.2670s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1022 acc_val: 0.4767 loss_test: 1.3772 acc_test: 0.6920 time: 0.2698s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1442 acc_val: 0.4967 loss_test: 1.4091 acc_test: 0.6950 time: 0.1700s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1805 acc_val: 0.5033 loss_test: 1.4358 acc_test: 0.6940 time: 0.1751s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2187 acc_val: 0.5033 loss_test: 1.4629 acc_test: 0.6990 time: 0.2395s
Optimization Finished!
Total time elapsed: 105.8397s, best testing performance  0.699000, minimun loss  0.999722
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7944 acc_train: 0.2000 loss_val: 1.8087 acc_val: 0.1400 loss_test: 1.6811 acc_test: 0.4740 time: 0.2576s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.8067 acc_val: 0.3900 loss_test: 1.1491 acc_test: 0.6650 time: 0.2550s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8500 acc_val: 0.4333 loss_test: 1.1754 acc_test: 0.6770 time: 0.2407s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9287 acc_val: 0.4333 loss_test: 1.2299 acc_test: 0.6880 time: 0.2472s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0117 acc_val: 0.4500 loss_test: 1.2841 acc_test: 0.6880 time: 0.2265s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0654 acc_val: 0.4667 loss_test: 1.3256 acc_test: 0.6920 time: 0.2540s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1070 acc_val: 0.4767 loss_test: 1.3627 acc_test: 0.6910 time: 0.1710s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1549 acc_val: 0.4967 loss_test: 1.3981 acc_test: 0.6920 time: 0.1824s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1970 acc_val: 0.5033 loss_test: 1.4316 acc_test: 0.6930 time: 0.2252s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2335 acc_val: 0.5000 loss_test: 1.4589 acc_test: 0.6930 time: 0.2152s
Optimization Finished!
Total time elapsed: 109.8835s, best testing performance  0.695000, minimun loss  0.977799
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8022 acc_train: 0.1167 loss_val: 1.7942 acc_val: 0.1333 loss_test: 1.6786 acc_test: 0.4930 time: 0.2262s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7865 acc_val: 0.3867 loss_test: 1.1457 acc_test: 0.6610 time: 0.2394s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8303 acc_val: 0.4200 loss_test: 1.1808 acc_test: 0.6790 time: 0.2229s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9057 acc_val: 0.4433 loss_test: 1.2361 acc_test: 0.6850 time: 0.2473s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9432 acc_val: 0.4633 loss_test: 1.2735 acc_test: 0.6880 time: 0.2366s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9587 acc_val: 0.4767 loss_test: 1.3078 acc_test: 0.6880 time: 0.1703s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0331 acc_val: 0.4933 loss_test: 1.3558 acc_test: 0.6890 time: 0.1781s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0784 acc_val: 0.5000 loss_test: 1.3892 acc_test: 0.6940 time: 0.2348s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1240 acc_val: 0.5000 loss_test: 1.4224 acc_test: 0.6920 time: 0.2643s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1734 acc_val: 0.5033 loss_test: 1.4532 acc_test: 0.6970 time: 0.2426s
Optimization Finished!
Total time elapsed: 112.4702s, best testing performance  0.701000, minimun loss  0.962725
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7914 acc_train: 0.2000 loss_val: 1.7941 acc_val: 0.1900 loss_test: 1.6728 acc_test: 0.5040 time: 0.2540s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.6273 acc_val: 0.4400 loss_test: 1.1006 acc_test: 0.6780 time: 0.2338s
Epoch: 0101 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.6853 acc_val: 0.4733 loss_test: 1.1429 acc_test: 0.6870 time: 0.2535s
Epoch: 0151 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.8329 acc_val: 0.4667 loss_test: 1.2180 acc_test: 0.6930 time: 0.2526s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9394 acc_val: 0.4567 loss_test: 1.2766 acc_test: 0.6910 time: 0.1725s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0001 acc_val: 0.4767 loss_test: 1.3208 acc_test: 0.6900 time: 0.1840s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0683 acc_val: 0.5000 loss_test: 1.3636 acc_test: 0.6880 time: 0.2517s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1365 acc_val: 0.5033 loss_test: 1.4067 acc_test: 0.6900 time: 0.2230s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1510 acc_val: 0.5033 loss_test: 1.4286 acc_test: 0.6950 time: 0.2311s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2095 acc_val: 0.5000 loss_test: 1.4647 acc_test: 0.7000 time: 0.2477s
Optimization Finished!
Total time elapsed: 111.3503s, best testing performance  0.701000, minimun loss  0.971214
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7952 acc_train: 0.1167 loss_val: 1.8207 acc_val: 0.0600 loss_test: 1.6714 acc_test: 0.4110 time: 0.2376s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8447 acc_val: 0.3833 loss_test: 1.1847 acc_test: 0.6610 time: 0.2597s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8622 acc_val: 0.4133 loss_test: 1.1926 acc_test: 0.6730 time: 0.2297s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9479 acc_val: 0.4300 loss_test: 1.2432 acc_test: 0.6840 time: 0.1707s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0397 acc_val: 0.4400 loss_test: 1.2965 acc_test: 0.6860 time: 0.1699s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0642 acc_val: 0.4700 loss_test: 1.3305 acc_test: 0.6930 time: 0.2512s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0881 acc_val: 0.4967 loss_test: 1.3635 acc_test: 0.6910 time: 0.2327s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0863 acc_val: 0.5033 loss_test: 1.3945 acc_test: 0.6990 time: 0.2778s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1280 acc_val: 0.5067 loss_test: 1.4282 acc_test: 0.7030 time: 0.2145s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1236 acc_val: 0.5100 loss_test: 1.4476 acc_test: 0.7030 time: 0.1708s
Optimization Finished!
Total time elapsed: 107.2592s, best testing performance  0.707000, minimun loss  0.978393
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7837 acc_train: 0.2167 loss_val: 1.7869 acc_val: 0.2100 loss_test: 1.6747 acc_test: 0.4450 time: 0.2787s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8633 acc_val: 0.3767 loss_test: 1.1711 acc_test: 0.6640 time: 0.2208s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8447 acc_val: 0.4367 loss_test: 1.1891 acc_test: 0.6750 time: 0.1707s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9049 acc_val: 0.4433 loss_test: 1.2385 acc_test: 0.6790 time: 0.1695s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9964 acc_val: 0.4600 loss_test: 1.2903 acc_test: 0.6860 time: 0.2597s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0463 acc_val: 0.4767 loss_test: 1.3328 acc_test: 0.6930 time: 0.2045s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0630 acc_val: 0.5067 loss_test: 1.3659 acc_test: 0.6980 time: 0.2303s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1362 acc_val: 0.5000 loss_test: 1.4078 acc_test: 0.6960 time: 0.2433s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1734 acc_val: 0.5033 loss_test: 1.4364 acc_test: 0.7020 time: 0.1734s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1590 acc_val: 0.5033 loss_test: 1.4545 acc_test: 0.7000 time: 0.1715s
Optimization Finished!
Total time elapsed: 105.4325s, best testing performance  0.705000, minimun loss  0.995688
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8009 acc_train: 0.1333 loss_val: 1.8105 acc_val: 0.1500 loss_test: 1.6667 acc_test: 0.5160 time: 0.2218s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.9653 acc_val: 0.3633 loss_test: 1.2443 acc_test: 0.6530 time: 0.1702s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.9319 acc_val: 0.3967 loss_test: 1.2432 acc_test: 0.6670 time: 0.1712s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9902 acc_val: 0.4367 loss_test: 1.2843 acc_test: 0.6770 time: 0.2400s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0477 acc_val: 0.4600 loss_test: 1.3250 acc_test: 0.6850 time: 0.2593s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0942 acc_val: 0.4633 loss_test: 1.3666 acc_test: 0.6860 time: 0.2371s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1330 acc_val: 0.4733 loss_test: 1.4030 acc_test: 0.6920 time: 0.2196s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1917 acc_val: 0.4867 loss_test: 1.4382 acc_test: 0.6940 time: 0.2178s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2407 acc_val: 0.4900 loss_test: 1.4742 acc_test: 0.6960 time: 0.1737s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2440 acc_val: 0.5067 loss_test: 1.4938 acc_test: 0.6970 time: 0.1813s
Optimization Finished!
Total time elapsed: 105.8108s, best testing performance  0.699000, minimun loss  0.985502
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8022 acc_train: 0.1167 loss_val: 1.8278 acc_val: 0.0933 loss_test: 1.6773 acc_test: 0.4010 time: 0.2168s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8222 acc_val: 0.3967 loss_test: 1.1536 acc_test: 0.6710 time: 0.1804s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8966 acc_val: 0.4300 loss_test: 1.1951 acc_test: 0.6800 time: 0.1782s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9849 acc_val: 0.4467 loss_test: 1.2574 acc_test: 0.6860 time: 0.2310s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0797 acc_val: 0.4533 loss_test: 1.3127 acc_test: 0.6840 time: 0.2246s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1340 acc_val: 0.4667 loss_test: 1.3563 acc_test: 0.6870 time: 0.2454s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1804 acc_val: 0.4767 loss_test: 1.4003 acc_test: 0.6930 time: 0.2411s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2177 acc_val: 0.4900 loss_test: 1.4355 acc_test: 0.6940 time: 0.1772s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2238 acc_val: 0.5067 loss_test: 1.4643 acc_test: 0.6920 time: 0.1758s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2666 acc_val: 0.5067 loss_test: 1.4994 acc_test: 0.6910 time: 0.2145s
Optimization Finished!
Total time elapsed: 105.9365s, best testing performance  0.696000, minimun loss  0.972107
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7900 acc_train: 0.1417 loss_val: 1.8147 acc_val: 0.1667 loss_test: 1.6711 acc_test: 0.5070 time: 0.2167s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9723 acc_val: 0.3700 loss_test: 1.2160 acc_test: 0.6490 time: 0.1819s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8600 acc_val: 0.4200 loss_test: 1.1941 acc_test: 0.6780 time: 0.2587s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9170 acc_val: 0.4367 loss_test: 1.2465 acc_test: 0.6890 time: 0.2473s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9658 acc_val: 0.4600 loss_test: 1.2903 acc_test: 0.6880 time: 0.2462s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0190 acc_val: 0.4733 loss_test: 1.3315 acc_test: 0.6900 time: 0.2473s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0495 acc_val: 0.4933 loss_test: 1.3650 acc_test: 0.6970 time: 0.1720s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.5033 loss_test: 1.3989 acc_test: 0.7000 time: 0.1796s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1218 acc_val: 0.5033 loss_test: 1.4290 acc_test: 0.7020 time: 0.2476s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1492 acc_val: 0.5000 loss_test: 1.4570 acc_test: 0.7000 time: 0.2328s
Optimization Finished!
Total time elapsed: 109.3430s, best testing performance  0.703000, minimun loss  0.974939
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7943 acc_train: 0.1583 loss_val: 1.7922 acc_val: 0.1067 loss_test: 1.6640 acc_test: 0.4630 time: 0.2254s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8114 acc_val: 0.4033 loss_test: 1.1788 acc_test: 0.6620 time: 0.3139s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8190 acc_val: 0.4333 loss_test: 1.1922 acc_test: 0.6720 time: 0.2091s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8920 acc_val: 0.4567 loss_test: 1.2386 acc_test: 0.6830 time: 0.2223s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9813 acc_val: 0.4700 loss_test: 1.2876 acc_test: 0.6860 time: 0.2437s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0153 acc_val: 0.4800 loss_test: 1.3223 acc_test: 0.6910 time: 0.1712s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0394 acc_val: 0.4900 loss_test: 1.3543 acc_test: 0.6950 time: 0.1724s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0916 acc_val: 0.5067 loss_test: 1.3848 acc_test: 0.6960 time: 0.2263s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0980 acc_val: 0.5000 loss_test: 1.4102 acc_test: 0.6960 time: 0.2814s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1465 acc_val: 0.5167 loss_test: 1.4387 acc_test: 0.6990 time: 0.2286s
Optimization Finished!
Total time elapsed: 112.0664s, best testing performance  0.702000, minimun loss  0.975070
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7957 acc_train: 0.1917 loss_val: 1.8206 acc_val: 0.1733 loss_test: 1.6819 acc_test: 0.4560 time: 0.2261s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8055 acc_val: 0.4067 loss_test: 1.1711 acc_test: 0.6630 time: 0.2276s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8215 acc_val: 0.4200 loss_test: 1.1956 acc_test: 0.6730 time: 0.2746s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8907 acc_val: 0.4333 loss_test: 1.2465 acc_test: 0.6840 time: 0.2189s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0019 acc_val: 0.4567 loss_test: 1.2993 acc_test: 0.6860 time: 0.1709s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0237 acc_val: 0.4833 loss_test: 1.3283 acc_test: 0.6910 time: 0.1697s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0622 acc_val: 0.5000 loss_test: 1.3647 acc_test: 0.6930 time: 0.2230s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0848 acc_val: 0.5067 loss_test: 1.3946 acc_test: 0.6910 time: 0.2392s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1241 acc_val: 0.5033 loss_test: 1.4251 acc_test: 0.6940 time: 0.2393s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1775 acc_val: 0.5133 loss_test: 1.4598 acc_test: 0.6930 time: 0.2389s
Optimization Finished!
Total time elapsed: 111.0460s, best testing performance  0.695000, minimun loss  0.977407
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8014 acc_train: 0.1333 loss_val: 1.8086 acc_val: 0.1267 loss_test: 1.6812 acc_test: 0.4540 time: 0.2255s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8225 acc_val: 0.3933 loss_test: 1.1732 acc_test: 0.6640 time: 0.2513s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8307 acc_val: 0.4267 loss_test: 1.1900 acc_test: 0.6730 time: 0.2306s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8646 acc_val: 0.4567 loss_test: 1.2291 acc_test: 0.6800 time: 0.1709s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9163 acc_val: 0.4800 loss_test: 1.2754 acc_test: 0.6890 time: 0.1703s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9926 acc_val: 0.4867 loss_test: 1.3235 acc_test: 0.6940 time: 0.2249s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0129 acc_val: 0.4967 loss_test: 1.3554 acc_test: 0.6970 time: 0.2618s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0552 acc_val: 0.5067 loss_test: 1.3917 acc_test: 0.6980 time: 0.2298s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0699 acc_val: 0.5133 loss_test: 1.4189 acc_test: 0.7020 time: 0.2596s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0753 acc_val: 0.5167 loss_test: 1.4426 acc_test: 0.7040 time: 0.1702s
Optimization Finished!
Total time elapsed: 108.5538s, best testing performance  0.705000, minimun loss  0.981219
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7919 acc_train: 0.1917 loss_val: 1.8048 acc_val: 0.1933 loss_test: 1.6783 acc_test: 0.4080 time: 0.2413s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8538 acc_val: 0.3667 loss_test: 1.1999 acc_test: 0.6660 time: 0.2495s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8459 acc_val: 0.4300 loss_test: 1.2135 acc_test: 0.6730 time: 0.1711s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9310 acc_val: 0.4367 loss_test: 1.2631 acc_test: 0.6790 time: 0.1693s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9896 acc_val: 0.4667 loss_test: 1.3071 acc_test: 0.6850 time: 0.2548s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0359 acc_val: 0.4867 loss_test: 1.3426 acc_test: 0.6920 time: 0.2268s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0822 acc_val: 0.5000 loss_test: 1.3774 acc_test: 0.6960 time: 0.2881s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1270 acc_val: 0.5033 loss_test: 1.4136 acc_test: 0.6920 time: 0.2378s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1713 acc_val: 0.5067 loss_test: 1.4432 acc_test: 0.6940 time: 0.2266s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2166 acc_val: 0.5100 loss_test: 1.4759 acc_test: 0.6960 time: 0.1725s
Optimization Finished!
Total time elapsed: 107.5529s, best testing performance  0.699000, minimun loss  0.999781
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8016 acc_train: 0.1500 loss_val: 1.8095 acc_val: 0.1267 loss_test: 1.7005 acc_test: 0.4420 time: 0.2288s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8613 acc_val: 0.3733 loss_test: 1.2041 acc_test: 0.6550 time: 0.2297s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8556 acc_val: 0.4367 loss_test: 1.2050 acc_test: 0.6760 time: 0.1717s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9360 acc_val: 0.4600 loss_test: 1.2542 acc_test: 0.6830 time: 0.1691s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9983 acc_val: 0.4767 loss_test: 1.2993 acc_test: 0.6910 time: 0.1808s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0417 acc_val: 0.4767 loss_test: 1.3393 acc_test: 0.6940 time: 0.2606s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.5033 loss_test: 1.3733 acc_test: 0.6950 time: 0.2255s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1232 acc_val: 0.5033 loss_test: 1.4113 acc_test: 0.7020 time: 0.2229s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1850 acc_val: 0.5033 loss_test: 1.4510 acc_test: 0.7010 time: 0.2375s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2298 acc_val: 0.5033 loss_test: 1.4869 acc_test: 0.7040 time: 0.1711s
Optimization Finished!
Total time elapsed: 106.6958s, best testing performance  0.708000, minimun loss  1.002308
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8017 acc_train: 0.1750 loss_val: 1.8025 acc_val: 0.2000 loss_test: 1.6978 acc_test: 0.4490 time: 0.2445s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9352 acc_val: 0.3767 loss_test: 1.2283 acc_test: 0.6580 time: 0.2404s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8888 acc_val: 0.4133 loss_test: 1.2156 acc_test: 0.6730 time: 0.1723s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9590 acc_val: 0.4467 loss_test: 1.2610 acc_test: 0.6870 time: 0.1765s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9865 acc_val: 0.4633 loss_test: 1.2924 acc_test: 0.6910 time: 0.1796s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0195 acc_val: 0.4733 loss_test: 1.3286 acc_test: 0.6960 time: 0.2245s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0113 acc_val: 0.4933 loss_test: 1.3532 acc_test: 0.6970 time: 0.2703s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0257 acc_val: 0.5100 loss_test: 1.3796 acc_test: 0.6990 time: 0.2690s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0627 acc_val: 0.5100 loss_test: 1.4134 acc_test: 0.6970 time: 0.2249s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0953 acc_val: 0.5067 loss_test: 1.4379 acc_test: 0.6940 time: 0.1715s
Optimization Finished!
Total time elapsed: 107.7398s, best testing performance  0.702000, minimun loss  0.988787
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8016 acc_train: 0.1083 loss_val: 1.8012 acc_val: 0.1933 loss_test: 1.6951 acc_test: 0.5190 time: 0.2112s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8736 acc_val: 0.3700 loss_test: 1.2100 acc_test: 0.6540 time: 0.2256s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8099 acc_val: 0.4400 loss_test: 1.2035 acc_test: 0.6660 time: 0.1719s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9347 acc_val: 0.4267 loss_test: 1.2685 acc_test: 0.6790 time: 0.1703s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0155 acc_val: 0.4500 loss_test: 1.3147 acc_test: 0.6860 time: 0.1798s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0460 acc_val: 0.4733 loss_test: 1.3477 acc_test: 0.6900 time: 0.2222s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0943 acc_val: 0.4867 loss_test: 1.3820 acc_test: 0.6930 time: 0.2333s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1331 acc_val: 0.4967 loss_test: 1.4134 acc_test: 0.6920 time: 0.2343s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1516 acc_val: 0.5133 loss_test: 1.4341 acc_test: 0.6970 time: 0.2231s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1913 acc_val: 0.5033 loss_test: 1.4571 acc_test: 0.6950 time: 0.1715s
Optimization Finished!
Total time elapsed: 107.5146s, best testing performance  0.701000, minimun loss  0.966717
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7933 acc_train: 0.1333 loss_val: 1.8003 acc_val: 0.1833 loss_test: 1.6942 acc_test: 0.4720 time: 0.1988s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9370 acc_val: 0.3667 loss_test: 1.2378 acc_test: 0.6530 time: 0.2177s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8017 acc_val: 0.4333 loss_test: 1.2080 acc_test: 0.6680 time: 0.1702s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9292 acc_val: 0.4400 loss_test: 1.2717 acc_test: 0.6780 time: 0.1699s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9518 acc_val: 0.4533 loss_test: 1.2998 acc_test: 0.6890 time: 0.2131s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0343 acc_val: 0.4667 loss_test: 1.3437 acc_test: 0.6900 time: 0.2387s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0873 acc_val: 0.4833 loss_test: 1.3779 acc_test: 0.6920 time: 0.2470s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0993 acc_val: 0.5000 loss_test: 1.4081 acc_test: 0.6970 time: 0.2560s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1468 acc_val: 0.5067 loss_test: 1.4382 acc_test: 0.7000 time: 0.2497s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1838 acc_val: 0.4967 loss_test: 1.4669 acc_test: 0.7060 time: 0.1741s
Optimization Finished!
Total time elapsed: 107.7857s, best testing performance  0.706000, minimun loss  0.995651
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8028 acc_train: 0.1667 loss_val: 1.8021 acc_val: 0.0733 loss_test: 1.7116 acc_test: 0.3420 time: 0.2662s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.6816 acc_val: 0.4200 loss_test: 1.1417 acc_test: 0.6730 time: 0.2704s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7245 acc_val: 0.4600 loss_test: 1.1668 acc_test: 0.6820 time: 0.1703s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9945 acc_val: 0.4333 loss_test: 1.2719 acc_test: 0.6860 time: 0.1698s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0747 acc_val: 0.4567 loss_test: 1.3208 acc_test: 0.6930 time: 0.2459s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0959 acc_val: 0.4667 loss_test: 1.3523 acc_test: 0.6920 time: 0.2679s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0835 acc_val: 0.4800 loss_test: 1.3786 acc_test: 0.6950 time: 0.2193s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1824 acc_val: 0.4900 loss_test: 1.4230 acc_test: 0.6960 time: 0.2640s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2358 acc_val: 0.5033 loss_test: 1.4546 acc_test: 0.6940 time: 0.2874s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.3046 acc_val: 0.5000 loss_test: 1.4887 acc_test: 0.6890 time: 0.1742s
Optimization Finished!
Total time elapsed: 107.5661s, best testing performance  0.697000, minimun loss  0.980110
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7888 acc_train: 0.1917 loss_val: 1.8249 acc_val: 0.0867 loss_test: 1.6880 acc_test: 0.3940 time: 0.2652s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8230 acc_val: 0.3900 loss_test: 1.2289 acc_test: 0.6560 time: 0.2274s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8013 acc_val: 0.4233 loss_test: 1.2242 acc_test: 0.6710 time: 0.1709s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9145 acc_val: 0.4400 loss_test: 1.2799 acc_test: 0.6790 time: 0.1694s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9731 acc_val: 0.4533 loss_test: 1.3195 acc_test: 0.6880 time: 0.2320s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0033 acc_val: 0.4767 loss_test: 1.3488 acc_test: 0.6910 time: 0.3161s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0836 acc_val: 0.4767 loss_test: 1.3907 acc_test: 0.6900 time: 0.2173s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1216 acc_val: 0.5000 loss_test: 1.4186 acc_test: 0.6940 time: 0.2829s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1978 acc_val: 0.4933 loss_test: 1.4555 acc_test: 0.6950 time: 0.2514s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2376 acc_val: 0.4967 loss_test: 1.4812 acc_test: 0.6990 time: 0.1728s
Optimization Finished!
Total time elapsed: 107.4580s, best testing performance  0.704000, minimun loss  1.006438
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8059 acc_train: 0.2083 loss_val: 1.8169 acc_val: 0.1200 loss_test: 1.6878 acc_test: 0.4680 time: 0.2353s
Epoch: 0051 loss_train: 0.0128 acc_train: 1.0000 loss_val: 1.8416 acc_val: 0.4100 loss_test: 1.1484 acc_test: 0.6690 time: 0.2530s
Epoch: 0101 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8793 acc_val: 0.4433 loss_test: 1.1720 acc_test: 0.6800 time: 0.1697s
Epoch: 0151 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9131 acc_val: 0.4600 loss_test: 1.2153 acc_test: 0.6840 time: 0.1705s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9839 acc_val: 0.4700 loss_test: 1.2670 acc_test: 0.6860 time: 0.2304s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0506 acc_val: 0.4733 loss_test: 1.3147 acc_test: 0.6890 time: 0.2488s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0882 acc_val: 0.4900 loss_test: 1.3579 acc_test: 0.6910 time: 0.2152s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1349 acc_val: 0.4900 loss_test: 1.4022 acc_test: 0.6980 time: 0.2323s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.5000 loss_test: 1.4408 acc_test: 0.6990 time: 0.2168s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1998 acc_val: 0.5167 loss_test: 1.4760 acc_test: 0.6960 time: 0.1767s
Optimization Finished!
Total time elapsed: 106.9488s, best testing performance  0.704000, minimun loss  1.010139
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8168 acc_train: 0.1333 loss_val: 1.7786 acc_val: 0.2633 loss_test: 1.7052 acc_test: 0.4370 time: 0.2337s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8529 acc_val: 0.3833 loss_test: 1.1859 acc_test: 0.6580 time: 0.2688s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8120 acc_val: 0.4467 loss_test: 1.1850 acc_test: 0.6720 time: 0.1705s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8602 acc_val: 0.4533 loss_test: 1.2229 acc_test: 0.6840 time: 0.1701s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9546 acc_val: 0.4667 loss_test: 1.2742 acc_test: 0.6840 time: 0.2286s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0163 acc_val: 0.4633 loss_test: 1.3162 acc_test: 0.6940 time: 0.2594s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0816 acc_val: 0.4867 loss_test: 1.3652 acc_test: 0.6910 time: 0.2912s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1337 acc_val: 0.4967 loss_test: 1.4116 acc_test: 0.6910 time: 0.2274s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1877 acc_val: 0.5067 loss_test: 1.4607 acc_test: 0.6940 time: 0.1748s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2282 acc_val: 0.4933 loss_test: 1.5051 acc_test: 0.6960 time: 0.1809s
Optimization Finished!
Total time elapsed: 107.1280s, best testing performance  0.699000, minimun loss  1.033231
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8109 acc_train: 0.1417 loss_val: 1.8183 acc_val: 0.1600 loss_test: 1.6958 acc_test: 0.4820 time: 0.2877s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.7640 acc_val: 0.4067 loss_test: 1.1489 acc_test: 0.6670 time: 0.2478s
Epoch: 0101 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7886 acc_val: 0.4567 loss_test: 1.1644 acc_test: 0.6800 time: 0.1774s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8763 acc_val: 0.4600 loss_test: 1.2156 acc_test: 0.6830 time: 0.1777s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9697 acc_val: 0.4533 loss_test: 1.2725 acc_test: 0.6890 time: 0.2277s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0161 acc_val: 0.4667 loss_test: 1.3139 acc_test: 0.6910 time: 0.2321s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0652 acc_val: 0.4767 loss_test: 1.3557 acc_test: 0.6940 time: 0.2166s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1018 acc_val: 0.5067 loss_test: 1.3916 acc_test: 0.6970 time: 0.2258s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1174 acc_val: 0.5100 loss_test: 1.4213 acc_test: 0.6980 time: 0.1736s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1560 acc_val: 0.5067 loss_test: 1.4533 acc_test: 0.6970 time: 0.1796s
Optimization Finished!
Total time elapsed: 106.5758s, best testing performance  0.700000, minimun loss  1.014792
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7893 acc_train: 0.2000 loss_val: 1.8005 acc_val: 0.2033 loss_test: 1.6803 acc_test: 0.5450 time: 0.2370s
Epoch: 0051 loss_train: 0.0137 acc_train: 1.0000 loss_val: 1.8051 acc_val: 0.3900 loss_test: 1.1644 acc_test: 0.6650 time: 0.2502s
Epoch: 0101 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8159 acc_val: 0.4400 loss_test: 1.1801 acc_test: 0.6730 time: 0.1703s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8775 acc_val: 0.4433 loss_test: 1.2264 acc_test: 0.6810 time: 0.1828s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9763 acc_val: 0.4533 loss_test: 1.2778 acc_test: 0.6860 time: 0.2303s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0265 acc_val: 0.4700 loss_test: 1.3154 acc_test: 0.6890 time: 0.2328s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0833 acc_val: 0.4800 loss_test: 1.3550 acc_test: 0.6900 time: 0.2302s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1117 acc_val: 0.4900 loss_test: 1.3866 acc_test: 0.6930 time: 0.2653s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1212 acc_val: 0.5000 loss_test: 1.4124 acc_test: 0.7000 time: 0.1717s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1795 acc_val: 0.5100 loss_test: 1.4458 acc_test: 0.6980 time: 0.1756s
Optimization Finished!
Total time elapsed: 105.8590s, best testing performance  0.702000, minimun loss  1.007481
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8124 acc_train: 0.1833 loss_val: 1.7943 acc_val: 0.2033 loss_test: 1.7063 acc_test: 0.3870 time: 0.2551s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.9101 acc_val: 0.3633 loss_test: 1.1948 acc_test: 0.6500 time: 0.1701s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8951 acc_val: 0.4067 loss_test: 1.1996 acc_test: 0.6630 time: 0.1703s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9177 acc_val: 0.4300 loss_test: 1.2300 acc_test: 0.6750 time: 0.2277s
Epoch: 0201 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9787 acc_val: 0.4433 loss_test: 1.2693 acc_test: 0.6880 time: 0.2400s
Epoch: 0251 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0127 acc_val: 0.4633 loss_test: 1.3021 acc_test: 0.6890 time: 0.2252s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0521 acc_val: 0.4767 loss_test: 1.3373 acc_test: 0.6900 time: 0.2486s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0872 acc_val: 0.5033 loss_test: 1.3704 acc_test: 0.6940 time: 0.2520s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1179 acc_val: 0.5100 loss_test: 1.3998 acc_test: 0.6930 time: 0.1742s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1394 acc_val: 0.4967 loss_test: 1.4273 acc_test: 0.6920 time: 0.1757s
Optimization Finished!
Total time elapsed: 106.6190s, best testing performance  0.696000, minimun loss  1.021222
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8006 acc_train: 0.1500 loss_val: 1.7999 acc_val: 0.1867 loss_test: 1.6605 acc_test: 0.5100 time: 0.2525s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6745 acc_val: 0.4333 loss_test: 1.1381 acc_test: 0.6790 time: 0.1711s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7417 acc_val: 0.4667 loss_test: 1.1691 acc_test: 0.6880 time: 0.1698s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8848 acc_val: 0.4767 loss_test: 1.2453 acc_test: 0.6970 time: 0.2738s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0163 acc_val: 0.4533 loss_test: 1.3070 acc_test: 0.6880 time: 0.2200s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0851 acc_val: 0.4567 loss_test: 1.3563 acc_test: 0.6930 time: 0.2396s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1598 acc_val: 0.4833 loss_test: 1.4058 acc_test: 0.6990 time: 0.2605s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2088 acc_val: 0.4867 loss_test: 1.4424 acc_test: 0.6960 time: 0.2556s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2212 acc_val: 0.4933 loss_test: 1.4705 acc_test: 0.6940 time: 0.1741s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2645 acc_val: 0.5067 loss_test: 1.5058 acc_test: 0.6930 time: 0.1759s
Optimization Finished!
Total time elapsed: 106.6477s, best testing performance  0.705000, minimun loss  0.941714
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7954 acc_train: 0.1583 loss_val: 1.8080 acc_val: 0.2067 loss_test: 1.6515 acc_test: 0.5260 time: 0.2209s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6850 acc_val: 0.4400 loss_test: 1.1614 acc_test: 0.6760 time: 0.1709s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7428 acc_val: 0.4600 loss_test: 1.1990 acc_test: 0.6810 time: 0.1694s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8412 acc_val: 0.4567 loss_test: 1.2647 acc_test: 0.6910 time: 0.2360s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0223 acc_val: 0.4533 loss_test: 1.3397 acc_test: 0.6830 time: 0.2779s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0792 acc_val: 0.4667 loss_test: 1.3778 acc_test: 0.6890 time: 0.2370s
Epoch: 0301 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1238 acc_val: 0.4767 loss_test: 1.4226 acc_test: 0.6950 time: 0.2269s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1533 acc_val: 0.4933 loss_test: 1.4545 acc_test: 0.6970 time: 0.2444s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1494 acc_val: 0.5067 loss_test: 1.4863 acc_test: 0.6960 time: 0.1739s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1813 acc_val: 0.5067 loss_test: 1.5160 acc_test: 0.6950 time: 0.1797s
Optimization Finished!
Total time elapsed: 105.6613s, best testing performance  0.701000, minimun loss  0.969175
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8006 acc_train: 0.1333 loss_val: 1.8020 acc_val: 0.1667 loss_test: 1.6570 acc_test: 0.4080 time: 0.2317s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.5859 acc_val: 0.4767 loss_test: 1.1401 acc_test: 0.6900 time: 0.1707s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.6992 acc_val: 0.4867 loss_test: 1.1889 acc_test: 0.6950 time: 0.1707s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8808 acc_val: 0.4767 loss_test: 1.2705 acc_test: 0.6990 time: 0.2357s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0271 acc_val: 0.4733 loss_test: 1.3295 acc_test: 0.6970 time: 0.2328s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1018 acc_val: 0.4733 loss_test: 1.3673 acc_test: 0.6950 time: 0.2398s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1219 acc_val: 0.4867 loss_test: 1.4012 acc_test: 0.6940 time: 0.2305s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1235 acc_val: 0.5000 loss_test: 1.4275 acc_test: 0.6960 time: 0.1779s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1746 acc_val: 0.5100 loss_test: 1.4598 acc_test: 0.6950 time: 0.1756s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1917 acc_val: 0.5067 loss_test: 1.4830 acc_test: 0.6940 time: 0.1794s
Optimization Finished!
Total time elapsed: 105.8443s, best testing performance  0.701000, minimun loss  0.975191
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7850 acc_train: 0.2083 loss_val: 1.8221 acc_val: 0.1467 loss_test: 1.6603 acc_test: 0.5050 time: 0.2583s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.5903 acc_val: 0.4633 loss_test: 1.1308 acc_test: 0.6880 time: 0.1733s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.6664 acc_val: 0.4933 loss_test: 1.1736 acc_test: 0.6870 time: 0.1774s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8188 acc_val: 0.5000 loss_test: 1.2510 acc_test: 0.6950 time: 0.2220s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9587 acc_val: 0.4767 loss_test: 1.3118 acc_test: 0.6960 time: 0.2450s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0127 acc_val: 0.4900 loss_test: 1.3516 acc_test: 0.6940 time: 0.2454s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0782 acc_val: 0.4833 loss_test: 1.3878 acc_test: 0.6940 time: 0.2351s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1377 acc_val: 0.4933 loss_test: 1.4228 acc_test: 0.6950 time: 0.1745s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1047 acc_val: 0.5100 loss_test: 1.4355 acc_test: 0.6980 time: 0.1726s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1183 acc_val: 0.5167 loss_test: 1.4592 acc_test: 0.7020 time: 0.2005s
Optimization Finished!
Total time elapsed: 105.8220s, best testing performance  0.706000, minimun loss  0.960213
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1750 loss_val: 1.8297 acc_val: 0.1567 loss_test: 1.6746 acc_test: 0.5410 time: 0.2371s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7411 acc_val: 0.4467 loss_test: 1.1810 acc_test: 0.6760 time: 0.1711s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8212 acc_val: 0.4367 loss_test: 1.2224 acc_test: 0.6810 time: 0.1743s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9661 acc_val: 0.4467 loss_test: 1.2946 acc_test: 0.6810 time: 0.2644s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0520 acc_val: 0.4700 loss_test: 1.3383 acc_test: 0.6890 time: 0.2190s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1009 acc_val: 0.4700 loss_test: 1.3754 acc_test: 0.6880 time: 0.2431s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0845 acc_val: 0.4900 loss_test: 1.3971 acc_test: 0.6940 time: 0.2398s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1197 acc_val: 0.5067 loss_test: 1.4245 acc_test: 0.6980 time: 0.1747s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1626 acc_val: 0.5033 loss_test: 1.4545 acc_test: 0.6980 time: 0.1723s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1924 acc_val: 0.5067 loss_test: 1.4800 acc_test: 0.6970 time: 0.2345s
Optimization Finished!
Total time elapsed: 106.1132s, best testing performance  0.703000, minimun loss  0.974086
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8090 acc_train: 0.1917 loss_val: 1.8074 acc_val: 0.0600 loss_test: 1.6754 acc_test: 0.3660 time: 0.2002s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8563 acc_val: 0.3933 loss_test: 1.1841 acc_test: 0.6670 time: 0.1694s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9333 acc_val: 0.4267 loss_test: 1.2201 acc_test: 0.6790 time: 0.1798s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9734 acc_val: 0.4400 loss_test: 1.2568 acc_test: 0.6870 time: 0.2237s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0183 acc_val: 0.4600 loss_test: 1.2976 acc_test: 0.6890 time: 0.2310s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0467 acc_val: 0.4733 loss_test: 1.3367 acc_test: 0.6910 time: 0.2286s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0676 acc_val: 0.4900 loss_test: 1.3721 acc_test: 0.6930 time: 0.2323s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1154 acc_val: 0.5067 loss_test: 1.4124 acc_test: 0.6940 time: 0.1747s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1761 acc_val: 0.5067 loss_test: 1.4504 acc_test: 0.6920 time: 0.1717s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2057 acc_val: 0.5067 loss_test: 1.4776 acc_test: 0.6960 time: 0.2266s
Optimization Finished!
Total time elapsed: 106.2076s, best testing performance  0.701000, minimun loss  1.000798
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7946 acc_train: 0.1167 loss_val: 1.8201 acc_val: 0.1600 loss_test: 1.6471 acc_test: 0.5310 time: 0.2712s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6997 acc_val: 0.4267 loss_test: 1.1367 acc_test: 0.6760 time: 0.1697s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8537 acc_val: 0.4433 loss_test: 1.1989 acc_test: 0.6890 time: 0.2468s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9145 acc_val: 0.4633 loss_test: 1.2494 acc_test: 0.6930 time: 0.2242s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9840 acc_val: 0.4700 loss_test: 1.2954 acc_test: 0.6940 time: 0.2314s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9880 acc_val: 0.4967 loss_test: 1.3245 acc_test: 0.6960 time: 0.2569s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0370 acc_val: 0.5067 loss_test: 1.3619 acc_test: 0.6950 time: 0.2380s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0651 acc_val: 0.5033 loss_test: 1.3905 acc_test: 0.6970 time: 0.1722s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0884 acc_val: 0.5133 loss_test: 1.4132 acc_test: 0.6970 time: 0.1844s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1054 acc_val: 0.5200 loss_test: 1.4386 acc_test: 0.6970 time: 0.2330s
Optimization Finished!
Total time elapsed: 106.9952s, best testing performance  0.701000, minimun loss  0.990593
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8063 acc_train: 0.1000 loss_val: 1.8200 acc_val: 0.1733 loss_test: 1.6778 acc_test: 0.4860 time: 0.2263s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8292 acc_val: 0.3967 loss_test: 1.1741 acc_test: 0.6750 time: 0.1697s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8632 acc_val: 0.4467 loss_test: 1.2092 acc_test: 0.6790 time: 0.2164s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9065 acc_val: 0.4667 loss_test: 1.2494 acc_test: 0.6920 time: 0.2585s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9483 acc_val: 0.4767 loss_test: 1.2868 acc_test: 0.6910 time: 0.2271s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0153 acc_val: 0.4900 loss_test: 1.3325 acc_test: 0.6920 time: 0.2637s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0312 acc_val: 0.4967 loss_test: 1.3641 acc_test: 0.6910 time: 0.2318s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0622 acc_val: 0.5067 loss_test: 1.4009 acc_test: 0.6960 time: 0.1758s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0688 acc_val: 0.5133 loss_test: 1.4267 acc_test: 0.6940 time: 0.1770s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0969 acc_val: 0.5167 loss_test: 1.4515 acc_test: 0.6950 time: 0.2435s
Optimization Finished!
Total time elapsed: 107.8072s, best testing performance  0.698000, minimun loss  0.986822
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7798 acc_train: 0.2000 loss_val: 1.8450 acc_val: 0.0667 loss_test: 1.6652 acc_test: 0.4320 time: 0.2294s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7887 acc_val: 0.4033 loss_test: 1.1584 acc_test: 0.6640 time: 0.1764s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9181 acc_val: 0.4167 loss_test: 1.2171 acc_test: 0.6800 time: 0.2379s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9501 acc_val: 0.4533 loss_test: 1.2547 acc_test: 0.6940 time: 0.2245s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9829 acc_val: 0.4767 loss_test: 1.2962 acc_test: 0.6960 time: 0.2151s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9945 acc_val: 0.4767 loss_test: 1.3356 acc_test: 0.6940 time: 0.2471s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0182 acc_val: 0.5167 loss_test: 1.3721 acc_test: 0.6960 time: 0.1715s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0613 acc_val: 0.5267 loss_test: 1.4131 acc_test: 0.7010 time: 0.1741s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1105 acc_val: 0.5267 loss_test: 1.4531 acc_test: 0.6990 time: 0.1957s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1610 acc_val: 0.5233 loss_test: 1.4903 acc_test: 0.6990 time: 0.2294s
Optimization Finished!
Total time elapsed: 108.0017s, best testing performance  0.702000, minimun loss  1.017426
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 20, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7835 acc_train: 0.2333 loss_val: 1.8062 acc_val: 0.1633 loss_test: 1.6540 acc_test: 0.5270 time: 0.2315s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8342 acc_val: 0.4000 loss_test: 1.1665 acc_test: 0.6710 time: 0.1810s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9075 acc_val: 0.4333 loss_test: 1.2069 acc_test: 0.6810 time: 0.2356s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9624 acc_val: 0.4467 loss_test: 1.2539 acc_test: 0.6870 time: 0.2373s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0134 acc_val: 0.4700 loss_test: 1.2986 acc_test: 0.6890 time: 0.2357s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0635 acc_val: 0.4767 loss_test: 1.3393 acc_test: 0.6900 time: 0.2653s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0992 acc_val: 0.5067 loss_test: 1.3789 acc_test: 0.6930 time: 0.1727s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.4967 loss_test: 1.4103 acc_test: 0.6960 time: 0.1723s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1599 acc_val: 0.5067 loss_test: 1.4400 acc_test: 0.6970 time: 0.2441s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1804 acc_val: 0.5133 loss_test: 1.4634 acc_test: 0.6990 time: 0.2898s
Optimization Finished!
Total time elapsed: 109.4718s, best testing performance  0.703000, minimun loss  0.987648
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.1667 loss_val: 1.8216 acc_val: 0.1500 loss_test: 1.6517 acc_test: 0.4890 time: 0.2478s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.9063 acc_val: 0.3800 loss_test: 1.1603 acc_test: 0.6680 time: 0.2650s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7909 acc_val: 0.4367 loss_test: 1.1373 acc_test: 0.6870 time: 0.3165s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9143 acc_val: 0.4333 loss_test: 1.2195 acc_test: 0.6910 time: 0.2836s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0391 acc_val: 0.4533 loss_test: 1.3062 acc_test: 0.6880 time: 0.2839s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0753 acc_val: 0.4633 loss_test: 1.3455 acc_test: 0.6920 time: 0.1997s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1217 acc_val: 0.4800 loss_test: 1.3846 acc_test: 0.6940 time: 0.2157s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1540 acc_val: 0.5067 loss_test: 1.4120 acc_test: 0.6880 time: 0.2794s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2130 acc_val: 0.5033 loss_test: 1.4435 acc_test: 0.6900 time: 0.2994s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2398 acc_val: 0.5067 loss_test: 1.4661 acc_test: 0.6930 time: 0.2645s
Optimization Finished!
Total time elapsed: 132.4220s, best testing performance  0.697000, minimun loss  0.951071
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7786 acc_train: 0.2167 loss_val: 1.8633 acc_val: 0.0633 loss_test: 1.6615 acc_test: 0.4120 time: 0.2644s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.9395 acc_val: 0.3600 loss_test: 1.1758 acc_test: 0.6700 time: 0.2721s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8201 acc_val: 0.4267 loss_test: 1.1405 acc_test: 0.6790 time: 0.2618s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8908 acc_val: 0.4300 loss_test: 1.1950 acc_test: 0.6830 time: 0.2028s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1127 acc_val: 0.4400 loss_test: 1.3302 acc_test: 0.6830 time: 0.2068s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1911 acc_val: 0.4633 loss_test: 1.3895 acc_test: 0.6860 time: 0.2561s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.2328 acc_val: 0.4733 loss_test: 1.4288 acc_test: 0.6830 time: 0.3339s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.3025 acc_val: 0.4900 loss_test: 1.4718 acc_test: 0.6850 time: 0.2648s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.3198 acc_val: 0.4933 loss_test: 1.4981 acc_test: 0.6860 time: 0.2087s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.3615 acc_val: 0.4967 loss_test: 1.5216 acc_test: 0.6870 time: 0.2029s
Optimization Finished!
Total time elapsed: 127.2699s, best testing performance  0.691000, minimun loss  0.958788
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7927 acc_train: 0.0917 loss_val: 1.8620 acc_val: 0.0500 loss_test: 1.6708 acc_test: 0.3300 time: 0.2546s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.9291 acc_val: 0.3667 loss_test: 1.1904 acc_test: 0.6590 time: 0.2033s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8866 acc_val: 0.4200 loss_test: 1.1817 acc_test: 0.6760 time: 0.2146s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0051 acc_val: 0.4167 loss_test: 1.2511 acc_test: 0.6800 time: 0.3010s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1449 acc_val: 0.4533 loss_test: 1.3434 acc_test: 0.6840 time: 0.2856s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1565 acc_val: 0.4800 loss_test: 1.3707 acc_test: 0.6880 time: 0.3004s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1801 acc_val: 0.4833 loss_test: 1.4045 acc_test: 0.6910 time: 0.2845s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1840 acc_val: 0.4967 loss_test: 1.4222 acc_test: 0.6910 time: 0.2096s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2240 acc_val: 0.5000 loss_test: 1.4543 acc_test: 0.6950 time: 0.2852s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2190 acc_val: 0.5133 loss_test: 1.4725 acc_test: 0.6950 time: 0.2887s
Optimization Finished!
Total time elapsed: 127.4403s, best testing performance  0.699000, minimun loss  0.982790
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8140 acc_train: 0.0833 loss_val: 1.7935 acc_val: 0.1967 loss_test: 1.6866 acc_test: 0.4270 time: 0.2494s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8616 acc_val: 0.3733 loss_test: 1.1475 acc_test: 0.6650 time: 0.3069s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8654 acc_val: 0.4167 loss_test: 1.1627 acc_test: 0.6770 time: 0.2887s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9457 acc_val: 0.4233 loss_test: 1.2253 acc_test: 0.6810 time: 0.2645s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0166 acc_val: 0.4433 loss_test: 1.2916 acc_test: 0.6870 time: 0.2746s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0763 acc_val: 0.4633 loss_test: 1.3392 acc_test: 0.6940 time: 0.2010s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0497 acc_val: 0.4900 loss_test: 1.3603 acc_test: 0.6950 time: 0.2406s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0586 acc_val: 0.5167 loss_test: 1.3894 acc_test: 0.6980 time: 0.2803s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0906 acc_val: 0.5167 loss_test: 1.4213 acc_test: 0.7000 time: 0.3312s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0844 acc_val: 0.5200 loss_test: 1.4384 acc_test: 0.7000 time: 0.2969s
Optimization Finished!
Total time elapsed: 131.7913s, best testing performance  0.702000, minimun loss  0.957363
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7923 acc_train: 0.1417 loss_val: 1.8538 acc_val: 0.0600 loss_test: 1.6589 acc_test: 0.3670 time: 0.2639s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.9574 acc_val: 0.3600 loss_test: 1.1944 acc_test: 0.6640 time: 0.2549s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8064 acc_val: 0.4200 loss_test: 1.1598 acc_test: 0.6810 time: 0.2545s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9177 acc_val: 0.4133 loss_test: 1.2392 acc_test: 0.6800 time: 0.2027s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0506 acc_val: 0.4567 loss_test: 1.3267 acc_test: 0.6850 time: 0.2056s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1099 acc_val: 0.4767 loss_test: 1.3745 acc_test: 0.6890 time: 0.3077s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1692 acc_val: 0.4867 loss_test: 1.4068 acc_test: 0.6900 time: 0.2937s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2357 acc_val: 0.4933 loss_test: 1.4385 acc_test: 0.6930 time: 0.2682s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2473 acc_val: 0.4967 loss_test: 1.4641 acc_test: 0.6900 time: 0.2106s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2789 acc_val: 0.4933 loss_test: 1.4839 acc_test: 0.6900 time: 0.2043s
Optimization Finished!
Total time elapsed: 127.1950s, best testing performance  0.695000, minimun loss  0.971922
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.1417 loss_val: 1.8015 acc_val: 0.1467 loss_test: 1.6768 acc_test: 0.4820 time: 0.2892s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7953 acc_val: 0.3600 loss_test: 1.1626 acc_test: 0.6550 time: 0.2019s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8035 acc_val: 0.3933 loss_test: 1.1713 acc_test: 0.6700 time: 0.1994s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9939 acc_val: 0.3967 loss_test: 1.2669 acc_test: 0.6740 time: 0.3476s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0531 acc_val: 0.4433 loss_test: 1.3162 acc_test: 0.6830 time: 0.2566s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0813 acc_val: 0.4633 loss_test: 1.3514 acc_test: 0.6880 time: 0.2853s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0845 acc_val: 0.4967 loss_test: 1.3752 acc_test: 0.6930 time: 0.3231s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1137 acc_val: 0.5100 loss_test: 1.4040 acc_test: 0.6940 time: 0.2123s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1489 acc_val: 0.5100 loss_test: 1.4302 acc_test: 0.6950 time: 0.2058s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1811 acc_val: 0.5067 loss_test: 1.4580 acc_test: 0.6920 time: 0.2685s
Optimization Finished!
Total time elapsed: 127.0630s, best testing performance  0.700000, minimun loss  0.971086
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8037 acc_train: 0.1333 loss_val: 1.7987 acc_val: 0.1533 loss_test: 1.6909 acc_test: 0.4630 time: 0.2652s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8903 acc_val: 0.3467 loss_test: 1.1630 acc_test: 0.6570 time: 0.2004s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7968 acc_val: 0.3867 loss_test: 1.1493 acc_test: 0.6800 time: 0.2668s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9008 acc_val: 0.4233 loss_test: 1.2223 acc_test: 0.6800 time: 0.2508s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0888 acc_val: 0.4300 loss_test: 1.3141 acc_test: 0.6840 time: 0.3043s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1131 acc_val: 0.4600 loss_test: 1.3551 acc_test: 0.6870 time: 0.2626s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1018 acc_val: 0.4767 loss_test: 1.3747 acc_test: 0.6900 time: 0.2041s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1267 acc_val: 0.5033 loss_test: 1.4090 acc_test: 0.6880 time: 0.2097s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1431 acc_val: 0.5033 loss_test: 1.4322 acc_test: 0.6900 time: 0.3072s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1725 acc_val: 0.5100 loss_test: 1.4624 acc_test: 0.6940 time: 0.2627s
Optimization Finished!
Total time elapsed: 128.4414s, best testing performance  0.695000, minimun loss  0.972635
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.1667 loss_val: 1.8366 acc_val: 0.0733 loss_test: 1.6784 acc_test: 0.3800 time: 0.2637s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7147 acc_val: 0.3967 loss_test: 1.0971 acc_test: 0.6680 time: 0.3055s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8278 acc_val: 0.4067 loss_test: 1.1603 acc_test: 0.6780 time: 0.3005s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8369 acc_val: 0.4400 loss_test: 1.2050 acc_test: 0.6910 time: 0.2618s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9953 acc_val: 0.4567 loss_test: 1.2939 acc_test: 0.6890 time: 0.3247s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0367 acc_val: 0.4667 loss_test: 1.3284 acc_test: 0.6920 time: 0.2017s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0382 acc_val: 0.4833 loss_test: 1.3575 acc_test: 0.6920 time: 0.2001s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1134 acc_val: 0.4967 loss_test: 1.4046 acc_test: 0.6930 time: 0.2665s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1515 acc_val: 0.5000 loss_test: 1.4332 acc_test: 0.6940 time: 0.2917s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1819 acc_val: 0.5133 loss_test: 1.4646 acc_test: 0.6920 time: 0.2818s
Optimization Finished!
Total time elapsed: 131.7554s, best testing performance  0.698000, minimun loss  0.983295
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7825 acc_train: 0.2000 loss_val: 1.8013 acc_val: 0.1400 loss_test: 1.6815 acc_test: 0.5090 time: 0.2544s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8869 acc_val: 0.3733 loss_test: 1.1700 acc_test: 0.6640 time: 0.2785s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7824 acc_val: 0.4100 loss_test: 1.1597 acc_test: 0.6800 time: 0.2973s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8429 acc_val: 0.4433 loss_test: 1.2278 acc_test: 0.6870 time: 0.2647s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9807 acc_val: 0.4700 loss_test: 1.3036 acc_test: 0.6900 time: 0.2007s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0673 acc_val: 0.4633 loss_test: 1.3590 acc_test: 0.6950 time: 0.1997s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1163 acc_val: 0.4867 loss_test: 1.3990 acc_test: 0.6930 time: 0.2859s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1867 acc_val: 0.4900 loss_test: 1.4415 acc_test: 0.6920 time: 0.3137s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2273 acc_val: 0.5000 loss_test: 1.4698 acc_test: 0.6910 time: 0.3112s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2444 acc_val: 0.5000 loss_test: 1.4893 acc_test: 0.6920 time: 0.2875s
Optimization Finished!
Total time elapsed: 132.1318s, best testing performance  0.695000, minimun loss  0.982366
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7861 acc_train: 0.2000 loss_val: 1.8122 acc_val: 0.1200 loss_test: 1.6673 acc_test: 0.4990 time: 0.2829s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7155 acc_val: 0.4000 loss_test: 1.1177 acc_test: 0.6700 time: 0.3043s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7823 acc_val: 0.4067 loss_test: 1.1542 acc_test: 0.6790 time: 0.3035s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9962 acc_val: 0.4100 loss_test: 1.2573 acc_test: 0.6740 time: 0.2013s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.1044 acc_val: 0.4433 loss_test: 1.3300 acc_test: 0.6820 time: 0.1981s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0828 acc_val: 0.4800 loss_test: 1.3508 acc_test: 0.6940 time: 0.2789s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1165 acc_val: 0.4767 loss_test: 1.3843 acc_test: 0.6940 time: 0.2849s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1341 acc_val: 0.5000 loss_test: 1.4154 acc_test: 0.6970 time: 0.2888s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1689 acc_val: 0.5067 loss_test: 1.4443 acc_test: 0.6980 time: 0.2861s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1615 acc_val: 0.5167 loss_test: 1.4680 acc_test: 0.7020 time: 0.2038s
Optimization Finished!
Total time elapsed: 128.7395s, best testing performance  0.707000, minimun loss  0.970127
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7925 acc_train: 0.1417 loss_val: 1.8148 acc_val: 0.0700 loss_test: 1.7165 acc_test: 0.4220 time: 0.2745s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8392 acc_val: 0.3800 loss_test: 1.1688 acc_test: 0.6690 time: 0.2758s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8907 acc_val: 0.4167 loss_test: 1.2086 acc_test: 0.6770 time: 0.2007s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0170 acc_val: 0.4367 loss_test: 1.2782 acc_test: 0.6870 time: 0.1998s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0304 acc_val: 0.4700 loss_test: 1.3106 acc_test: 0.6940 time: 0.2988s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0760 acc_val: 0.4700 loss_test: 1.3464 acc_test: 0.6960 time: 0.2918s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1231 acc_val: 0.4867 loss_test: 1.3886 acc_test: 0.6970 time: 0.2813s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1761 acc_val: 0.4867 loss_test: 1.4267 acc_test: 0.6960 time: 0.2799s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2153 acc_val: 0.4967 loss_test: 1.4597 acc_test: 0.7030 time: 0.2078s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.3071 acc_val: 0.4967 loss_test: 1.5047 acc_test: 0.7030 time: 0.2011s
Optimization Finished!
Total time elapsed: 126.9060s, best testing performance  0.706000, minimun loss  0.953369
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8004 acc_train: 0.1500 loss_val: 1.7924 acc_val: 0.1900 loss_test: 1.7126 acc_test: 0.4670 time: 0.2771s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7776 acc_val: 0.3833 loss_test: 1.1747 acc_test: 0.6670 time: 0.2004s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7855 acc_val: 0.4100 loss_test: 1.2005 acc_test: 0.6780 time: 0.1996s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9379 acc_val: 0.4300 loss_test: 1.2770 acc_test: 0.6740 time: 0.2691s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9974 acc_val: 0.4600 loss_test: 1.3234 acc_test: 0.6830 time: 0.2628s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0205 acc_val: 0.4867 loss_test: 1.3555 acc_test: 0.6890 time: 0.3013s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0832 acc_val: 0.4833 loss_test: 1.3966 acc_test: 0.6940 time: 0.2675s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1044 acc_val: 0.5000 loss_test: 1.4276 acc_test: 0.7010 time: 0.2130s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1453 acc_val: 0.5133 loss_test: 1.4613 acc_test: 0.7030 time: 0.2056s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2064 acc_val: 0.5100 loss_test: 1.4970 acc_test: 0.7040 time: 0.2995s
Optimization Finished!
Total time elapsed: 126.3576s, best testing performance  0.707000, minimun loss  0.969622
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7750 acc_train: 0.3000 loss_val: 1.7957 acc_val: 0.0667 loss_test: 1.6849 acc_test: 0.4020 time: 0.2580s
Epoch: 0051 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9015 acc_val: 0.3733 loss_test: 1.2091 acc_test: 0.6610 time: 0.1999s
Epoch: 0101 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8514 acc_val: 0.4200 loss_test: 1.2086 acc_test: 0.6780 time: 0.3032s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0115 acc_val: 0.4367 loss_test: 1.2877 acc_test: 0.6780 time: 0.3063s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1084 acc_val: 0.4533 loss_test: 1.3448 acc_test: 0.6850 time: 0.2854s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1332 acc_val: 0.4833 loss_test: 1.3735 acc_test: 0.6920 time: 0.2811s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1553 acc_val: 0.4967 loss_test: 1.3994 acc_test: 0.6950 time: 0.2011s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2238 acc_val: 0.4933 loss_test: 1.4383 acc_test: 0.6950 time: 0.2099s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2289 acc_val: 0.4933 loss_test: 1.4595 acc_test: 0.6940 time: 0.2823s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2516 acc_val: 0.5067 loss_test: 1.4793 acc_test: 0.6970 time: 0.2853s
Optimization Finished!
Total time elapsed: 128.1907s, best testing performance  0.701000, minimun loss  0.967400
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.1750 loss_val: 1.8126 acc_val: 0.2000 loss_test: 1.6985 acc_test: 0.4880 time: 0.2527s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.6698 acc_val: 0.4167 loss_test: 1.1233 acc_test: 0.6750 time: 0.2857s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7068 acc_val: 0.4467 loss_test: 1.1543 acc_test: 0.6930 time: 0.2856s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8697 acc_val: 0.4533 loss_test: 1.2371 acc_test: 0.6970 time: 0.2919s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9804 acc_val: 0.4800 loss_test: 1.3047 acc_test: 0.6960 time: 0.2858s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0396 acc_val: 0.4867 loss_test: 1.3483 acc_test: 0.6980 time: 0.2053s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0604 acc_val: 0.4867 loss_test: 1.3841 acc_test: 0.6970 time: 0.2101s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0598 acc_val: 0.5000 loss_test: 1.4083 acc_test: 0.7020 time: 0.3035s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0919 acc_val: 0.5000 loss_test: 1.4413 acc_test: 0.7010 time: 0.2828s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0977 acc_val: 0.5033 loss_test: 1.4630 acc_test: 0.7010 time: 0.2948s
Optimization Finished!
Total time elapsed: 131.5553s, best testing performance  0.704000, minimun loss  0.971164
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7914 acc_train: 0.1667 loss_val: 1.7920 acc_val: 0.1933 loss_test: 1.7059 acc_test: 0.5060 time: 0.2922s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.6664 acc_val: 0.4067 loss_test: 1.1281 acc_test: 0.6750 time: 0.2477s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7139 acc_val: 0.4533 loss_test: 1.1582 acc_test: 0.6900 time: 0.2795s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9823 acc_val: 0.4300 loss_test: 1.2750 acc_test: 0.6920 time: 0.3032s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0214 acc_val: 0.4567 loss_test: 1.3203 acc_test: 0.6950 time: 0.2015s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0726 acc_val: 0.4767 loss_test: 1.3658 acc_test: 0.6950 time: 0.1993s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1252 acc_val: 0.4933 loss_test: 1.4032 acc_test: 0.6920 time: 0.2538s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1636 acc_val: 0.5033 loss_test: 1.4397 acc_test: 0.6920 time: 0.2775s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2082 acc_val: 0.5067 loss_test: 1.4701 acc_test: 0.6930 time: 0.2794s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2150 acc_val: 0.5067 loss_test: 1.4904 acc_test: 0.6930 time: 0.3088s
Optimization Finished!
Total time elapsed: 132.4236s, best testing performance  0.698000, minimun loss  0.967462
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8016 acc_train: 0.1000 loss_val: 1.8570 acc_val: 0.0633 loss_test: 1.6692 acc_test: 0.3510 time: 0.2790s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.9087 acc_val: 0.3800 loss_test: 1.1954 acc_test: 0.6610 time: 0.2735s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9069 acc_val: 0.4200 loss_test: 1.2091 acc_test: 0.6740 time: 0.2551s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9740 acc_val: 0.4400 loss_test: 1.2641 acc_test: 0.6860 time: 0.2003s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0604 acc_val: 0.4600 loss_test: 1.3164 acc_test: 0.6860 time: 0.2019s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1222 acc_val: 0.4800 loss_test: 1.3583 acc_test: 0.6870 time: 0.2744s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1726 acc_val: 0.4900 loss_test: 1.3956 acc_test: 0.6900 time: 0.2972s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2192 acc_val: 0.4867 loss_test: 1.4369 acc_test: 0.6970 time: 0.2759s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2491 acc_val: 0.4933 loss_test: 1.4660 acc_test: 0.7030 time: 0.2831s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.2409 acc_val: 0.5000 loss_test: 1.4965 acc_test: 0.7020 time: 0.2047s
Optimization Finished!
Total time elapsed: 127.7042s, best testing performance  0.704000, minimun loss  0.958033
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7821 acc_train: 0.2167 loss_val: 1.8225 acc_val: 0.1833 loss_test: 1.6718 acc_test: 0.5040 time: 0.2637s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8554 acc_val: 0.3733 loss_test: 1.1743 acc_test: 0.6610 time: 0.2793s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8575 acc_val: 0.4000 loss_test: 1.1932 acc_test: 0.6800 time: 0.1999s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9212 acc_val: 0.4300 loss_test: 1.2425 acc_test: 0.6820 time: 0.2006s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9958 acc_val: 0.4467 loss_test: 1.2927 acc_test: 0.6850 time: 0.2912s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0780 acc_val: 0.4633 loss_test: 1.3426 acc_test: 0.6900 time: 0.2699s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0909 acc_val: 0.4867 loss_test: 1.3743 acc_test: 0.6960 time: 0.2703s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1407 acc_val: 0.4900 loss_test: 1.4107 acc_test: 0.6960 time: 0.2861s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1799 acc_val: 0.4967 loss_test: 1.4382 acc_test: 0.7000 time: 0.2009s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1882 acc_val: 0.5000 loss_test: 1.4585 acc_test: 0.7000 time: 0.2019s
Optimization Finished!
Total time elapsed: 125.5218s, best testing performance  0.702000, minimun loss  0.964936
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8158 acc_train: 0.0250 loss_val: 1.7759 acc_val: 0.1300 loss_test: 1.6668 acc_test: 0.4760 time: 0.2710s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7374 acc_val: 0.4100 loss_test: 1.1427 acc_test: 0.6750 time: 0.2052s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7526 acc_val: 0.4333 loss_test: 1.1749 acc_test: 0.6790 time: 0.2007s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8855 acc_val: 0.4500 loss_test: 1.2416 acc_test: 0.6850 time: 0.2704s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9525 acc_val: 0.4667 loss_test: 1.2902 acc_test: 0.6860 time: 0.2963s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0089 acc_val: 0.4900 loss_test: 1.3364 acc_test: 0.6910 time: 0.2794s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0540 acc_val: 0.5000 loss_test: 1.3759 acc_test: 0.6910 time: 0.2570s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.5000 loss_test: 1.4140 acc_test: 0.6930 time: 0.2027s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1444 acc_val: 0.5033 loss_test: 1.4560 acc_test: 0.6980 time: 0.2024s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2020 acc_val: 0.5067 loss_test: 1.4965 acc_test: 0.6960 time: 0.2852s
Optimization Finished!
Total time elapsed: 125.6549s, best testing performance  0.700000, minimun loss  0.967122
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7962 acc_train: 0.1250 loss_val: 1.8287 acc_val: 0.0467 loss_test: 1.6681 acc_test: 0.3340 time: 0.2617s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.6970 acc_val: 0.4133 loss_test: 1.1578 acc_test: 0.6640 time: 0.2009s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7952 acc_val: 0.4367 loss_test: 1.2034 acc_test: 0.6770 time: 0.3022s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9116 acc_val: 0.4433 loss_test: 1.2685 acc_test: 0.6860 time: 0.2706s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9892 acc_val: 0.4633 loss_test: 1.3156 acc_test: 0.6900 time: 0.2889s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0362 acc_val: 0.4700 loss_test: 1.3546 acc_test: 0.6870 time: 0.2569s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0609 acc_val: 0.4933 loss_test: 1.3835 acc_test: 0.6930 time: 0.2075s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1234 acc_val: 0.5000 loss_test: 1.4183 acc_test: 0.6960 time: 0.2099s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1367 acc_val: 0.5067 loss_test: 1.4385 acc_test: 0.6940 time: 0.2721s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1540 acc_val: 0.5067 loss_test: 1.4613 acc_test: 0.6980 time: 0.2981s
Optimization Finished!
Total time elapsed: 127.5495s, best testing performance  0.700000, minimun loss  0.966881
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.2083 loss_val: 1.8076 acc_val: 0.1167 loss_test: 1.6556 acc_test: 0.4650 time: 0.2519s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8369 acc_val: 0.3667 loss_test: 1.1691 acc_test: 0.6640 time: 0.2806s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8406 acc_val: 0.4133 loss_test: 1.1882 acc_test: 0.6740 time: 0.2643s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9093 acc_val: 0.4367 loss_test: 1.2377 acc_test: 0.6890 time: 0.2726s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9920 acc_val: 0.4567 loss_test: 1.2918 acc_test: 0.6870 time: 0.2984s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0354 acc_val: 0.4700 loss_test: 1.3323 acc_test: 0.6910 time: 0.2026s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0934 acc_val: 0.4867 loss_test: 1.3763 acc_test: 0.6910 time: 0.2023s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.5033 loss_test: 1.4140 acc_test: 0.6940 time: 0.3244s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1591 acc_val: 0.5100 loss_test: 1.4468 acc_test: 0.7030 time: 0.2587s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1662 acc_val: 0.5133 loss_test: 1.4823 acc_test: 0.7030 time: 0.2853s
Optimization Finished!
Total time elapsed: 131.0150s, best testing performance  0.703000, minimun loss  0.952951
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8007 acc_train: 0.1417 loss_val: 1.8080 acc_val: 0.0567 loss_test: 1.6754 acc_test: 0.3220 time: 0.2911s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7315 acc_val: 0.4133 loss_test: 1.1340 acc_test: 0.6710 time: 0.2802s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8103 acc_val: 0.4267 loss_test: 1.1753 acc_test: 0.6810 time: 0.2492s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.8880 acc_val: 0.4367 loss_test: 1.2349 acc_test: 0.6830 time: 0.2694s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9655 acc_val: 0.4567 loss_test: 1.2839 acc_test: 0.6860 time: 0.2013s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9963 acc_val: 0.4800 loss_test: 1.3220 acc_test: 0.6900 time: 0.2005s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0212 acc_val: 0.4967 loss_test: 1.3549 acc_test: 0.6940 time: 0.2871s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0608 acc_val: 0.4967 loss_test: 1.3902 acc_test: 0.6980 time: 0.2491s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0681 acc_val: 0.5100 loss_test: 1.4191 acc_test: 0.7010 time: 0.2938s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1187 acc_val: 0.5100 loss_test: 1.4491 acc_test: 0.7020 time: 0.2671s
Optimization Finished!
Total time elapsed: 132.2761s, best testing performance  0.703000, minimun loss  0.961268
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7851 acc_train: 0.2417 loss_val: 1.8013 acc_val: 0.1800 loss_test: 1.6761 acc_test: 0.4920 time: 0.2800s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.6842 acc_val: 0.4033 loss_test: 1.1407 acc_test: 0.6680 time: 0.2557s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7869 acc_val: 0.4167 loss_test: 1.1937 acc_test: 0.6800 time: 0.2561s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8988 acc_val: 0.4433 loss_test: 1.2530 acc_test: 0.6860 time: 0.2002s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9424 acc_val: 0.4733 loss_test: 1.2932 acc_test: 0.6840 time: 0.2000s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9737 acc_val: 0.4967 loss_test: 1.3249 acc_test: 0.6900 time: 0.2781s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9898 acc_val: 0.5100 loss_test: 1.3565 acc_test: 0.6940 time: 0.2714s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0436 acc_val: 0.5100 loss_test: 1.3940 acc_test: 0.6980 time: 0.2484s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0742 acc_val: 0.5067 loss_test: 1.4218 acc_test: 0.7000 time: 0.2636s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1113 acc_val: 0.5067 loss_test: 1.4472 acc_test: 0.7000 time: 0.2070s
Optimization Finished!
Total time elapsed: 128.9452s, best testing performance  0.703000, minimun loss  1.003354
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7844 acc_train: 0.2083 loss_val: 1.8166 acc_val: 0.1333 loss_test: 1.6682 acc_test: 0.4790 time: 0.2828s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8852 acc_val: 0.3833 loss_test: 1.1826 acc_test: 0.6640 time: 0.2590s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8995 acc_val: 0.4200 loss_test: 1.2008 acc_test: 0.6770 time: 0.2040s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9812 acc_val: 0.4300 loss_test: 1.2538 acc_test: 0.6860 time: 0.2006s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0212 acc_val: 0.4533 loss_test: 1.2970 acc_test: 0.6900 time: 0.2563s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0573 acc_val: 0.4667 loss_test: 1.3365 acc_test: 0.6940 time: 0.2770s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0945 acc_val: 0.4933 loss_test: 1.3736 acc_test: 0.6970 time: 0.2847s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0931 acc_val: 0.5000 loss_test: 1.3962 acc_test: 0.7000 time: 0.2562s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1287 acc_val: 0.5000 loss_test: 1.4311 acc_test: 0.7000 time: 0.2892s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1523 acc_val: 0.5033 loss_test: 1.4594 acc_test: 0.6990 time: 0.2018s
Optimization Finished!
Total time elapsed: 126.0007s, best testing performance  0.702000, minimun loss  0.975811
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7924 acc_train: 0.2000 loss_val: 1.7953 acc_val: 0.1900 loss_test: 1.6716 acc_test: 0.5320 time: 0.2723s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7288 acc_val: 0.4200 loss_test: 1.1380 acc_test: 0.6700 time: 0.2019s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8216 acc_val: 0.4400 loss_test: 1.1870 acc_test: 0.6880 time: 0.1996s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9351 acc_val: 0.4533 loss_test: 1.2508 acc_test: 0.6890 time: 0.2652s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0268 acc_val: 0.4500 loss_test: 1.3077 acc_test: 0.6920 time: 0.2589s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0607 acc_val: 0.4667 loss_test: 1.3470 acc_test: 0.6910 time: 0.2817s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0919 acc_val: 0.4833 loss_test: 1.3838 acc_test: 0.6910 time: 0.2952s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1427 acc_val: 0.4900 loss_test: 1.4213 acc_test: 0.6970 time: 0.3124s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1927 acc_val: 0.4933 loss_test: 1.4541 acc_test: 0.6950 time: 0.2094s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2191 acc_val: 0.4867 loss_test: 1.4778 acc_test: 0.7020 time: 0.2255s
Optimization Finished!
Total time elapsed: 125.6550s, best testing performance  0.703000, minimun loss  0.987871
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7915 acc_train: 0.2167 loss_val: 1.8086 acc_val: 0.1133 loss_test: 1.6692 acc_test: 0.4440 time: 0.2761s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8943 acc_val: 0.3700 loss_test: 1.1925 acc_test: 0.6580 time: 0.2017s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9487 acc_val: 0.4000 loss_test: 1.2191 acc_test: 0.6640 time: 0.2550s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 2.0107 acc_val: 0.4333 loss_test: 1.2659 acc_test: 0.6780 time: 0.3209s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0419 acc_val: 0.4600 loss_test: 1.3006 acc_test: 0.6820 time: 0.3021s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0801 acc_val: 0.4733 loss_test: 1.3398 acc_test: 0.6870 time: 0.2624s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0942 acc_val: 0.4733 loss_test: 1.3678 acc_test: 0.6910 time: 0.3372s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1213 acc_val: 0.5000 loss_test: 1.3967 acc_test: 0.6920 time: 0.2112s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1675 acc_val: 0.4967 loss_test: 1.4293 acc_test: 0.6920 time: 0.2328s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1862 acc_val: 0.5100 loss_test: 1.4489 acc_test: 0.6940 time: 0.2800s
Optimization Finished!
Total time elapsed: 126.1739s, best testing performance  0.697000, minimun loss  0.966630
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7973 acc_train: 0.1167 loss_val: 1.8377 acc_val: 0.1667 loss_test: 1.6616 acc_test: 0.5230 time: 0.2468s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8902 acc_val: 0.3767 loss_test: 1.2332 acc_test: 0.6560 time: 0.2817s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8932 acc_val: 0.4233 loss_test: 1.2361 acc_test: 0.6750 time: 0.3048s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9803 acc_val: 0.4333 loss_test: 1.2925 acc_test: 0.6860 time: 0.2690s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0601 acc_val: 0.4533 loss_test: 1.3398 acc_test: 0.6860 time: 0.2736s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0880 acc_val: 0.4567 loss_test: 1.3678 acc_test: 0.6880 time: 0.2506s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1197 acc_val: 0.4833 loss_test: 1.3979 acc_test: 0.6900 time: 0.2027s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1393 acc_val: 0.4933 loss_test: 1.4259 acc_test: 0.6940 time: 0.2514s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1595 acc_val: 0.5000 loss_test: 1.4445 acc_test: 0.6990 time: 0.2724s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1949 acc_val: 0.5100 loss_test: 1.4640 acc_test: 0.6950 time: 0.2831s
Optimization Finished!
Total time elapsed: 130.5091s, best testing performance  0.700000, minimun loss  0.972137
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7896 acc_train: 0.1333 loss_val: 1.7907 acc_val: 0.2200 loss_test: 1.6650 acc_test: 0.4680 time: 0.2926s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.9163 acc_val: 0.3700 loss_test: 1.2026 acc_test: 0.6570 time: 0.3366s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8790 acc_val: 0.4167 loss_test: 1.2143 acc_test: 0.6750 time: 0.2713s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9748 acc_val: 0.4433 loss_test: 1.2728 acc_test: 0.6840 time: 0.2885s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0647 acc_val: 0.4667 loss_test: 1.3252 acc_test: 0.6900 time: 0.2854s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0868 acc_val: 0.4767 loss_test: 1.3600 acc_test: 0.6940 time: 0.2086s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1618 acc_val: 0.5000 loss_test: 1.4069 acc_test: 0.6970 time: 0.2256s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1796 acc_val: 0.5133 loss_test: 1.4296 acc_test: 0.6980 time: 0.2900s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2232 acc_val: 0.5100 loss_test: 1.4605 acc_test: 0.7040 time: 0.2772s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2516 acc_val: 0.5167 loss_test: 1.4826 acc_test: 0.7040 time: 0.3027s
Optimization Finished!
Total time elapsed: 133.4235s, best testing performance  0.705000, minimun loss  0.951300
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7857 acc_train: 0.2417 loss_val: 1.8004 acc_val: 0.1833 loss_test: 1.6602 acc_test: 0.5090 time: 0.2726s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7965 acc_val: 0.3933 loss_test: 1.1922 acc_test: 0.6580 time: 0.3008s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8589 acc_val: 0.4267 loss_test: 1.2177 acc_test: 0.6740 time: 0.2690s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9603 acc_val: 0.4267 loss_test: 1.2841 acc_test: 0.6840 time: 0.2926s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0686 acc_val: 0.4500 loss_test: 1.3381 acc_test: 0.6850 time: 0.2011s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1320 acc_val: 0.4633 loss_test: 1.3758 acc_test: 0.6890 time: 0.2114s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1541 acc_val: 0.4933 loss_test: 1.4060 acc_test: 0.6890 time: 0.2754s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2077 acc_val: 0.4967 loss_test: 1.4382 acc_test: 0.6910 time: 0.2814s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2227 acc_val: 0.4867 loss_test: 1.4591 acc_test: 0.6960 time: 0.2812s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2440 acc_val: 0.5000 loss_test: 1.4816 acc_test: 0.6940 time: 0.2843s
Optimization Finished!
Total time elapsed: 130.8457s, best testing performance  0.698000, minimun loss  0.969089
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7749 acc_train: 0.2417 loss_val: 1.8147 acc_val: 0.0500 loss_test: 1.6457 acc_test: 0.3660 time: 0.2670s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.9142 acc_val: 0.3800 loss_test: 1.2194 acc_test: 0.6580 time: 0.2731s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9190 acc_val: 0.4033 loss_test: 1.2536 acc_test: 0.6650 time: 0.2775s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9913 acc_val: 0.4367 loss_test: 1.3012 acc_test: 0.6740 time: 0.2006s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0420 acc_val: 0.4633 loss_test: 1.3347 acc_test: 0.6820 time: 0.2081s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0691 acc_val: 0.4800 loss_test: 1.3665 acc_test: 0.6910 time: 0.2767s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0794 acc_val: 0.4933 loss_test: 1.3883 acc_test: 0.6940 time: 0.2532s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0971 acc_val: 0.5000 loss_test: 1.4124 acc_test: 0.6980 time: 0.2956s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1242 acc_val: 0.5067 loss_test: 1.4325 acc_test: 0.7010 time: 0.2610s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1598 acc_val: 0.5100 loss_test: 1.4634 acc_test: 0.7000 time: 0.2049s
Optimization Finished!
Total time elapsed: 126.3176s, best testing performance  0.702000, minimun loss  0.960670
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8026 acc_train: 0.1083 loss_val: 1.8109 acc_val: 0.0733 loss_test: 1.6580 acc_test: 0.3750 time: 0.2804s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8475 acc_val: 0.3967 loss_test: 1.1905 acc_test: 0.6570 time: 0.3026s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8830 acc_val: 0.4267 loss_test: 1.2177 acc_test: 0.6740 time: 0.2057s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9694 acc_val: 0.4367 loss_test: 1.2821 acc_test: 0.6870 time: 0.2087s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0857 acc_val: 0.4567 loss_test: 1.3493 acc_test: 0.6880 time: 0.2488s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0919 acc_val: 0.4700 loss_test: 1.3788 acc_test: 0.6870 time: 0.2647s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1352 acc_val: 0.5000 loss_test: 1.4157 acc_test: 0.6880 time: 0.2624s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1505 acc_val: 0.5133 loss_test: 1.4449 acc_test: 0.6970 time: 0.2705s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2166 acc_val: 0.5133 loss_test: 1.4847 acc_test: 0.6950 time: 0.2069s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2211 acc_val: 0.5000 loss_test: 1.5075 acc_test: 0.6920 time: 0.2093s
Optimization Finished!
Total time elapsed: 126.2212s, best testing performance  0.697000, minimun loss  0.954824
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8043 acc_train: 0.0917 loss_val: 1.7865 acc_val: 0.1267 loss_test: 1.6812 acc_test: 0.4920 time: 0.2655s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.8421 acc_val: 0.3867 loss_test: 1.1811 acc_test: 0.6640 time: 0.2031s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8533 acc_val: 0.4200 loss_test: 1.1920 acc_test: 0.6720 time: 0.2096s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.9191 acc_val: 0.4367 loss_test: 1.2363 acc_test: 0.6780 time: 0.2881s
Epoch: 0201 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9690 acc_val: 0.4500 loss_test: 1.2762 acc_test: 0.6840 time: 0.2625s
Epoch: 0251 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9868 acc_val: 0.4767 loss_test: 1.3082 acc_test: 0.6880 time: 0.2852s
Epoch: 0301 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0252 acc_val: 0.4900 loss_test: 1.3449 acc_test: 0.6900 time: 0.2762s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0749 acc_val: 0.4900 loss_test: 1.3820 acc_test: 0.6920 time: 0.2028s
Epoch: 0401 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1229 acc_val: 0.5000 loss_test: 1.4170 acc_test: 0.6930 time: 0.2009s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1553 acc_val: 0.5000 loss_test: 1.4428 acc_test: 0.6950 time: 0.2552s
Optimization Finished!
Total time elapsed: 124.5128s, best testing performance  0.702000, minimun loss  0.986125
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7953 acc_train: 0.1583 loss_val: 1.8144 acc_val: 0.1333 loss_test: 1.6966 acc_test: 0.4940 time: 0.2995s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.8728 acc_val: 0.3567 loss_test: 1.1687 acc_test: 0.6530 time: 0.2003s
Epoch: 0101 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8470 acc_val: 0.4167 loss_test: 1.1649 acc_test: 0.6730 time: 0.2060s
Epoch: 0151 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.9118 acc_val: 0.4367 loss_test: 1.2108 acc_test: 0.6810 time: 0.2884s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9180 acc_val: 0.4600 loss_test: 1.2458 acc_test: 0.6880 time: 0.2501s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9458 acc_val: 0.4767 loss_test: 1.2863 acc_test: 0.6910 time: 0.3156s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0092 acc_val: 0.4833 loss_test: 1.3334 acc_test: 0.6940 time: 0.3028s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0425 acc_val: 0.4933 loss_test: 1.3711 acc_test: 0.6930 time: 0.2074s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1118 acc_val: 0.5000 loss_test: 1.4163 acc_test: 0.6970 time: 0.1993s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1507 acc_val: 0.5000 loss_test: 1.4533 acc_test: 0.6970 time: 0.2550s
Optimization Finished!
Total time elapsed: 125.5491s, best testing performance  0.701000, minimun loss  0.987592
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8149 acc_train: 0.0667 loss_val: 1.7800 acc_val: 0.2300 loss_test: 1.7030 acc_test: 0.4720 time: 0.2492s
Epoch: 0051 loss_train: 0.0131 acc_train: 1.0000 loss_val: 1.7440 acc_val: 0.3833 loss_test: 1.1323 acc_test: 0.6640 time: 0.2002s
Epoch: 0101 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8509 acc_val: 0.4300 loss_test: 1.1691 acc_test: 0.6760 time: 0.2483s
Epoch: 0151 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9035 acc_val: 0.4400 loss_test: 1.2046 acc_test: 0.6860 time: 0.2648s
Epoch: 0201 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9209 acc_val: 0.4500 loss_test: 1.2376 acc_test: 0.6900 time: 0.2692s
Epoch: 0251 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9648 acc_val: 0.4667 loss_test: 1.2776 acc_test: 0.6940 time: 0.2738s
Epoch: 0301 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9935 acc_val: 0.4800 loss_test: 1.3124 acc_test: 0.6940 time: 0.2733s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0226 acc_val: 0.5033 loss_test: 1.3471 acc_test: 0.6950 time: 0.2036s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0446 acc_val: 0.5067 loss_test: 1.3784 acc_test: 0.7010 time: 0.2169s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0817 acc_val: 0.5033 loss_test: 1.4119 acc_test: 0.6980 time: 0.3024s
Optimization Finished!
Total time elapsed: 125.4123s, best testing performance  0.701000, minimun loss  0.994218
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7753 acc_train: 0.2833 loss_val: 1.8116 acc_val: 0.1500 loss_test: 1.6706 acc_test: 0.5050 time: 0.2793s
Epoch: 0051 loss_train: 0.0132 acc_train: 1.0000 loss_val: 1.8056 acc_val: 0.3700 loss_test: 1.1278 acc_test: 0.6630 time: 0.2007s
Epoch: 0101 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8456 acc_val: 0.4167 loss_test: 1.1500 acc_test: 0.6780 time: 0.2804s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8886 acc_val: 0.4333 loss_test: 1.1952 acc_test: 0.6860 time: 0.2778s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9397 acc_val: 0.4667 loss_test: 1.2434 acc_test: 0.6880 time: 0.2836s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9850 acc_val: 0.4800 loss_test: 1.2902 acc_test: 0.6930 time: 0.2760s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4833 loss_test: 1.3423 acc_test: 0.6950 time: 0.2602s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1291 acc_val: 0.4933 loss_test: 1.3925 acc_test: 0.6960 time: 0.2081s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1850 acc_val: 0.5033 loss_test: 1.4351 acc_test: 0.6960 time: 0.2474s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2483 acc_val: 0.4933 loss_test: 1.4789 acc_test: 0.6930 time: 0.2750s
Optimization Finished!
Total time elapsed: 127.1416s, best testing performance  0.697000, minimun loss  0.990229
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7713 acc_train: 0.2750 loss_val: 1.8272 acc_val: 0.0900 loss_test: 1.6664 acc_test: 0.4710 time: 0.2780s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.9232 acc_val: 0.3867 loss_test: 1.1993 acc_test: 0.6610 time: 0.2078s
Epoch: 0101 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8934 acc_val: 0.4267 loss_test: 1.2019 acc_test: 0.6740 time: 0.2673s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8990 acc_val: 0.4533 loss_test: 1.2357 acc_test: 0.6800 time: 0.2757s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9379 acc_val: 0.4733 loss_test: 1.2751 acc_test: 0.6830 time: 0.2544s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9888 acc_val: 0.4733 loss_test: 1.3167 acc_test: 0.6860 time: 0.2489s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0210 acc_val: 0.4967 loss_test: 1.3554 acc_test: 0.6920 time: 0.2020s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0631 acc_val: 0.5067 loss_test: 1.3924 acc_test: 0.6990 time: 0.2004s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1153 acc_val: 0.5133 loss_test: 1.4276 acc_test: 0.7030 time: 0.2720s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1609 acc_val: 0.5133 loss_test: 1.4634 acc_test: 0.7020 time: 0.2986s
Optimization Finished!
Total time elapsed: 126.9086s, best testing performance  0.706000, minimun loss  1.010481
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7893 acc_train: 0.1583 loss_val: 1.8128 acc_val: 0.1433 loss_test: 1.6923 acc_test: 0.4740 time: 0.2520s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7542 acc_val: 0.4033 loss_test: 1.1842 acc_test: 0.6600 time: 0.2134s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7747 acc_val: 0.4367 loss_test: 1.2063 acc_test: 0.6730 time: 0.2895s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9349 acc_val: 0.4500 loss_test: 1.2753 acc_test: 0.6780 time: 0.2882s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9959 acc_val: 0.4633 loss_test: 1.3151 acc_test: 0.6860 time: 0.2808s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0542 acc_val: 0.4733 loss_test: 1.3580 acc_test: 0.6850 time: 0.2660s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0907 acc_val: 0.4967 loss_test: 1.3940 acc_test: 0.6930 time: 0.2089s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1493 acc_val: 0.4967 loss_test: 1.4329 acc_test: 0.6960 time: 0.2164s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1828 acc_val: 0.5033 loss_test: 1.4607 acc_test: 0.6990 time: 0.3141s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2225 acc_val: 0.5033 loss_test: 1.4882 acc_test: 0.6980 time: 0.2769s
Optimization Finished!
Total time elapsed: 129.6015s, best testing performance  0.700000, minimun loss  0.987228
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7961 acc_train: 0.2000 loss_val: 1.7954 acc_val: 0.1233 loss_test: 1.7165 acc_test: 0.3950 time: 0.2982s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7783 acc_val: 0.3967 loss_test: 1.1897 acc_test: 0.6690 time: 0.2864s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7638 acc_val: 0.4233 loss_test: 1.1911 acc_test: 0.6830 time: 0.2691s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9092 acc_val: 0.4400 loss_test: 1.2633 acc_test: 0.6880 time: 0.2861s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9978 acc_val: 0.4633 loss_test: 1.3166 acc_test: 0.6880 time: 0.2745s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0090 acc_val: 0.5000 loss_test: 1.3535 acc_test: 0.6900 time: 0.2931s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0354 acc_val: 0.5067 loss_test: 1.3887 acc_test: 0.6970 time: 0.2060s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0496 acc_val: 0.5067 loss_test: 1.4249 acc_test: 0.6960 time: 0.2134s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0661 acc_val: 0.5000 loss_test: 1.4584 acc_test: 0.6920 time: 0.2774s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.0827 acc_val: 0.5133 loss_test: 1.4897 acc_test: 0.6940 time: 0.2787s
Optimization Finished!
Total time elapsed: 131.1251s, best testing performance  0.699000, minimun loss  1.001531
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.1667 loss_val: 1.8253 acc_val: 0.0867 loss_test: 1.6924 acc_test: 0.4160 time: 0.2636s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8007 acc_val: 0.3800 loss_test: 1.1703 acc_test: 0.6590 time: 0.2836s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7604 acc_val: 0.4333 loss_test: 1.1798 acc_test: 0.6690 time: 0.2875s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8930 acc_val: 0.4567 loss_test: 1.2448 acc_test: 0.6830 time: 0.2556s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9739 acc_val: 0.4567 loss_test: 1.2975 acc_test: 0.6860 time: 0.2733s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0240 acc_val: 0.4700 loss_test: 1.3445 acc_test: 0.6930 time: 0.2019s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0662 acc_val: 0.4967 loss_test: 1.3854 acc_test: 0.6920 time: 0.2045s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0761 acc_val: 0.5100 loss_test: 1.4161 acc_test: 0.6950 time: 0.2684s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0922 acc_val: 0.5000 loss_test: 1.4459 acc_test: 0.6920 time: 0.2849s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1205 acc_val: 0.5033 loss_test: 1.4778 acc_test: 0.6970 time: 0.2593s
Optimization Finished!
Total time elapsed: 132.8164s, best testing performance  0.698000, minimun loss  0.960600
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8046 acc_train: 0.1000 loss_val: 1.8138 acc_val: 0.2067 loss_test: 1.6948 acc_test: 0.4900 time: 0.2991s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7971 acc_val: 0.3767 loss_test: 1.1809 acc_test: 0.6610 time: 0.3298s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.9034 acc_val: 0.4100 loss_test: 1.2237 acc_test: 0.6720 time: 0.2650s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9864 acc_val: 0.4267 loss_test: 1.2759 acc_test: 0.6820 time: 0.2733s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0088 acc_val: 0.4633 loss_test: 1.3115 acc_test: 0.6840 time: 0.2655s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0371 acc_val: 0.4767 loss_test: 1.3455 acc_test: 0.6860 time: 0.2016s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0506 acc_val: 0.4967 loss_test: 1.3772 acc_test: 0.6940 time: 0.2117s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0819 acc_val: 0.4967 loss_test: 1.4108 acc_test: 0.7000 time: 0.3021s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1194 acc_val: 0.5000 loss_test: 1.4466 acc_test: 0.7010 time: 0.2983s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1777 acc_val: 0.5033 loss_test: 1.4845 acc_test: 0.7010 time: 0.2831s
Optimization Finished!
Total time elapsed: 133.6983s, best testing performance  0.703000, minimun loss  0.971649
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7922 acc_train: 0.2333 loss_val: 1.7960 acc_val: 0.1733 loss_test: 1.6950 acc_test: 0.5060 time: 0.2580s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7601 acc_val: 0.4200 loss_test: 1.1835 acc_test: 0.6700 time: 0.2815s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7892 acc_val: 0.4567 loss_test: 1.2029 acc_test: 0.6800 time: 0.2788s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8859 acc_val: 0.4767 loss_test: 1.2619 acc_test: 0.6830 time: 0.2797s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9262 acc_val: 0.4833 loss_test: 1.2984 acc_test: 0.6870 time: 0.2773s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9483 acc_val: 0.4933 loss_test: 1.3294 acc_test: 0.6900 time: 0.2011s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 1.9716 acc_val: 0.5067 loss_test: 1.3572 acc_test: 0.6910 time: 0.2150s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 1.9869 acc_val: 0.5100 loss_test: 1.3844 acc_test: 0.6970 time: 0.3280s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0391 acc_val: 0.5133 loss_test: 1.4122 acc_test: 0.7000 time: 0.2644s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.0713 acc_val: 0.5033 loss_test: 1.4361 acc_test: 0.7000 time: 0.2998s
Optimization Finished!
Total time elapsed: 133.1867s, best testing performance  0.702000, minimun loss  0.995896
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8038 acc_train: 0.1583 loss_val: 1.8063 acc_val: 0.1300 loss_test: 1.6994 acc_test: 0.4490 time: 0.2908s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9629 acc_val: 0.3767 loss_test: 1.2204 acc_test: 0.6570 time: 0.2787s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9163 acc_val: 0.3967 loss_test: 1.2185 acc_test: 0.6740 time: 0.2795s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9615 acc_val: 0.4300 loss_test: 1.2604 acc_test: 0.6790 time: 0.3152s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9872 acc_val: 0.4467 loss_test: 1.2984 acc_test: 0.6870 time: 0.1995s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0466 acc_val: 0.4667 loss_test: 1.3426 acc_test: 0.6900 time: 0.2003s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0552 acc_val: 0.4900 loss_test: 1.3720 acc_test: 0.6920 time: 0.3103s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.5000 loss_test: 1.4010 acc_test: 0.6910 time: 0.2681s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1309 acc_val: 0.4933 loss_test: 1.4323 acc_test: 0.6910 time: 0.2631s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1597 acc_val: 0.4967 loss_test: 1.4588 acc_test: 0.6900 time: 0.2853s
Optimization Finished!
Total time elapsed: 131.8820s, best testing performance  0.696000, minimun loss  0.995473
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7789 acc_train: 0.2250 loss_val: 1.8064 acc_val: 0.1300 loss_test: 1.6812 acc_test: 0.4580 time: 0.2605s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9039 acc_val: 0.3833 loss_test: 1.1873 acc_test: 0.6600 time: 0.2738s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8793 acc_val: 0.4367 loss_test: 1.1965 acc_test: 0.6780 time: 0.2879s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9245 acc_val: 0.4533 loss_test: 1.2387 acc_test: 0.6890 time: 0.2647s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9916 acc_val: 0.4600 loss_test: 1.2861 acc_test: 0.6910 time: 0.2016s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0304 acc_val: 0.4733 loss_test: 1.3275 acc_test: 0.6910 time: 0.2001s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.5000 loss_test: 1.3661 acc_test: 0.6950 time: 0.2888s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0923 acc_val: 0.5100 loss_test: 1.4035 acc_test: 0.6970 time: 0.2944s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1434 acc_val: 0.5033 loss_test: 1.4431 acc_test: 0.6980 time: 0.2436s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2025 acc_val: 0.5033 loss_test: 1.4853 acc_test: 0.6990 time: 0.3037s
Optimization Finished!
Total time elapsed: 132.4818s, best testing performance  0.701000, minimun loss  0.979579
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7888 acc_train: 0.1667 loss_val: 1.8041 acc_val: 0.0933 loss_test: 1.6872 acc_test: 0.4130 time: 0.3225s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.9072 acc_val: 0.3667 loss_test: 1.1864 acc_test: 0.6580 time: 0.2706s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9001 acc_val: 0.4167 loss_test: 1.1966 acc_test: 0.6770 time: 0.3157s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9438 acc_val: 0.4233 loss_test: 1.2412 acc_test: 0.6860 time: 0.2911s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9670 acc_val: 0.4600 loss_test: 1.2781 acc_test: 0.6880 time: 0.2029s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9875 acc_val: 0.4800 loss_test: 1.3133 acc_test: 0.6950 time: 0.2071s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9985 acc_val: 0.5033 loss_test: 1.3465 acc_test: 0.6960 time: 0.2846s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0107 acc_val: 0.5200 loss_test: 1.3780 acc_test: 0.6990 time: 0.2642s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0179 acc_val: 0.5167 loss_test: 1.4055 acc_test: 0.6980 time: 0.2827s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0424 acc_val: 0.5267 loss_test: 1.4332 acc_test: 0.7000 time: 0.2788s
Optimization Finished!
Total time elapsed: 132.2601s, best testing performance  0.704000, minimun loss  0.969815
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7962 acc_train: 0.1000 loss_val: 1.7874 acc_val: 0.1800 loss_test: 1.6879 acc_test: 0.4980 time: 0.2886s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8921 acc_val: 0.3867 loss_test: 1.2202 acc_test: 0.6590 time: 0.2629s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9269 acc_val: 0.4333 loss_test: 1.2470 acc_test: 0.6730 time: 0.2673s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9788 acc_val: 0.4700 loss_test: 1.2888 acc_test: 0.6840 time: 0.2950s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0127 acc_val: 0.4767 loss_test: 1.3248 acc_test: 0.6900 time: 0.2030s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0300 acc_val: 0.4833 loss_test: 1.3568 acc_test: 0.6890 time: 0.2145s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0580 acc_val: 0.5000 loss_test: 1.3869 acc_test: 0.6920 time: 0.2559s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0976 acc_val: 0.4967 loss_test: 1.4166 acc_test: 0.6920 time: 0.3213s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1520 acc_val: 0.4933 loss_test: 1.4527 acc_test: 0.6950 time: 0.2743s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1788 acc_val: 0.4933 loss_test: 1.4745 acc_test: 0.6950 time: 0.3137s
Optimization Finished!
Total time elapsed: 131.7251s, best testing performance  0.697000, minimun loss  0.999717
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7854 acc_train: 0.2000 loss_val: 1.8172 acc_val: 0.1100 loss_test: 1.6782 acc_test: 0.4180 time: 0.2607s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8918 acc_val: 0.3800 loss_test: 1.2031 acc_test: 0.6630 time: 0.3156s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9163 acc_val: 0.4300 loss_test: 1.2208 acc_test: 0.6790 time: 0.2816s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9495 acc_val: 0.4433 loss_test: 1.2628 acc_test: 0.6830 time: 0.2811s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0185 acc_val: 0.4533 loss_test: 1.3133 acc_test: 0.6860 time: 0.2012s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0525 acc_val: 0.4700 loss_test: 1.3534 acc_test: 0.6880 time: 0.2128s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0609 acc_val: 0.4900 loss_test: 1.3846 acc_test: 0.6890 time: 0.2830s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0838 acc_val: 0.5133 loss_test: 1.4177 acc_test: 0.6940 time: 0.2866s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1331 acc_val: 0.5133 loss_test: 1.4495 acc_test: 0.6960 time: 0.2760s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1494 acc_val: 0.5067 loss_test: 1.4759 acc_test: 0.6970 time: 0.2860s
Optimization Finished!
Total time elapsed: 131.4021s, best testing performance  0.698000, minimun loss  0.981583
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7847 acc_train: 0.2417 loss_val: 1.8351 acc_val: 0.1067 loss_test: 1.6919 acc_test: 0.3780 time: 0.3320s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7568 acc_val: 0.4133 loss_test: 1.1592 acc_test: 0.6710 time: 0.2703s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8416 acc_val: 0.4600 loss_test: 1.2046 acc_test: 0.6840 time: 0.2632s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0020 acc_val: 0.4433 loss_test: 1.2867 acc_test: 0.6890 time: 0.2002s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1233 acc_val: 0.4300 loss_test: 1.3471 acc_test: 0.6910 time: 0.2054s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1326 acc_val: 0.4567 loss_test: 1.3781 acc_test: 0.6880 time: 0.2982s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1405 acc_val: 0.4833 loss_test: 1.4113 acc_test: 0.6870 time: 0.2612s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.4933 loss_test: 1.4383 acc_test: 0.6890 time: 0.3080s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1716 acc_val: 0.5067 loss_test: 1.4694 acc_test: 0.6920 time: 0.2722s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1932 acc_val: 0.5033 loss_test: 1.4946 acc_test: 0.6900 time: 0.2733s
Optimization Finished!
Total time elapsed: 130.8693s, best testing performance  0.694000, minimun loss  0.988169
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7891 acc_train: 0.1750 loss_val: 1.7945 acc_val: 0.1933 loss_test: 1.6874 acc_test: 0.5430 time: 0.2977s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8037 acc_val: 0.4300 loss_test: 1.1937 acc_test: 0.6680 time: 0.2982s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8503 acc_val: 0.4333 loss_test: 1.2229 acc_test: 0.6840 time: 0.2814s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9569 acc_val: 0.4567 loss_test: 1.2830 acc_test: 0.6900 time: 0.2013s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0600 acc_val: 0.4600 loss_test: 1.3356 acc_test: 0.6910 time: 0.2001s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0569 acc_val: 0.4700 loss_test: 1.3635 acc_test: 0.6920 time: 0.2545s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0964 acc_val: 0.4833 loss_test: 1.4033 acc_test: 0.6960 time: 0.2755s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1388 acc_val: 0.5067 loss_test: 1.4437 acc_test: 0.7020 time: 0.2683s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1896 acc_val: 0.5100 loss_test: 1.4815 acc_test: 0.7000 time: 0.2742s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2404 acc_val: 0.5100 loss_test: 1.5202 acc_test: 0.6960 time: 0.2588s
Optimization Finished!
Total time elapsed: 129.5901s, best testing performance  0.705000, minimun loss  0.972060
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8040 acc_train: 0.1333 loss_val: 1.8098 acc_val: 0.1700 loss_test: 1.6772 acc_test: 0.5450 time: 0.2695s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7066 acc_val: 0.4400 loss_test: 1.1358 acc_test: 0.6860 time: 0.2589s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8069 acc_val: 0.4600 loss_test: 1.1872 acc_test: 0.6870 time: 0.2715s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9498 acc_val: 0.4567 loss_test: 1.2657 acc_test: 0.6870 time: 0.2014s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0122 acc_val: 0.4567 loss_test: 1.3056 acc_test: 0.6950 time: 0.2024s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0689 acc_val: 0.4733 loss_test: 1.3516 acc_test: 0.6920 time: 0.2739s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0892 acc_val: 0.4733 loss_test: 1.3899 acc_test: 0.6970 time: 0.2876s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1179 acc_val: 0.4933 loss_test: 1.4177 acc_test: 0.6940 time: 0.2922s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1521 acc_val: 0.5100 loss_test: 1.4515 acc_test: 0.6940 time: 0.3054s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1934 acc_val: 0.5067 loss_test: 1.4805 acc_test: 0.6920 time: 0.2678s
Optimization Finished!
Total time elapsed: 129.3975s, best testing performance  0.699000, minimun loss  0.969115
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8051 acc_train: 0.0917 loss_val: 1.8058 acc_val: 0.1000 loss_test: 1.6883 acc_test: 0.3950 time: 0.2670s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8766 acc_val: 0.4000 loss_test: 1.2245 acc_test: 0.6580 time: 0.2589s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7897 acc_val: 0.4233 loss_test: 1.2213 acc_test: 0.6810 time: 0.2819s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9206 acc_val: 0.4433 loss_test: 1.2857 acc_test: 0.6870 time: 0.2014s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0699 acc_val: 0.4467 loss_test: 1.3496 acc_test: 0.6830 time: 0.2096s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1181 acc_val: 0.4667 loss_test: 1.3856 acc_test: 0.6860 time: 0.2602s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1966 acc_val: 0.4733 loss_test: 1.4277 acc_test: 0.6900 time: 0.2799s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2116 acc_val: 0.4967 loss_test: 1.4521 acc_test: 0.6920 time: 0.2794s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2751 acc_val: 0.4967 loss_test: 1.4846 acc_test: 0.6940 time: 0.2726s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.3088 acc_val: 0.5033 loss_test: 1.5057 acc_test: 0.6940 time: 0.2048s
Optimization Finished!
Total time elapsed: 128.7726s, best testing performance  0.702000, minimun loss  0.984985
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1000 loss_val: 1.8333 acc_val: 0.1433 loss_test: 1.6707 acc_test: 0.4790 time: 0.2668s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8848 acc_val: 0.4100 loss_test: 1.2079 acc_test: 0.6710 time: 0.2885s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8080 acc_val: 0.4433 loss_test: 1.2012 acc_test: 0.6860 time: 0.2555s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0045 acc_val: 0.4367 loss_test: 1.2921 acc_test: 0.6880 time: 0.2024s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1339 acc_val: 0.4433 loss_test: 1.3575 acc_test: 0.6880 time: 0.2055s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1580 acc_val: 0.4667 loss_test: 1.3832 acc_test: 0.6930 time: 0.2446s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1170 acc_val: 0.4867 loss_test: 1.3939 acc_test: 0.6940 time: 0.2924s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1352 acc_val: 0.5000 loss_test: 1.4203 acc_test: 0.6960 time: 0.2697s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1820 acc_val: 0.5067 loss_test: 1.4508 acc_test: 0.6940 time: 0.2681s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2005 acc_val: 0.5067 loss_test: 1.4753 acc_test: 0.6970 time: 0.2047s
Optimization Finished!
Total time elapsed: 128.2238s, best testing performance  0.703000, minimun loss  0.975152
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8004 acc_train: 0.1250 loss_val: 1.8063 acc_val: 0.1367 loss_test: 1.6542 acc_test: 0.4780 time: 0.3065s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7927 acc_val: 0.3967 loss_test: 1.1537 acc_test: 0.6660 time: 0.2835s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7754 acc_val: 0.4367 loss_test: 1.1696 acc_test: 0.6870 time: 0.2733s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8649 acc_val: 0.4633 loss_test: 1.2323 acc_test: 0.6970 time: 0.1999s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9655 acc_val: 0.4633 loss_test: 1.2837 acc_test: 0.6970 time: 0.2176s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0373 acc_val: 0.4767 loss_test: 1.3265 acc_test: 0.6960 time: 0.2960s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0956 acc_val: 0.4800 loss_test: 1.3745 acc_test: 0.6970 time: 0.2927s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1713 acc_val: 0.4900 loss_test: 1.4188 acc_test: 0.6980 time: 0.2956s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2114 acc_val: 0.4933 loss_test: 1.4561 acc_test: 0.6990 time: 0.3255s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2527 acc_val: 0.4967 loss_test: 1.4935 acc_test: 0.7010 time: 0.2045s
Optimization Finished!
Total time elapsed: 127.7174s, best testing performance  0.705000, minimun loss  0.980171
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7863 acc_train: 0.1583 loss_val: 1.7805 acc_val: 0.1400 loss_test: 1.6461 acc_test: 0.4800 time: 0.2618s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7360 acc_val: 0.4167 loss_test: 1.1554 acc_test: 0.6740 time: 0.2845s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8228 acc_val: 0.4467 loss_test: 1.2023 acc_test: 0.6870 time: 0.2008s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9672 acc_val: 0.4500 loss_test: 1.2704 acc_test: 0.6820 time: 0.2014s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0347 acc_val: 0.4533 loss_test: 1.3127 acc_test: 0.6890 time: 0.2670s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1052 acc_val: 0.4633 loss_test: 1.3591 acc_test: 0.6880 time: 0.2735s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1445 acc_val: 0.4733 loss_test: 1.3922 acc_test: 0.6940 time: 0.2707s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1390 acc_val: 0.4867 loss_test: 1.4162 acc_test: 0.6970 time: 0.2711s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1891 acc_val: 0.4833 loss_test: 1.4501 acc_test: 0.6990 time: 0.3105s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2234 acc_val: 0.4900 loss_test: 1.4729 acc_test: 0.6990 time: 0.2091s
Optimization Finished!
Total time elapsed: 126.5294s, best testing performance  0.701000, minimun loss  0.964837
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7797 acc_train: 0.2667 loss_val: 1.8261 acc_val: 0.1167 loss_test: 1.6239 acc_test: 0.4520 time: 0.2805s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.6912 acc_val: 0.4100 loss_test: 1.1474 acc_test: 0.6800 time: 0.2735s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7501 acc_val: 0.4500 loss_test: 1.1861 acc_test: 0.6920 time: 0.2007s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8832 acc_val: 0.4433 loss_test: 1.2577 acc_test: 0.6950 time: 0.2243s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0012 acc_val: 0.4500 loss_test: 1.3125 acc_test: 0.6970 time: 0.2682s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0379 acc_val: 0.4900 loss_test: 1.3485 acc_test: 0.6970 time: 0.2983s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0885 acc_val: 0.4833 loss_test: 1.3885 acc_test: 0.6930 time: 0.2736s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1106 acc_val: 0.5000 loss_test: 1.4214 acc_test: 0.6970 time: 0.2760s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1489 acc_val: 0.4967 loss_test: 1.4606 acc_test: 0.6990 time: 0.2345s
Epoch: 0451 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.2188 acc_val: 0.5033 loss_test: 1.5022 acc_test: 0.6950 time: 0.2014s
Optimization Finished!
Total time elapsed: 125.7175s, best testing performance  0.701000, minimun loss  0.972077
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7880 acc_train: 0.2333 loss_val: 1.8107 acc_val: 0.1967 loss_test: 1.6553 acc_test: 0.5550 time: 0.2734s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.9052 acc_val: 0.3933 loss_test: 1.1734 acc_test: 0.6640 time: 0.2594s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.9160 acc_val: 0.4067 loss_test: 1.2083 acc_test: 0.6810 time: 0.2095s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0178 acc_val: 0.4367 loss_test: 1.2690 acc_test: 0.6810 time: 0.2069s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0382 acc_val: 0.4500 loss_test: 1.3073 acc_test: 0.6860 time: 0.2627s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0702 acc_val: 0.4700 loss_test: 1.3468 acc_test: 0.6910 time: 0.2620s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0703 acc_val: 0.4800 loss_test: 1.3815 acc_test: 0.6930 time: 0.2942s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1287 acc_val: 0.5000 loss_test: 1.4179 acc_test: 0.6900 time: 0.2763s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1718 acc_val: 0.4967 loss_test: 1.4502 acc_test: 0.6940 time: 0.2097s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1864 acc_val: 0.4967 loss_test: 1.4702 acc_test: 0.6950 time: 0.2000s
Optimization Finished!
Total time elapsed: 126.0544s, best testing performance  0.699000, minimun loss  0.972400
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 25, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8085 acc_train: 0.0917 loss_val: 1.8160 acc_val: 0.0533 loss_test: 1.6794 acc_test: 0.3340 time: 0.3021s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7717 acc_val: 0.4167 loss_test: 1.1663 acc_test: 0.6710 time: 0.2864s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8266 acc_val: 0.4467 loss_test: 1.2104 acc_test: 0.6870 time: 0.1995s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9306 acc_val: 0.4733 loss_test: 1.2778 acc_test: 0.6880 time: 0.2771s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0231 acc_val: 0.4700 loss_test: 1.3236 acc_test: 0.6920 time: 0.2649s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0599 acc_val: 0.4833 loss_test: 1.3552 acc_test: 0.6940 time: 0.2883s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1263 acc_val: 0.4800 loss_test: 1.3958 acc_test: 0.6940 time: 0.2859s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1544 acc_val: 0.5000 loss_test: 1.4281 acc_test: 0.6940 time: 0.3311s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2238 acc_val: 0.5033 loss_test: 1.4648 acc_test: 0.6970 time: 0.2067s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2423 acc_val: 0.5033 loss_test: 1.4925 acc_test: 0.6990 time: 0.2123s
Optimization Finished!
Total time elapsed: 125.7282s, best testing performance  0.702000, minimun loss  0.980509
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7895 acc_train: 0.1500 loss_val: 1.8081 acc_val: 0.0667 loss_test: 1.6568 acc_test: 0.4020 time: 0.3155s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.9908 acc_val: 0.3400 loss_test: 1.2118 acc_test: 0.6520 time: 0.2359s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9807 acc_val: 0.3833 loss_test: 1.2279 acc_test: 0.6660 time: 0.2499s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0614 acc_val: 0.4067 loss_test: 1.2901 acc_test: 0.6750 time: 0.3513s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1128 acc_val: 0.4367 loss_test: 1.3399 acc_test: 0.6810 time: 0.3130s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1243 acc_val: 0.4733 loss_test: 1.3706 acc_test: 0.6900 time: 0.3472s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1652 acc_val: 0.4867 loss_test: 1.4115 acc_test: 0.6970 time: 0.2838s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1863 acc_val: 0.4967 loss_test: 1.4411 acc_test: 0.6930 time: 0.2459s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1738 acc_val: 0.5100 loss_test: 1.4680 acc_test: 0.6980 time: 0.3206s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2167 acc_val: 0.5133 loss_test: 1.5008 acc_test: 0.6990 time: 0.3195s
Optimization Finished!
Total time elapsed: 149.0668s, best testing performance  0.704000, minimun loss  0.961828
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8027 acc_train: 0.1667 loss_val: 1.8251 acc_val: 0.0900 loss_test: 1.6897 acc_test: 0.3900 time: 0.3545s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8725 acc_val: 0.4133 loss_test: 1.1792 acc_test: 0.6680 time: 0.3316s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8421 acc_val: 0.4567 loss_test: 1.1898 acc_test: 0.6800 time: 0.2997s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9818 acc_val: 0.4433 loss_test: 1.2711 acc_test: 0.6800 time: 0.3334s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0469 acc_val: 0.4700 loss_test: 1.3211 acc_test: 0.6900 time: 0.2362s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1109 acc_val: 0.4767 loss_test: 1.3665 acc_test: 0.6880 time: 0.2338s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1356 acc_val: 0.4967 loss_test: 1.3997 acc_test: 0.6900 time: 0.2986s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1341 acc_val: 0.5033 loss_test: 1.4305 acc_test: 0.6930 time: 0.3458s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1310 acc_val: 0.5167 loss_test: 1.4514 acc_test: 0.6940 time: 0.3159s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1929 acc_val: 0.5033 loss_test: 1.4826 acc_test: 0.6890 time: 0.3038s
Optimization Finished!
Total time elapsed: 152.8287s, best testing performance  0.697000, minimun loss  0.961003
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7833 acc_train: 0.2500 loss_val: 1.8325 acc_val: 0.0967 loss_test: 1.6390 acc_test: 0.4680 time: 0.3046s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8575 acc_val: 0.3833 loss_test: 1.1506 acc_test: 0.6640 time: 0.3011s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8515 acc_val: 0.4000 loss_test: 1.1706 acc_test: 0.6750 time: 0.3199s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0026 acc_val: 0.4233 loss_test: 1.2654 acc_test: 0.6780 time: 0.2349s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0822 acc_val: 0.4533 loss_test: 1.3278 acc_test: 0.6800 time: 0.2417s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1195 acc_val: 0.4667 loss_test: 1.3643 acc_test: 0.6880 time: 0.3247s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1681 acc_val: 0.4733 loss_test: 1.3992 acc_test: 0.6910 time: 0.3158s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2156 acc_val: 0.4967 loss_test: 1.4364 acc_test: 0.6920 time: 0.3161s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2297 acc_val: 0.5033 loss_test: 1.4606 acc_test: 0.6920 time: 0.3061s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2608 acc_val: 0.5067 loss_test: 1.4855 acc_test: 0.6920 time: 0.2403s
Optimization Finished!
Total time elapsed: 147.4096s, best testing performance  0.697000, minimun loss  0.949630
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7918 acc_train: 0.1917 loss_val: 1.8025 acc_val: 0.1300 loss_test: 1.6693 acc_test: 0.5080 time: 0.3356s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8654 acc_val: 0.3800 loss_test: 1.1423 acc_test: 0.6680 time: 0.3255s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8823 acc_val: 0.4100 loss_test: 1.1713 acc_test: 0.6760 time: 0.2330s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0806 acc_val: 0.4133 loss_test: 1.2786 acc_test: 0.6720 time: 0.3402s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.1447 acc_val: 0.4300 loss_test: 1.3262 acc_test: 0.6810 time: 0.3102s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1589 acc_val: 0.4600 loss_test: 1.3620 acc_test: 0.6830 time: 0.3509s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.2079 acc_val: 0.4767 loss_test: 1.4035 acc_test: 0.6880 time: 0.3023s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2341 acc_val: 0.4833 loss_test: 1.4343 acc_test: 0.6900 time: 0.3156s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2812 acc_val: 0.4867 loss_test: 1.4678 acc_test: 0.6860 time: 0.2378s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2748 acc_val: 0.4933 loss_test: 1.4807 acc_test: 0.6920 time: 0.3635s
Optimization Finished!
Total time elapsed: 147.4048s, best testing performance  0.698000, minimun loss  0.958266
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7943 acc_train: 0.1500 loss_val: 1.8051 acc_val: 0.1833 loss_test: 1.6667 acc_test: 0.5340 time: 0.2904s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.9259 acc_val: 0.3633 loss_test: 1.1854 acc_test: 0.6600 time: 0.2366s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9142 acc_val: 0.4100 loss_test: 1.2013 acc_test: 0.6720 time: 0.3031s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0306 acc_val: 0.4233 loss_test: 1.2781 acc_test: 0.6770 time: 0.3200s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0418 acc_val: 0.4667 loss_test: 1.3171 acc_test: 0.6860 time: 0.3281s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0484 acc_val: 0.4733 loss_test: 1.3522 acc_test: 0.6900 time: 0.3148s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4833 loss_test: 1.3883 acc_test: 0.6900 time: 0.2401s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1105 acc_val: 0.4933 loss_test: 1.4162 acc_test: 0.6890 time: 0.2390s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1481 acc_val: 0.5000 loss_test: 1.4393 acc_test: 0.6950 time: 0.3118s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1279 acc_val: 0.5100 loss_test: 1.4509 acc_test: 0.6970 time: 0.3186s
Optimization Finished!
Total time elapsed: 147.9735s, best testing performance  0.704000, minimun loss  0.962082
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1250 loss_val: 1.7969 acc_val: 0.1800 loss_test: 1.6951 acc_test: 0.5310 time: 0.3145s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9146 acc_val: 0.3733 loss_test: 1.1765 acc_test: 0.6590 time: 0.3201s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8787 acc_val: 0.4100 loss_test: 1.1868 acc_test: 0.6720 time: 0.3197s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9310 acc_val: 0.4400 loss_test: 1.2334 acc_test: 0.6870 time: 0.3556s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9828 acc_val: 0.4633 loss_test: 1.2759 acc_test: 0.6870 time: 0.3450s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0156 acc_val: 0.4733 loss_test: 1.3134 acc_test: 0.6950 time: 0.2353s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0596 acc_val: 0.4967 loss_test: 1.3509 acc_test: 0.6970 time: 0.2435s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1215 acc_val: 0.5033 loss_test: 1.3912 acc_test: 0.6990 time: 0.3183s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1661 acc_val: 0.5067 loss_test: 1.4277 acc_test: 0.7000 time: 0.3292s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2216 acc_val: 0.5000 loss_test: 1.4589 acc_test: 0.7010 time: 0.3499s
Optimization Finished!
Total time elapsed: 153.0116s, best testing performance  0.703000, minimun loss  0.963658
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8010 acc_train: 0.1833 loss_val: 1.8113 acc_val: 0.1200 loss_test: 1.6889 acc_test: 0.4600 time: 0.3295s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8676 acc_val: 0.3733 loss_test: 1.1802 acc_test: 0.6650 time: 0.3347s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8491 acc_val: 0.4133 loss_test: 1.1844 acc_test: 0.6780 time: 0.3318s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9531 acc_val: 0.4333 loss_test: 1.2403 acc_test: 0.6830 time: 0.3303s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9952 acc_val: 0.4733 loss_test: 1.2829 acc_test: 0.6900 time: 0.2387s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0795 acc_val: 0.4833 loss_test: 1.3314 acc_test: 0.6940 time: 0.2487s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1465 acc_val: 0.4867 loss_test: 1.3774 acc_test: 0.6920 time: 0.3401s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1792 acc_val: 0.5000 loss_test: 1.4128 acc_test: 0.6990 time: 0.3276s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2265 acc_val: 0.5133 loss_test: 1.4511 acc_test: 0.6970 time: 0.3055s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2758 acc_val: 0.5033 loss_test: 1.4826 acc_test: 0.6990 time: 0.3737s
Optimization Finished!
Total time elapsed: 151.6469s, best testing performance  0.703000, minimun loss  0.981798
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7886 acc_train: 0.1667 loss_val: 1.8026 acc_val: 0.1733 loss_test: 1.6882 acc_test: 0.4840 time: 0.3323s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8819 acc_val: 0.3867 loss_test: 1.1951 acc_test: 0.6620 time: 0.3245s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8488 acc_val: 0.4133 loss_test: 1.2018 acc_test: 0.6710 time: 0.3175s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9121 acc_val: 0.4533 loss_test: 1.2512 acc_test: 0.6810 time: 0.2391s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9573 acc_val: 0.4867 loss_test: 1.2962 acc_test: 0.6870 time: 0.3541s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9983 acc_val: 0.4933 loss_test: 1.3345 acc_test: 0.6940 time: 0.3457s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0530 acc_val: 0.5000 loss_test: 1.3775 acc_test: 0.6950 time: 0.3253s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0878 acc_val: 0.5100 loss_test: 1.4124 acc_test: 0.6940 time: 0.3198s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1325 acc_val: 0.5100 loss_test: 1.4501 acc_test: 0.6960 time: 0.2434s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1742 acc_val: 0.5033 loss_test: 1.4818 acc_test: 0.6940 time: 0.2360s
Optimization Finished!
Total time elapsed: 148.7255s, best testing performance  0.698000, minimun loss  1.005940
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7813 acc_train: 0.1667 loss_val: 1.8025 acc_val: 0.1867 loss_test: 1.6686 acc_test: 0.5360 time: 0.3053s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8475 acc_val: 0.3567 loss_test: 1.1555 acc_test: 0.6550 time: 0.2340s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8632 acc_val: 0.3967 loss_test: 1.1860 acc_test: 0.6720 time: 0.2394s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9432 acc_val: 0.4400 loss_test: 1.2434 acc_test: 0.6790 time: 0.3386s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0256 acc_val: 0.4533 loss_test: 1.2977 acc_test: 0.6860 time: 0.3089s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0804 acc_val: 0.4667 loss_test: 1.3467 acc_test: 0.6890 time: 0.3206s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1398 acc_val: 0.4833 loss_test: 1.3932 acc_test: 0.6920 time: 0.3532s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1775 acc_val: 0.4900 loss_test: 1.4349 acc_test: 0.6950 time: 0.2454s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2175 acc_val: 0.5033 loss_test: 1.4747 acc_test: 0.6930 time: 0.2523s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2532 acc_val: 0.5100 loss_test: 1.5108 acc_test: 0.6930 time: 0.3252s
Optimization Finished!
Total time elapsed: 148.6394s, best testing performance  0.697000, minimun loss  0.974120
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1583 loss_val: 1.8215 acc_val: 0.0633 loss_test: 1.6902 acc_test: 0.3620 time: 0.3208s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9535 acc_val: 0.3600 loss_test: 1.1868 acc_test: 0.6550 time: 0.2652s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.9334 acc_val: 0.4067 loss_test: 1.1986 acc_test: 0.6720 time: 0.3049s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9615 acc_val: 0.4300 loss_test: 1.2389 acc_test: 0.6860 time: 0.3212s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9804 acc_val: 0.4533 loss_test: 1.2763 acc_test: 0.6870 time: 0.3129s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0039 acc_val: 0.4767 loss_test: 1.3145 acc_test: 0.6910 time: 0.3065s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0282 acc_val: 0.5000 loss_test: 1.3501 acc_test: 0.6920 time: 0.2524s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0754 acc_val: 0.5067 loss_test: 1.3888 acc_test: 0.6950 time: 0.3372s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1347 acc_val: 0.5033 loss_test: 1.4302 acc_test: 0.6960 time: 0.3139s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1770 acc_val: 0.5067 loss_test: 1.4647 acc_test: 0.6960 time: 0.3067s
Optimization Finished!
Total time elapsed: 150.3221s, best testing performance  0.697000, minimun loss  0.974793
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7792 acc_train: 0.2333 loss_val: 1.7903 acc_val: 0.2167 loss_test: 1.6681 acc_test: 0.5050 time: 0.2947s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8705 acc_val: 0.3867 loss_test: 1.1945 acc_test: 0.6640 time: 0.2973s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9078 acc_val: 0.4333 loss_test: 1.2233 acc_test: 0.6740 time: 0.3263s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9288 acc_val: 0.4633 loss_test: 1.2671 acc_test: 0.6830 time: 0.3112s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9980 acc_val: 0.4800 loss_test: 1.3170 acc_test: 0.6890 time: 0.3312s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0249 acc_val: 0.4933 loss_test: 1.3602 acc_test: 0.6950 time: 0.2372s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0464 acc_val: 0.5067 loss_test: 1.4050 acc_test: 0.6970 time: 0.3126s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0845 acc_val: 0.5133 loss_test: 1.4491 acc_test: 0.7000 time: 0.3224s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1061 acc_val: 0.5167 loss_test: 1.4835 acc_test: 0.7010 time: 0.3926s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1701 acc_val: 0.5167 loss_test: 1.5266 acc_test: 0.7000 time: 0.2917s
Optimization Finished!
Total time elapsed: 154.2866s, best testing performance  0.703000, minimun loss  0.969770
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7961 acc_train: 0.1667 loss_val: 1.8165 acc_val: 0.1667 loss_test: 1.6584 acc_test: 0.5050 time: 0.3434s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7403 acc_val: 0.4000 loss_test: 1.1428 acc_test: 0.6750 time: 0.3129s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8450 acc_val: 0.4200 loss_test: 1.2024 acc_test: 0.6770 time: 0.3243s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9504 acc_val: 0.4433 loss_test: 1.2651 acc_test: 0.6870 time: 0.2350s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0031 acc_val: 0.4667 loss_test: 1.3043 acc_test: 0.6890 time: 0.2475s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0774 acc_val: 0.4733 loss_test: 1.3440 acc_test: 0.6920 time: 0.3336s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1323 acc_val: 0.4767 loss_test: 1.3811 acc_test: 0.6900 time: 0.3201s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1388 acc_val: 0.4900 loss_test: 1.4048 acc_test: 0.6910 time: 0.3139s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1865 acc_val: 0.4933 loss_test: 1.4343 acc_test: 0.6940 time: 0.3631s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2309 acc_val: 0.4967 loss_test: 1.4621 acc_test: 0.6890 time: 0.2461s
Optimization Finished!
Total time elapsed: 149.5108s, best testing performance  0.694000, minimun loss  0.968399
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1250 loss_val: 1.8253 acc_val: 0.1400 loss_test: 1.6644 acc_test: 0.4770 time: 0.2891s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8267 acc_val: 0.3767 loss_test: 1.1863 acc_test: 0.6690 time: 0.3139s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7990 acc_val: 0.4500 loss_test: 1.2009 acc_test: 0.6800 time: 0.2334s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9428 acc_val: 0.4533 loss_test: 1.2762 acc_test: 0.6840 time: 0.2448s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9949 acc_val: 0.4700 loss_test: 1.3166 acc_test: 0.6870 time: 0.3166s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0312 acc_val: 0.4800 loss_test: 1.3476 acc_test: 0.6910 time: 0.2838s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0939 acc_val: 0.4833 loss_test: 1.3888 acc_test: 0.6870 time: 0.3087s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1161 acc_val: 0.4900 loss_test: 1.4154 acc_test: 0.6930 time: 0.3424s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0805 acc_val: 0.5000 loss_test: 1.4237 acc_test: 0.6990 time: 0.2455s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1683 acc_val: 0.4967 loss_test: 1.4600 acc_test: 0.6940 time: 0.2465s
Optimization Finished!
Total time elapsed: 147.7942s, best testing performance  0.701000, minimun loss  0.976652
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7912 acc_train: 0.1750 loss_val: 1.7977 acc_val: 0.2067 loss_test: 1.6799 acc_test: 0.5340 time: 0.3183s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8359 acc_val: 0.3900 loss_test: 1.1608 acc_test: 0.6720 time: 0.2405s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9170 acc_val: 0.4267 loss_test: 1.2041 acc_test: 0.6770 time: 0.3526s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9900 acc_val: 0.4367 loss_test: 1.2642 acc_test: 0.6890 time: 0.3325s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0410 acc_val: 0.4667 loss_test: 1.3125 acc_test: 0.6900 time: 0.3580s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0525 acc_val: 0.4800 loss_test: 1.3456 acc_test: 0.6930 time: 0.3306s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0865 acc_val: 0.4867 loss_test: 1.3823 acc_test: 0.7000 time: 0.3449s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0752 acc_val: 0.5033 loss_test: 1.4068 acc_test: 0.7020 time: 0.2553s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1034 acc_val: 0.5100 loss_test: 1.4345 acc_test: 0.7020 time: 0.3725s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1304 acc_val: 0.5100 loss_test: 1.4620 acc_test: 0.6990 time: 0.3140s
Optimization Finished!
Total time elapsed: 148.2474s, best testing performance  0.705000, minimun loss  0.955818
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.1583 loss_val: 1.8308 acc_val: 0.0800 loss_test: 1.6780 acc_test: 0.4500 time: 0.2967s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8315 acc_val: 0.3667 loss_test: 1.1744 acc_test: 0.6610 time: 0.2930s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8065 acc_val: 0.4100 loss_test: 1.1866 acc_test: 0.6760 time: 0.2903s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9449 acc_val: 0.4400 loss_test: 1.2595 acc_test: 0.6810 time: 0.3602s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0061 acc_val: 0.4667 loss_test: 1.3055 acc_test: 0.6850 time: 0.3185s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0368 acc_val: 0.4800 loss_test: 1.3398 acc_test: 0.6970 time: 0.2419s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0790 acc_val: 0.5000 loss_test: 1.3715 acc_test: 0.6970 time: 0.2387s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1193 acc_val: 0.5067 loss_test: 1.4060 acc_test: 0.6940 time: 0.3285s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1278 acc_val: 0.5200 loss_test: 1.4248 acc_test: 0.6950 time: 0.3582s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1368 acc_val: 0.5167 loss_test: 1.4498 acc_test: 0.6980 time: 0.3218s
Optimization Finished!
Total time elapsed: 152.3820s, best testing performance  0.703000, minimun loss  0.978555
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7983 acc_train: 0.1500 loss_val: 1.8007 acc_val: 0.1767 loss_test: 1.6371 acc_test: 0.5450 time: 0.3392s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7205 acc_val: 0.3900 loss_test: 1.1146 acc_test: 0.6710 time: 0.3590s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7255 acc_val: 0.3967 loss_test: 1.1428 acc_test: 0.6860 time: 0.2841s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8622 acc_val: 0.4233 loss_test: 1.2241 acc_test: 0.6860 time: 0.3142s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9781 acc_val: 0.4367 loss_test: 1.2900 acc_test: 0.6800 time: 0.2375s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0448 acc_val: 0.4733 loss_test: 1.3364 acc_test: 0.6850 time: 0.2434s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0654 acc_val: 0.4800 loss_test: 1.3712 acc_test: 0.6930 time: 0.3097s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1473 acc_val: 0.4933 loss_test: 1.4119 acc_test: 0.6950 time: 0.3164s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2342 acc_val: 0.5000 loss_test: 1.4628 acc_test: 0.6950 time: 0.3160s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2692 acc_val: 0.5100 loss_test: 1.4897 acc_test: 0.6970 time: 0.3220s
Optimization Finished!
Total time elapsed: 152.9160s, best testing performance  0.701000, minimun loss  0.933145
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7742 acc_train: 0.2500 loss_val: 1.8092 acc_val: 0.2000 loss_test: 1.6486 acc_test: 0.5310 time: 0.2908s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7227 acc_val: 0.4133 loss_test: 1.1458 acc_test: 0.6770 time: 0.3681s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8348 acc_val: 0.4167 loss_test: 1.2021 acc_test: 0.6830 time: 0.2874s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0225 acc_val: 0.4467 loss_test: 1.2998 acc_test: 0.6860 time: 0.2337s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0569 acc_val: 0.4600 loss_test: 1.3377 acc_test: 0.6920 time: 0.2476s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.4800 loss_test: 1.3672 acc_test: 0.6900 time: 0.3354s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1145 acc_val: 0.4900 loss_test: 1.4032 acc_test: 0.6930 time: 0.3401s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1061 acc_val: 0.5100 loss_test: 1.4243 acc_test: 0.6970 time: 0.3565s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1356 acc_val: 0.5200 loss_test: 1.4473 acc_test: 0.6990 time: 0.3051s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1799 acc_val: 0.5100 loss_test: 1.4833 acc_test: 0.7000 time: 0.2454s
Optimization Finished!
Total time elapsed: 147.9203s, best testing performance  0.705000, minimun loss  0.954678
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7870 acc_train: 0.1833 loss_val: 1.8210 acc_val: 0.0867 loss_test: 1.6462 acc_test: 0.4670 time: 0.2932s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7750 acc_val: 0.3867 loss_test: 1.1664 acc_test: 0.6730 time: 0.3097s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8149 acc_val: 0.4033 loss_test: 1.1967 acc_test: 0.6820 time: 0.2442s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9409 acc_val: 0.4333 loss_test: 1.2739 acc_test: 0.6840 time: 0.3130s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0109 acc_val: 0.4567 loss_test: 1.3194 acc_test: 0.6850 time: 0.3316s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0399 acc_val: 0.4867 loss_test: 1.3587 acc_test: 0.6920 time: 0.3193s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0915 acc_val: 0.4967 loss_test: 1.3969 acc_test: 0.6930 time: 0.3167s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0920 acc_val: 0.5100 loss_test: 1.4257 acc_test: 0.7000 time: 0.3405s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1069 acc_val: 0.5167 loss_test: 1.4491 acc_test: 0.7000 time: 0.2376s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1522 acc_val: 0.5067 loss_test: 1.4792 acc_test: 0.6980 time: 0.3325s
Optimization Finished!
Total time elapsed: 147.7242s, best testing performance  0.705000, minimun loss  0.938044
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7871 acc_train: 0.2000 loss_val: 1.8018 acc_val: 0.2133 loss_test: 1.6667 acc_test: 0.4430 time: 0.2857s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7046 acc_val: 0.4000 loss_test: 1.1424 acc_test: 0.6680 time: 0.2572s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7709 acc_val: 0.4367 loss_test: 1.1863 acc_test: 0.6830 time: 0.3363s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9378 acc_val: 0.4433 loss_test: 1.2716 acc_test: 0.6840 time: 0.3032s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0163 acc_val: 0.4567 loss_test: 1.3227 acc_test: 0.6830 time: 0.3453s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0472 acc_val: 0.4800 loss_test: 1.3562 acc_test: 0.6870 time: 0.2921s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0674 acc_val: 0.5033 loss_test: 1.3829 acc_test: 0.6890 time: 0.2334s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0988 acc_val: 0.5067 loss_test: 1.4164 acc_test: 0.6950 time: 0.2586s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1472 acc_val: 0.5033 loss_test: 1.4473 acc_test: 0.6940 time: 0.3204s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1745 acc_val: 0.5033 loss_test: 1.4742 acc_test: 0.6950 time: 0.3091s
Optimization Finished!
Total time elapsed: 149.6798s, best testing performance  0.699000, minimun loss  0.963332
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7891 acc_train: 0.1667 loss_val: 1.8120 acc_val: 0.1900 loss_test: 1.6598 acc_test: 0.5330 time: 0.2980s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7141 acc_val: 0.4133 loss_test: 1.1097 acc_test: 0.6800 time: 0.3220s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8148 acc_val: 0.4300 loss_test: 1.1615 acc_test: 0.6910 time: 0.3283s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9666 acc_val: 0.4300 loss_test: 1.2478 acc_test: 0.6900 time: 0.3572s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0681 acc_val: 0.4633 loss_test: 1.3013 acc_test: 0.6880 time: 0.3572s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0966 acc_val: 0.4767 loss_test: 1.3433 acc_test: 0.6900 time: 0.2467s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1324 acc_val: 0.4933 loss_test: 1.3845 acc_test: 0.6920 time: 0.2500s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1639 acc_val: 0.5000 loss_test: 1.4155 acc_test: 0.6950 time: 0.3160s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1881 acc_val: 0.5000 loss_test: 1.4474 acc_test: 0.6930 time: 0.3071s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2414 acc_val: 0.5067 loss_test: 1.4841 acc_test: 0.6920 time: 0.3224s
Optimization Finished!
Total time elapsed: 154.7507s, best testing performance  0.698000, minimun loss  0.938091
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7882 acc_train: 0.1667 loss_val: 1.8352 acc_val: 0.1200 loss_test: 1.6680 acc_test: 0.4980 time: 0.3308s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.8001 acc_val: 0.3833 loss_test: 1.1718 acc_test: 0.6660 time: 0.3199s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8864 acc_val: 0.4100 loss_test: 1.2202 acc_test: 0.6690 time: 0.3293s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9456 acc_val: 0.4533 loss_test: 1.2670 acc_test: 0.6820 time: 0.2362s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.4700 loss_test: 1.3184 acc_test: 0.6860 time: 0.2319s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0567 acc_val: 0.4800 loss_test: 1.3565 acc_test: 0.6880 time: 0.3241s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1146 acc_val: 0.4900 loss_test: 1.3982 acc_test: 0.6910 time: 0.3218s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1519 acc_val: 0.4967 loss_test: 1.4329 acc_test: 0.6950 time: 0.3636s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1872 acc_val: 0.5000 loss_test: 1.4639 acc_test: 0.7000 time: 0.3168s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2188 acc_val: 0.5100 loss_test: 1.4989 acc_test: 0.7060 time: 0.2367s
Optimization Finished!
Total time elapsed: 149.8788s, best testing performance  0.709000, minimun loss  0.977939
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7946 acc_train: 0.1000 loss_val: 1.8194 acc_val: 0.1167 loss_test: 1.6750 acc_test: 0.4760 time: 0.3469s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6269 acc_val: 0.4200 loss_test: 1.1117 acc_test: 0.6760 time: 0.2915s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7371 acc_val: 0.4567 loss_test: 1.1604 acc_test: 0.6850 time: 0.2412s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8630 acc_val: 0.4633 loss_test: 1.2256 acc_test: 0.6890 time: 0.2444s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9782 acc_val: 0.4667 loss_test: 1.2889 acc_test: 0.6890 time: 0.3186s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0432 acc_val: 0.4700 loss_test: 1.3377 acc_test: 0.6870 time: 0.3189s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1164 acc_val: 0.4900 loss_test: 1.3897 acc_test: 0.6910 time: 0.3482s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1702 acc_val: 0.4933 loss_test: 1.4324 acc_test: 0.6920 time: 0.3194s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2211 acc_val: 0.5000 loss_test: 1.4687 acc_test: 0.6940 time: 0.2437s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2794 acc_val: 0.4933 loss_test: 1.5066 acc_test: 0.6950 time: 0.2507s
Optimization Finished!
Total time elapsed: 147.6953s, best testing performance  0.698000, minimun loss  0.975719
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7916 acc_train: 0.1667 loss_val: 1.7942 acc_val: 0.2000 loss_test: 1.6764 acc_test: 0.4280 time: 0.3593s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8096 acc_val: 0.3800 loss_test: 1.1476 acc_test: 0.6610 time: 0.2346s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8821 acc_val: 0.4367 loss_test: 1.1860 acc_test: 0.6860 time: 0.2498s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 2.0089 acc_val: 0.4467 loss_test: 1.2572 acc_test: 0.6900 time: 0.3218s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0478 acc_val: 0.4667 loss_test: 1.3043 acc_test: 0.6930 time: 0.3033s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0902 acc_val: 0.4867 loss_test: 1.3476 acc_test: 0.6890 time: 0.3767s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.5100 loss_test: 1.3822 acc_test: 0.6950 time: 0.3213s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1195 acc_val: 0.5100 loss_test: 1.4175 acc_test: 0.7020 time: 0.2467s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1366 acc_val: 0.5133 loss_test: 1.4489 acc_test: 0.7000 time: 0.3313s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1706 acc_val: 0.5067 loss_test: 1.4801 acc_test: 0.6990 time: 0.3139s
Optimization Finished!
Total time elapsed: 147.8474s, best testing performance  0.703000, minimun loss  0.969319
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7934 acc_train: 0.1417 loss_val: 1.7689 acc_val: 0.1867 loss_test: 1.6663 acc_test: 0.3900 time: 0.2926s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8364 acc_val: 0.3767 loss_test: 1.1718 acc_test: 0.6640 time: 0.3108s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8021 acc_val: 0.4267 loss_test: 1.1732 acc_test: 0.6790 time: 0.3132s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9027 acc_val: 0.4433 loss_test: 1.2295 acc_test: 0.6890 time: 0.3147s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0109 acc_val: 0.4600 loss_test: 1.2852 acc_test: 0.6830 time: 0.2848s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0601 acc_val: 0.4767 loss_test: 1.3240 acc_test: 0.6900 time: 0.2695s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0887 acc_val: 0.4967 loss_test: 1.3554 acc_test: 0.6900 time: 0.2357s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1323 acc_val: 0.4900 loss_test: 1.3902 acc_test: 0.6930 time: 0.3265s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1621 acc_val: 0.5000 loss_test: 1.4198 acc_test: 0.6920 time: 0.3057s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2086 acc_val: 0.5000 loss_test: 1.4515 acc_test: 0.6930 time: 0.3216s
Optimization Finished!
Total time elapsed: 151.2122s, best testing performance  0.696000, minimun loss  0.966418
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8177 acc_train: 0.1167 loss_val: 1.8067 acc_val: 0.0767 loss_test: 1.6808 acc_test: 0.4540 time: 0.3327s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7805 acc_val: 0.4033 loss_test: 1.1410 acc_test: 0.6670 time: 0.3574s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8831 acc_val: 0.4200 loss_test: 1.1929 acc_test: 0.6740 time: 0.3227s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9738 acc_val: 0.4367 loss_test: 1.2494 acc_test: 0.6810 time: 0.3290s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0532 acc_val: 0.4467 loss_test: 1.2988 acc_test: 0.6830 time: 0.2328s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0861 acc_val: 0.4767 loss_test: 1.3377 acc_test: 0.6880 time: 0.2525s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1247 acc_val: 0.4867 loss_test: 1.3773 acc_test: 0.6890 time: 0.3114s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1561 acc_val: 0.5033 loss_test: 1.4143 acc_test: 0.6920 time: 0.3204s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1765 acc_val: 0.4967 loss_test: 1.4472 acc_test: 0.6930 time: 0.3070s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1996 acc_val: 0.5000 loss_test: 1.4788 acc_test: 0.6970 time: 0.3239s
Optimization Finished!
Total time elapsed: 153.1558s, best testing performance  0.699000, minimun loss  0.964033
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7861 acc_train: 0.2000 loss_val: 1.8047 acc_val: 0.1233 loss_test: 1.6552 acc_test: 0.4720 time: 0.3385s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6307 acc_val: 0.4333 loss_test: 1.1225 acc_test: 0.6760 time: 0.3271s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7397 acc_val: 0.4333 loss_test: 1.1776 acc_test: 0.6880 time: 0.3178s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9596 acc_val: 0.4467 loss_test: 1.2853 acc_test: 0.6840 time: 0.2392s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0267 acc_val: 0.4700 loss_test: 1.3304 acc_test: 0.6920 time: 0.2379s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0795 acc_val: 0.4833 loss_test: 1.3726 acc_test: 0.6900 time: 0.3670s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1032 acc_val: 0.4967 loss_test: 1.4016 acc_test: 0.6940 time: 0.3361s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1141 acc_val: 0.5100 loss_test: 1.4247 acc_test: 0.7000 time: 0.3133s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1069 acc_val: 0.5167 loss_test: 1.4413 acc_test: 0.6980 time: 0.3310s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1071 acc_val: 0.5233 loss_test: 1.4626 acc_test: 0.7030 time: 0.2416s
Optimization Finished!
Total time elapsed: 147.8546s, best testing performance  0.706000, minimun loss  0.946458
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1417 loss_val: 1.8136 acc_val: 0.1400 loss_test: 1.6818 acc_test: 0.4880 time: 0.2773s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8460 acc_val: 0.3833 loss_test: 1.1833 acc_test: 0.6580 time: 0.3089s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8799 acc_val: 0.4233 loss_test: 1.2116 acc_test: 0.6740 time: 0.2342s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9865 acc_val: 0.4367 loss_test: 1.2708 acc_test: 0.6820 time: 0.3104s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0586 acc_val: 0.4567 loss_test: 1.3197 acc_test: 0.6830 time: 0.3443s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1213 acc_val: 0.4833 loss_test: 1.3620 acc_test: 0.6840 time: 0.3040s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1505 acc_val: 0.4867 loss_test: 1.3906 acc_test: 0.6900 time: 0.3468s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2205 acc_val: 0.4933 loss_test: 1.4330 acc_test: 0.6910 time: 0.2572s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2350 acc_val: 0.5033 loss_test: 1.4587 acc_test: 0.6920 time: 0.2357s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2714 acc_val: 0.5033 loss_test: 1.4887 acc_test: 0.6940 time: 0.3300s
Optimization Finished!
Total time elapsed: 147.0677s, best testing performance  0.698000, minimun loss  0.957194
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7813 acc_train: 0.3000 loss_val: 1.8195 acc_val: 0.0700 loss_test: 1.6405 acc_test: 0.4250 time: 0.3115s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7749 acc_val: 0.3967 loss_test: 1.1672 acc_test: 0.6620 time: 0.2438s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7433 acc_val: 0.4433 loss_test: 1.1750 acc_test: 0.6840 time: 0.2522s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8645 acc_val: 0.4567 loss_test: 1.2505 acc_test: 0.6880 time: 0.3318s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0130 acc_val: 0.4567 loss_test: 1.3172 acc_test: 0.6870 time: 0.3055s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0343 acc_val: 0.4900 loss_test: 1.3490 acc_test: 0.6900 time: 0.3356s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1101 acc_val: 0.4933 loss_test: 1.3912 acc_test: 0.6910 time: 0.3325s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1462 acc_val: 0.4967 loss_test: 1.4209 acc_test: 0.6970 time: 0.2410s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1907 acc_val: 0.5067 loss_test: 1.4502 acc_test: 0.6960 time: 0.2423s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2243 acc_val: 0.5067 loss_test: 1.4698 acc_test: 0.6970 time: 0.3459s
Optimization Finished!
Total time elapsed: 147.4164s, best testing performance  0.700000, minimun loss  0.935196
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7968 acc_train: 0.1167 loss_val: 1.8147 acc_val: 0.0533 loss_test: 1.6581 acc_test: 0.3580 time: 0.2885s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7852 acc_val: 0.3933 loss_test: 1.1641 acc_test: 0.6570 time: 0.2409s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8451 acc_val: 0.4267 loss_test: 1.2005 acc_test: 0.6830 time: 0.3142s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9746 acc_val: 0.4400 loss_test: 1.2767 acc_test: 0.6880 time: 0.3296s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0387 acc_val: 0.4633 loss_test: 1.3263 acc_test: 0.6920 time: 0.3190s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0895 acc_val: 0.4800 loss_test: 1.3679 acc_test: 0.6920 time: 0.3427s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1206 acc_val: 0.5000 loss_test: 1.3995 acc_test: 0.6930 time: 0.2371s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1900 acc_val: 0.5000 loss_test: 1.4341 acc_test: 0.6930 time: 0.2621s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2155 acc_val: 0.5000 loss_test: 1.4621 acc_test: 0.6960 time: 0.3263s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2451 acc_val: 0.5100 loss_test: 1.4916 acc_test: 0.6970 time: 0.3138s
Optimization Finished!
Total time elapsed: 152.5058s, best testing performance  0.701000, minimun loss  0.946497
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7847 acc_train: 0.2333 loss_val: 1.8354 acc_val: 0.0800 loss_test: 1.6482 acc_test: 0.4430 time: 0.2939s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8248 acc_val: 0.4033 loss_test: 1.1653 acc_test: 0.6610 time: 0.2979s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8876 acc_val: 0.4267 loss_test: 1.2035 acc_test: 0.6750 time: 0.3103s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0107 acc_val: 0.4367 loss_test: 1.2741 acc_test: 0.6810 time: 0.3113s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0672 acc_val: 0.4567 loss_test: 1.3205 acc_test: 0.6860 time: 0.3174s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0881 acc_val: 0.4667 loss_test: 1.3536 acc_test: 0.6880 time: 0.2348s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1160 acc_val: 0.4900 loss_test: 1.3919 acc_test: 0.6920 time: 0.2406s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1816 acc_val: 0.4933 loss_test: 1.4277 acc_test: 0.6950 time: 0.3161s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2311 acc_val: 0.5000 loss_test: 1.4574 acc_test: 0.6950 time: 0.3470s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2395 acc_val: 0.5100 loss_test: 1.4787 acc_test: 0.6940 time: 0.3423s
Optimization Finished!
Total time elapsed: 154.6295s, best testing performance  0.701000, minimun loss  0.942273
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7930 acc_train: 0.2000 loss_val: 1.7882 acc_val: 0.2067 loss_test: 1.6658 acc_test: 0.5310 time: 0.3314s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.6390 acc_val: 0.4467 loss_test: 1.1161 acc_test: 0.6810 time: 0.3397s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7511 acc_val: 0.4567 loss_test: 1.1738 acc_test: 0.6840 time: 0.3105s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9464 acc_val: 0.4533 loss_test: 1.2668 acc_test: 0.6850 time: 0.2937s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0278 acc_val: 0.4700 loss_test: 1.3199 acc_test: 0.6840 time: 0.3511s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0851 acc_val: 0.4800 loss_test: 1.3650 acc_test: 0.6870 time: 0.2346s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1365 acc_val: 0.4767 loss_test: 1.4081 acc_test: 0.6930 time: 0.2555s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.4967 loss_test: 1.4507 acc_test: 0.6950 time: 0.2955s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2073 acc_val: 0.5000 loss_test: 1.4888 acc_test: 0.6930 time: 0.3144s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2394 acc_val: 0.5067 loss_test: 1.5293 acc_test: 0.6930 time: 0.3432s
Optimization Finished!
Total time elapsed: 154.5079s, best testing performance  0.698000, minimun loss  0.966500
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8115 acc_train: 0.0917 loss_val: 1.8060 acc_val: 0.1500 loss_test: 1.6822 acc_test: 0.5200 time: 0.3306s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.6068 acc_val: 0.4533 loss_test: 1.1180 acc_test: 0.6750 time: 0.3611s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.6780 acc_val: 0.4900 loss_test: 1.1611 acc_test: 0.6890 time: 0.3122s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.7993 acc_val: 0.4833 loss_test: 1.2273 acc_test: 0.6970 time: 0.3497s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8970 acc_val: 0.4867 loss_test: 1.2814 acc_test: 0.6900 time: 0.2324s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9560 acc_val: 0.4967 loss_test: 1.3217 acc_test: 0.6930 time: 0.2528s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0207 acc_val: 0.5033 loss_test: 1.3661 acc_test: 0.6930 time: 0.3108s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0631 acc_val: 0.5033 loss_test: 1.3985 acc_test: 0.6960 time: 0.3383s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1024 acc_val: 0.5067 loss_test: 1.4303 acc_test: 0.6980 time: 0.3350s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1490 acc_val: 0.5100 loss_test: 1.4568 acc_test: 0.7000 time: 0.3245s
Optimization Finished!
Total time elapsed: 154.2781s, best testing performance  0.701000, minimun loss  0.996003
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7939 acc_train: 0.1583 loss_val: 1.8281 acc_val: 0.1767 loss_test: 1.6558 acc_test: 0.5230 time: 0.3398s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7277 acc_val: 0.3967 loss_test: 1.1445 acc_test: 0.6710 time: 0.3324s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8493 acc_val: 0.4133 loss_test: 1.1971 acc_test: 0.6850 time: 0.3143s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0212 acc_val: 0.4400 loss_test: 1.2767 acc_test: 0.6900 time: 0.2373s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0570 acc_val: 0.4467 loss_test: 1.3164 acc_test: 0.6890 time: 0.2390s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0684 acc_val: 0.4833 loss_test: 1.3512 acc_test: 0.6880 time: 0.3419s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1158 acc_val: 0.4933 loss_test: 1.3910 acc_test: 0.6890 time: 0.3057s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1824 acc_val: 0.5067 loss_test: 1.4322 acc_test: 0.6900 time: 0.3293s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2174 acc_val: 0.5000 loss_test: 1.4597 acc_test: 0.6920 time: 0.4075s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2831 acc_val: 0.5000 loss_test: 1.4961 acc_test: 0.6900 time: 0.3085s
Optimization Finished!
Total time elapsed: 152.0530s, best testing performance  0.696000, minimun loss  0.960332
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8159 acc_train: 0.1000 loss_val: 1.8064 acc_val: 0.1900 loss_test: 1.7073 acc_test: 0.4710 time: 0.3653s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.5804 acc_val: 0.4500 loss_test: 1.1342 acc_test: 0.6880 time: 0.2932s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.6851 acc_val: 0.4933 loss_test: 1.1850 acc_test: 0.6900 time: 0.2998s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8332 acc_val: 0.4933 loss_test: 1.2545 acc_test: 0.6910 time: 0.2350s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9025 acc_val: 0.4933 loss_test: 1.3006 acc_test: 0.6940 time: 0.2498s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9806 acc_val: 0.4933 loss_test: 1.3456 acc_test: 0.6940 time: 0.3131s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0091 acc_val: 0.5100 loss_test: 1.3713 acc_test: 0.6990 time: 0.3388s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0839 acc_val: 0.5067 loss_test: 1.4116 acc_test: 0.6930 time: 0.3299s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1278 acc_val: 0.5100 loss_test: 1.4403 acc_test: 0.6940 time: 0.3214s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1475 acc_val: 0.5100 loss_test: 1.4622 acc_test: 0.6970 time: 0.2419s
Optimization Finished!
Total time elapsed: 148.8777s, best testing performance  0.699000, minimun loss  0.997544
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7898 acc_train: 0.1583 loss_val: 1.8180 acc_val: 0.1100 loss_test: 1.6516 acc_test: 0.4720 time: 0.3388s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6953 acc_val: 0.4067 loss_test: 1.1366 acc_test: 0.6720 time: 0.3163s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7840 acc_val: 0.4333 loss_test: 1.1785 acc_test: 0.6740 time: 0.2347s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9265 acc_val: 0.4300 loss_test: 1.2402 acc_test: 0.6820 time: 0.2539s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9975 acc_val: 0.4533 loss_test: 1.2888 acc_test: 0.6850 time: 0.3279s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0705 acc_val: 0.4667 loss_test: 1.3367 acc_test: 0.6900 time: 0.3263s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0886 acc_val: 0.4833 loss_test: 1.3703 acc_test: 0.6890 time: 0.3452s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1046 acc_val: 0.4933 loss_test: 1.3997 acc_test: 0.6930 time: 0.3315s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1554 acc_val: 0.5033 loss_test: 1.4376 acc_test: 0.6920 time: 0.2386s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1801 acc_val: 0.5067 loss_test: 1.4649 acc_test: 0.6950 time: 0.2405s
Optimization Finished!
Total time elapsed: 147.8841s, best testing performance  0.698000, minimun loss  0.958315
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7804 acc_train: 0.1833 loss_val: 1.8104 acc_val: 0.1833 loss_test: 1.6462 acc_test: 0.5340 time: 0.3146s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6105 acc_val: 0.4367 loss_test: 1.1119 acc_test: 0.6730 time: 0.2352s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7682 acc_val: 0.4700 loss_test: 1.1776 acc_test: 0.6860 time: 0.2320s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0022 acc_val: 0.4433 loss_test: 1.2831 acc_test: 0.6870 time: 0.3177s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0516 acc_val: 0.4567 loss_test: 1.3267 acc_test: 0.6890 time: 0.3595s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1226 acc_val: 0.4633 loss_test: 1.3619 acc_test: 0.6890 time: 0.3549s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1084 acc_val: 0.4867 loss_test: 1.3856 acc_test: 0.6940 time: 0.3025s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1622 acc_val: 0.5033 loss_test: 1.4211 acc_test: 0.6940 time: 0.3293s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1929 acc_val: 0.5133 loss_test: 1.4481 acc_test: 0.6930 time: 0.2451s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2075 acc_val: 0.5100 loss_test: 1.4683 acc_test: 0.6940 time: 0.3161s
Optimization Finished!
Total time elapsed: 149.4011s, best testing performance  0.701000, minimun loss  0.935456
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7997 acc_train: 0.1750 loss_val: 1.8348 acc_val: 0.0733 loss_test: 1.6587 acc_test: 0.3550 time: 0.3431s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.5424 acc_val: 0.4733 loss_test: 1.1133 acc_test: 0.6920 time: 0.2332s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7103 acc_val: 0.4733 loss_test: 1.1799 acc_test: 0.6950 time: 0.3529s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9105 acc_val: 0.4667 loss_test: 1.2789 acc_test: 0.6890 time: 0.3158s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0520 acc_val: 0.4633 loss_test: 1.3413 acc_test: 0.6880 time: 0.3303s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0230 acc_val: 0.4833 loss_test: 1.3585 acc_test: 0.6920 time: 0.3261s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0579 acc_val: 0.5000 loss_test: 1.3898 acc_test: 0.6920 time: 0.2971s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0821 acc_val: 0.5033 loss_test: 1.4160 acc_test: 0.6960 time: 0.2541s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1098 acc_val: 0.5067 loss_test: 1.4422 acc_test: 0.6940 time: 0.2596s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1569 acc_val: 0.5033 loss_test: 1.4700 acc_test: 0.6950 time: 0.3140s
Optimization Finished!
Total time elapsed: 148.5418s, best testing performance  0.703000, minimun loss  0.968737
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.0917 loss_val: 1.8015 acc_val: 0.1200 loss_test: 1.6589 acc_test: 0.5350 time: 0.3030s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.5235 acc_val: 0.4733 loss_test: 1.0982 acc_test: 0.6890 time: 0.3451s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.6464 acc_val: 0.4867 loss_test: 1.1515 acc_test: 0.6990 time: 0.3667s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8944 acc_val: 0.4767 loss_test: 1.2640 acc_test: 0.6890 time: 0.3175s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9897 acc_val: 0.4733 loss_test: 1.3205 acc_test: 0.6950 time: 0.3328s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0296 acc_val: 0.4900 loss_test: 1.3549 acc_test: 0.6910 time: 0.3451s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0826 acc_val: 0.5100 loss_test: 1.3915 acc_test: 0.6930 time: 0.2369s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1220 acc_val: 0.5167 loss_test: 1.4267 acc_test: 0.6960 time: 0.2564s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1395 acc_val: 0.5167 loss_test: 1.4510 acc_test: 0.6970 time: 0.3292s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2096 acc_val: 0.4967 loss_test: 1.4921 acc_test: 0.6920 time: 0.3111s
Optimization Finished!
Total time elapsed: 152.1702s, best testing performance  0.706000, minimun loss  0.938601
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7931 acc_train: 0.2250 loss_val: 1.7749 acc_val: 0.2100 loss_test: 1.6577 acc_test: 0.5520 time: 0.2750s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.4790 acc_val: 0.4800 loss_test: 1.0991 acc_test: 0.6960 time: 0.3532s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.6300 acc_val: 0.4800 loss_test: 1.1592 acc_test: 0.6970 time: 0.3289s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9153 acc_val: 0.4733 loss_test: 1.2784 acc_test: 0.6900 time: 0.3369s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0282 acc_val: 0.4700 loss_test: 1.3312 acc_test: 0.6950 time: 0.3621s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0830 acc_val: 0.4800 loss_test: 1.3742 acc_test: 0.6920 time: 0.2331s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1165 acc_val: 0.4900 loss_test: 1.4079 acc_test: 0.6910 time: 0.2405s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2202 acc_val: 0.4933 loss_test: 1.4508 acc_test: 0.6920 time: 0.3297s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2423 acc_val: 0.5000 loss_test: 1.4706 acc_test: 0.6920 time: 0.3228s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2390 acc_val: 0.5033 loss_test: 1.4855 acc_test: 0.6960 time: 0.3751s
Optimization Finished!
Total time elapsed: 154.9314s, best testing performance  0.701000, minimun loss  0.951278
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8097 acc_train: 0.0917 loss_val: 1.8052 acc_val: 0.1300 loss_test: 1.6522 acc_test: 0.5000 time: 0.3396s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6599 acc_val: 0.4500 loss_test: 1.1285 acc_test: 0.6810 time: 0.3313s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7630 acc_val: 0.4567 loss_test: 1.1673 acc_test: 0.6870 time: 0.3293s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0169 acc_val: 0.4600 loss_test: 1.2823 acc_test: 0.6800 time: 0.3795s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1751 acc_val: 0.4500 loss_test: 1.3530 acc_test: 0.6840 time: 0.2325s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1865 acc_val: 0.4633 loss_test: 1.3831 acc_test: 0.6860 time: 0.2346s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.2265 acc_val: 0.4800 loss_test: 1.4195 acc_test: 0.6930 time: 0.3143s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2355 acc_val: 0.4967 loss_test: 1.4413 acc_test: 0.6950 time: 0.3057s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2357 acc_val: 0.5067 loss_test: 1.4662 acc_test: 0.6920 time: 0.3191s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2637 acc_val: 0.5067 loss_test: 1.4962 acc_test: 0.6920 time: 0.2988s
Optimization Finished!
Total time elapsed: 155.5560s, best testing performance  0.701000, minimun loss  0.962207
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8013 acc_train: 0.1083 loss_val: 1.8228 acc_val: 0.0467 loss_test: 1.6975 acc_test: 0.3270 time: 0.3318s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8169 acc_val: 0.4000 loss_test: 1.1732 acc_test: 0.6630 time: 0.3020s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8372 acc_val: 0.4600 loss_test: 1.1894 acc_test: 0.6820 time: 0.3148s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8959 acc_val: 0.4633 loss_test: 1.2370 acc_test: 0.6890 time: 0.3117s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9664 acc_val: 0.4733 loss_test: 1.2830 acc_test: 0.6870 time: 0.2342s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0136 acc_val: 0.4867 loss_test: 1.3294 acc_test: 0.6910 time: 0.2451s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0509 acc_val: 0.4933 loss_test: 1.3683 acc_test: 0.6940 time: 0.3020s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0928 acc_val: 0.5100 loss_test: 1.4074 acc_test: 0.6950 time: 0.3822s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1133 acc_val: 0.5100 loss_test: 1.4415 acc_test: 0.6980 time: 0.3544s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1282 acc_val: 0.5200 loss_test: 1.4727 acc_test: 0.6990 time: 0.2951s
Optimization Finished!
Total time elapsed: 153.4533s, best testing performance  0.704000, minimun loss  0.972635
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8028 acc_train: 0.1167 loss_val: 1.7801 acc_val: 0.2267 loss_test: 1.6951 acc_test: 0.5210 time: 0.3483s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7356 acc_val: 0.4233 loss_test: 1.1507 acc_test: 0.6700 time: 0.3187s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8097 acc_val: 0.4233 loss_test: 1.1810 acc_test: 0.6830 time: 0.3065s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8520 acc_val: 0.4567 loss_test: 1.2209 acc_test: 0.6920 time: 0.2349s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9083 acc_val: 0.4667 loss_test: 1.2640 acc_test: 0.6920 time: 0.2480s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9394 acc_val: 0.4767 loss_test: 1.3013 acc_test: 0.6940 time: 0.3825s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9728 acc_val: 0.5100 loss_test: 1.3363 acc_test: 0.6990 time: 0.3486s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0056 acc_val: 0.5067 loss_test: 1.3695 acc_test: 0.7000 time: 0.3068s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0527 acc_val: 0.5100 loss_test: 1.4055 acc_test: 0.6980 time: 0.3154s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1009 acc_val: 0.5100 loss_test: 1.4372 acc_test: 0.7010 time: 0.2395s
Optimization Finished!
Total time elapsed: 151.2449s, best testing performance  0.705000, minimun loss  0.974093
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7757 acc_train: 0.2583 loss_val: 1.8074 acc_val: 0.1567 loss_test: 1.6811 acc_test: 0.4850 time: 0.3159s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8769 acc_val: 0.3767 loss_test: 1.2020 acc_test: 0.6640 time: 0.3130s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8793 acc_val: 0.4233 loss_test: 1.2098 acc_test: 0.6780 time: 0.2999s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9299 acc_val: 0.4567 loss_test: 1.2520 acc_test: 0.6870 time: 0.2346s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9821 acc_val: 0.4700 loss_test: 1.2940 acc_test: 0.6900 time: 0.3245s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0226 acc_val: 0.4767 loss_test: 1.3341 acc_test: 0.6930 time: 0.3046s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0910 acc_val: 0.4833 loss_test: 1.3810 acc_test: 0.6930 time: 0.3238s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1166 acc_val: 0.5033 loss_test: 1.4161 acc_test: 0.6940 time: 0.3427s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1429 acc_val: 0.5100 loss_test: 1.4522 acc_test: 0.6950 time: 0.3146s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1756 acc_val: 0.5133 loss_test: 1.4860 acc_test: 0.6970 time: 0.2412s
Optimization Finished!
Total time elapsed: 148.8582s, best testing performance  0.705000, minimun loss  0.982138
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8067 acc_train: 0.1083 loss_val: 1.8241 acc_val: 0.1933 loss_test: 1.7004 acc_test: 0.5240 time: 0.3468s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7861 acc_val: 0.4033 loss_test: 1.1734 acc_test: 0.6680 time: 0.3145s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8261 acc_val: 0.4233 loss_test: 1.1954 acc_test: 0.6760 time: 0.2354s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8696 acc_val: 0.4567 loss_test: 1.2356 acc_test: 0.6890 time: 0.2527s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9428 acc_val: 0.4667 loss_test: 1.2827 acc_test: 0.6890 time: 0.3259s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9880 acc_val: 0.4900 loss_test: 1.3235 acc_test: 0.6930 time: 0.3048s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 1.9871 acc_val: 0.5100 loss_test: 1.3515 acc_test: 0.6950 time: 0.3224s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0363 acc_val: 0.5100 loss_test: 1.3894 acc_test: 0.6980 time: 0.3383s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0491 acc_val: 0.5167 loss_test: 1.4162 acc_test: 0.7000 time: 0.2406s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0460 acc_val: 0.5133 loss_test: 1.4348 acc_test: 0.7010 time: 0.2559s
Optimization Finished!
Total time elapsed: 147.8716s, best testing performance  0.707000, minimun loss  0.980702
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7900 acc_train: 0.1667 loss_val: 1.7831 acc_val: 0.2100 loss_test: 1.6703 acc_test: 0.5430 time: 0.2874s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.6252 acc_val: 0.4333 loss_test: 1.1131 acc_test: 0.6820 time: 0.2345s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7562 acc_val: 0.4733 loss_test: 1.1716 acc_test: 0.6850 time: 0.2417s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8817 acc_val: 0.4567 loss_test: 1.2310 acc_test: 0.6860 time: 0.3187s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9456 acc_val: 0.4600 loss_test: 1.2762 acc_test: 0.6910 time: 0.3264s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0023 acc_val: 0.4800 loss_test: 1.3189 acc_test: 0.6920 time: 0.3160s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4900 loss_test: 1.3625 acc_test: 0.6920 time: 0.2865s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0995 acc_val: 0.5100 loss_test: 1.4003 acc_test: 0.6910 time: 0.2437s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1410 acc_val: 0.5067 loss_test: 1.4370 acc_test: 0.6930 time: 0.2409s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1719 acc_val: 0.5067 loss_test: 1.4693 acc_test: 0.6910 time: 0.3306s
Optimization Finished!
Total time elapsed: 147.7779s, best testing performance  0.695000, minimun loss  0.981281
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8150 acc_train: 0.0417 loss_val: 1.8196 acc_val: 0.1967 loss_test: 1.6984 acc_test: 0.4380 time: 0.3323s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8226 acc_val: 0.4100 loss_test: 1.1895 acc_test: 0.6680 time: 0.2460s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8743 acc_val: 0.4400 loss_test: 1.2177 acc_test: 0.6800 time: 0.2929s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9684 acc_val: 0.4467 loss_test: 1.2723 acc_test: 0.6840 time: 0.3267s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0156 acc_val: 0.4667 loss_test: 1.3146 acc_test: 0.6890 time: 0.2893s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0459 acc_val: 0.4767 loss_test: 1.3539 acc_test: 0.6860 time: 0.3173s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0832 acc_val: 0.4833 loss_test: 1.3891 acc_test: 0.6900 time: 0.3147s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1224 acc_val: 0.5033 loss_test: 1.4248 acc_test: 0.6910 time: 0.2422s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1629 acc_val: 0.5067 loss_test: 1.4583 acc_test: 0.6970 time: 0.3607s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1955 acc_val: 0.5167 loss_test: 1.4882 acc_test: 0.7010 time: 0.3709s
Optimization Finished!
Total time elapsed: 149.2235s, best testing performance  0.703000, minimun loss  1.004168
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7853 acc_train: 0.1583 loss_val: 1.7856 acc_val: 0.0767 loss_test: 1.6830 acc_test: 0.4150 time: 0.2824s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7249 acc_val: 0.3933 loss_test: 1.1458 acc_test: 0.6690 time: 0.3218s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7689 acc_val: 0.4433 loss_test: 1.1819 acc_test: 0.6790 time: 0.3181s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8825 acc_val: 0.4533 loss_test: 1.2407 acc_test: 0.6820 time: 0.3027s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9487 acc_val: 0.4667 loss_test: 1.2906 acc_test: 0.6870 time: 0.3013s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9783 acc_val: 0.4733 loss_test: 1.3349 acc_test: 0.6940 time: 0.3287s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0561 acc_val: 0.4867 loss_test: 1.3874 acc_test: 0.6930 time: 0.2423s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1152 acc_val: 0.5033 loss_test: 1.4386 acc_test: 0.6960 time: 0.3296s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1719 acc_val: 0.5133 loss_test: 1.4868 acc_test: 0.6990 time: 0.3192s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2019 acc_val: 0.5133 loss_test: 1.5229 acc_test: 0.7000 time: 0.3534s
Optimization Finished!
Total time elapsed: 154.1272s, best testing performance  0.702000, minimun loss  0.983332
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.1833 loss_val: 1.8151 acc_val: 0.1600 loss_test: 1.6937 acc_test: 0.4960 time: 0.2931s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.9968 acc_val: 0.3767 loss_test: 1.2250 acc_test: 0.6560 time: 0.3341s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9614 acc_val: 0.4033 loss_test: 1.2256 acc_test: 0.6700 time: 0.3015s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9691 acc_val: 0.4400 loss_test: 1.2566 acc_test: 0.6800 time: 0.3214s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0017 acc_val: 0.4600 loss_test: 1.2933 acc_test: 0.6870 time: 0.2979s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0334 acc_val: 0.4667 loss_test: 1.3305 acc_test: 0.6920 time: 0.2382s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0748 acc_val: 0.4867 loss_test: 1.3714 acc_test: 0.6940 time: 0.2452s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1219 acc_val: 0.4967 loss_test: 1.4110 acc_test: 0.6970 time: 0.3163s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1770 acc_val: 0.5000 loss_test: 1.4493 acc_test: 0.6970 time: 0.2983s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2235 acc_val: 0.5100 loss_test: 1.4891 acc_test: 0.7000 time: 0.3000s
Optimization Finished!
Total time elapsed: 154.2713s, best testing performance  0.702000, minimun loss  0.998590
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7881 acc_train: 0.1667 loss_val: 1.8028 acc_val: 0.1433 loss_test: 1.6868 acc_test: 0.5000 time: 0.3088s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7875 acc_val: 0.3933 loss_test: 1.1560 acc_test: 0.6630 time: 0.3382s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7742 acc_val: 0.4500 loss_test: 1.1612 acc_test: 0.6830 time: 0.3132s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8263 acc_val: 0.4633 loss_test: 1.2072 acc_test: 0.6880 time: 0.3147s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9123 acc_val: 0.4633 loss_test: 1.2638 acc_test: 0.6880 time: 0.2346s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9424 acc_val: 0.4733 loss_test: 1.3021 acc_test: 0.6910 time: 0.2503s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0020 acc_val: 0.4900 loss_test: 1.3455 acc_test: 0.6920 time: 0.3417s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0234 acc_val: 0.5067 loss_test: 1.3788 acc_test: 0.6970 time: 0.3038s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0453 acc_val: 0.5100 loss_test: 1.4128 acc_test: 0.7010 time: 0.3256s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0678 acc_val: 0.5067 loss_test: 1.4421 acc_test: 0.6990 time: 0.3322s
Optimization Finished!
Total time elapsed: 154.8644s, best testing performance  0.701000, minimun loss  0.981466
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.2167 loss_val: 1.7924 acc_val: 0.2333 loss_test: 1.6735 acc_test: 0.5660 time: 0.3217s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.7629 acc_val: 0.4167 loss_test: 1.1728 acc_test: 0.6650 time: 0.2986s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7683 acc_val: 0.4500 loss_test: 1.1820 acc_test: 0.6820 time: 0.3328s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8934 acc_val: 0.4533 loss_test: 1.2437 acc_test: 0.6920 time: 0.2975s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9808 acc_val: 0.4700 loss_test: 1.2941 acc_test: 0.6900 time: 0.2341s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0205 acc_val: 0.4767 loss_test: 1.3376 acc_test: 0.6930 time: 0.3348s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0334 acc_val: 0.4900 loss_test: 1.3691 acc_test: 0.6950 time: 0.3210s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1022 acc_val: 0.4900 loss_test: 1.4167 acc_test: 0.6910 time: 0.3256s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1487 acc_val: 0.4933 loss_test: 1.4525 acc_test: 0.6910 time: 0.3687s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2191 acc_val: 0.5067 loss_test: 1.4950 acc_test: 0.6960 time: 0.3406s
Optimization Finished!
Total time elapsed: 152.9063s, best testing performance  0.696000, minimun loss  0.985357
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7821 acc_train: 0.1833 loss_val: 1.7948 acc_val: 0.1933 loss_test: 1.6438 acc_test: 0.4960 time: 0.3060s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6493 acc_val: 0.4100 loss_test: 1.1392 acc_test: 0.6750 time: 0.3104s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8336 acc_val: 0.4267 loss_test: 1.2130 acc_test: 0.6860 time: 0.3018s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9990 acc_val: 0.4367 loss_test: 1.2923 acc_test: 0.6890 time: 0.2376s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0855 acc_val: 0.4467 loss_test: 1.3380 acc_test: 0.6910 time: 0.2468s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0890 acc_val: 0.4700 loss_test: 1.3643 acc_test: 0.6910 time: 0.2989s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0774 acc_val: 0.4900 loss_test: 1.3861 acc_test: 0.6940 time: 0.3285s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0860 acc_val: 0.5033 loss_test: 1.4158 acc_test: 0.7000 time: 0.3189s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1199 acc_val: 0.5033 loss_test: 1.4480 acc_test: 0.7000 time: 0.3179s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1668 acc_val: 0.5067 loss_test: 1.4780 acc_test: 0.7020 time: 0.2402s
Optimization Finished!
Total time elapsed: 149.5205s, best testing performance  0.703000, minimun loss  0.972021
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8079 acc_train: 0.0833 loss_val: 1.7982 acc_val: 0.1333 loss_test: 1.6554 acc_test: 0.5400 time: 0.3350s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.6488 acc_val: 0.4233 loss_test: 1.1422 acc_test: 0.6800 time: 0.3047s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.6985 acc_val: 0.4400 loss_test: 1.1728 acc_test: 0.6840 time: 0.2343s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9479 acc_val: 0.4300 loss_test: 1.2870 acc_test: 0.6850 time: 0.2333s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0615 acc_val: 0.4533 loss_test: 1.3368 acc_test: 0.6920 time: 0.3240s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0416 acc_val: 0.4800 loss_test: 1.3514 acc_test: 0.6880 time: 0.3074s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0716 acc_val: 0.4867 loss_test: 1.3812 acc_test: 0.6910 time: 0.3338s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0767 acc_val: 0.5033 loss_test: 1.4048 acc_test: 0.6960 time: 0.3300s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1168 acc_val: 0.5133 loss_test: 1.4352 acc_test: 0.6960 time: 0.3147s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1443 acc_val: 0.5100 loss_test: 1.4612 acc_test: 0.6970 time: 0.2347s
Optimization Finished!
Total time elapsed: 148.6289s, best testing performance  0.699000, minimun loss  0.969307
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7699 acc_train: 0.2583 loss_val: 1.8197 acc_val: 0.1700 loss_test: 1.6554 acc_test: 0.5390 time: 0.2934s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.4761 acc_val: 0.4433 loss_test: 1.0817 acc_test: 0.6980 time: 0.2367s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.6241 acc_val: 0.4733 loss_test: 1.1386 acc_test: 0.6980 time: 0.2326s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8689 acc_val: 0.4667 loss_test: 1.2439 acc_test: 0.6970 time: 0.3299s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9728 acc_val: 0.4700 loss_test: 1.3052 acc_test: 0.6920 time: 0.3345s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0311 acc_val: 0.4800 loss_test: 1.3483 acc_test: 0.6930 time: 0.3143s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0723 acc_val: 0.5000 loss_test: 1.3877 acc_test: 0.6940 time: 0.3471s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0978 acc_val: 0.5033 loss_test: 1.4242 acc_test: 0.7000 time: 0.3119s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1272 acc_val: 0.5133 loss_test: 1.4641 acc_test: 0.6970 time: 0.2453s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1878 acc_val: 0.5033 loss_test: 1.5028 acc_test: 0.6960 time: 0.2493s
Optimization Finished!
Total time elapsed: 147.9358s, best testing performance  0.705000, minimun loss  0.959669
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8134 acc_train: 0.1000 loss_val: 1.7821 acc_val: 0.1967 loss_test: 1.6693 acc_test: 0.5480 time: 0.3086s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.6931 acc_val: 0.4100 loss_test: 1.1304 acc_test: 0.6880 time: 0.2352s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8138 acc_val: 0.4300 loss_test: 1.1865 acc_test: 0.6880 time: 0.2437s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9979 acc_val: 0.4433 loss_test: 1.2752 acc_test: 0.6860 time: 0.3432s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0359 acc_val: 0.4533 loss_test: 1.3135 acc_test: 0.6910 time: 0.3508s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0612 acc_val: 0.4633 loss_test: 1.3528 acc_test: 0.6900 time: 0.3268s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0970 acc_val: 0.4900 loss_test: 1.3877 acc_test: 0.6960 time: 0.3126s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1061 acc_val: 0.4967 loss_test: 1.4184 acc_test: 0.7020 time: 0.3169s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1367 acc_val: 0.4967 loss_test: 1.4448 acc_test: 0.6990 time: 0.2403s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1754 acc_val: 0.5000 loss_test: 1.4777 acc_test: 0.6980 time: 0.2477s
Optimization Finished!
Total time elapsed: 146.9638s, best testing performance  0.704000, minimun loss  0.965566
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 30, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8088 acc_train: 0.1417 loss_val: 1.7747 acc_val: 0.2100 loss_test: 1.6931 acc_test: 0.3370 time: 0.3424s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6426 acc_val: 0.4167 loss_test: 1.1465 acc_test: 0.6750 time: 0.2359s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7514 acc_val: 0.4367 loss_test: 1.1953 acc_test: 0.6780 time: 0.2399s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8732 acc_val: 0.4467 loss_test: 1.2712 acc_test: 0.6850 time: 0.3236s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0256 acc_val: 0.4433 loss_test: 1.3284 acc_test: 0.6900 time: 0.3366s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0825 acc_val: 0.4733 loss_test: 1.3660 acc_test: 0.6910 time: 0.3237s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0821 acc_val: 0.4800 loss_test: 1.3892 acc_test: 0.6920 time: 0.3123s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0643 acc_val: 0.5033 loss_test: 1.4065 acc_test: 0.6930 time: 0.3553s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1013 acc_val: 0.5133 loss_test: 1.4382 acc_test: 0.6980 time: 0.2444s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1480 acc_val: 0.5133 loss_test: 1.4666 acc_test: 0.6990 time: 0.2508s
Optimization Finished!
Total time elapsed: 148.0937s, best testing performance  0.701000, minimun loss  0.986579
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7881 acc_train: 0.1917 loss_val: 1.8235 acc_val: 0.0833 loss_test: 1.6517 acc_test: 0.4690 time: 0.3698s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.9504 acc_val: 0.3800 loss_test: 1.2031 acc_test: 0.6650 time: 0.2694s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.9428 acc_val: 0.3967 loss_test: 1.2211 acc_test: 0.6750 time: 0.4086s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0471 acc_val: 0.4333 loss_test: 1.2872 acc_test: 0.6830 time: 0.3587s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0782 acc_val: 0.4533 loss_test: 1.3291 acc_test: 0.6850 time: 0.3242s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1025 acc_val: 0.4733 loss_test: 1.3614 acc_test: 0.6890 time: 0.4159s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1437 acc_val: 0.4833 loss_test: 1.4014 acc_test: 0.6920 time: 0.2951s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1446 acc_val: 0.4967 loss_test: 1.4268 acc_test: 0.6910 time: 0.2835s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1950 acc_val: 0.4933 loss_test: 1.4550 acc_test: 0.6920 time: 0.3647s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1865 acc_val: 0.5033 loss_test: 1.4724 acc_test: 0.6940 time: 0.4097s
Optimization Finished!
Total time elapsed: 170.6045s, best testing performance  0.698000, minimun loss  0.986263
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7994 acc_train: 0.1333 loss_val: 1.8499 acc_val: 0.1133 loss_test: 1.6718 acc_test: 0.4030 time: 0.3334s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.9003 acc_val: 0.3933 loss_test: 1.1966 acc_test: 0.6630 time: 0.3354s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9956 acc_val: 0.3900 loss_test: 1.2461 acc_test: 0.6720 time: 0.3904s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0674 acc_val: 0.4167 loss_test: 1.3022 acc_test: 0.6810 time: 0.4260s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0918 acc_val: 0.4567 loss_test: 1.3413 acc_test: 0.6860 time: 0.3953s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0997 acc_val: 0.4733 loss_test: 1.3769 acc_test: 0.6920 time: 0.2680s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1605 acc_val: 0.4833 loss_test: 1.4195 acc_test: 0.6900 time: 0.2915s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1903 acc_val: 0.4867 loss_test: 1.4513 acc_test: 0.6910 time: 0.3961s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2480 acc_val: 0.4833 loss_test: 1.4821 acc_test: 0.6950 time: 0.3880s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3010 acc_val: 0.4900 loss_test: 1.5174 acc_test: 0.6880 time: 0.3501s
Optimization Finished!
Total time elapsed: 177.0333s, best testing performance  0.695000, minimun loss  1.005979
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8329 acc_train: 0.0667 loss_val: 1.8306 acc_val: 0.0600 loss_test: 1.7023 acc_test: 0.3460 time: 0.3799s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9497 acc_val: 0.3667 loss_test: 1.2044 acc_test: 0.6580 time: 0.4129s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.9601 acc_val: 0.4067 loss_test: 1.2176 acc_test: 0.6680 time: 0.3611s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0509 acc_val: 0.4200 loss_test: 1.2760 acc_test: 0.6750 time: 0.2753s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0758 acc_val: 0.4500 loss_test: 1.3170 acc_test: 0.6870 time: 0.2830s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1100 acc_val: 0.4667 loss_test: 1.3554 acc_test: 0.6930 time: 0.4143s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1393 acc_val: 0.4767 loss_test: 1.3881 acc_test: 0.6960 time: 0.3596s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1931 acc_val: 0.4833 loss_test: 1.4242 acc_test: 0.7000 time: 0.3906s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2345 acc_val: 0.5000 loss_test: 1.4544 acc_test: 0.7000 time: 0.3752s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2664 acc_val: 0.4967 loss_test: 1.4767 acc_test: 0.7030 time: 0.2711s
Optimization Finished!
Total time elapsed: 171.1039s, best testing performance  0.704000, minimun loss  0.993321
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7829 acc_train: 0.2000 loss_val: 1.8191 acc_val: 0.1400 loss_test: 1.6496 acc_test: 0.4960 time: 0.3652s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 2.0765 acc_val: 0.3733 loss_test: 1.2430 acc_test: 0.6590 time: 0.3820s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 2.0001 acc_val: 0.4033 loss_test: 1.2353 acc_test: 0.6680 time: 0.2654s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0817 acc_val: 0.4267 loss_test: 1.2947 acc_test: 0.6800 time: 0.3653s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.1191 acc_val: 0.4633 loss_test: 1.3361 acc_test: 0.6860 time: 0.3312s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1428 acc_val: 0.4833 loss_test: 1.3680 acc_test: 0.6900 time: 0.3794s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1469 acc_val: 0.4867 loss_test: 1.3948 acc_test: 0.6920 time: 0.3506s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1205 acc_val: 0.4967 loss_test: 1.4138 acc_test: 0.6970 time: 0.2946s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1304 acc_val: 0.5133 loss_test: 1.4389 acc_test: 0.6960 time: 0.2894s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.5233 loss_test: 1.4559 acc_test: 0.6960 time: 0.3463s
Optimization Finished!
Total time elapsed: 170.7029s, best testing performance  0.702000, minimun loss  0.984612
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7884 acc_train: 0.2417 loss_val: 1.8700 acc_val: 0.1067 loss_test: 1.6312 acc_test: 0.4280 time: 0.3243s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.9387 acc_val: 0.3700 loss_test: 1.1913 acc_test: 0.6670 time: 0.2834s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.9527 acc_val: 0.4067 loss_test: 1.2122 acc_test: 0.6730 time: 0.3796s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0586 acc_val: 0.4167 loss_test: 1.2836 acc_test: 0.6800 time: 0.3647s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1149 acc_val: 0.4433 loss_test: 1.3251 acc_test: 0.6870 time: 0.3548s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1524 acc_val: 0.4700 loss_test: 1.3654 acc_test: 0.6890 time: 0.3457s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1751 acc_val: 0.4900 loss_test: 1.3957 acc_test: 0.6900 time: 0.2682s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2186 acc_val: 0.4900 loss_test: 1.4302 acc_test: 0.6960 time: 0.3955s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2641 acc_val: 0.4967 loss_test: 1.4675 acc_test: 0.6950 time: 0.3879s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.3106 acc_val: 0.5000 loss_test: 1.4970 acc_test: 0.6960 time: 0.3698s
Optimization Finished!
Total time elapsed: 173.4044s, best testing performance  0.699000, minimun loss  0.967948
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1000 loss_val: 1.8554 acc_val: 0.1600 loss_test: 1.6844 acc_test: 0.4710 time: 0.4167s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8800 acc_val: 0.3800 loss_test: 1.1695 acc_test: 0.6660 time: 0.3413s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8896 acc_val: 0.4167 loss_test: 1.1914 acc_test: 0.6830 time: 0.3467s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9955 acc_val: 0.4400 loss_test: 1.2631 acc_test: 0.6880 time: 0.3463s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0303 acc_val: 0.4600 loss_test: 1.3011 acc_test: 0.6890 time: 0.2696s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0555 acc_val: 0.4800 loss_test: 1.3399 acc_test: 0.6940 time: 0.2794s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0621 acc_val: 0.5000 loss_test: 1.3674 acc_test: 0.6950 time: 0.3635s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0965 acc_val: 0.5067 loss_test: 1.4010 acc_test: 0.6970 time: 0.3694s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0755 acc_val: 0.5100 loss_test: 1.4143 acc_test: 0.6990 time: 0.3910s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1303 acc_val: 0.5100 loss_test: 1.4491 acc_test: 0.7000 time: 0.4077s
Optimization Finished!
Total time elapsed: 175.8967s, best testing performance  0.702000, minimun loss  0.978848
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7688 acc_train: 0.3667 loss_val: 1.8163 acc_val: 0.2133 loss_test: 1.6649 acc_test: 0.4730 time: 0.4152s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 2.0524 acc_val: 0.3367 loss_test: 1.2238 acc_test: 0.6500 time: 0.3501s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 2.0251 acc_val: 0.3867 loss_test: 1.2327 acc_test: 0.6680 time: 0.3534s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0667 acc_val: 0.4100 loss_test: 1.2824 acc_test: 0.6820 time: 0.2672s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0514 acc_val: 0.4500 loss_test: 1.3141 acc_test: 0.6870 time: 0.3668s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.4767 loss_test: 1.3481 acc_test: 0.6940 time: 0.3659s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0238 acc_val: 0.5000 loss_test: 1.3745 acc_test: 0.6940 time: 0.4032s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0393 acc_val: 0.5167 loss_test: 1.4049 acc_test: 0.7000 time: 0.4584s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0038 acc_val: 0.5200 loss_test: 1.4231 acc_test: 0.7020 time: 0.2873s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.0125 acc_val: 0.5300 loss_test: 1.4495 acc_test: 0.7030 time: 0.2797s
Optimization Finished!
Total time elapsed: 170.9697s, best testing performance  0.704000, minimun loss  0.975002
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7942 acc_train: 0.1500 loss_val: 1.8265 acc_val: 0.1100 loss_test: 1.6776 acc_test: 0.4440 time: 0.4022s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8048 acc_val: 0.3733 loss_test: 1.1533 acc_test: 0.6670 time: 0.2714s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8748 acc_val: 0.4167 loss_test: 1.1942 acc_test: 0.6750 time: 0.3583s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0032 acc_val: 0.4333 loss_test: 1.2694 acc_test: 0.6810 time: 0.3361s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0515 acc_val: 0.4667 loss_test: 1.3136 acc_test: 0.6850 time: 0.3733s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0823 acc_val: 0.4800 loss_test: 1.3496 acc_test: 0.6890 time: 0.3526s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0962 acc_val: 0.4933 loss_test: 1.3795 acc_test: 0.6870 time: 0.3505s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1284 acc_val: 0.4933 loss_test: 1.4095 acc_test: 0.6890 time: 0.2832s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1483 acc_val: 0.4933 loss_test: 1.4392 acc_test: 0.6870 time: 0.3688s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1948 acc_val: 0.4900 loss_test: 1.4701 acc_test: 0.6930 time: 0.3712s
Optimization Finished!
Total time elapsed: 170.8045s, best testing performance  0.693000, minimun loss  0.975716
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7854 acc_train: 0.1417 loss_val: 1.8029 acc_val: 0.1867 loss_test: 1.6835 acc_test: 0.4360 time: 0.3421s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8637 acc_val: 0.3700 loss_test: 1.1742 acc_test: 0.6680 time: 0.3552s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9363 acc_val: 0.4133 loss_test: 1.2133 acc_test: 0.6800 time: 0.3834s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9802 acc_val: 0.4367 loss_test: 1.2605 acc_test: 0.6870 time: 0.3969s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9961 acc_val: 0.4567 loss_test: 1.2997 acc_test: 0.6870 time: 0.4162s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0122 acc_val: 0.4800 loss_test: 1.3358 acc_test: 0.6930 time: 0.2733s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0328 acc_val: 0.5033 loss_test: 1.3715 acc_test: 0.6920 time: 0.2912s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0530 acc_val: 0.5033 loss_test: 1.4037 acc_test: 0.6930 time: 0.3718s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0652 acc_val: 0.4967 loss_test: 1.4282 acc_test: 0.6920 time: 0.3600s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0882 acc_val: 0.4900 loss_test: 1.4597 acc_test: 0.6880 time: 0.4116s
Optimization Finished!
Total time elapsed: 176.7714s, best testing performance  0.697000, minimun loss  0.961291
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1917 loss_val: 1.8422 acc_val: 0.1233 loss_test: 1.6753 acc_test: 0.4950 time: 0.4276s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.9731 acc_val: 0.3700 loss_test: 1.2136 acc_test: 0.6600 time: 0.3995s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9297 acc_val: 0.4133 loss_test: 1.2153 acc_test: 0.6750 time: 0.3517s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0518 acc_val: 0.4367 loss_test: 1.2900 acc_test: 0.6810 time: 0.2665s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.1357 acc_val: 0.4467 loss_test: 1.3404 acc_test: 0.6810 time: 0.2792s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1647 acc_val: 0.4700 loss_test: 1.3713 acc_test: 0.6870 time: 0.3873s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1964 acc_val: 0.4767 loss_test: 1.4045 acc_test: 0.6940 time: 0.4028s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2264 acc_val: 0.4867 loss_test: 1.4354 acc_test: 0.6950 time: 0.3882s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2161 acc_val: 0.4867 loss_test: 1.4554 acc_test: 0.6960 time: 0.4027s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1825 acc_val: 0.4967 loss_test: 1.4666 acc_test: 0.6970 time: 0.2709s
Optimization Finished!
Total time elapsed: 172.0452s, best testing performance  0.701000, minimun loss  0.988824
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7881 acc_train: 0.1333 loss_val: 1.7979 acc_val: 0.1333 loss_test: 1.6471 acc_test: 0.5380 time: 0.3678s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7636 acc_val: 0.4200 loss_test: 1.1462 acc_test: 0.6840 time: 0.3276s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7104 acc_val: 0.4600 loss_test: 1.1478 acc_test: 0.6900 time: 0.2712s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9261 acc_val: 0.4433 loss_test: 1.2707 acc_test: 0.6820 time: 0.4067s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0354 acc_val: 0.4667 loss_test: 1.3350 acc_test: 0.6860 time: 0.3406s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1018 acc_val: 0.4900 loss_test: 1.3756 acc_test: 0.6930 time: 0.3331s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1507 acc_val: 0.4800 loss_test: 1.4080 acc_test: 0.6940 time: 0.3658s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1877 acc_val: 0.4800 loss_test: 1.4303 acc_test: 0.6930 time: 0.3485s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2083 acc_val: 0.4967 loss_test: 1.4499 acc_test: 0.6980 time: 0.2822s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2246 acc_val: 0.4933 loss_test: 1.4670 acc_test: 0.6980 time: 0.4055s
Optimization Finished!
Total time elapsed: 170.2946s, best testing performance  0.702000, minimun loss  0.957735
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7835 acc_train: 0.1750 loss_val: 1.8292 acc_val: 0.0800 loss_test: 1.6819 acc_test: 0.3870 time: 0.3688s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7717 acc_val: 0.4067 loss_test: 1.1441 acc_test: 0.6730 time: 0.2849s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8091 acc_val: 0.4200 loss_test: 1.1774 acc_test: 0.6840 time: 0.3675s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0350 acc_val: 0.4233 loss_test: 1.2868 acc_test: 0.6740 time: 0.3512s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1111 acc_val: 0.4500 loss_test: 1.3345 acc_test: 0.6780 time: 0.3551s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1218 acc_val: 0.4733 loss_test: 1.3650 acc_test: 0.6830 time: 0.3935s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1451 acc_val: 0.4800 loss_test: 1.3953 acc_test: 0.6930 time: 0.2746s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1608 acc_val: 0.5000 loss_test: 1.4178 acc_test: 0.6940 time: 0.2986s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1967 acc_val: 0.5067 loss_test: 1.4484 acc_test: 0.6980 time: 0.3746s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2289 acc_val: 0.5100 loss_test: 1.4744 acc_test: 0.6980 time: 0.3949s
Optimization Finished!
Total time elapsed: 171.7128s, best testing performance  0.701000, minimun loss  0.945766
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7788 acc_train: 0.2417 loss_val: 1.8006 acc_val: 0.0533 loss_test: 1.6549 acc_test: 0.3400 time: 0.3959s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8109 acc_val: 0.3767 loss_test: 1.1433 acc_test: 0.6780 time: 0.3746s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7655 acc_val: 0.4300 loss_test: 1.1608 acc_test: 0.6860 time: 0.3313s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9850 acc_val: 0.4333 loss_test: 1.2713 acc_test: 0.6810 time: 0.3705s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0074 acc_val: 0.4667 loss_test: 1.3075 acc_test: 0.6850 time: 0.3702s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1002 acc_val: 0.4733 loss_test: 1.3607 acc_test: 0.6930 time: 0.2663s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1400 acc_val: 0.4833 loss_test: 1.3943 acc_test: 0.6930 time: 0.4263s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1497 acc_val: 0.5033 loss_test: 1.4155 acc_test: 0.6950 time: 0.3792s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1765 acc_val: 0.5100 loss_test: 1.4408 acc_test: 0.6930 time: 0.3532s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2079 acc_val: 0.5100 loss_test: 1.4623 acc_test: 0.6900 time: 0.3745s
Optimization Finished!
Total time elapsed: 177.8076s, best testing performance  0.698000, minimun loss  0.922192
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7870 acc_train: 0.1833 loss_val: 1.8127 acc_val: 0.1200 loss_test: 1.6723 acc_test: 0.4680 time: 0.4036s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.6953 acc_val: 0.3967 loss_test: 1.1184 acc_test: 0.6710 time: 0.3754s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.6669 acc_val: 0.4433 loss_test: 1.1442 acc_test: 0.6860 time: 0.3406s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8628 acc_val: 0.4467 loss_test: 1.2465 acc_test: 0.6890 time: 0.2737s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9637 acc_val: 0.4600 loss_test: 1.3103 acc_test: 0.6960 time: 0.2722s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0604 acc_val: 0.4733 loss_test: 1.3621 acc_test: 0.6940 time: 0.3592s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1134 acc_val: 0.4900 loss_test: 1.4025 acc_test: 0.6980 time: 0.3725s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.4967 loss_test: 1.4396 acc_test: 0.6980 time: 0.3708s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2260 acc_val: 0.4933 loss_test: 1.4735 acc_test: 0.6980 time: 0.3803s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2564 acc_val: 0.4967 loss_test: 1.5038 acc_test: 0.7030 time: 0.2806s
Optimization Finished!
Total time elapsed: 170.3854s, best testing performance  0.708000, minimun loss  0.932035
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7922 acc_train: 0.1833 loss_val: 1.8177 acc_val: 0.0533 loss_test: 1.6599 acc_test: 0.3210 time: 0.3350s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7528 acc_val: 0.4200 loss_test: 1.1323 acc_test: 0.6780 time: 0.2690s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8156 acc_val: 0.4200 loss_test: 1.1870 acc_test: 0.6810 time: 0.2778s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0035 acc_val: 0.4233 loss_test: 1.2820 acc_test: 0.6820 time: 0.3697s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0507 acc_val: 0.4533 loss_test: 1.3245 acc_test: 0.6830 time: 0.4034s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1366 acc_val: 0.4600 loss_test: 1.3767 acc_test: 0.6920 time: 0.3602s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1289 acc_val: 0.4767 loss_test: 1.3988 acc_test: 0.6920 time: 0.3700s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1643 acc_val: 0.4900 loss_test: 1.4303 acc_test: 0.6960 time: 0.2889s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2268 acc_val: 0.5000 loss_test: 1.4670 acc_test: 0.6960 time: 0.2879s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2750 acc_val: 0.5033 loss_test: 1.4989 acc_test: 0.6960 time: 0.3432s
Optimization Finished!
Total time elapsed: 171.2032s, best testing performance  0.702000, minimun loss  0.950248
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7866 acc_train: 0.2083 loss_val: 1.8197 acc_val: 0.0733 loss_test: 1.7067 acc_test: 0.3950 time: 0.3308s
Epoch: 0051 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.4597 acc_val: 0.4767 loss_test: 1.0643 acc_test: 0.6910 time: 0.4193s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.5347 acc_val: 0.4800 loss_test: 1.0952 acc_test: 0.7000 time: 0.3486s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.6390 acc_val: 0.4900 loss_test: 1.1763 acc_test: 0.7020 time: 0.3750s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9402 acc_val: 0.4700 loss_test: 1.3021 acc_test: 0.6930 time: 0.3513s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0614 acc_val: 0.4800 loss_test: 1.3568 acc_test: 0.6920 time: 0.2674s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0984 acc_val: 0.4900 loss_test: 1.3894 acc_test: 0.6920 time: 0.2852s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1716 acc_val: 0.4933 loss_test: 1.4278 acc_test: 0.6930 time: 0.3734s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2078 acc_val: 0.4967 loss_test: 1.4556 acc_test: 0.6970 time: 0.4284s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2306 acc_val: 0.5000 loss_test: 1.4753 acc_test: 0.6970 time: 0.4214s
Optimization Finished!
Total time elapsed: 175.9902s, best testing performance  0.703000, minimun loss  0.942764
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.2167 loss_val: 1.7946 acc_val: 0.1667 loss_test: 1.6934 acc_test: 0.4710 time: 0.4142s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8476 acc_val: 0.3500 loss_test: 1.1858 acc_test: 0.6600 time: 0.3941s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8053 acc_val: 0.4033 loss_test: 1.1891 acc_test: 0.6830 time: 0.3427s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9368 acc_val: 0.4567 loss_test: 1.2677 acc_test: 0.6920 time: 0.3909s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0293 acc_val: 0.4600 loss_test: 1.3179 acc_test: 0.6880 time: 0.2714s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0651 acc_val: 0.4700 loss_test: 1.3479 acc_test: 0.6920 time: 0.3625s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1013 acc_val: 0.4833 loss_test: 1.3807 acc_test: 0.6930 time: 0.3596s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1148 acc_val: 0.5033 loss_test: 1.4086 acc_test: 0.7000 time: 0.3842s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1392 acc_val: 0.5167 loss_test: 1.4361 acc_test: 0.6990 time: 0.3802s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1475 acc_val: 0.5133 loss_test: 1.4560 acc_test: 0.7000 time: 0.3294s
Optimization Finished!
Total time elapsed: 173.6138s, best testing performance  0.704000, minimun loss  0.963279
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7806 acc_train: 0.2083 loss_val: 1.7930 acc_val: 0.2267 loss_test: 1.7285 acc_test: 0.4490 time: 0.4018s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.6202 acc_val: 0.4433 loss_test: 1.1027 acc_test: 0.6800 time: 0.3515s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.6509 acc_val: 0.4600 loss_test: 1.1260 acc_test: 0.6980 time: 0.2720s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8631 acc_val: 0.4633 loss_test: 1.2303 acc_test: 0.6930 time: 0.2782s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0248 acc_val: 0.4600 loss_test: 1.3049 acc_test: 0.6880 time: 0.3732s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0543 acc_val: 0.4833 loss_test: 1.3423 acc_test: 0.6910 time: 0.3493s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1072 acc_val: 0.4933 loss_test: 1.3809 acc_test: 0.6950 time: 0.3560s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1512 acc_val: 0.5067 loss_test: 1.4178 acc_test: 0.7010 time: 0.3582s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1864 acc_val: 0.5133 loss_test: 1.4529 acc_test: 0.7010 time: 0.2786s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2245 acc_val: 0.5067 loss_test: 1.4824 acc_test: 0.7030 time: 0.4169s
Optimization Finished!
Total time elapsed: 171.3504s, best testing performance  0.706000, minimun loss  0.961017
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7880 acc_train: 0.2000 loss_val: 1.7959 acc_val: 0.1533 loss_test: 1.7054 acc_test: 0.4510 time: 0.3669s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.5395 acc_val: 0.4433 loss_test: 1.0996 acc_test: 0.6840 time: 0.2787s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.6077 acc_val: 0.5000 loss_test: 1.1287 acc_test: 0.6920 time: 0.3548s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8319 acc_val: 0.4933 loss_test: 1.2536 acc_test: 0.6880 time: 0.3671s
Epoch: 0201 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9659 acc_val: 0.4900 loss_test: 1.3308 acc_test: 0.6920 time: 0.3374s
Epoch: 0251 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0346 acc_val: 0.4967 loss_test: 1.3812 acc_test: 0.6910 time: 0.3415s
Epoch: 0301 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0992 acc_val: 0.5033 loss_test: 1.4248 acc_test: 0.6960 time: 0.2687s
Epoch: 0351 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0935 acc_val: 0.5100 loss_test: 1.4563 acc_test: 0.6920 time: 0.3032s
Epoch: 0401 loss_train: 0.0016 acc_train: 1.0000 loss_val: 2.1596 acc_val: 0.5000 loss_test: 1.5017 acc_test: 0.6930 time: 0.3879s
Epoch: 0451 loss_train: 0.0014 acc_train: 1.0000 loss_val: 2.2041 acc_val: 0.5033 loss_test: 1.5396 acc_test: 0.6920 time: 0.3633s
Optimization Finished!
Total time elapsed: 173.0338s, best testing performance  0.699000, minimun loss  0.948001
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7821 acc_train: 0.2750 loss_val: 1.8210 acc_val: 0.1200 loss_test: 1.6900 acc_test: 0.4640 time: 0.3668s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.9467 acc_val: 0.3767 loss_test: 1.2198 acc_test: 0.6590 time: 0.3698s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9180 acc_val: 0.4067 loss_test: 1.2201 acc_test: 0.6760 time: 0.3621s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0777 acc_val: 0.4267 loss_test: 1.3038 acc_test: 0.6800 time: 0.3787s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1467 acc_val: 0.4467 loss_test: 1.3541 acc_test: 0.6800 time: 0.2681s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1293 acc_val: 0.4667 loss_test: 1.3745 acc_test: 0.6860 time: 0.2838s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1580 acc_val: 0.4800 loss_test: 1.4060 acc_test: 0.6870 time: 0.3813s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1850 acc_val: 0.4900 loss_test: 1.4344 acc_test: 0.6910 time: 0.3713s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.5000 loss_test: 1.4473 acc_test: 0.6980 time: 0.3662s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1888 acc_val: 0.5067 loss_test: 1.4765 acc_test: 0.6980 time: 0.3466s
Optimization Finished!
Total time elapsed: 176.2550s, best testing performance  0.701000, minimun loss  0.966233
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8082 acc_train: 0.1417 loss_val: 1.7824 acc_val: 0.1633 loss_test: 1.6878 acc_test: 0.4650 time: 0.3773s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8770 acc_val: 0.3833 loss_test: 1.1933 acc_test: 0.6660 time: 0.3713s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8693 acc_val: 0.4233 loss_test: 1.1939 acc_test: 0.6810 time: 0.3885s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9237 acc_val: 0.4600 loss_test: 1.2426 acc_test: 0.6840 time: 0.2669s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9818 acc_val: 0.4733 loss_test: 1.2859 acc_test: 0.6880 time: 0.3549s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9976 acc_val: 0.4833 loss_test: 1.3221 acc_test: 0.6930 time: 0.3530s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0233 acc_val: 0.5033 loss_test: 1.3564 acc_test: 0.6930 time: 0.3574s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0630 acc_val: 0.5100 loss_test: 1.3988 acc_test: 0.6980 time: 0.3774s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.5100 loss_test: 1.4309 acc_test: 0.6980 time: 0.2705s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1590 acc_val: 0.5067 loss_test: 1.4666 acc_test: 0.6980 time: 0.2833s
Optimization Finished!
Total time elapsed: 170.9569s, best testing performance  0.702000, minimun loss  0.973467
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7992 acc_train: 0.1167 loss_val: 1.8016 acc_val: 0.1467 loss_test: 1.6786 acc_test: 0.5200 time: 0.3620s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6529 acc_val: 0.4300 loss_test: 1.1078 acc_test: 0.6810 time: 0.2713s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7109 acc_val: 0.4733 loss_test: 1.1509 acc_test: 0.6810 time: 0.2801s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8772 acc_val: 0.4533 loss_test: 1.2290 acc_test: 0.6890 time: 0.3926s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9612 acc_val: 0.4667 loss_test: 1.2799 acc_test: 0.6910 time: 0.3300s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0216 acc_val: 0.4867 loss_test: 1.3202 acc_test: 0.6920 time: 0.3819s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0728 acc_val: 0.4967 loss_test: 1.3583 acc_test: 0.6940 time: 0.3803s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1269 acc_val: 0.5133 loss_test: 1.3967 acc_test: 0.6930 time: 0.2751s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1543 acc_val: 0.5167 loss_test: 1.4228 acc_test: 0.6980 time: 0.2847s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2050 acc_val: 0.5133 loss_test: 1.4505 acc_test: 0.6970 time: 0.3400s
Optimization Finished!
Total time elapsed: 170.0340s, best testing performance  0.699000, minimun loss  0.971705
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8101 acc_train: 0.1500 loss_val: 1.8014 acc_val: 0.1233 loss_test: 1.6932 acc_test: 0.4750 time: 0.3290s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.9108 acc_val: 0.3667 loss_test: 1.2049 acc_test: 0.6500 time: 0.2317s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.9201 acc_val: 0.4300 loss_test: 1.2162 acc_test: 0.6730 time: 0.2239s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9753 acc_val: 0.4467 loss_test: 1.2594 acc_test: 0.6820 time: 0.2319s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0263 acc_val: 0.4667 loss_test: 1.3059 acc_test: 0.6860 time: 0.2373s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0449 acc_val: 0.4800 loss_test: 1.3389 acc_test: 0.6900 time: 0.2336s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0712 acc_val: 0.4900 loss_test: 1.3774 acc_test: 0.6900 time: 0.2402s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1003 acc_val: 0.4967 loss_test: 1.4113 acc_test: 0.6950 time: 0.2335s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0997 acc_val: 0.5067 loss_test: 1.4363 acc_test: 0.7010 time: 0.2323s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1168 acc_val: 0.5033 loss_test: 1.4640 acc_test: 0.7030 time: 0.2295s
Optimization Finished!
Total time elapsed: 116.3149s, best testing performance  0.705000, minimun loss  0.983825
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7832 acc_train: 0.1833 loss_val: 1.7990 acc_val: 0.1533 loss_test: 1.6788 acc_test: 0.5150 time: 0.3530s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8360 acc_val: 0.3700 loss_test: 1.1720 acc_test: 0.6570 time: 0.2269s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8879 acc_val: 0.4167 loss_test: 1.1944 acc_test: 0.6770 time: 0.2267s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9647 acc_val: 0.4433 loss_test: 1.2501 acc_test: 0.6820 time: 0.2387s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0134 acc_val: 0.4533 loss_test: 1.2931 acc_test: 0.6870 time: 0.2292s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0225 acc_val: 0.4833 loss_test: 1.3263 acc_test: 0.6900 time: 0.2355s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0721 acc_val: 0.4900 loss_test: 1.3685 acc_test: 0.6890 time: 0.2437s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1135 acc_val: 0.4933 loss_test: 1.4041 acc_test: 0.6940 time: 0.2474s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1399 acc_val: 0.4967 loss_test: 1.4364 acc_test: 0.6960 time: 0.2534s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1738 acc_val: 0.5067 loss_test: 1.4645 acc_test: 0.6970 time: 0.2650s
Optimization Finished!
Total time elapsed: 117.5782s, best testing performance  0.699000, minimun loss  0.971873
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1417 loss_val: 1.8047 acc_val: 0.1333 loss_test: 1.6766 acc_test: 0.5040 time: 0.3223s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.7590 acc_val: 0.4067 loss_test: 1.1614 acc_test: 0.6620 time: 0.2290s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8165 acc_val: 0.4200 loss_test: 1.1942 acc_test: 0.6770 time: 0.2314s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9223 acc_val: 0.4467 loss_test: 1.2576 acc_test: 0.6860 time: 0.2252s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0080 acc_val: 0.4733 loss_test: 1.3039 acc_test: 0.6890 time: 0.2278s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0456 acc_val: 0.4800 loss_test: 1.3408 acc_test: 0.6890 time: 0.2397s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0781 acc_val: 0.4867 loss_test: 1.3771 acc_test: 0.6930 time: 0.2408s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1230 acc_val: 0.4900 loss_test: 1.4126 acc_test: 0.6970 time: 0.2380s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1534 acc_val: 0.5000 loss_test: 1.4441 acc_test: 0.6980 time: 0.2533s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1502 acc_val: 0.5100 loss_test: 1.4634 acc_test: 0.6940 time: 0.2296s
Optimization Finished!
Total time elapsed: 116.1077s, best testing performance  0.701000, minimun loss  0.980736
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7999 acc_train: 0.1250 loss_val: 1.7987 acc_val: 0.1767 loss_test: 1.7022 acc_test: 0.5090 time: 0.3205s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8034 acc_val: 0.3900 loss_test: 1.1657 acc_test: 0.6640 time: 0.2332s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8501 acc_val: 0.4300 loss_test: 1.1937 acc_test: 0.6800 time: 0.2304s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9429 acc_val: 0.4333 loss_test: 1.2533 acc_test: 0.6810 time: 0.2327s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9977 acc_val: 0.4600 loss_test: 1.2968 acc_test: 0.6830 time: 0.2383s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0481 acc_val: 0.4667 loss_test: 1.3394 acc_test: 0.6870 time: 0.2326s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0663 acc_val: 0.4900 loss_test: 1.3739 acc_test: 0.6900 time: 0.2387s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0793 acc_val: 0.5033 loss_test: 1.4042 acc_test: 0.6960 time: 0.2515s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1005 acc_val: 0.5067 loss_test: 1.4316 acc_test: 0.7010 time: 0.2301s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1302 acc_val: 0.5067 loss_test: 1.4612 acc_test: 0.6980 time: 0.2401s
Optimization Finished!
Total time elapsed: 115.9654s, best testing performance  0.702000, minimun loss  0.977470
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7948 acc_train: 0.1083 loss_val: 1.8055 acc_val: 0.1233 loss_test: 1.6828 acc_test: 0.4630 time: 0.3273s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.7343 acc_val: 0.4033 loss_test: 1.1246 acc_test: 0.6660 time: 0.2315s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8287 acc_val: 0.4300 loss_test: 1.1729 acc_test: 0.6730 time: 0.2246s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9437 acc_val: 0.4400 loss_test: 1.2398 acc_test: 0.6830 time: 0.2287s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0143 acc_val: 0.4567 loss_test: 1.2861 acc_test: 0.6850 time: 0.2289s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0401 acc_val: 0.4667 loss_test: 1.3239 acc_test: 0.6930 time: 0.2332s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0650 acc_val: 0.4767 loss_test: 1.3601 acc_test: 0.6950 time: 0.2507s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1110 acc_val: 0.5033 loss_test: 1.4003 acc_test: 0.6970 time: 0.2382s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1299 acc_val: 0.5133 loss_test: 1.4290 acc_test: 0.6980 time: 0.2255s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1759 acc_val: 0.5133 loss_test: 1.4598 acc_test: 0.7000 time: 0.2411s
Optimization Finished!
Total time elapsed: 117.7261s, best testing performance  0.702000, minimun loss  0.948483
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7818 acc_train: 0.2083 loss_val: 1.8106 acc_val: 0.1567 loss_test: 1.6883 acc_test: 0.4780 time: 0.3069s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7018 acc_val: 0.4033 loss_test: 1.1242 acc_test: 0.6730 time: 0.2699s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8345 acc_val: 0.4133 loss_test: 1.1808 acc_test: 0.6770 time: 0.2673s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9333 acc_val: 0.4433 loss_test: 1.2404 acc_test: 0.6820 time: 0.2227s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9711 acc_val: 0.4600 loss_test: 1.2807 acc_test: 0.6890 time: 0.2272s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0084 acc_val: 0.4800 loss_test: 1.3210 acc_test: 0.6970 time: 0.2287s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0427 acc_val: 0.5000 loss_test: 1.3627 acc_test: 0.6970 time: 0.2326s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0683 acc_val: 0.5167 loss_test: 1.3973 acc_test: 0.6970 time: 0.2278s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1235 acc_val: 0.5033 loss_test: 1.4397 acc_test: 0.6950 time: 0.2295s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1791 acc_val: 0.5033 loss_test: 1.4793 acc_test: 0.6950 time: 0.2297s
Optimization Finished!
Total time elapsed: 118.7460s, best testing performance  0.700000, minimun loss  0.965071
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7778 acc_train: 0.2667 loss_val: 1.8193 acc_val: 0.1500 loss_test: 1.6718 acc_test: 0.5450 time: 0.3176s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7266 acc_val: 0.4067 loss_test: 1.1195 acc_test: 0.6770 time: 0.2417s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8081 acc_val: 0.4300 loss_test: 1.1637 acc_test: 0.6820 time: 0.2556s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9424 acc_val: 0.4433 loss_test: 1.2432 acc_test: 0.6850 time: 0.2226s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0317 acc_val: 0.4633 loss_test: 1.2983 acc_test: 0.6830 time: 0.2224s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0955 acc_val: 0.4767 loss_test: 1.3387 acc_test: 0.6880 time: 0.2239s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1000 acc_val: 0.4900 loss_test: 1.3709 acc_test: 0.6910 time: 0.2312s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1183 acc_val: 0.5000 loss_test: 1.3989 acc_test: 0.6970 time: 0.2526s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1523 acc_val: 0.5033 loss_test: 1.4277 acc_test: 0.7010 time: 0.2429s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1889 acc_val: 0.5033 loss_test: 1.4586 acc_test: 0.6950 time: 0.2332s
Optimization Finished!
Total time elapsed: 116.5676s, best testing performance  0.701000, minimun loss  0.966484
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7860 acc_train: 0.1750 loss_val: 1.8225 acc_val: 0.0800 loss_test: 1.6795 acc_test: 0.4150 time: 0.3675s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.6763 acc_val: 0.4167 loss_test: 1.1235 acc_test: 0.6740 time: 0.2370s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8321 acc_val: 0.4200 loss_test: 1.1838 acc_test: 0.6830 time: 0.2315s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9208 acc_val: 0.4367 loss_test: 1.2469 acc_test: 0.6840 time: 0.2315s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0146 acc_val: 0.4667 loss_test: 1.3012 acc_test: 0.6850 time: 0.2196s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0500 acc_val: 0.4733 loss_test: 1.3349 acc_test: 0.6900 time: 0.2296s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4867 loss_test: 1.3731 acc_test: 0.6940 time: 0.2336s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1112 acc_val: 0.5033 loss_test: 1.4024 acc_test: 0.6930 time: 0.2337s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1609 acc_val: 0.5033 loss_test: 1.4365 acc_test: 0.6950 time: 0.2319s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2051 acc_val: 0.5067 loss_test: 1.4645 acc_test: 0.6950 time: 0.2241s
Optimization Finished!
Total time elapsed: 117.5618s, best testing performance  0.700000, minimun loss  0.972670
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8155 acc_train: 0.1167 loss_val: 1.8371 acc_val: 0.0900 loss_test: 1.6838 acc_test: 0.3780 time: 0.3375s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7300 acc_val: 0.4133 loss_test: 1.1590 acc_test: 0.6680 time: 0.2322s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8651 acc_val: 0.4367 loss_test: 1.2118 acc_test: 0.6790 time: 0.2284s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9546 acc_val: 0.4467 loss_test: 1.2637 acc_test: 0.6860 time: 0.2297s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9866 acc_val: 0.4700 loss_test: 1.2987 acc_test: 0.6900 time: 0.2167s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0269 acc_val: 0.4667 loss_test: 1.3351 acc_test: 0.6880 time: 0.2212s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0743 acc_val: 0.4833 loss_test: 1.3726 acc_test: 0.6880 time: 0.2342s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1036 acc_val: 0.5000 loss_test: 1.3995 acc_test: 0.6910 time: 0.2435s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1476 acc_val: 0.4967 loss_test: 1.4292 acc_test: 0.6910 time: 0.2447s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1783 acc_val: 0.4900 loss_test: 1.4558 acc_test: 0.6930 time: 0.2191s
Optimization Finished!
Total time elapsed: 117.0020s, best testing performance  0.695000, minimun loss  0.963123
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7891 acc_train: 0.1833 loss_val: 1.8259 acc_val: 0.1700 loss_test: 1.6585 acc_test: 0.5250 time: 0.2821s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6428 acc_val: 0.4467 loss_test: 1.1194 acc_test: 0.6830 time: 0.2211s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8195 acc_val: 0.4600 loss_test: 1.1974 acc_test: 0.6840 time: 0.2317s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9661 acc_val: 0.4500 loss_test: 1.2678 acc_test: 0.6880 time: 0.2218s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0434 acc_val: 0.4600 loss_test: 1.3127 acc_test: 0.6860 time: 0.2279s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0937 acc_val: 0.4733 loss_test: 1.3537 acc_test: 0.6930 time: 0.2241s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1003 acc_val: 0.4867 loss_test: 1.3868 acc_test: 0.6950 time: 0.2494s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1143 acc_val: 0.5000 loss_test: 1.4162 acc_test: 0.6960 time: 0.2404s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1358 acc_val: 0.5100 loss_test: 1.4447 acc_test: 0.6960 time: 0.2438s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1779 acc_val: 0.5067 loss_test: 1.4750 acc_test: 0.6950 time: 0.2480s
Optimization Finished!
Total time elapsed: 117.8643s, best testing performance  0.699000, minimun loss  0.953460
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7959 acc_train: 0.1333 loss_val: 1.8269 acc_val: 0.1833 loss_test: 1.6603 acc_test: 0.4270 time: 0.2778s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.5209 acc_val: 0.4733 loss_test: 1.0899 acc_test: 0.6930 time: 0.2264s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8234 acc_val: 0.4467 loss_test: 1.2003 acc_test: 0.6930 time: 0.2279s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0041 acc_val: 0.4500 loss_test: 1.2789 acc_test: 0.6930 time: 0.2367s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0494 acc_val: 0.4700 loss_test: 1.3187 acc_test: 0.6900 time: 0.2311s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0608 acc_val: 0.4833 loss_test: 1.3449 acc_test: 0.6940 time: 0.2312s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0986 acc_val: 0.4933 loss_test: 1.3797 acc_test: 0.6990 time: 0.2395s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1322 acc_val: 0.5033 loss_test: 1.4091 acc_test: 0.6960 time: 0.2473s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1904 acc_val: 0.5033 loss_test: 1.4364 acc_test: 0.6990 time: 0.2422s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2243 acc_val: 0.5100 loss_test: 1.4591 acc_test: 0.6970 time: 0.2302s
Optimization Finished!
Total time elapsed: 117.3787s, best testing performance  0.700000, minimun loss  0.963795
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7956 acc_train: 0.0833 loss_val: 1.7923 acc_val: 0.1267 loss_test: 1.6767 acc_test: 0.4810 time: 0.3114s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.5886 acc_val: 0.4367 loss_test: 1.1254 acc_test: 0.6790 time: 0.2227s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7962 acc_val: 0.4467 loss_test: 1.2014 acc_test: 0.6830 time: 0.2225s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9188 acc_val: 0.4533 loss_test: 1.2601 acc_test: 0.6900 time: 0.2338s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9441 acc_val: 0.4800 loss_test: 1.2939 acc_test: 0.6880 time: 0.2335s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9771 acc_val: 0.4900 loss_test: 1.3270 acc_test: 0.6900 time: 0.2301s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0063 acc_val: 0.4900 loss_test: 1.3567 acc_test: 0.6910 time: 0.2338s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0384 acc_val: 0.4967 loss_test: 1.3830 acc_test: 0.6940 time: 0.2496s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0397 acc_val: 0.5033 loss_test: 1.4034 acc_test: 0.6940 time: 0.2424s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0934 acc_val: 0.4967 loss_test: 1.4361 acc_test: 0.6940 time: 0.2307s
Optimization Finished!
Total time elapsed: 117.4015s, best testing performance  0.697000, minimun loss  0.983298
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7799 acc_train: 0.2167 loss_val: 1.8213 acc_val: 0.1667 loss_test: 1.6609 acc_test: 0.5220 time: 0.2981s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6003 acc_val: 0.4567 loss_test: 1.1111 acc_test: 0.6820 time: 0.2300s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7361 acc_val: 0.4733 loss_test: 1.1655 acc_test: 0.6900 time: 0.2288s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8870 acc_val: 0.4767 loss_test: 1.2369 acc_test: 0.6920 time: 0.2249s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9471 acc_val: 0.4733 loss_test: 1.2793 acc_test: 0.6910 time: 0.2247s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9988 acc_val: 0.4867 loss_test: 1.3153 acc_test: 0.6900 time: 0.2174s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0192 acc_val: 0.5033 loss_test: 1.3456 acc_test: 0.6890 time: 0.2245s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0406 acc_val: 0.5000 loss_test: 1.3706 acc_test: 0.6920 time: 0.2352s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0756 acc_val: 0.5000 loss_test: 1.3980 acc_test: 0.6940 time: 0.2431s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1452 acc_val: 0.4967 loss_test: 1.4362 acc_test: 0.6890 time: 0.2240s
Optimization Finished!
Total time elapsed: 116.9161s, best testing performance  0.696000, minimun loss  0.951927
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7844 acc_train: 0.2083 loss_val: 1.8007 acc_val: 0.1933 loss_test: 1.6948 acc_test: 0.4560 time: 0.2982s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 2.1738 acc_val: 0.3367 loss_test: 1.3112 acc_test: 0.6370 time: 0.2295s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8937 acc_val: 0.4167 loss_test: 1.2352 acc_test: 0.6710 time: 0.2345s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9938 acc_val: 0.4367 loss_test: 1.3067 acc_test: 0.6810 time: 0.2372s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.1110 acc_val: 0.4467 loss_test: 1.3664 acc_test: 0.6800 time: 0.2258s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1484 acc_val: 0.4700 loss_test: 1.3974 acc_test: 0.6850 time: 0.2297s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1458 acc_val: 0.4833 loss_test: 1.4185 acc_test: 0.6900 time: 0.2341s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1712 acc_val: 0.4933 loss_test: 1.4453 acc_test: 0.6900 time: 0.2445s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1737 acc_val: 0.4933 loss_test: 1.4645 acc_test: 0.6910 time: 0.2493s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1920 acc_val: 0.5033 loss_test: 1.4838 acc_test: 0.6940 time: 0.2256s
Optimization Finished!
Total time elapsed: 117.5037s, best testing performance  0.697000, minimun loss  1.002581
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7968 acc_train: 0.1750 loss_val: 1.8040 acc_val: 0.1533 loss_test: 1.7160 acc_test: 0.3920 time: 0.3132s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.9447 acc_val: 0.3633 loss_test: 1.2609 acc_test: 0.6550 time: 0.2322s
Epoch: 0101 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.8926 acc_val: 0.4300 loss_test: 1.2428 acc_test: 0.6760 time: 0.2385s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0132 acc_val: 0.4467 loss_test: 1.3146 acc_test: 0.6800 time: 0.2265s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0511 acc_val: 0.4633 loss_test: 1.3462 acc_test: 0.6840 time: 0.2291s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1019 acc_val: 0.4767 loss_test: 1.3804 acc_test: 0.6870 time: 0.2407s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0982 acc_val: 0.4833 loss_test: 1.3982 acc_test: 0.6900 time: 0.2336s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1097 acc_val: 0.4933 loss_test: 1.4223 acc_test: 0.6930 time: 0.2348s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1412 acc_val: 0.5033 loss_test: 1.4477 acc_test: 0.6970 time: 0.2430s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1585 acc_val: 0.5067 loss_test: 1.4669 acc_test: 0.6960 time: 0.2404s
Optimization Finished!
Total time elapsed: 117.4887s, best testing performance  0.698000, minimun loss  0.998398
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7927 acc_train: 0.1417 loss_val: 1.8212 acc_val: 0.1167 loss_test: 1.7073 acc_test: 0.4130 time: 0.3139s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 2.0162 acc_val: 0.3533 loss_test: 1.2529 acc_test: 0.6560 time: 0.2331s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9346 acc_val: 0.4000 loss_test: 1.2429 acc_test: 0.6730 time: 0.2225s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0505 acc_val: 0.4300 loss_test: 1.3214 acc_test: 0.6800 time: 0.2447s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.1462 acc_val: 0.4667 loss_test: 1.3690 acc_test: 0.6850 time: 0.2223s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1472 acc_val: 0.4867 loss_test: 1.3867 acc_test: 0.6910 time: 0.2174s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1790 acc_val: 0.4867 loss_test: 1.4160 acc_test: 0.6920 time: 0.2357s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1941 acc_val: 0.5000 loss_test: 1.4339 acc_test: 0.6970 time: 0.2393s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2212 acc_val: 0.4967 loss_test: 1.4596 acc_test: 0.6970 time: 0.2411s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2286 acc_val: 0.5000 loss_test: 1.4775 acc_test: 0.6990 time: 0.2269s
Optimization Finished!
Total time elapsed: 117.5212s, best testing performance  0.699000, minimun loss  1.011317
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7884 acc_train: 0.1833 loss_val: 1.8026 acc_val: 0.2000 loss_test: 1.7072 acc_test: 0.4140 time: 0.3025s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.9257 acc_val: 0.3700 loss_test: 1.2376 acc_test: 0.6550 time: 0.2220s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9121 acc_val: 0.4200 loss_test: 1.2406 acc_test: 0.6780 time: 0.2346s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9927 acc_val: 0.4533 loss_test: 1.3008 acc_test: 0.6770 time: 0.2258s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0599 acc_val: 0.4633 loss_test: 1.3490 acc_test: 0.6860 time: 0.2277s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0960 acc_val: 0.4700 loss_test: 1.3873 acc_test: 0.6900 time: 0.2328s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1416 acc_val: 0.4833 loss_test: 1.4201 acc_test: 0.6910 time: 0.2457s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1676 acc_val: 0.5000 loss_test: 1.4471 acc_test: 0.6930 time: 0.2450s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1975 acc_val: 0.5033 loss_test: 1.4742 acc_test: 0.6950 time: 0.2392s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2374 acc_val: 0.5033 loss_test: 1.5007 acc_test: 0.6940 time: 0.2250s
Optimization Finished!
Total time elapsed: 117.1630s, best testing performance  0.697000, minimun loss  1.015811
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7890 acc_train: 0.2083 loss_val: 1.7963 acc_val: 0.1567 loss_test: 1.7347 acc_test: 0.3670 time: 0.3253s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8432 acc_val: 0.4033 loss_test: 1.2047 acc_test: 0.6570 time: 0.2318s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.7175 acc_val: 0.4567 loss_test: 1.1781 acc_test: 0.6810 time: 0.2245s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9047 acc_val: 0.4567 loss_test: 1.2612 acc_test: 0.6850 time: 0.2315s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0231 acc_val: 0.4633 loss_test: 1.3178 acc_test: 0.6910 time: 0.2234s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0794 acc_val: 0.4767 loss_test: 1.3572 acc_test: 0.6940 time: 0.2429s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1242 acc_val: 0.4833 loss_test: 1.3893 acc_test: 0.6930 time: 0.2286s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1542 acc_val: 0.5067 loss_test: 1.4230 acc_test: 0.6980 time: 0.2619s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1980 acc_val: 0.5000 loss_test: 1.4571 acc_test: 0.6980 time: 0.2404s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2330 acc_val: 0.5067 loss_test: 1.4835 acc_test: 0.6990 time: 0.2363s
Optimization Finished!
Total time elapsed: 117.3469s, best testing performance  0.701000, minimun loss  0.986847
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7866 acc_train: 0.1917 loss_val: 1.8107 acc_val: 0.1733 loss_test: 1.6453 acc_test: 0.5510 time: 0.3058s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8983 acc_val: 0.3767 loss_test: 1.2082 acc_test: 0.6640 time: 0.2250s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8216 acc_val: 0.4233 loss_test: 1.1898 acc_test: 0.6820 time: 0.2217s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9030 acc_val: 0.4467 loss_test: 1.2411 acc_test: 0.6890 time: 0.2327s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9716 acc_val: 0.4600 loss_test: 1.2865 acc_test: 0.6860 time: 0.2320s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0233 acc_val: 0.4800 loss_test: 1.3264 acc_test: 0.6920 time: 0.2232s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0467 acc_val: 0.4933 loss_test: 1.3601 acc_test: 0.6930 time: 0.2384s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0758 acc_val: 0.5067 loss_test: 1.3939 acc_test: 0.6950 time: 0.2424s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0786 acc_val: 0.5100 loss_test: 1.4228 acc_test: 0.6930 time: 0.2452s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1069 acc_val: 0.5033 loss_test: 1.4479 acc_test: 0.6970 time: 0.2344s
Optimization Finished!
Total time elapsed: 116.8423s, best testing performance  0.705000, minimun loss  0.971404
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7867 acc_train: 0.1750 loss_val: 1.7835 acc_val: 0.2833 loss_test: 1.6742 acc_test: 0.5820 time: 0.3025s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8660 acc_val: 0.4300 loss_test: 1.2112 acc_test: 0.6740 time: 0.2266s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8715 acc_val: 0.4433 loss_test: 1.2241 acc_test: 0.6810 time: 0.2261s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9472 acc_val: 0.4533 loss_test: 1.2754 acc_test: 0.6940 time: 0.2229s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0121 acc_val: 0.4567 loss_test: 1.3223 acc_test: 0.6920 time: 0.2234s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0594 acc_val: 0.4667 loss_test: 1.3604 acc_test: 0.6940 time: 0.2442s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1121 acc_val: 0.4800 loss_test: 1.4013 acc_test: 0.6980 time: 0.2318s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1746 acc_val: 0.5033 loss_test: 1.4410 acc_test: 0.6970 time: 0.2550s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2217 acc_val: 0.4967 loss_test: 1.4721 acc_test: 0.6980 time: 0.2413s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2590 acc_val: 0.4933 loss_test: 1.4965 acc_test: 0.6960 time: 0.2339s
Optimization Finished!
Total time elapsed: 116.9214s, best testing performance  0.700000, minimun loss  0.960851
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8135 acc_train: 0.1250 loss_val: 1.8129 acc_val: 0.1733 loss_test: 1.6789 acc_test: 0.5310 time: 0.3286s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8495 acc_val: 0.4167 loss_test: 1.2118 acc_test: 0.6710 time: 0.2238s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8440 acc_val: 0.4567 loss_test: 1.2265 acc_test: 0.6810 time: 0.2227s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9387 acc_val: 0.4533 loss_test: 1.2820 acc_test: 0.6880 time: 0.2313s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9716 acc_val: 0.4800 loss_test: 1.3159 acc_test: 0.6910 time: 0.2267s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0298 acc_val: 0.4867 loss_test: 1.3565 acc_test: 0.6940 time: 0.2280s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0384 acc_val: 0.5100 loss_test: 1.3848 acc_test: 0.6970 time: 0.2344s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1115 acc_val: 0.5033 loss_test: 1.4217 acc_test: 0.6920 time: 0.2609s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1302 acc_val: 0.5000 loss_test: 1.4474 acc_test: 0.6960 time: 0.2418s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1729 acc_val: 0.5000 loss_test: 1.4751 acc_test: 0.6970 time: 0.2394s
Optimization Finished!
Total time elapsed: 116.8112s, best testing performance  0.700000, minimun loss  0.971408
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8118 acc_train: 0.0917 loss_val: 1.8108 acc_val: 0.1567 loss_test: 1.6993 acc_test: 0.4020 time: 0.3291s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.6441 acc_val: 0.4200 loss_test: 1.1365 acc_test: 0.6700 time: 0.2317s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.6856 acc_val: 0.4633 loss_test: 1.1633 acc_test: 0.6900 time: 0.2392s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.7913 acc_val: 0.4733 loss_test: 1.2291 acc_test: 0.6930 time: 0.2279s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9043 acc_val: 0.4767 loss_test: 1.2902 acc_test: 0.6960 time: 0.2275s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9831 acc_val: 0.4933 loss_test: 1.3415 acc_test: 0.6950 time: 0.2343s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0643 acc_val: 0.4933 loss_test: 1.3868 acc_test: 0.6950 time: 0.2316s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1296 acc_val: 0.5000 loss_test: 1.4291 acc_test: 0.6950 time: 0.2424s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2044 acc_val: 0.5067 loss_test: 1.4654 acc_test: 0.6940 time: 0.2308s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2550 acc_val: 0.5100 loss_test: 1.4984 acc_test: 0.6980 time: 0.2300s
Optimization Finished!
Total time elapsed: 116.4479s, best testing performance  0.700000, minimun loss  0.961367
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8079 acc_train: 0.1083 loss_val: 1.8126 acc_val: 0.1133 loss_test: 1.6818 acc_test: 0.4380 time: 0.3166s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8534 acc_val: 0.3933 loss_test: 1.2179 acc_test: 0.6540 time: 0.2181s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9337 acc_val: 0.4133 loss_test: 1.2526 acc_test: 0.6650 time: 0.2287s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9970 acc_val: 0.4200 loss_test: 1.2947 acc_test: 0.6740 time: 0.2237s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0192 acc_val: 0.4567 loss_test: 1.3243 acc_test: 0.6830 time: 0.2310s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0400 acc_val: 0.4767 loss_test: 1.3516 acc_test: 0.6920 time: 0.2400s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0550 acc_val: 0.4933 loss_test: 1.3773 acc_test: 0.6890 time: 0.2327s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0757 acc_val: 0.5133 loss_test: 1.4035 acc_test: 0.6960 time: 0.2436s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1180 acc_val: 0.5133 loss_test: 1.4360 acc_test: 0.6970 time: 0.2429s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1368 acc_val: 0.5100 loss_test: 1.4572 acc_test: 0.6960 time: 0.2343s
Optimization Finished!
Total time elapsed: 117.3410s, best testing performance  0.702000, minimun loss  0.965928
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7903 acc_train: 0.1417 loss_val: 1.8012 acc_val: 0.1400 loss_test: 1.6851 acc_test: 0.4810 time: 0.3115s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.8510 acc_val: 0.3733 loss_test: 1.1766 acc_test: 0.6670 time: 0.2246s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8790 acc_val: 0.4167 loss_test: 1.1986 acc_test: 0.6840 time: 0.2379s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9171 acc_val: 0.4467 loss_test: 1.2441 acc_test: 0.6930 time: 0.2239s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9619 acc_val: 0.4567 loss_test: 1.2894 acc_test: 0.6920 time: 0.2305s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0219 acc_val: 0.4833 loss_test: 1.3361 acc_test: 0.6930 time: 0.2294s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0553 acc_val: 0.4933 loss_test: 1.3749 acc_test: 0.6970 time: 0.2388s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1198 acc_val: 0.5033 loss_test: 1.4171 acc_test: 0.6970 time: 0.2347s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1876 acc_val: 0.5100 loss_test: 1.4620 acc_test: 0.7000 time: 0.2231s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2143 acc_val: 0.5100 loss_test: 1.4860 acc_test: 0.6980 time: 0.2317s
Optimization Finished!
Total time elapsed: 116.8614s, best testing performance  0.702000, minimun loss  0.960905
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1417 loss_val: 1.7840 acc_val: 0.1900 loss_test: 1.6629 acc_test: 0.5630 time: 0.3271s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8031 acc_val: 0.4000 loss_test: 1.1641 acc_test: 0.6600 time: 0.2333s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.9252 acc_val: 0.4233 loss_test: 1.2200 acc_test: 0.6770 time: 0.2461s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9662 acc_val: 0.4467 loss_test: 1.2654 acc_test: 0.6830 time: 0.2308s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9823 acc_val: 0.4600 loss_test: 1.3043 acc_test: 0.6900 time: 0.2284s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0020 acc_val: 0.4700 loss_test: 1.3431 acc_test: 0.6900 time: 0.2323s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0386 acc_val: 0.5000 loss_test: 1.3826 acc_test: 0.6910 time: 0.2287s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0601 acc_val: 0.5200 loss_test: 1.4167 acc_test: 0.6930 time: 0.2271s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1047 acc_val: 0.5100 loss_test: 1.4524 acc_test: 0.6950 time: 0.2346s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1264 acc_val: 0.5033 loss_test: 1.4793 acc_test: 0.6980 time: 0.2365s
Optimization Finished!
Total time elapsed: 116.0645s, best testing performance  0.698000, minimun loss  0.967494
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7842 acc_train: 0.1750 loss_val: 1.7876 acc_val: 0.2033 loss_test: 1.6793 acc_test: 0.5290 time: 0.3103s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.7449 acc_val: 0.4267 loss_test: 1.1662 acc_test: 0.6740 time: 0.2245s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8296 acc_val: 0.4600 loss_test: 1.2159 acc_test: 0.6840 time: 0.2260s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9339 acc_val: 0.4667 loss_test: 1.2738 acc_test: 0.6820 time: 0.2211s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9968 acc_val: 0.4733 loss_test: 1.3244 acc_test: 0.6910 time: 0.2283s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0240 acc_val: 0.4867 loss_test: 1.3616 acc_test: 0.6920 time: 0.2270s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0803 acc_val: 0.5067 loss_test: 1.4050 acc_test: 0.6960 time: 0.2309s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1255 acc_val: 0.5133 loss_test: 1.4387 acc_test: 0.6960 time: 0.2409s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1843 acc_val: 0.5133 loss_test: 1.4811 acc_test: 0.6980 time: 0.2367s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2185 acc_val: 0.5133 loss_test: 1.5134 acc_test: 0.7020 time: 0.2329s
Optimization Finished!
Total time elapsed: 116.7273s, best testing performance  0.704000, minimun loss  0.994868
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7731 acc_train: 0.2167 loss_val: 1.8084 acc_val: 0.1267 loss_test: 1.6574 acc_test: 0.5060 time: 0.2740s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.5166 acc_val: 0.4733 loss_test: 1.1190 acc_test: 0.6900 time: 0.2265s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7859 acc_val: 0.4567 loss_test: 1.2129 acc_test: 0.6830 time: 0.2328s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9076 acc_val: 0.4733 loss_test: 1.2712 acc_test: 0.6900 time: 0.2348s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9482 acc_val: 0.4767 loss_test: 1.3097 acc_test: 0.6900 time: 0.2283s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0097 acc_val: 0.4767 loss_test: 1.3525 acc_test: 0.6920 time: 0.2241s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0507 acc_val: 0.5000 loss_test: 1.3856 acc_test: 0.6950 time: 0.2442s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0637 acc_val: 0.5100 loss_test: 1.4081 acc_test: 0.6940 time: 0.2421s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1085 acc_val: 0.5133 loss_test: 1.4363 acc_test: 0.6960 time: 0.2472s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1474 acc_val: 0.5133 loss_test: 1.4596 acc_test: 0.6960 time: 0.2528s
Optimization Finished!
Total time elapsed: 118.4701s, best testing performance  0.700000, minimun loss  0.985917
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7762 acc_train: 0.2667 loss_val: 1.8221 acc_val: 0.2033 loss_test: 1.6377 acc_test: 0.5410 time: 0.2941s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7335 acc_val: 0.4133 loss_test: 1.1519 acc_test: 0.6710 time: 0.2283s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9262 acc_val: 0.4300 loss_test: 1.2264 acc_test: 0.6790 time: 0.2297s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9890 acc_val: 0.4333 loss_test: 1.2690 acc_test: 0.6860 time: 0.2270s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0029 acc_val: 0.4667 loss_test: 1.3033 acc_test: 0.6920 time: 0.2568s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0611 acc_val: 0.4800 loss_test: 1.3486 acc_test: 0.6900 time: 0.2269s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1127 acc_val: 0.4900 loss_test: 1.3889 acc_test: 0.6910 time: 0.2426s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1228 acc_val: 0.5067 loss_test: 1.4172 acc_test: 0.6920 time: 0.2349s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1819 acc_val: 0.5000 loss_test: 1.4563 acc_test: 0.6940 time: 0.2313s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2272 acc_val: 0.4967 loss_test: 1.4906 acc_test: 0.6950 time: 0.2280s
Optimization Finished!
Total time elapsed: 117.5387s, best testing performance  0.697000, minimun loss  0.960811
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7912 acc_train: 0.2500 loss_val: 1.7950 acc_val: 0.1400 loss_test: 1.6833 acc_test: 0.4830 time: 0.3100s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.8101 acc_val: 0.3767 loss_test: 1.1810 acc_test: 0.6600 time: 0.2302s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8151 acc_val: 0.4233 loss_test: 1.1886 acc_test: 0.6760 time: 0.2582s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8517 acc_val: 0.4433 loss_test: 1.2249 acc_test: 0.6840 time: 0.2278s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.8979 acc_val: 0.4733 loss_test: 1.2673 acc_test: 0.6850 time: 0.2278s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9393 acc_val: 0.4833 loss_test: 1.3047 acc_test: 0.6910 time: 0.2306s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 1.9904 acc_val: 0.5067 loss_test: 1.3459 acc_test: 0.6910 time: 0.2546s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0396 acc_val: 0.5100 loss_test: 1.3827 acc_test: 0.6960 time: 0.2351s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0933 acc_val: 0.4967 loss_test: 1.4162 acc_test: 0.6960 time: 0.2216s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1366 acc_val: 0.5000 loss_test: 1.4437 acc_test: 0.6990 time: 0.2267s
Optimization Finished!
Total time elapsed: 117.8045s, best testing performance  0.702000, minimun loss  1.014527
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7918 acc_train: 0.2250 loss_val: 1.8009 acc_val: 0.0967 loss_test: 1.6903 acc_test: 0.4250 time: 0.3012s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.7789 acc_val: 0.3933 loss_test: 1.1625 acc_test: 0.6670 time: 0.2269s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8039 acc_val: 0.4300 loss_test: 1.1744 acc_test: 0.6800 time: 0.2214s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8680 acc_val: 0.4533 loss_test: 1.2169 acc_test: 0.6810 time: 0.2296s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9090 acc_val: 0.4833 loss_test: 1.2560 acc_test: 0.6870 time: 0.2191s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9445 acc_val: 0.4933 loss_test: 1.2936 acc_test: 0.6900 time: 0.2266s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9650 acc_val: 0.4967 loss_test: 1.3263 acc_test: 0.6920 time: 0.2387s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 1.9707 acc_val: 0.4967 loss_test: 1.3522 acc_test: 0.6950 time: 0.2393s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 1.9973 acc_val: 0.5067 loss_test: 1.3813 acc_test: 0.6950 time: 0.2249s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0277 acc_val: 0.5133 loss_test: 1.4112 acc_test: 0.6960 time: 0.2425s
Optimization Finished!
Total time elapsed: 118.3410s, best testing performance  0.699000, minimun loss  1.001094
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8177 acc_train: 0.1417 loss_val: 1.7844 acc_val: 0.2067 loss_test: 1.7124 acc_test: 0.4480 time: 0.2910s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.8363 acc_val: 0.3900 loss_test: 1.1670 acc_test: 0.6650 time: 0.2591s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8649 acc_val: 0.4400 loss_test: 1.1918 acc_test: 0.6770 time: 0.2286s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9156 acc_val: 0.4333 loss_test: 1.2325 acc_test: 0.6850 time: 0.2360s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9485 acc_val: 0.4767 loss_test: 1.2696 acc_test: 0.6900 time: 0.2652s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0040 acc_val: 0.4867 loss_test: 1.3120 acc_test: 0.6880 time: 0.2249s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0583 acc_val: 0.4833 loss_test: 1.3563 acc_test: 0.6910 time: 0.2494s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0948 acc_val: 0.5067 loss_test: 1.3913 acc_test: 0.6980 time: 0.2258s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.5100 loss_test: 1.4300 acc_test: 0.6990 time: 0.2283s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2063 acc_val: 0.5033 loss_test: 1.4673 acc_test: 0.6980 time: 0.2295s
Optimization Finished!
Total time elapsed: 116.3940s, best testing performance  0.701000, minimun loss  1.010519
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7926 acc_train: 0.2333 loss_val: 1.8023 acc_val: 0.1667 loss_test: 1.6900 acc_test: 0.4970 time: 0.2982s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.8447 acc_val: 0.3800 loss_test: 1.1856 acc_test: 0.6610 time: 0.2288s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8263 acc_val: 0.4300 loss_test: 1.1850 acc_test: 0.6710 time: 0.2370s
Epoch: 0151 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8836 acc_val: 0.4567 loss_test: 1.2265 acc_test: 0.6860 time: 0.2297s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9325 acc_val: 0.4700 loss_test: 1.2668 acc_test: 0.6870 time: 0.2268s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9666 acc_val: 0.4833 loss_test: 1.3063 acc_test: 0.6920 time: 0.2272s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0133 acc_val: 0.4900 loss_test: 1.3489 acc_test: 0.6920 time: 0.2357s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0436 acc_val: 0.5000 loss_test: 1.3813 acc_test: 0.6950 time: 0.2283s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0972 acc_val: 0.5000 loss_test: 1.4186 acc_test: 0.6970 time: 0.2290s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1365 acc_val: 0.5033 loss_test: 1.4498 acc_test: 0.6960 time: 0.2318s
Optimization Finished!
Total time elapsed: 116.2032s, best testing performance  0.699000, minimun loss  0.998071
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 35, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7824 acc_train: 0.2000 loss_val: 1.8125 acc_val: 0.1867 loss_test: 1.7005 acc_test: 0.4590 time: 0.3150s
Epoch: 0051 loss_train: 0.0121 acc_train: 1.0000 loss_val: 1.8299 acc_val: 0.3767 loss_test: 1.1821 acc_test: 0.6550 time: 0.2304s
Epoch: 0101 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8114 acc_val: 0.4133 loss_test: 1.1800 acc_test: 0.6690 time: 0.2467s
Epoch: 0151 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.8342 acc_val: 0.4467 loss_test: 1.2143 acc_test: 0.6830 time: 0.2213s
Epoch: 0201 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8506 acc_val: 0.4733 loss_test: 1.2478 acc_test: 0.6850 time: 0.2320s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.8849 acc_val: 0.5033 loss_test: 1.2878 acc_test: 0.6840 time: 0.2224s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9397 acc_val: 0.5100 loss_test: 1.3300 acc_test: 0.6910 time: 0.2381s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 1.9602 acc_val: 0.5200 loss_test: 1.3603 acc_test: 0.6950 time: 0.2576s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 1.9992 acc_val: 0.5133 loss_test: 1.3961 acc_test: 0.6950 time: 0.2444s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0500 acc_val: 0.5000 loss_test: 1.4296 acc_test: 0.6940 time: 0.2369s
Optimization Finished!
Total time elapsed: 118.1547s, best testing performance  0.697000, minimun loss  1.009201
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7893 acc_train: 0.2083 loss_val: 1.8303 acc_val: 0.1633 loss_test: 1.6725 acc_test: 0.4610 time: 0.3315s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.9742 acc_val: 0.4000 loss_test: 1.2052 acc_test: 0.6700 time: 0.2588s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 2.0182 acc_val: 0.4133 loss_test: 1.2495 acc_test: 0.6720 time: 0.2952s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0946 acc_val: 0.4367 loss_test: 1.3155 acc_test: 0.6790 time: 0.2636s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.1343 acc_val: 0.4667 loss_test: 1.3582 acc_test: 0.6870 time: 0.2467s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1379 acc_val: 0.4833 loss_test: 1.3868 acc_test: 0.6910 time: 0.2535s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1703 acc_val: 0.4933 loss_test: 1.4187 acc_test: 0.6920 time: 0.2669s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1886 acc_val: 0.5000 loss_test: 1.4493 acc_test: 0.6950 time: 0.2772s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2284 acc_val: 0.5033 loss_test: 1.4799 acc_test: 0.6990 time: 0.2984s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2732 acc_val: 0.5067 loss_test: 1.5082 acc_test: 0.7030 time: 0.2524s
Optimization Finished!
Total time elapsed: 133.0939s, best testing performance  0.705000, minimun loss  0.995838
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7850 acc_train: 0.1333 loss_val: 1.8126 acc_val: 0.1567 loss_test: 1.6492 acc_test: 0.4770 time: 0.3109s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8524 acc_val: 0.3800 loss_test: 1.1737 acc_test: 0.6670 time: 0.2648s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8903 acc_val: 0.4100 loss_test: 1.2064 acc_test: 0.6760 time: 0.2667s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9485 acc_val: 0.4533 loss_test: 1.2687 acc_test: 0.6830 time: 0.2607s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9987 acc_val: 0.4833 loss_test: 1.3136 acc_test: 0.6880 time: 0.2799s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0472 acc_val: 0.4800 loss_test: 1.3546 acc_test: 0.6890 time: 0.2592s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1091 acc_val: 0.4900 loss_test: 1.3964 acc_test: 0.6940 time: 0.2689s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1365 acc_val: 0.5067 loss_test: 1.4256 acc_test: 0.6960 time: 0.2747s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1810 acc_val: 0.5100 loss_test: 1.4560 acc_test: 0.6930 time: 0.2660s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2514 acc_val: 0.4967 loss_test: 1.4932 acc_test: 0.6910 time: 0.2738s
Optimization Finished!
Total time elapsed: 133.8744s, best testing performance  0.696000, minimun loss  0.996325
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1000 loss_val: 1.8320 acc_val: 0.1133 loss_test: 1.6626 acc_test: 0.4580 time: 0.3288s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.7774 acc_val: 0.3867 loss_test: 1.1349 acc_test: 0.6750 time: 0.2482s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7964 acc_val: 0.4233 loss_test: 1.1610 acc_test: 0.6830 time: 0.2559s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9372 acc_val: 0.4467 loss_test: 1.2491 acc_test: 0.6920 time: 0.2557s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0622 acc_val: 0.4767 loss_test: 1.3183 acc_test: 0.6900 time: 0.2553s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1594 acc_val: 0.4733 loss_test: 1.3699 acc_test: 0.6930 time: 0.2570s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1982 acc_val: 0.4967 loss_test: 1.4088 acc_test: 0.6890 time: 0.2818s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2096 acc_val: 0.5033 loss_test: 1.4370 acc_test: 0.6930 time: 0.2806s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2090 acc_val: 0.5067 loss_test: 1.4603 acc_test: 0.6940 time: 0.2648s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1971 acc_val: 0.5133 loss_test: 1.4767 acc_test: 0.6970 time: 0.2636s
Optimization Finished!
Total time elapsed: 132.5168s, best testing performance  0.700000, minimun loss  0.991639
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8130 acc_train: 0.1417 loss_val: 1.8442 acc_val: 0.1533 loss_test: 1.6709 acc_test: 0.4280 time: 0.3677s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 2.0317 acc_val: 0.3567 loss_test: 1.2108 acc_test: 0.6560 time: 0.2614s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9768 acc_val: 0.3900 loss_test: 1.2145 acc_test: 0.6690 time: 0.2568s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 2.0590 acc_val: 0.4233 loss_test: 1.2779 acc_test: 0.6750 time: 0.2699s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0959 acc_val: 0.4367 loss_test: 1.3173 acc_test: 0.6860 time: 0.2650s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1188 acc_val: 0.4667 loss_test: 1.3519 acc_test: 0.6890 time: 0.2568s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1410 acc_val: 0.4733 loss_test: 1.3857 acc_test: 0.6920 time: 0.2665s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1132 acc_val: 0.4900 loss_test: 1.4037 acc_test: 0.6950 time: 0.2841s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1357 acc_val: 0.5000 loss_test: 1.4305 acc_test: 0.6960 time: 0.2736s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1270 acc_val: 0.5100 loss_test: 1.4480 acc_test: 0.6960 time: 0.2700s
Optimization Finished!
Total time elapsed: 133.6717s, best testing performance  0.701000, minimun loss  0.996540
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7725 acc_train: 0.2500 loss_val: 1.8416 acc_val: 0.1267 loss_test: 1.6448 acc_test: 0.4470 time: 0.3425s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9582 acc_val: 0.3767 loss_test: 1.1935 acc_test: 0.6700 time: 0.2741s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9185 acc_val: 0.4167 loss_test: 1.1945 acc_test: 0.6810 time: 0.2455s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9918 acc_val: 0.4400 loss_test: 1.2578 acc_test: 0.6860 time: 0.2616s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0468 acc_val: 0.4667 loss_test: 1.3047 acc_test: 0.6890 time: 0.2581s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0946 acc_val: 0.4700 loss_test: 1.3467 acc_test: 0.6950 time: 0.2723s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1165 acc_val: 0.4933 loss_test: 1.3788 acc_test: 0.6930 time: 0.2667s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1498 acc_val: 0.5033 loss_test: 1.4113 acc_test: 0.6960 time: 0.2742s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1740 acc_val: 0.5067 loss_test: 1.4385 acc_test: 0.6960 time: 0.2642s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1885 acc_val: 0.5000 loss_test: 1.4614 acc_test: 0.6990 time: 0.2589s
Optimization Finished!
Total time elapsed: 132.4513s, best testing performance  0.701000, minimun loss  0.982226
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8141 acc_train: 0.1417 loss_val: 1.8201 acc_val: 0.0967 loss_test: 1.6540 acc_test: 0.4140 time: 0.3309s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.6569 acc_val: 0.4267 loss_test: 1.1081 acc_test: 0.6900 time: 0.2522s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.5961 acc_val: 0.4833 loss_test: 1.0897 acc_test: 0.7000 time: 0.2658s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.7338 acc_val: 0.4500 loss_test: 1.1617 acc_test: 0.7000 time: 0.2595s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9737 acc_val: 0.4600 loss_test: 1.2964 acc_test: 0.6980 time: 0.2575s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1689 acc_val: 0.4600 loss_test: 1.3996 acc_test: 0.6880 time: 0.2579s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1826 acc_val: 0.4733 loss_test: 1.4327 acc_test: 0.6900 time: 0.3024s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1626 acc_val: 0.4933 loss_test: 1.4414 acc_test: 0.6920 time: 0.2589s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2110 acc_val: 0.5000 loss_test: 1.4694 acc_test: 0.6920 time: 0.2626s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1889 acc_val: 0.5133 loss_test: 1.4862 acc_test: 0.6930 time: 0.2541s
Optimization Finished!
Total time elapsed: 131.9230s, best testing performance  0.706000, minimun loss  0.948954
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8053 acc_train: 0.1167 loss_val: 1.8190 acc_val: 0.1400 loss_test: 1.6534 acc_test: 0.5120 time: 0.3542s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.6071 acc_val: 0.4200 loss_test: 1.0762 acc_test: 0.6880 time: 0.2496s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.6608 acc_val: 0.4567 loss_test: 1.1156 acc_test: 0.6890 time: 0.2720s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9592 acc_val: 0.4333 loss_test: 1.2715 acc_test: 0.6850 time: 0.2435s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0688 acc_val: 0.4600 loss_test: 1.3387 acc_test: 0.6880 time: 0.2574s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0557 acc_val: 0.4800 loss_test: 1.3646 acc_test: 0.6950 time: 0.2537s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0820 acc_val: 0.5067 loss_test: 1.3902 acc_test: 0.6900 time: 0.2605s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1103 acc_val: 0.5133 loss_test: 1.4160 acc_test: 0.6940 time: 0.2634s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1432 acc_val: 0.5067 loss_test: 1.4472 acc_test: 0.6950 time: 0.3041s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1665 acc_val: 0.5133 loss_test: 1.4677 acc_test: 0.6970 time: 0.2566s
Optimization Finished!
Total time elapsed: 131.7712s, best testing performance  0.701000, minimun loss  0.924178
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7754 acc_train: 0.1917 loss_val: 1.8014 acc_val: 0.0700 loss_test: 1.6484 acc_test: 0.3760 time: 0.3399s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.5726 acc_val: 0.4567 loss_test: 1.0434 acc_test: 0.6880 time: 0.2433s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.6305 acc_val: 0.4533 loss_test: 1.0920 acc_test: 0.6880 time: 0.2563s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8643 acc_val: 0.4367 loss_test: 1.2224 acc_test: 0.6790 time: 0.2495s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9790 acc_val: 0.4633 loss_test: 1.2971 acc_test: 0.6820 time: 0.2601s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0497 acc_val: 0.4733 loss_test: 1.3459 acc_test: 0.6850 time: 0.2600s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0855 acc_val: 0.4800 loss_test: 1.3827 acc_test: 0.6910 time: 0.2742s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1244 acc_val: 0.4900 loss_test: 1.4202 acc_test: 0.6960 time: 0.3082s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1449 acc_val: 0.5067 loss_test: 1.4443 acc_test: 0.6960 time: 0.3064s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1964 acc_val: 0.5000 loss_test: 1.4770 acc_test: 0.6940 time: 0.2606s
Optimization Finished!
Total time elapsed: 132.3772s, best testing performance  0.700000, minimun loss  0.936372
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7842 acc_train: 0.2083 loss_val: 1.8432 acc_val: 0.1600 loss_test: 1.6573 acc_test: 0.5070 time: 0.3459s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.6939 acc_val: 0.4433 loss_test: 1.1103 acc_test: 0.6850 time: 0.2632s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.6747 acc_val: 0.4633 loss_test: 1.1226 acc_test: 0.6990 time: 0.2487s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8714 acc_val: 0.4500 loss_test: 1.2492 acc_test: 0.6920 time: 0.2492s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0795 acc_val: 0.4600 loss_test: 1.3551 acc_test: 0.6870 time: 0.2586s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1527 acc_val: 0.4800 loss_test: 1.3932 acc_test: 0.6880 time: 0.2507s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2423 acc_val: 0.4800 loss_test: 1.4389 acc_test: 0.6880 time: 0.2739s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2859 acc_val: 0.4967 loss_test: 1.4676 acc_test: 0.6910 time: 0.2629s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.3389 acc_val: 0.4933 loss_test: 1.4971 acc_test: 0.6910 time: 0.2716s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3455 acc_val: 0.5000 loss_test: 1.5199 acc_test: 0.6970 time: 0.2602s
Optimization Finished!
Total time elapsed: 131.9398s, best testing performance  0.700000, minimun loss  0.949987
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7864 acc_train: 0.2083 loss_val: 1.8030 acc_val: 0.1833 loss_test: 1.6461 acc_test: 0.5390 time: 0.3015s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.5920 acc_val: 0.4567 loss_test: 1.0764 acc_test: 0.6850 time: 0.2704s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.5170 acc_val: 0.4967 loss_test: 1.0530 acc_test: 0.6990 time: 0.2524s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.6137 acc_val: 0.4967 loss_test: 1.1016 acc_test: 0.7050 time: 0.2672s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.5502 acc_val: 0.5000 loss_test: 1.1196 acc_test: 0.7050 time: 0.2562s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.8059 acc_val: 0.4967 loss_test: 1.2765 acc_test: 0.7000 time: 0.2559s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0306 acc_val: 0.5133 loss_test: 1.3768 acc_test: 0.6910 time: 0.2705s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0820 acc_val: 0.5133 loss_test: 1.4039 acc_test: 0.6920 time: 0.3201s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1306 acc_val: 0.5067 loss_test: 1.4327 acc_test: 0.6930 time: 0.2565s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1633 acc_val: 0.5100 loss_test: 1.4573 acc_test: 0.6970 time: 0.2815s
Optimization Finished!
Total time elapsed: 132.2247s, best testing performance  0.717000, minimun loss  0.946811
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7773 acc_train: 0.2583 loss_val: 1.8274 acc_val: 0.1300 loss_test: 1.6397 acc_test: 0.5030 time: 0.3093s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8734 acc_val: 0.3667 loss_test: 1.1810 acc_test: 0.6630 time: 0.2795s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9042 acc_val: 0.4033 loss_test: 1.2193 acc_test: 0.6750 time: 0.2601s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0238 acc_val: 0.4267 loss_test: 1.2959 acc_test: 0.6820 time: 0.2550s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0569 acc_val: 0.4633 loss_test: 1.3393 acc_test: 0.6850 time: 0.2560s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0811 acc_val: 0.4700 loss_test: 1.3765 acc_test: 0.6930 time: 0.2522s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0927 acc_val: 0.4967 loss_test: 1.4117 acc_test: 0.6940 time: 0.2589s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1123 acc_val: 0.5033 loss_test: 1.4458 acc_test: 0.7020 time: 0.2845s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1572 acc_val: 0.5167 loss_test: 1.4735 acc_test: 0.6990 time: 0.2879s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1813 acc_val: 0.5167 loss_test: 1.5040 acc_test: 0.6990 time: 0.2654s
Optimization Finished!
Total time elapsed: 133.1498s, best testing performance  0.703000, minimun loss  0.957194
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7931 acc_train: 0.1667 loss_val: 1.8420 acc_val: 0.0933 loss_test: 1.6497 acc_test: 0.4040 time: 0.3260s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8666 acc_val: 0.3733 loss_test: 1.1688 acc_test: 0.6720 time: 0.2517s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9335 acc_val: 0.4167 loss_test: 1.2162 acc_test: 0.6820 time: 0.2584s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0184 acc_val: 0.4367 loss_test: 1.2774 acc_test: 0.6870 time: 0.2679s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0403 acc_val: 0.4600 loss_test: 1.3192 acc_test: 0.6860 time: 0.2619s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0835 acc_val: 0.4733 loss_test: 1.3644 acc_test: 0.6880 time: 0.2442s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1337 acc_val: 0.4933 loss_test: 1.4036 acc_test: 0.6890 time: 0.2586s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1461 acc_val: 0.5100 loss_test: 1.4293 acc_test: 0.6960 time: 0.2713s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2208 acc_val: 0.5000 loss_test: 1.4679 acc_test: 0.6940 time: 0.2878s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2518 acc_val: 0.5033 loss_test: 1.4935 acc_test: 0.6930 time: 0.2699s
Optimization Finished!
Total time elapsed: 132.5704s, best testing performance  0.699000, minimun loss  0.962352
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7851 acc_train: 0.1833 loss_val: 1.8183 acc_val: 0.0700 loss_test: 1.6481 acc_test: 0.4530 time: 0.3320s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7283 acc_val: 0.4200 loss_test: 1.1598 acc_test: 0.6760 time: 0.2557s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8204 acc_val: 0.4400 loss_test: 1.2052 acc_test: 0.6900 time: 0.2777s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9817 acc_val: 0.4500 loss_test: 1.2963 acc_test: 0.6870 time: 0.2565s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0154 acc_val: 0.4633 loss_test: 1.3306 acc_test: 0.6870 time: 0.2499s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0449 acc_val: 0.4767 loss_test: 1.3669 acc_test: 0.6950 time: 0.2591s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0981 acc_val: 0.4800 loss_test: 1.4031 acc_test: 0.6950 time: 0.2589s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1106 acc_val: 0.5033 loss_test: 1.4264 acc_test: 0.6980 time: 0.3079s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1635 acc_val: 0.5067 loss_test: 1.4569 acc_test: 0.6980 time: 0.2744s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1956 acc_val: 0.5133 loss_test: 1.4817 acc_test: 0.6990 time: 0.2600s
Optimization Finished!
Total time elapsed: 132.7080s, best testing performance  0.702000, minimun loss  0.940928
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8022 acc_train: 0.1250 loss_val: 1.8584 acc_val: 0.1000 loss_test: 1.6661 acc_test: 0.4330 time: 0.3379s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8198 acc_val: 0.3867 loss_test: 1.1541 acc_test: 0.6690 time: 0.2581s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8343 acc_val: 0.4367 loss_test: 1.1945 acc_test: 0.6820 time: 0.2574s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9923 acc_val: 0.4500 loss_test: 1.2799 acc_test: 0.6800 time: 0.2616s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0417 acc_val: 0.4667 loss_test: 1.3224 acc_test: 0.6860 time: 0.2512s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1232 acc_val: 0.4733 loss_test: 1.3735 acc_test: 0.6910 time: 0.2482s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1691 acc_val: 0.4800 loss_test: 1.4103 acc_test: 0.6900 time: 0.2615s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2066 acc_val: 0.4900 loss_test: 1.4416 acc_test: 0.6940 time: 0.2741s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2235 acc_val: 0.5067 loss_test: 1.4663 acc_test: 0.6940 time: 0.2748s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2422 acc_val: 0.5033 loss_test: 1.4878 acc_test: 0.6980 time: 0.2489s
Optimization Finished!
Total time elapsed: 132.5823s, best testing performance  0.700000, minimun loss  0.958689
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8151 acc_train: 0.0750 loss_val: 1.8467 acc_val: 0.0600 loss_test: 1.6835 acc_test: 0.3350 time: 0.3190s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7967 acc_val: 0.4000 loss_test: 1.1829 acc_test: 0.6690 time: 0.2569s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8352 acc_val: 0.4500 loss_test: 1.2221 acc_test: 0.6770 time: 0.2596s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9478 acc_val: 0.4667 loss_test: 1.2970 acc_test: 0.6870 time: 0.2508s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9882 acc_val: 0.4800 loss_test: 1.3299 acc_test: 0.6880 time: 0.2699s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0317 acc_val: 0.4833 loss_test: 1.3610 acc_test: 0.6930 time: 0.2563s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0669 acc_val: 0.4933 loss_test: 1.3891 acc_test: 0.6910 time: 0.2593s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1245 acc_val: 0.4900 loss_test: 1.4233 acc_test: 0.6940 time: 0.2844s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1754 acc_val: 0.4933 loss_test: 1.4570 acc_test: 0.6930 time: 0.2751s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1758 acc_val: 0.5033 loss_test: 1.4732 acc_test: 0.6970 time: 0.2557s
Optimization Finished!
Total time elapsed: 132.5963s, best testing performance  0.700000, minimun loss  0.960583
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8002 acc_train: 0.1667 loss_val: 1.8273 acc_val: 0.0867 loss_test: 1.6564 acc_test: 0.4530 time: 0.3118s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7147 acc_val: 0.4200 loss_test: 1.1254 acc_test: 0.6840 time: 0.2607s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8268 acc_val: 0.4167 loss_test: 1.1937 acc_test: 0.6840 time: 0.2580s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0050 acc_val: 0.4300 loss_test: 1.2875 acc_test: 0.6850 time: 0.2613s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0460 acc_val: 0.4600 loss_test: 1.3199 acc_test: 0.6860 time: 0.2537s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0717 acc_val: 0.4667 loss_test: 1.3585 acc_test: 0.6890 time: 0.2795s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.4900 loss_test: 1.3907 acc_test: 0.6960 time: 0.2635s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1481 acc_val: 0.4967 loss_test: 1.4334 acc_test: 0.6950 time: 0.2785s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1951 acc_val: 0.5033 loss_test: 1.4706 acc_test: 0.6960 time: 0.2747s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1629 acc_val: 0.5167 loss_test: 1.4848 acc_test: 0.6980 time: 0.2706s
Optimization Finished!
Total time elapsed: 132.3125s, best testing performance  0.703000, minimun loss  0.942525
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7803 acc_train: 0.1833 loss_val: 1.8120 acc_val: 0.2167 loss_test: 1.6563 acc_test: 0.5430 time: 0.3541s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8162 acc_val: 0.4033 loss_test: 1.1742 acc_test: 0.6740 time: 0.2526s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8379 acc_val: 0.4367 loss_test: 1.2009 acc_test: 0.6890 time: 0.2607s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0288 acc_val: 0.4500 loss_test: 1.3005 acc_test: 0.6900 time: 0.2626s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.1248 acc_val: 0.4600 loss_test: 1.3537 acc_test: 0.6840 time: 0.2567s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1496 acc_val: 0.4767 loss_test: 1.3862 acc_test: 0.6920 time: 0.2634s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1519 acc_val: 0.4900 loss_test: 1.4118 acc_test: 0.6910 time: 0.2576s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1553 acc_val: 0.5033 loss_test: 1.4352 acc_test: 0.6950 time: 0.2761s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2145 acc_val: 0.5033 loss_test: 1.4713 acc_test: 0.6940 time: 0.2871s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2371 acc_val: 0.5100 loss_test: 1.4919 acc_test: 0.6940 time: 0.2624s
Optimization Finished!
Total time elapsed: 132.3463s, best testing performance  0.699000, minimun loss  0.959935
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7839 acc_train: 0.2583 loss_val: 1.8065 acc_val: 0.2100 loss_test: 1.6598 acc_test: 0.5280 time: 0.3609s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7739 acc_val: 0.3967 loss_test: 1.1682 acc_test: 0.6790 time: 0.2615s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8139 acc_val: 0.4500 loss_test: 1.1968 acc_test: 0.6880 time: 0.2715s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9319 acc_val: 0.4867 loss_test: 1.2722 acc_test: 0.6930 time: 0.2563s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0262 acc_val: 0.4833 loss_test: 1.3269 acc_test: 0.6900 time: 0.2537s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0693 acc_val: 0.4833 loss_test: 1.3663 acc_test: 0.6930 time: 0.2496s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0940 acc_val: 0.5067 loss_test: 1.3944 acc_test: 0.6940 time: 0.2602s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1452 acc_val: 0.5033 loss_test: 1.4292 acc_test: 0.6960 time: 0.2912s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1834 acc_val: 0.5133 loss_test: 1.4591 acc_test: 0.6940 time: 0.2765s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2135 acc_val: 0.5067 loss_test: 1.4810 acc_test: 0.6960 time: 0.2655s
Optimization Finished!
Total time elapsed: 132.0378s, best testing performance  0.697000, minimun loss  0.964150
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7901 acc_train: 0.0917 loss_val: 1.8381 acc_val: 0.0667 loss_test: 1.6656 acc_test: 0.3690 time: 0.3180s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7196 acc_val: 0.4200 loss_test: 1.1375 acc_test: 0.6900 time: 0.2608s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7866 acc_val: 0.4333 loss_test: 1.1818 acc_test: 0.6910 time: 0.2615s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9579 acc_val: 0.4500 loss_test: 1.2790 acc_test: 0.6880 time: 0.2533s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0033 acc_val: 0.4733 loss_test: 1.3240 acc_test: 0.6850 time: 0.2522s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0674 acc_val: 0.4800 loss_test: 1.3697 acc_test: 0.6850 time: 0.2536s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1283 acc_val: 0.4800 loss_test: 1.4080 acc_test: 0.6900 time: 0.2644s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.4867 loss_test: 1.4350 acc_test: 0.6940 time: 0.2748s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2170 acc_val: 0.4967 loss_test: 1.4687 acc_test: 0.6910 time: 0.2744s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2258 acc_val: 0.5000 loss_test: 1.4845 acc_test: 0.6950 time: 0.2801s
Optimization Finished!
Total time elapsed: 132.6896s, best testing performance  0.699000, minimun loss  0.947475
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8066 acc_train: 0.1333 loss_val: 1.8079 acc_val: 0.1400 loss_test: 1.6633 acc_test: 0.5000 time: 0.3085s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7271 acc_val: 0.4133 loss_test: 1.1568 acc_test: 0.6780 time: 0.2483s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.7911 acc_val: 0.4433 loss_test: 1.1993 acc_test: 0.6870 time: 0.2779s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9284 acc_val: 0.4467 loss_test: 1.2831 acc_test: 0.6890 time: 0.2504s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9603 acc_val: 0.4767 loss_test: 1.3196 acc_test: 0.6910 time: 0.2521s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0118 acc_val: 0.4900 loss_test: 1.3623 acc_test: 0.6880 time: 0.2565s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0413 acc_val: 0.5033 loss_test: 1.3902 acc_test: 0.6910 time: 0.2588s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0713 acc_val: 0.5167 loss_test: 1.4196 acc_test: 0.6910 time: 0.2831s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1157 acc_val: 0.5100 loss_test: 1.4469 acc_test: 0.6910 time: 0.2724s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1348 acc_val: 0.5133 loss_test: 1.4686 acc_test: 0.6950 time: 0.2561s
Optimization Finished!
Total time elapsed: 132.8485s, best testing performance  0.706000, minimun loss  0.947384
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8042 acc_train: 0.1083 loss_val: 1.8279 acc_val: 0.0800 loss_test: 1.6635 acc_test: 0.4320 time: 0.3223s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.5988 acc_val: 0.4467 loss_test: 1.0975 acc_test: 0.6870 time: 0.2560s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7192 acc_val: 0.4533 loss_test: 1.1573 acc_test: 0.6980 time: 0.2647s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8952 acc_val: 0.4633 loss_test: 1.2400 acc_test: 0.6870 time: 0.2609s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9924 acc_val: 0.4700 loss_test: 1.2947 acc_test: 0.6880 time: 0.2555s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0109 acc_val: 0.4867 loss_test: 1.3277 acc_test: 0.6890 time: 0.2614s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0408 acc_val: 0.4900 loss_test: 1.3577 acc_test: 0.6950 time: 0.2505s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0566 acc_val: 0.5100 loss_test: 1.3836 acc_test: 0.7000 time: 0.2697s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1315 acc_val: 0.5067 loss_test: 1.4181 acc_test: 0.7000 time: 0.2749s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1167 acc_val: 0.5133 loss_test: 1.4319 acc_test: 0.6980 time: 0.2664s
Optimization Finished!
Total time elapsed: 132.4719s, best testing performance  0.705000, minimun loss  0.940585
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8051 acc_train: 0.1083 loss_val: 1.8293 acc_val: 0.0800 loss_test: 1.6756 acc_test: 0.3960 time: 0.3321s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7768 acc_val: 0.3967 loss_test: 1.1684 acc_test: 0.6680 time: 0.2760s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7122 acc_val: 0.4600 loss_test: 1.1677 acc_test: 0.6940 time: 0.2620s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8892 acc_val: 0.4700 loss_test: 1.2622 acc_test: 0.6900 time: 0.2604s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9862 acc_val: 0.4800 loss_test: 1.3157 acc_test: 0.6870 time: 0.2577s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0761 acc_val: 0.4767 loss_test: 1.3658 acc_test: 0.6870 time: 0.2652s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1303 acc_val: 0.4900 loss_test: 1.4012 acc_test: 0.6900 time: 0.2585s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1904 acc_val: 0.4967 loss_test: 1.4383 acc_test: 0.6900 time: 0.2789s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2223 acc_val: 0.4967 loss_test: 1.4623 acc_test: 0.6920 time: 0.2778s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2770 acc_val: 0.5033 loss_test: 1.4910 acc_test: 0.6930 time: 0.2877s
Optimization Finished!
Total time elapsed: 133.1649s, best testing performance  0.696000, minimun loss  0.951616
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8003 acc_train: 0.1083 loss_val: 1.8044 acc_val: 0.1533 loss_test: 1.6599 acc_test: 0.4780 time: 0.3236s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7882 acc_val: 0.4033 loss_test: 1.1578 acc_test: 0.6700 time: 0.2541s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8565 acc_val: 0.4300 loss_test: 1.1996 acc_test: 0.6800 time: 0.2591s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9865 acc_val: 0.4467 loss_test: 1.2718 acc_test: 0.6840 time: 0.2546s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0565 acc_val: 0.4633 loss_test: 1.3159 acc_test: 0.6890 time: 0.2476s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1042 acc_val: 0.4733 loss_test: 1.3536 acc_test: 0.6940 time: 0.2533s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1419 acc_val: 0.4833 loss_test: 1.3880 acc_test: 0.6910 time: 0.2508s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1819 acc_val: 0.5033 loss_test: 1.4189 acc_test: 0.6920 time: 0.2688s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2030 acc_val: 0.5100 loss_test: 1.4420 acc_test: 0.6950 time: 0.2752s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2115 acc_val: 0.5033 loss_test: 1.4632 acc_test: 0.6970 time: 0.2650s
Optimization Finished!
Total time elapsed: 132.5289s, best testing performance  0.700000, minimun loss  0.955564
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7886 acc_train: 0.1750 loss_val: 1.8281 acc_val: 0.1767 loss_test: 1.6741 acc_test: 0.4920 time: 0.3615s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8127 acc_val: 0.4200 loss_test: 1.1754 acc_test: 0.6790 time: 0.2548s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8423 acc_val: 0.4667 loss_test: 1.2019 acc_test: 0.6910 time: 0.2634s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9828 acc_val: 0.4733 loss_test: 1.2792 acc_test: 0.6890 time: 0.2611s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0648 acc_val: 0.4700 loss_test: 1.3301 acc_test: 0.6920 time: 0.2513s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1206 acc_val: 0.4667 loss_test: 1.3689 acc_test: 0.6930 time: 0.2494s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1408 acc_val: 0.4900 loss_test: 1.4029 acc_test: 0.6900 time: 0.2580s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1707 acc_val: 0.5033 loss_test: 1.4311 acc_test: 0.6900 time: 0.2881s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1929 acc_val: 0.5000 loss_test: 1.4546 acc_test: 0.6930 time: 0.2862s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1873 acc_val: 0.5033 loss_test: 1.4672 acc_test: 0.6920 time: 0.2492s
Optimization Finished!
Total time elapsed: 132.5797s, best testing performance  0.696000, minimun loss  0.954837
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8031 acc_train: 0.1500 loss_val: 1.8044 acc_val: 0.1400 loss_test: 1.6467 acc_test: 0.4380 time: 0.3389s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7867 acc_val: 0.4033 loss_test: 1.1551 acc_test: 0.6640 time: 0.2518s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.7847 acc_val: 0.4267 loss_test: 1.1790 acc_test: 0.6790 time: 0.2489s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9304 acc_val: 0.4500 loss_test: 1.2568 acc_test: 0.6860 time: 0.2564s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9906 acc_val: 0.4733 loss_test: 1.3018 acc_test: 0.6920 time: 0.2568s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0803 acc_val: 0.4733 loss_test: 1.3595 acc_test: 0.6950 time: 0.2587s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1186 acc_val: 0.4767 loss_test: 1.3996 acc_test: 0.6940 time: 0.2590s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1322 acc_val: 0.5000 loss_test: 1.4308 acc_test: 0.6970 time: 0.2729s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1869 acc_val: 0.5100 loss_test: 1.4689 acc_test: 0.7000 time: 0.2737s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1946 acc_val: 0.5100 loss_test: 1.5008 acc_test: 0.7000 time: 0.2682s
Optimization Finished!
Total time elapsed: 132.7680s, best testing performance  0.704000, minimun loss  0.929488
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7928 acc_train: 0.1500 loss_val: 1.7986 acc_val: 0.1933 loss_test: 1.6578 acc_test: 0.5580 time: 0.3383s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.9936 acc_val: 0.3600 loss_test: 1.1939 acc_test: 0.6550 time: 0.2693s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9365 acc_val: 0.4100 loss_test: 1.1922 acc_test: 0.6680 time: 0.2712s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9922 acc_val: 0.4333 loss_test: 1.2430 acc_test: 0.6800 time: 0.2617s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0465 acc_val: 0.4533 loss_test: 1.2887 acc_test: 0.6840 time: 0.2463s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0709 acc_val: 0.4667 loss_test: 1.3257 acc_test: 0.6930 time: 0.2622s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1049 acc_val: 0.4933 loss_test: 1.3618 acc_test: 0.6930 time: 0.2512s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1463 acc_val: 0.5100 loss_test: 1.3980 acc_test: 0.6950 time: 0.2659s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.5133 loss_test: 1.4232 acc_test: 0.6930 time: 0.2567s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1877 acc_val: 0.5133 loss_test: 1.4498 acc_test: 0.6950 time: 0.2604s
Optimization Finished!
Total time elapsed: 131.3225s, best testing performance  0.697000, minimun loss  0.977947
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7979 acc_train: 0.1750 loss_val: 1.8424 acc_val: 0.1333 loss_test: 1.6714 acc_test: 0.4770 time: 0.3351s
Epoch: 0051 loss_train: 0.0117 acc_train: 1.0000 loss_val: 1.9787 acc_val: 0.3667 loss_test: 1.2254 acc_test: 0.6540 time: 0.2458s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.9508 acc_val: 0.4033 loss_test: 1.2248 acc_test: 0.6670 time: 0.2604s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 2.0344 acc_val: 0.4367 loss_test: 1.2741 acc_test: 0.6810 time: 0.2549s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0777 acc_val: 0.4500 loss_test: 1.3084 acc_test: 0.6840 time: 0.2609s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0973 acc_val: 0.4700 loss_test: 1.3375 acc_test: 0.6910 time: 0.2516s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1097 acc_val: 0.4833 loss_test: 1.3662 acc_test: 0.6890 time: 0.2776s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1403 acc_val: 0.4967 loss_test: 1.3966 acc_test: 0.6920 time: 0.2760s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1620 acc_val: 0.5100 loss_test: 1.4234 acc_test: 0.6960 time: 0.2609s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2090 acc_val: 0.5033 loss_test: 1.4515 acc_test: 0.6940 time: 0.2623s
Optimization Finished!
Total time elapsed: 130.8049s, best testing performance  0.697000, minimun loss  1.004859
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7991 acc_train: 0.1333 loss_val: 1.8009 acc_val: 0.1300 loss_test: 1.6812 acc_test: 0.4560 time: 0.3346s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.9267 acc_val: 0.3533 loss_test: 1.1816 acc_test: 0.6620 time: 0.2563s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.9071 acc_val: 0.4133 loss_test: 1.1835 acc_test: 0.6720 time: 0.2606s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9616 acc_val: 0.4367 loss_test: 1.2310 acc_test: 0.6800 time: 0.2671s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0010 acc_val: 0.4500 loss_test: 1.2708 acc_test: 0.6870 time: 0.3000s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0408 acc_val: 0.4700 loss_test: 1.3090 acc_test: 0.6930 time: 0.2517s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0526 acc_val: 0.4800 loss_test: 1.3427 acc_test: 0.6950 time: 0.2573s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1049 acc_val: 0.4867 loss_test: 1.3820 acc_test: 0.6980 time: 0.2615s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1050 acc_val: 0.5033 loss_test: 1.4088 acc_test: 0.7010 time: 0.2591s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1488 acc_val: 0.4967 loss_test: 1.4388 acc_test: 0.7000 time: 0.2613s
Optimization Finished!
Total time elapsed: 130.3134s, best testing performance  0.703000, minimun loss  0.988219
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7809 acc_train: 0.2167 loss_val: 1.8024 acc_val: 0.1800 loss_test: 1.6615 acc_test: 0.5240 time: 0.3889s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.9056 acc_val: 0.3767 loss_test: 1.2190 acc_test: 0.6550 time: 0.2562s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9054 acc_val: 0.4067 loss_test: 1.2248 acc_test: 0.6720 time: 0.2551s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9485 acc_val: 0.4367 loss_test: 1.2654 acc_test: 0.6810 time: 0.2561s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9975 acc_val: 0.4567 loss_test: 1.3080 acc_test: 0.6870 time: 0.2568s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0392 acc_val: 0.4833 loss_test: 1.3482 acc_test: 0.6930 time: 0.2574s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0917 acc_val: 0.5000 loss_test: 1.3877 acc_test: 0.6950 time: 0.2661s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1544 acc_val: 0.4967 loss_test: 1.4277 acc_test: 0.6960 time: 0.2462s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1891 acc_val: 0.5000 loss_test: 1.4605 acc_test: 0.7000 time: 0.2650s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2508 acc_val: 0.4967 loss_test: 1.4965 acc_test: 0.7030 time: 0.2542s
Optimization Finished!
Total time elapsed: 130.7961s, best testing performance  0.704000, minimun loss  0.995402
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7803 acc_train: 0.1667 loss_val: 1.8321 acc_val: 0.1633 loss_test: 1.6501 acc_test: 0.5320 time: 0.3433s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.9346 acc_val: 0.3733 loss_test: 1.2047 acc_test: 0.6590 time: 0.2482s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.9068 acc_val: 0.4100 loss_test: 1.2069 acc_test: 0.6780 time: 0.2715s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9487 acc_val: 0.4333 loss_test: 1.2545 acc_test: 0.6870 time: 0.2594s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0007 acc_val: 0.4533 loss_test: 1.2999 acc_test: 0.6840 time: 0.2721s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0437 acc_val: 0.4600 loss_test: 1.3414 acc_test: 0.6880 time: 0.2599s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0740 acc_val: 0.4833 loss_test: 1.3756 acc_test: 0.6910 time: 0.2720s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.5033 loss_test: 1.4045 acc_test: 0.6930 time: 0.2724s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1223 acc_val: 0.5100 loss_test: 1.4353 acc_test: 0.6960 time: 0.2530s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1610 acc_val: 0.5067 loss_test: 1.4642 acc_test: 0.6970 time: 0.2954s
Optimization Finished!
Total time elapsed: 132.7949s, best testing performance  0.698000, minimun loss  0.974616
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8119 acc_train: 0.0917 loss_val: 1.7936 acc_val: 0.1867 loss_test: 1.6757 acc_test: 0.3500 time: 0.3274s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.5237 acc_val: 0.4533 loss_test: 1.0773 acc_test: 0.6800 time: 0.2547s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7479 acc_val: 0.4367 loss_test: 1.1810 acc_test: 0.6860 time: 0.2899s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9503 acc_val: 0.4300 loss_test: 1.2859 acc_test: 0.6830 time: 0.2488s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9999 acc_val: 0.4533 loss_test: 1.3234 acc_test: 0.6910 time: 0.2601s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0416 acc_val: 0.4833 loss_test: 1.3652 acc_test: 0.6890 time: 0.2584s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0638 acc_val: 0.4867 loss_test: 1.3978 acc_test: 0.6960 time: 0.2525s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0725 acc_val: 0.5067 loss_test: 1.4238 acc_test: 0.6990 time: 0.3020s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0677 acc_val: 0.5167 loss_test: 1.4460 acc_test: 0.7000 time: 0.2698s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1314 acc_val: 0.5067 loss_test: 1.4806 acc_test: 0.7000 time: 0.2628s
Optimization Finished!
Total time elapsed: 132.6141s, best testing performance  0.705000, minimun loss  0.936588
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8078 acc_train: 0.1000 loss_val: 1.8311 acc_val: 0.0967 loss_test: 1.6608 acc_test: 0.4950 time: 0.3223s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.6453 acc_val: 0.4300 loss_test: 1.1089 acc_test: 0.6780 time: 0.2616s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7360 acc_val: 0.4533 loss_test: 1.1543 acc_test: 0.6900 time: 0.2571s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9383 acc_val: 0.4300 loss_test: 1.2690 acc_test: 0.6880 time: 0.2460s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0508 acc_val: 0.4400 loss_test: 1.3290 acc_test: 0.6880 time: 0.2542s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1335 acc_val: 0.4667 loss_test: 1.3727 acc_test: 0.6870 time: 0.2568s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1734 acc_val: 0.4733 loss_test: 1.4107 acc_test: 0.6910 time: 0.2550s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1645 acc_val: 0.4867 loss_test: 1.4342 acc_test: 0.6900 time: 0.2828s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2117 acc_val: 0.5000 loss_test: 1.4668 acc_test: 0.6910 time: 0.2713s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2444 acc_val: 0.4967 loss_test: 1.4946 acc_test: 0.6930 time: 0.2765s
Optimization Finished!
Total time elapsed: 132.3374s, best testing performance  0.697000, minimun loss  0.943387
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7950 acc_train: 0.1917 loss_val: 1.8587 acc_val: 0.1267 loss_test: 1.6672 acc_test: 0.4390 time: 0.3304s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7091 acc_val: 0.4000 loss_test: 1.1281 acc_test: 0.6700 time: 0.2476s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7837 acc_val: 0.4367 loss_test: 1.1770 acc_test: 0.6850 time: 0.2475s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9580 acc_val: 0.4400 loss_test: 1.2733 acc_test: 0.6850 time: 0.2614s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0299 acc_val: 0.4633 loss_test: 1.3193 acc_test: 0.6860 time: 0.2627s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0781 acc_val: 0.4800 loss_test: 1.3586 acc_test: 0.6900 time: 0.2664s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0573 acc_val: 0.5000 loss_test: 1.3845 acc_test: 0.6950 time: 0.2667s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0866 acc_val: 0.5033 loss_test: 1.4159 acc_test: 0.6990 time: 0.3000s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1098 acc_val: 0.5000 loss_test: 1.4435 acc_test: 0.7000 time: 0.2910s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1216 acc_val: 0.4967 loss_test: 1.4671 acc_test: 0.7000 time: 0.2728s
Optimization Finished!
Total time elapsed: 132.8571s, best testing performance  0.706000, minimun loss  0.951834
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7904 acc_train: 0.1500 loss_val: 1.8561 acc_val: 0.0567 loss_test: 1.6754 acc_test: 0.3740 time: 0.3278s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.5947 acc_val: 0.4600 loss_test: 1.1158 acc_test: 0.6820 time: 0.2645s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.6648 acc_val: 0.4767 loss_test: 1.1584 acc_test: 0.6900 time: 0.2659s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8754 acc_val: 0.4733 loss_test: 1.2635 acc_test: 0.6880 time: 0.2560s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0707 acc_val: 0.4700 loss_test: 1.3443 acc_test: 0.6870 time: 0.2839s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1780 acc_val: 0.4733 loss_test: 1.3875 acc_test: 0.6950 time: 0.2481s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.2327 acc_val: 0.4767 loss_test: 1.4204 acc_test: 0.6900 time: 0.2795s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2452 acc_val: 0.4833 loss_test: 1.4366 acc_test: 0.6900 time: 0.2920s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2648 acc_val: 0.4900 loss_test: 1.4547 acc_test: 0.6940 time: 0.2972s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2798 acc_val: 0.4967 loss_test: 1.4720 acc_test: 0.6940 time: 0.2520s
Optimization Finished!
Total time elapsed: 132.6305s, best testing performance  0.697000, minimun loss  0.959123
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7955 acc_train: 0.1083 loss_val: 1.8359 acc_val: 0.2133 loss_test: 1.6680 acc_test: 0.4940 time: 0.3530s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.5911 acc_val: 0.4367 loss_test: 1.1009 acc_test: 0.6810 time: 0.2461s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7727 acc_val: 0.4467 loss_test: 1.1827 acc_test: 0.6890 time: 0.2822s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9676 acc_val: 0.4533 loss_test: 1.2892 acc_test: 0.6880 time: 0.2649s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9897 acc_val: 0.4633 loss_test: 1.3227 acc_test: 0.6890 time: 0.2902s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0573 acc_val: 0.4800 loss_test: 1.3694 acc_test: 0.6900 time: 0.2550s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1079 acc_val: 0.5067 loss_test: 1.4077 acc_test: 0.6910 time: 0.2702s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1373 acc_val: 0.5100 loss_test: 1.4385 acc_test: 0.6920 time: 0.2902s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2013 acc_val: 0.5033 loss_test: 1.4728 acc_test: 0.6920 time: 0.2756s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2608 acc_val: 0.4967 loss_test: 1.5058 acc_test: 0.6950 time: 0.2602s
Optimization Finished!
Total time elapsed: 132.6662s, best testing performance  0.702000, minimun loss  0.941316
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7880 acc_train: 0.1583 loss_val: 1.7959 acc_val: 0.0733 loss_test: 1.6720 acc_test: 0.3770 time: 0.3305s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7780 acc_val: 0.4067 loss_test: 1.1738 acc_test: 0.6620 time: 0.2804s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8477 acc_val: 0.4267 loss_test: 1.2065 acc_test: 0.6740 time: 0.2550s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9215 acc_val: 0.4400 loss_test: 1.2593 acc_test: 0.6830 time: 0.2599s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9630 acc_val: 0.4667 loss_test: 1.2997 acc_test: 0.6860 time: 0.2664s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0004 acc_val: 0.4767 loss_test: 1.3368 acc_test: 0.6900 time: 0.2452s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0768 acc_val: 0.4933 loss_test: 1.3799 acc_test: 0.6910 time: 0.2650s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1302 acc_val: 0.5067 loss_test: 1.4153 acc_test: 0.6920 time: 0.2723s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1910 acc_val: 0.5100 loss_test: 1.4528 acc_test: 0.6940 time: 0.2546s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2345 acc_val: 0.5133 loss_test: 1.4814 acc_test: 0.6960 time: 0.2696s
Optimization Finished!
Total time elapsed: 131.2282s, best testing performance  0.697000, minimun loss  0.980952
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8019 acc_train: 0.0917 loss_val: 1.8200 acc_val: 0.1200 loss_test: 1.6753 acc_test: 0.4570 time: 0.3523s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7224 acc_val: 0.4067 loss_test: 1.1424 acc_test: 0.6680 time: 0.2576s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.7661 acc_val: 0.4200 loss_test: 1.1703 acc_test: 0.6820 time: 0.2596s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8729 acc_val: 0.4533 loss_test: 1.2362 acc_test: 0.6910 time: 0.2568s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9699 acc_val: 0.4733 loss_test: 1.2899 acc_test: 0.6930 time: 0.2507s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0128 acc_val: 0.4767 loss_test: 1.3289 acc_test: 0.6910 time: 0.2752s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0256 acc_val: 0.5000 loss_test: 1.3576 acc_test: 0.6930 time: 0.2955s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0507 acc_val: 0.5133 loss_test: 1.3936 acc_test: 0.7000 time: 0.2753s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0743 acc_val: 0.5167 loss_test: 1.4250 acc_test: 0.7050 time: 0.2879s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0840 acc_val: 0.5100 loss_test: 1.4492 acc_test: 0.7050 time: 0.2747s
Optimization Finished!
Total time elapsed: 132.9577s, best testing performance  0.708000, minimun loss  0.972135
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7942 acc_train: 0.1250 loss_val: 1.8046 acc_val: 0.1867 loss_test: 1.6565 acc_test: 0.5470 time: 0.3569s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8228 acc_val: 0.3867 loss_test: 1.1816 acc_test: 0.6620 time: 0.2681s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8589 acc_val: 0.4233 loss_test: 1.2083 acc_test: 0.6730 time: 0.2657s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9538 acc_val: 0.4367 loss_test: 1.2690 acc_test: 0.6800 time: 0.2457s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9879 acc_val: 0.4667 loss_test: 1.3078 acc_test: 0.6840 time: 0.2570s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0280 acc_val: 0.4800 loss_test: 1.3426 acc_test: 0.6920 time: 0.2574s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0409 acc_val: 0.5000 loss_test: 1.3727 acc_test: 0.6940 time: 0.2572s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0859 acc_val: 0.5067 loss_test: 1.4049 acc_test: 0.6950 time: 0.2642s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0875 acc_val: 0.5133 loss_test: 1.4254 acc_test: 0.6960 time: 0.2620s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1366 acc_val: 0.5133 loss_test: 1.4515 acc_test: 0.6950 time: 0.2664s
Optimization Finished!
Total time elapsed: 131.8996s, best testing performance  0.701000, minimun loss  0.962651
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7836 acc_train: 0.2417 loss_val: 1.8375 acc_val: 0.1767 loss_test: 1.6565 acc_test: 0.5240 time: 0.3803s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.8501 acc_val: 0.3867 loss_test: 1.1876 acc_test: 0.6650 time: 0.2521s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9156 acc_val: 0.4000 loss_test: 1.2120 acc_test: 0.6810 time: 0.2573s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9660 acc_val: 0.4200 loss_test: 1.2555 acc_test: 0.6870 time: 0.2746s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0152 acc_val: 0.4433 loss_test: 1.2932 acc_test: 0.6910 time: 0.2579s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0464 acc_val: 0.4600 loss_test: 1.3287 acc_test: 0.6900 time: 0.2752s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0536 acc_val: 0.4833 loss_test: 1.3545 acc_test: 0.6920 time: 0.2718s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0850 acc_val: 0.4933 loss_test: 1.3854 acc_test: 0.6890 time: 0.2778s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0766 acc_val: 0.5000 loss_test: 1.4027 acc_test: 0.6920 time: 0.2700s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1273 acc_val: 0.5033 loss_test: 1.4338 acc_test: 0.6920 time: 0.2709s
Optimization Finished!
Total time elapsed: 132.9193s, best testing performance  0.698000, minimun loss  0.965084
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7790 acc_train: 0.2333 loss_val: 1.8220 acc_val: 0.0633 loss_test: 1.6535 acc_test: 0.4260 time: 0.3475s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8572 acc_val: 0.3700 loss_test: 1.1845 acc_test: 0.6530 time: 0.2679s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8236 acc_val: 0.4100 loss_test: 1.1842 acc_test: 0.6740 time: 0.2854s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8823 acc_val: 0.4267 loss_test: 1.2339 acc_test: 0.6830 time: 0.2571s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9750 acc_val: 0.4567 loss_test: 1.2888 acc_test: 0.6860 time: 0.2582s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0078 acc_val: 0.4667 loss_test: 1.3313 acc_test: 0.6920 time: 0.2563s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0671 acc_val: 0.4667 loss_test: 1.3783 acc_test: 0.6950 time: 0.2728s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1149 acc_val: 0.4833 loss_test: 1.4225 acc_test: 0.6990 time: 0.2747s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1451 acc_val: 0.5033 loss_test: 1.4629 acc_test: 0.7010 time: 0.2682s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2136 acc_val: 0.5067 loss_test: 1.5064 acc_test: 0.6990 time: 0.2631s
Optimization Finished!
Total time elapsed: 131.8021s, best testing performance  0.703000, minimun loss  0.948773
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8047 acc_train: 0.1417 loss_val: 1.8135 acc_val: 0.2133 loss_test: 1.6801 acc_test: 0.5260 time: 0.3613s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7521 acc_val: 0.3867 loss_test: 1.1654 acc_test: 0.6580 time: 0.2584s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8801 acc_val: 0.4233 loss_test: 1.2114 acc_test: 0.6750 time: 0.2655s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9822 acc_val: 0.4300 loss_test: 1.2619 acc_test: 0.6810 time: 0.2605s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0229 acc_val: 0.4500 loss_test: 1.3041 acc_test: 0.6850 time: 0.2714s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0505 acc_val: 0.4633 loss_test: 1.3445 acc_test: 0.6900 time: 0.2713s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1081 acc_val: 0.4833 loss_test: 1.3876 acc_test: 0.6920 time: 0.2685s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1652 acc_val: 0.4833 loss_test: 1.4275 acc_test: 0.6950 time: 0.2941s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1862 acc_val: 0.4800 loss_test: 1.4581 acc_test: 0.6930 time: 0.2684s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2492 acc_val: 0.4867 loss_test: 1.4955 acc_test: 0.6960 time: 0.2868s
Optimization Finished!
Total time elapsed: 133.6850s, best testing performance  0.698000, minimun loss  0.980936
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8027 acc_train: 0.1500 loss_val: 1.8232 acc_val: 0.1767 loss_test: 1.6756 acc_test: 0.5170 time: 0.3308s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.6288 acc_val: 0.4367 loss_test: 1.1229 acc_test: 0.6780 time: 0.2783s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8232 acc_val: 0.4500 loss_test: 1.1937 acc_test: 0.6840 time: 0.2573s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9341 acc_val: 0.4533 loss_test: 1.2487 acc_test: 0.6840 time: 0.2574s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0033 acc_val: 0.4633 loss_test: 1.2949 acc_test: 0.6840 time: 0.2599s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0660 acc_val: 0.4833 loss_test: 1.3381 acc_test: 0.6870 time: 0.2563s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0768 acc_val: 0.4867 loss_test: 1.3709 acc_test: 0.6940 time: 0.2695s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1376 acc_val: 0.4900 loss_test: 1.4082 acc_test: 0.6950 time: 0.2606s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1732 acc_val: 0.4967 loss_test: 1.4396 acc_test: 0.6940 time: 0.2815s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1981 acc_val: 0.5033 loss_test: 1.4641 acc_test: 0.6990 time: 0.2742s
Optimization Finished!
Total time elapsed: 134.0448s, best testing performance  0.702000, minimun loss  0.979897
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7937 acc_train: 0.1083 loss_val: 1.7883 acc_val: 0.1967 loss_test: 1.6777 acc_test: 0.5270 time: 0.3859s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.7966 acc_val: 0.3767 loss_test: 1.1523 acc_test: 0.6620 time: 0.2669s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8646 acc_val: 0.4200 loss_test: 1.1857 acc_test: 0.6780 time: 0.2527s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8971 acc_val: 0.4400 loss_test: 1.2268 acc_test: 0.6860 time: 0.2571s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9523 acc_val: 0.4633 loss_test: 1.2701 acc_test: 0.6890 time: 0.2778s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9611 acc_val: 0.4867 loss_test: 1.3053 acc_test: 0.6950 time: 0.2561s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9918 acc_val: 0.5067 loss_test: 1.3421 acc_test: 0.6970 time: 0.2761s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0165 acc_val: 0.5167 loss_test: 1.3753 acc_test: 0.7000 time: 0.2603s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0483 acc_val: 0.5167 loss_test: 1.4074 acc_test: 0.7030 time: 0.2550s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0835 acc_val: 0.5200 loss_test: 1.4400 acc_test: 0.7020 time: 0.2769s
Optimization Finished!
Total time elapsed: 133.1283s, best testing performance  0.705000, minimun loss  0.965686
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7782 acc_train: 0.2750 loss_val: 1.8078 acc_val: 0.2333 loss_test: 1.6796 acc_test: 0.5420 time: 0.3343s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.9198 acc_val: 0.3833 loss_test: 1.1916 acc_test: 0.6680 time: 0.2563s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9092 acc_val: 0.4167 loss_test: 1.2043 acc_test: 0.6770 time: 0.2613s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9339 acc_val: 0.4633 loss_test: 1.2447 acc_test: 0.6860 time: 0.2472s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9684 acc_val: 0.4733 loss_test: 1.2808 acc_test: 0.6860 time: 0.2744s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9679 acc_val: 0.4900 loss_test: 1.3144 acc_test: 0.6880 time: 0.2542s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0424 acc_val: 0.5000 loss_test: 1.3593 acc_test: 0.6940 time: 0.2625s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0567 acc_val: 0.5100 loss_test: 1.3903 acc_test: 0.7000 time: 0.2672s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1229 acc_val: 0.5133 loss_test: 1.4305 acc_test: 0.6980 time: 0.2571s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1853 acc_val: 0.5133 loss_test: 1.4677 acc_test: 0.7030 time: 0.2718s
Optimization Finished!
Total time elapsed: 132.3936s, best testing performance  0.707000, minimun loss  0.976849
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8072 acc_train: 0.1750 loss_val: 1.8060 acc_val: 0.1467 loss_test: 1.6862 acc_test: 0.4960 time: 0.3743s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8535 acc_val: 0.3700 loss_test: 1.2043 acc_test: 0.6580 time: 0.2574s
Epoch: 0101 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8451 acc_val: 0.4233 loss_test: 1.2126 acc_test: 0.6730 time: 0.2548s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9054 acc_val: 0.4433 loss_test: 1.2587 acc_test: 0.6830 time: 0.2592s
Epoch: 0201 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9725 acc_val: 0.4633 loss_test: 1.3022 acc_test: 0.6840 time: 0.3117s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0166 acc_val: 0.4933 loss_test: 1.3416 acc_test: 0.6890 time: 0.2577s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0578 acc_val: 0.5033 loss_test: 1.3772 acc_test: 0.6880 time: 0.2626s
Epoch: 0351 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0935 acc_val: 0.5067 loss_test: 1.4075 acc_test: 0.6940 time: 0.2865s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1439 acc_val: 0.5133 loss_test: 1.4406 acc_test: 0.6920 time: 0.2729s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1866 acc_val: 0.5133 loss_test: 1.4665 acc_test: 0.6940 time: 0.2656s
Optimization Finished!
Total time elapsed: 133.3974s, best testing performance  0.696000, minimun loss  1.001072
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7921 acc_train: 0.1750 loss_val: 1.8130 acc_val: 0.0933 loss_test: 1.6488 acc_test: 0.4310 time: 0.3463s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8853 acc_val: 0.3900 loss_test: 1.1927 acc_test: 0.6640 time: 0.2555s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8966 acc_val: 0.4267 loss_test: 1.2077 acc_test: 0.6810 time: 0.2565s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9777 acc_val: 0.4367 loss_test: 1.2587 acc_test: 0.6840 time: 0.2572s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0415 acc_val: 0.4467 loss_test: 1.3030 acc_test: 0.6810 time: 0.2918s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0722 acc_val: 0.4700 loss_test: 1.3376 acc_test: 0.6880 time: 0.2558s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0876 acc_val: 0.4867 loss_test: 1.3681 acc_test: 0.6870 time: 0.2600s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1179 acc_val: 0.5000 loss_test: 1.3994 acc_test: 0.6920 time: 0.2592s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1567 acc_val: 0.4967 loss_test: 1.4271 acc_test: 0.6950 time: 0.2558s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1950 acc_val: 0.5100 loss_test: 1.4548 acc_test: 0.6960 time: 0.2644s
Optimization Finished!
Total time elapsed: 131.3126s, best testing performance  0.698000, minimun loss  0.985878
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7980 acc_train: 0.1167 loss_val: 1.7955 acc_val: 0.1633 loss_test: 1.6785 acc_test: 0.4980 time: 0.3322s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8363 acc_val: 0.3933 loss_test: 1.1653 acc_test: 0.6680 time: 0.2641s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8526 acc_val: 0.4367 loss_test: 1.1808 acc_test: 0.6820 time: 0.2605s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9101 acc_val: 0.4367 loss_test: 1.2277 acc_test: 0.6890 time: 0.2593s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9767 acc_val: 0.4567 loss_test: 1.2712 acc_test: 0.6910 time: 0.2718s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0218 acc_val: 0.4667 loss_test: 1.3100 acc_test: 0.6900 time: 0.2554s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0624 acc_val: 0.4767 loss_test: 1.3488 acc_test: 0.6900 time: 0.2658s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0746 acc_val: 0.4933 loss_test: 1.3797 acc_test: 0.6950 time: 0.2757s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1270 acc_val: 0.5033 loss_test: 1.4158 acc_test: 0.6970 time: 0.2438s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1587 acc_val: 0.5033 loss_test: 1.4487 acc_test: 0.6980 time: 0.2751s
Optimization Finished!
Total time elapsed: 131.1765s, best testing performance  0.701000, minimun loss  0.969430
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7882 acc_train: 0.2417 loss_val: 1.8173 acc_val: 0.1567 loss_test: 1.6761 acc_test: 0.5120 time: 0.3441s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 2.0074 acc_val: 0.3633 loss_test: 1.2405 acc_test: 0.6520 time: 0.2588s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.9915 acc_val: 0.4100 loss_test: 1.2455 acc_test: 0.6680 time: 0.2662s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 2.0290 acc_val: 0.4367 loss_test: 1.2831 acc_test: 0.6760 time: 0.2818s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0932 acc_val: 0.4567 loss_test: 1.3242 acc_test: 0.6800 time: 0.2501s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.1155 acc_val: 0.4767 loss_test: 1.3543 acc_test: 0.6840 time: 0.2507s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1358 acc_val: 0.4833 loss_test: 1.3854 acc_test: 0.6880 time: 0.2515s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1570 acc_val: 0.4900 loss_test: 1.4141 acc_test: 0.6930 time: 0.2671s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1985 acc_val: 0.4967 loss_test: 1.4455 acc_test: 0.6910 time: 0.2570s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2057 acc_val: 0.5033 loss_test: 1.4685 acc_test: 0.6920 time: 0.2542s
Optimization Finished!
Total time elapsed: 130.2369s, best testing performance  0.698000, minimun loss  1.009950
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8078 acc_train: 0.1167 loss_val: 1.8185 acc_val: 0.0933 loss_test: 1.6758 acc_test: 0.4180 time: 0.3590s
Epoch: 0051 loss_train: 0.0125 acc_train: 1.0000 loss_val: 1.8712 acc_val: 0.3933 loss_test: 1.1809 acc_test: 0.6610 time: 0.2526s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.9251 acc_val: 0.4200 loss_test: 1.2088 acc_test: 0.6730 time: 0.2535s
Epoch: 0151 loss_train: 0.0071 acc_train: 1.0000 loss_val: 1.9982 acc_val: 0.4333 loss_test: 1.2566 acc_test: 0.6820 time: 0.2541s
Epoch: 0201 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0500 acc_val: 0.4500 loss_test: 1.2983 acc_test: 0.6850 time: 0.2519s
Epoch: 0251 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0744 acc_val: 0.4633 loss_test: 1.3357 acc_test: 0.6860 time: 0.2624s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0969 acc_val: 0.4867 loss_test: 1.3691 acc_test: 0.6870 time: 0.2618s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1362 acc_val: 0.4967 loss_test: 1.4073 acc_test: 0.6920 time: 0.2530s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1767 acc_val: 0.5033 loss_test: 1.4413 acc_test: 0.6930 time: 0.2636s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2231 acc_val: 0.5100 loss_test: 1.4741 acc_test: 0.6930 time: 0.2827s
Optimization Finished!
Total time elapsed: 130.6997s, best testing performance  0.695000, minimun loss  0.978930
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7843 acc_train: 0.2333 loss_val: 1.8429 acc_val: 0.0900 loss_test: 1.6654 acc_test: 0.4590 time: 0.3746s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.9451 acc_val: 0.3667 loss_test: 1.2271 acc_test: 0.6530 time: 0.2527s
Epoch: 0101 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.8921 acc_val: 0.4133 loss_test: 1.2176 acc_test: 0.6770 time: 0.2615s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9212 acc_val: 0.4500 loss_test: 1.2563 acc_test: 0.6840 time: 0.2544s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9643 acc_val: 0.4633 loss_test: 1.2981 acc_test: 0.6880 time: 0.2645s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0021 acc_val: 0.4733 loss_test: 1.3391 acc_test: 0.6920 time: 0.2576s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0328 acc_val: 0.4900 loss_test: 1.3726 acc_test: 0.6950 time: 0.2592s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0668 acc_val: 0.5067 loss_test: 1.4048 acc_test: 0.6950 time: 0.2599s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1031 acc_val: 0.5167 loss_test: 1.4369 acc_test: 0.7040 time: 0.2727s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1412 acc_val: 0.5133 loss_test: 1.4669 acc_test: 0.7060 time: 0.2714s
Optimization Finished!
Total time elapsed: 132.1230s, best testing performance  0.708000, minimun loss  1.004418
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7873 acc_train: 0.2250 loss_val: 1.8213 acc_val: 0.0867 loss_test: 1.6663 acc_test: 0.3960 time: 0.3369s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7817 acc_val: 0.4033 loss_test: 1.1887 acc_test: 0.6660 time: 0.2476s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8836 acc_val: 0.4133 loss_test: 1.2403 acc_test: 0.6810 time: 0.2533s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9521 acc_val: 0.4333 loss_test: 1.2901 acc_test: 0.6890 time: 0.2539s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0245 acc_val: 0.4533 loss_test: 1.3371 acc_test: 0.6860 time: 0.2604s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0486 acc_val: 0.4700 loss_test: 1.3685 acc_test: 0.6880 time: 0.2587s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0774 acc_val: 0.4833 loss_test: 1.3988 acc_test: 0.6900 time: 0.2604s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1289 acc_val: 0.4867 loss_test: 1.4242 acc_test: 0.6900 time: 0.2827s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1430 acc_val: 0.4900 loss_test: 1.4419 acc_test: 0.6910 time: 0.2661s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1874 acc_val: 0.5000 loss_test: 1.4692 acc_test: 0.6940 time: 0.2601s
Optimization Finished!
Total time elapsed: 133.1184s, best testing performance  0.698000, minimun loss  0.979211
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1417 loss_val: 1.8187 acc_val: 0.1367 loss_test: 1.6698 acc_test: 0.5140 time: 0.3636s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6590 acc_val: 0.4100 loss_test: 1.1345 acc_test: 0.6770 time: 0.2636s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7579 acc_val: 0.4400 loss_test: 1.1766 acc_test: 0.6920 time: 0.2587s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9195 acc_val: 0.4467 loss_test: 1.2686 acc_test: 0.6920 time: 0.2789s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0118 acc_val: 0.4533 loss_test: 1.3197 acc_test: 0.6960 time: 0.2883s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0611 acc_val: 0.4800 loss_test: 1.3549 acc_test: 0.6950 time: 0.2724s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0893 acc_val: 0.4867 loss_test: 1.3860 acc_test: 0.6930 time: 0.2700s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1488 acc_val: 0.4967 loss_test: 1.4185 acc_test: 0.6910 time: 0.2798s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1497 acc_val: 0.5067 loss_test: 1.4386 acc_test: 0.6990 time: 0.2632s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2165 acc_val: 0.5100 loss_test: 1.4711 acc_test: 0.6950 time: 0.2623s
Optimization Finished!
Total time elapsed: 133.4756s, best testing performance  0.699000, minimun loss  0.965409
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7733 acc_train: 0.2583 loss_val: 1.8142 acc_val: 0.1867 loss_test: 1.6490 acc_test: 0.5270 time: 0.3256s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7087 acc_val: 0.4000 loss_test: 1.1728 acc_test: 0.6750 time: 0.2511s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7393 acc_val: 0.4467 loss_test: 1.1968 acc_test: 0.6880 time: 0.2609s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9124 acc_val: 0.4667 loss_test: 1.2840 acc_test: 0.6920 time: 0.2452s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9579 acc_val: 0.4733 loss_test: 1.3184 acc_test: 0.6920 time: 0.2479s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9692 acc_val: 0.4900 loss_test: 1.3505 acc_test: 0.6910 time: 0.2506s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0158 acc_val: 0.5000 loss_test: 1.3854 acc_test: 0.6950 time: 0.2650s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0379 acc_val: 0.5000 loss_test: 1.4135 acc_test: 0.6940 time: 0.2670s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1121 acc_val: 0.4933 loss_test: 1.4506 acc_test: 0.6950 time: 0.2706s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1321 acc_val: 0.5033 loss_test: 1.4736 acc_test: 0.6970 time: 0.2669s
Optimization Finished!
Total time elapsed: 132.7939s, best testing performance  0.700000, minimun loss  0.962861
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7796 acc_train: 0.2083 loss_val: 1.8037 acc_val: 0.2000 loss_test: 1.6434 acc_test: 0.5400 time: 0.3251s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7789 acc_val: 0.4067 loss_test: 1.1990 acc_test: 0.6800 time: 0.2645s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.7331 acc_val: 0.4567 loss_test: 1.2095 acc_test: 0.6900 time: 0.2544s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8691 acc_val: 0.4633 loss_test: 1.2845 acc_test: 0.6910 time: 0.2609s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9493 acc_val: 0.4900 loss_test: 1.3242 acc_test: 0.6940 time: 0.2586s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0038 acc_val: 0.4933 loss_test: 1.3583 acc_test: 0.6940 time: 0.2719s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0737 acc_val: 0.4933 loss_test: 1.4003 acc_test: 0.6930 time: 0.2641s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1169 acc_val: 0.4933 loss_test: 1.4301 acc_test: 0.6950 time: 0.2794s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2010 acc_val: 0.5067 loss_test: 1.4716 acc_test: 0.6980 time: 0.2804s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2172 acc_val: 0.5067 loss_test: 1.4953 acc_test: 0.6990 time: 0.2754s
Optimization Finished!
Total time elapsed: 132.9709s, best testing performance  0.701000, minimun loss  0.977377
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 40, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.2250 loss_val: 1.7983 acc_val: 0.1267 loss_test: 1.6565 acc_test: 0.4850 time: 0.2977s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7660 acc_val: 0.4100 loss_test: 1.1950 acc_test: 0.6790 time: 0.2479s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7867 acc_val: 0.4333 loss_test: 1.2129 acc_test: 0.6850 time: 0.2488s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9299 acc_val: 0.4733 loss_test: 1.2952 acc_test: 0.6860 time: 0.2526s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0395 acc_val: 0.4733 loss_test: 1.3453 acc_test: 0.6830 time: 0.2469s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0984 acc_val: 0.4833 loss_test: 1.3795 acc_test: 0.6900 time: 0.2542s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.4933 loss_test: 1.4071 acc_test: 0.6870 time: 0.2732s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1409 acc_val: 0.4967 loss_test: 1.4287 acc_test: 0.6870 time: 0.2822s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1401 acc_val: 0.4933 loss_test: 1.4450 acc_test: 0.6930 time: 0.2708s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1670 acc_val: 0.5100 loss_test: 1.4646 acc_test: 0.6950 time: 0.2564s
Optimization Finished!
Total time elapsed: 133.0225s, best testing performance  0.699000, minimun loss  0.973621
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7951 acc_train: 0.1417 loss_val: 1.8376 acc_val: 0.1400 loss_test: 1.6582 acc_test: 0.4910 time: 0.3875s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9385 acc_val: 0.3667 loss_test: 1.2170 acc_test: 0.6600 time: 0.3203s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8896 acc_val: 0.4167 loss_test: 1.2100 acc_test: 0.6740 time: 0.2895s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9414 acc_val: 0.4533 loss_test: 1.2633 acc_test: 0.6840 time: 0.2973s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9904 acc_val: 0.4833 loss_test: 1.3132 acc_test: 0.6880 time: 0.2884s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0433 acc_val: 0.4900 loss_test: 1.3578 acc_test: 0.6920 time: 0.3080s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0663 acc_val: 0.5033 loss_test: 1.3937 acc_test: 0.6930 time: 0.3027s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.5133 loss_test: 1.4256 acc_test: 0.6990 time: 0.3363s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1191 acc_val: 0.5167 loss_test: 1.4636 acc_test: 0.7000 time: 0.3024s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1453 acc_val: 0.5133 loss_test: 1.4907 acc_test: 0.7010 time: 0.2927s
Optimization Finished!
Total time elapsed: 150.1720s, best testing performance  0.703000, minimun loss  1.000296
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7869 acc_train: 0.1750 loss_val: 1.8268 acc_val: 0.1267 loss_test: 1.6616 acc_test: 0.4520 time: 0.3640s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 2.0492 acc_val: 0.3367 loss_test: 1.2320 acc_test: 0.6520 time: 0.2875s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9328 acc_val: 0.4000 loss_test: 1.2128 acc_test: 0.6690 time: 0.2898s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9868 acc_val: 0.4333 loss_test: 1.2754 acc_test: 0.6840 time: 0.2812s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0098 acc_val: 0.4600 loss_test: 1.3183 acc_test: 0.6860 time: 0.3005s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0151 acc_val: 0.4800 loss_test: 1.3547 acc_test: 0.6950 time: 0.3052s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0739 acc_val: 0.5067 loss_test: 1.4042 acc_test: 0.6980 time: 0.3174s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0933 acc_val: 0.5067 loss_test: 1.4401 acc_test: 0.6980 time: 0.3103s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1329 acc_val: 0.5133 loss_test: 1.4784 acc_test: 0.6970 time: 0.3152s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1943 acc_val: 0.5100 loss_test: 1.5195 acc_test: 0.6960 time: 0.3141s
Optimization Finished!
Total time elapsed: 149.7068s, best testing performance  0.699000, minimun loss  0.988237
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7766 acc_train: 0.2667 loss_val: 1.8110 acc_val: 0.1300 loss_test: 1.6639 acc_test: 0.4770 time: 0.3498s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.9708 acc_val: 0.3533 loss_test: 1.1987 acc_test: 0.6540 time: 0.3059s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8942 acc_val: 0.4067 loss_test: 1.2010 acc_test: 0.6690 time: 0.3012s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9875 acc_val: 0.4233 loss_test: 1.2693 acc_test: 0.6770 time: 0.2930s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0547 acc_val: 0.4567 loss_test: 1.3157 acc_test: 0.6860 time: 0.3030s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1329 acc_val: 0.4567 loss_test: 1.3654 acc_test: 0.6890 time: 0.3213s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1448 acc_val: 0.4733 loss_test: 1.3895 acc_test: 0.6910 time: 0.3239s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1802 acc_val: 0.4867 loss_test: 1.4232 acc_test: 0.6910 time: 0.2981s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2160 acc_val: 0.4867 loss_test: 1.4523 acc_test: 0.6920 time: 0.2914s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2495 acc_val: 0.4933 loss_test: 1.4758 acc_test: 0.6940 time: 0.3120s
Optimization Finished!
Total time elapsed: 150.2110s, best testing performance  0.695000, minimun loss  0.963730
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8051 acc_train: 0.1250 loss_val: 1.8123 acc_val: 0.1667 loss_test: 1.6664 acc_test: 0.4780 time: 0.3743s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 2.0717 acc_val: 0.3600 loss_test: 1.2476 acc_test: 0.6570 time: 0.2897s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 2.0177 acc_val: 0.4000 loss_test: 1.2371 acc_test: 0.6650 time: 0.3146s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0452 acc_val: 0.4333 loss_test: 1.2760 acc_test: 0.6790 time: 0.2920s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0730 acc_val: 0.4567 loss_test: 1.3166 acc_test: 0.6850 time: 0.2835s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1059 acc_val: 0.4767 loss_test: 1.3554 acc_test: 0.6940 time: 0.2829s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1609 acc_val: 0.4967 loss_test: 1.3984 acc_test: 0.6910 time: 0.3163s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1670 acc_val: 0.5067 loss_test: 1.4231 acc_test: 0.6930 time: 0.3272s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2008 acc_val: 0.5067 loss_test: 1.4523 acc_test: 0.6930 time: 0.3130s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2574 acc_val: 0.5100 loss_test: 1.4838 acc_test: 0.6950 time: 0.2971s
Optimization Finished!
Total time elapsed: 149.4024s, best testing performance  0.696000, minimun loss  1.011325
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8136 acc_train: 0.1500 loss_val: 1.8186 acc_val: 0.1100 loss_test: 1.6843 acc_test: 0.4740 time: 0.3649s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 2.0203 acc_val: 0.3433 loss_test: 1.2481 acc_test: 0.6580 time: 0.2916s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9178 acc_val: 0.4033 loss_test: 1.2251 acc_test: 0.6670 time: 0.3148s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9851 acc_val: 0.4400 loss_test: 1.2812 acc_test: 0.6820 time: 0.3131s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0008 acc_val: 0.4667 loss_test: 1.3192 acc_test: 0.6900 time: 0.2944s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0492 acc_val: 0.4867 loss_test: 1.3597 acc_test: 0.6940 time: 0.2909s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0439 acc_val: 0.4967 loss_test: 1.3844 acc_test: 0.6970 time: 0.2969s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0615 acc_val: 0.5167 loss_test: 1.4095 acc_test: 0.6980 time: 0.3073s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1093 acc_val: 0.5033 loss_test: 1.4449 acc_test: 0.7000 time: 0.3000s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1164 acc_val: 0.5067 loss_test: 1.4630 acc_test: 0.6960 time: 0.2778s
Optimization Finished!
Total time elapsed: 149.9666s, best testing performance  0.703000, minimun loss  1.017357
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7692 acc_train: 0.3333 loss_val: 1.8114 acc_val: 0.1533 loss_test: 1.6588 acc_test: 0.4900 time: 0.3541s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.8896 acc_val: 0.3933 loss_test: 1.1872 acc_test: 0.6630 time: 0.2911s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8278 acc_val: 0.4300 loss_test: 1.1810 acc_test: 0.6810 time: 0.2978s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9035 acc_val: 0.4600 loss_test: 1.2367 acc_test: 0.6890 time: 0.2843s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9550 acc_val: 0.4767 loss_test: 1.2858 acc_test: 0.6860 time: 0.3246s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9897 acc_val: 0.4700 loss_test: 1.3243 acc_test: 0.6930 time: 0.2873s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0343 acc_val: 0.4933 loss_test: 1.3660 acc_test: 0.6920 time: 0.3024s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0410 acc_val: 0.5133 loss_test: 1.3952 acc_test: 0.6930 time: 0.3044s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0521 acc_val: 0.5167 loss_test: 1.4227 acc_test: 0.6920 time: 0.2935s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0577 acc_val: 0.5067 loss_test: 1.4389 acc_test: 0.6930 time: 0.3011s
Optimization Finished!
Total time elapsed: 149.5621s, best testing performance  0.697000, minimun loss  0.983495
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7784 acc_train: 0.2167 loss_val: 1.8147 acc_val: 0.2133 loss_test: 1.6613 acc_test: 0.4240 time: 0.3526s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 2.0530 acc_val: 0.3500 loss_test: 1.2321 acc_test: 0.6540 time: 0.2869s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 2.0404 acc_val: 0.4200 loss_test: 1.2309 acc_test: 0.6730 time: 0.2706s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 2.1093 acc_val: 0.4333 loss_test: 1.2811 acc_test: 0.6840 time: 0.2900s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.1208 acc_val: 0.4633 loss_test: 1.3180 acc_test: 0.6900 time: 0.2940s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1464 acc_val: 0.4767 loss_test: 1.3576 acc_test: 0.6920 time: 0.2929s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1647 acc_val: 0.4967 loss_test: 1.3938 acc_test: 0.6950 time: 0.3176s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1755 acc_val: 0.5100 loss_test: 1.4227 acc_test: 0.6940 time: 0.3115s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1932 acc_val: 0.5100 loss_test: 1.4484 acc_test: 0.7000 time: 0.2921s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2159 acc_val: 0.5067 loss_test: 1.4770 acc_test: 0.6970 time: 0.3015s
Optimization Finished!
Total time elapsed: 149.4461s, best testing performance  0.702000, minimun loss  0.995184
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7989 acc_train: 0.1250 loss_val: 1.7945 acc_val: 0.2100 loss_test: 1.6908 acc_test: 0.4890 time: 0.3465s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9975 acc_val: 0.3633 loss_test: 1.2366 acc_test: 0.6650 time: 0.3053s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9748 acc_val: 0.4067 loss_test: 1.2412 acc_test: 0.6650 time: 0.2819s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 2.0090 acc_val: 0.4333 loss_test: 1.2843 acc_test: 0.6800 time: 0.2861s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0415 acc_val: 0.4600 loss_test: 1.3239 acc_test: 0.6830 time: 0.2852s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0596 acc_val: 0.4900 loss_test: 1.3588 acc_test: 0.6890 time: 0.2898s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0827 acc_val: 0.5133 loss_test: 1.3933 acc_test: 0.6940 time: 0.3173s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1328 acc_val: 0.5100 loss_test: 1.4308 acc_test: 0.6960 time: 0.3022s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1562 acc_val: 0.5100 loss_test: 1.4601 acc_test: 0.6990 time: 0.2936s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1973 acc_val: 0.5100 loss_test: 1.4889 acc_test: 0.6990 time: 0.2936s
Optimization Finished!
Total time elapsed: 148.4674s, best testing performance  0.701000, minimun loss  1.020697
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7933 acc_train: 0.1667 loss_val: 1.7879 acc_val: 0.1567 loss_test: 1.6774 acc_test: 0.4680 time: 0.3615s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.9906 acc_val: 0.3567 loss_test: 1.2278 acc_test: 0.6520 time: 0.2879s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9621 acc_val: 0.4067 loss_test: 1.2270 acc_test: 0.6640 time: 0.2911s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9832 acc_val: 0.4333 loss_test: 1.2647 acc_test: 0.6830 time: 0.3410s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9998 acc_val: 0.4600 loss_test: 1.3029 acc_test: 0.6870 time: 0.2892s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0303 acc_val: 0.4800 loss_test: 1.3415 acc_test: 0.6940 time: 0.2993s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0669 acc_val: 0.4900 loss_test: 1.3822 acc_test: 0.6950 time: 0.3253s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1118 acc_val: 0.4867 loss_test: 1.4193 acc_test: 0.6960 time: 0.3059s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1567 acc_val: 0.5000 loss_test: 1.4551 acc_test: 0.7030 time: 0.2955s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1918 acc_val: 0.5033 loss_test: 1.4861 acc_test: 0.7040 time: 0.3122s
Optimization Finished!
Total time elapsed: 150.6830s, best testing performance  0.708000, minimun loss  0.997511
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7816 acc_train: 0.1917 loss_val: 1.8221 acc_val: 0.1167 loss_test: 1.6588 acc_test: 0.4810 time: 0.3711s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 2.0683 acc_val: 0.3533 loss_test: 1.2584 acc_test: 0.6480 time: 0.2922s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9343 acc_val: 0.4167 loss_test: 1.2129 acc_test: 0.6740 time: 0.2964s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9687 acc_val: 0.4433 loss_test: 1.2528 acc_test: 0.6900 time: 0.3029s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0057 acc_val: 0.4667 loss_test: 1.2952 acc_test: 0.6870 time: 0.2870s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0308 acc_val: 0.4800 loss_test: 1.3328 acc_test: 0.6920 time: 0.3117s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0411 acc_val: 0.4933 loss_test: 1.3654 acc_test: 0.6950 time: 0.3141s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0662 acc_val: 0.5100 loss_test: 1.3993 acc_test: 0.6980 time: 0.3019s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0909 acc_val: 0.5100 loss_test: 1.4294 acc_test: 0.6990 time: 0.3112s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0985 acc_val: 0.5200 loss_test: 1.4555 acc_test: 0.6950 time: 0.2814s
Optimization Finished!
Total time elapsed: 148.0854s, best testing performance  0.701000, minimun loss  0.993918
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8088 acc_train: 0.1500 loss_val: 1.8068 acc_val: 0.1900 loss_test: 1.6640 acc_test: 0.5580 time: 0.3876s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7009 acc_val: 0.4267 loss_test: 1.1191 acc_test: 0.6740 time: 0.2837s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8129 acc_val: 0.4533 loss_test: 1.1868 acc_test: 0.6860 time: 0.2866s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9815 acc_val: 0.4433 loss_test: 1.2726 acc_test: 0.6870 time: 0.2924s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0198 acc_val: 0.4667 loss_test: 1.3100 acc_test: 0.6940 time: 0.2888s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0530 acc_val: 0.4800 loss_test: 1.3417 acc_test: 0.6940 time: 0.2877s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0719 acc_val: 0.4967 loss_test: 1.3762 acc_test: 0.6960 time: 0.2902s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0897 acc_val: 0.5033 loss_test: 1.4076 acc_test: 0.7000 time: 0.3176s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1130 acc_val: 0.5133 loss_test: 1.4320 acc_test: 0.6970 time: 0.2988s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1277 acc_val: 0.5100 loss_test: 1.4552 acc_test: 0.7000 time: 0.2972s
Optimization Finished!
Total time elapsed: 149.7708s, best testing performance  0.703000, minimun loss  0.957281
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7948 acc_train: 0.1583 loss_val: 1.8444 acc_val: 0.1767 loss_test: 1.6655 acc_test: 0.5010 time: 0.3618s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.9560 acc_val: 0.3633 loss_test: 1.2143 acc_test: 0.6630 time: 0.2894s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9891 acc_val: 0.3967 loss_test: 1.2440 acc_test: 0.6740 time: 0.2764s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0863 acc_val: 0.4233 loss_test: 1.3096 acc_test: 0.6810 time: 0.2871s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0887 acc_val: 0.4567 loss_test: 1.3434 acc_test: 0.6870 time: 0.2770s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1195 acc_val: 0.4767 loss_test: 1.3764 acc_test: 0.6890 time: 0.2921s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1176 acc_val: 0.4900 loss_test: 1.4015 acc_test: 0.6960 time: 0.2892s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1312 acc_val: 0.5000 loss_test: 1.4244 acc_test: 0.6960 time: 0.3035s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1458 acc_val: 0.5100 loss_test: 1.4516 acc_test: 0.6960 time: 0.3267s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1823 acc_val: 0.5067 loss_test: 1.4748 acc_test: 0.6940 time: 0.2959s
Optimization Finished!
Total time elapsed: 149.4225s, best testing performance  0.700000, minimun loss  0.976296
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7913 acc_train: 0.1667 loss_val: 1.8164 acc_val: 0.1567 loss_test: 1.6616 acc_test: 0.5390 time: 0.3474s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8272 acc_val: 0.3800 loss_test: 1.1641 acc_test: 0.6660 time: 0.2875s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.9203 acc_val: 0.4000 loss_test: 1.2258 acc_test: 0.6750 time: 0.2877s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.0561 acc_val: 0.4400 loss_test: 1.3034 acc_test: 0.6740 time: 0.2852s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0805 acc_val: 0.4633 loss_test: 1.3345 acc_test: 0.6840 time: 0.2781s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0974 acc_val: 0.4733 loss_test: 1.3686 acc_test: 0.6900 time: 0.2824s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1036 acc_val: 0.4833 loss_test: 1.3969 acc_test: 0.6920 time: 0.2944s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1215 acc_val: 0.4933 loss_test: 1.4228 acc_test: 0.6970 time: 0.3041s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1701 acc_val: 0.5033 loss_test: 1.4580 acc_test: 0.6960 time: 0.2957s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2003 acc_val: 0.5100 loss_test: 1.4845 acc_test: 0.6970 time: 0.2943s
Optimization Finished!
Total time elapsed: 149.2983s, best testing performance  0.701000, minimun loss  0.973356
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1917 loss_val: 1.8008 acc_val: 0.2100 loss_test: 1.6639 acc_test: 0.5560 time: 0.4154s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.9264 acc_val: 0.3667 loss_test: 1.2109 acc_test: 0.6600 time: 0.2931s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9159 acc_val: 0.4033 loss_test: 1.2232 acc_test: 0.6740 time: 0.2826s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0316 acc_val: 0.4233 loss_test: 1.2965 acc_test: 0.6760 time: 0.2881s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0909 acc_val: 0.4567 loss_test: 1.3342 acc_test: 0.6840 time: 0.2872s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1315 acc_val: 0.4700 loss_test: 1.3655 acc_test: 0.6930 time: 0.2988s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1112 acc_val: 0.4867 loss_test: 1.3827 acc_test: 0.6940 time: 0.3234s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1582 acc_val: 0.4933 loss_test: 1.4113 acc_test: 0.6900 time: 0.3281s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1757 acc_val: 0.4967 loss_test: 1.4405 acc_test: 0.6900 time: 0.3259s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2255 acc_val: 0.4933 loss_test: 1.4645 acc_test: 0.6900 time: 0.2874s
Optimization Finished!
Total time elapsed: 148.6541s, best testing performance  0.695000, minimun loss  0.955337
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7832 acc_train: 0.1917 loss_val: 1.8030 acc_val: 0.0967 loss_test: 1.6685 acc_test: 0.4560 time: 0.3480s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.6639 acc_val: 0.4067 loss_test: 1.1302 acc_test: 0.6820 time: 0.2837s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8514 acc_val: 0.4167 loss_test: 1.2163 acc_test: 0.6760 time: 0.3054s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0132 acc_val: 0.4333 loss_test: 1.2994 acc_test: 0.6800 time: 0.2861s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0225 acc_val: 0.4767 loss_test: 1.3340 acc_test: 0.6880 time: 0.3112s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0381 acc_val: 0.4833 loss_test: 1.3625 acc_test: 0.6910 time: 0.2843s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0535 acc_val: 0.5100 loss_test: 1.3931 acc_test: 0.6920 time: 0.2958s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0546 acc_val: 0.5133 loss_test: 1.4174 acc_test: 0.6950 time: 0.3240s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0601 acc_val: 0.5133 loss_test: 1.4423 acc_test: 0.6940 time: 0.3465s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0905 acc_val: 0.5033 loss_test: 1.4696 acc_test: 0.6900 time: 0.2896s
Optimization Finished!
Total time elapsed: 149.0912s, best testing performance  0.697000, minimun loss  0.955936
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8005 acc_train: 0.1167 loss_val: 1.8144 acc_val: 0.1367 loss_test: 1.6822 acc_test: 0.4850 time: 0.4050s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7599 acc_val: 0.3800 loss_test: 1.1394 acc_test: 0.6680 time: 0.2910s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8575 acc_val: 0.4000 loss_test: 1.2030 acc_test: 0.6770 time: 0.3082s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0138 acc_val: 0.4267 loss_test: 1.2829 acc_test: 0.6790 time: 0.2773s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0141 acc_val: 0.4633 loss_test: 1.3100 acc_test: 0.6890 time: 0.2865s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0351 acc_val: 0.4733 loss_test: 1.3479 acc_test: 0.6920 time: 0.2902s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0953 acc_val: 0.4867 loss_test: 1.3868 acc_test: 0.6940 time: 0.2908s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1020 acc_val: 0.5067 loss_test: 1.4141 acc_test: 0.6970 time: 0.3050s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1252 acc_val: 0.5067 loss_test: 1.4380 acc_test: 0.6930 time: 0.3122s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1508 acc_val: 0.5100 loss_test: 1.4618 acc_test: 0.6960 time: 0.2964s
Optimization Finished!
Total time elapsed: 150.1188s, best testing performance  0.700000, minimun loss  0.935246
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7924 acc_train: 0.1500 loss_val: 1.8114 acc_val: 0.0667 loss_test: 1.6843 acc_test: 0.3430 time: 0.3510s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6760 acc_val: 0.4167 loss_test: 1.1211 acc_test: 0.6820 time: 0.2820s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.6414 acc_val: 0.4700 loss_test: 1.1289 acc_test: 0.6960 time: 0.3033s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8235 acc_val: 0.4700 loss_test: 1.2316 acc_test: 0.6920 time: 0.2826s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9500 acc_val: 0.4633 loss_test: 1.2998 acc_test: 0.6910 time: 0.3008s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0055 acc_val: 0.4800 loss_test: 1.3389 acc_test: 0.6930 time: 0.3018s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0772 acc_val: 0.4933 loss_test: 1.3768 acc_test: 0.6900 time: 0.3142s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0903 acc_val: 0.4933 loss_test: 1.4003 acc_test: 0.6950 time: 0.3236s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1243 acc_val: 0.5067 loss_test: 1.4265 acc_test: 0.6980 time: 0.2951s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1531 acc_val: 0.5100 loss_test: 1.4534 acc_test: 0.6940 time: 0.3015s
Optimization Finished!
Total time elapsed: 150.1230s, best testing performance  0.702000, minimun loss  0.944817
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7977 acc_train: 0.1500 loss_val: 1.8016 acc_val: 0.0800 loss_test: 1.6652 acc_test: 0.4310 time: 0.3899s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7853 acc_val: 0.3800 loss_test: 1.1740 acc_test: 0.6710 time: 0.2925s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.6753 acc_val: 0.4333 loss_test: 1.1508 acc_test: 0.6890 time: 0.2951s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8669 acc_val: 0.4367 loss_test: 1.2584 acc_test: 0.6840 time: 0.2956s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0260 acc_val: 0.4667 loss_test: 1.3297 acc_test: 0.6860 time: 0.2908s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0564 acc_val: 0.4767 loss_test: 1.3608 acc_test: 0.6930 time: 0.2806s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1043 acc_val: 0.4867 loss_test: 1.3946 acc_test: 0.6920 time: 0.3052s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1383 acc_val: 0.4967 loss_test: 1.4246 acc_test: 0.6960 time: 0.3113s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1794 acc_val: 0.5000 loss_test: 1.4552 acc_test: 0.6960 time: 0.3084s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2163 acc_val: 0.5000 loss_test: 1.4819 acc_test: 0.6970 time: 0.2816s
Optimization Finished!
Total time elapsed: 150.2763s, best testing performance  0.704000, minimun loss  0.950332
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7965 acc_train: 0.1500 loss_val: 1.8050 acc_val: 0.1700 loss_test: 1.6820 acc_test: 0.4960 time: 0.3513s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7007 acc_val: 0.4033 loss_test: 1.1053 acc_test: 0.6760 time: 0.3098s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.6938 acc_val: 0.4300 loss_test: 1.1375 acc_test: 0.6920 time: 0.3086s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8653 acc_val: 0.4333 loss_test: 1.2341 acc_test: 0.6860 time: 0.2845s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9949 acc_val: 0.4633 loss_test: 1.2988 acc_test: 0.6860 time: 0.2927s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0598 acc_val: 0.4733 loss_test: 1.3454 acc_test: 0.6940 time: 0.2769s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1318 acc_val: 0.4867 loss_test: 1.3904 acc_test: 0.6900 time: 0.2915s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1311 acc_val: 0.5067 loss_test: 1.4166 acc_test: 0.6960 time: 0.3057s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1791 acc_val: 0.5033 loss_test: 1.4514 acc_test: 0.6940 time: 0.3036s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2328 acc_val: 0.5067 loss_test: 1.4823 acc_test: 0.6970 time: 0.3081s
Optimization Finished!
Total time elapsed: 149.7356s, best testing performance  0.700000, minimun loss  0.932932
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7712 acc_train: 0.2833 loss_val: 1.8169 acc_val: 0.0967 loss_test: 1.6598 acc_test: 0.4440 time: 0.3264s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7404 acc_val: 0.3833 loss_test: 1.1182 acc_test: 0.6800 time: 0.3040s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7923 acc_val: 0.4200 loss_test: 1.1725 acc_test: 0.6820 time: 0.2801s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9427 acc_val: 0.4367 loss_test: 1.2554 acc_test: 0.6850 time: 0.2728s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0245 acc_val: 0.4567 loss_test: 1.3075 acc_test: 0.6840 time: 0.3052s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0721 acc_val: 0.4767 loss_test: 1.3477 acc_test: 0.6890 time: 0.2925s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1129 acc_val: 0.4900 loss_test: 1.3812 acc_test: 0.6920 time: 0.3003s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1439 acc_val: 0.4867 loss_test: 1.4131 acc_test: 0.6940 time: 0.3099s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1678 acc_val: 0.4933 loss_test: 1.4348 acc_test: 0.6990 time: 0.2972s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2247 acc_val: 0.5000 loss_test: 1.4637 acc_test: 0.7000 time: 0.2913s
Optimization Finished!
Total time elapsed: 148.5967s, best testing performance  0.706000, minimun loss  0.928969
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7799 acc_train: 0.1833 loss_val: 1.8227 acc_val: 0.1367 loss_test: 1.6433 acc_test: 0.5100 time: 0.3678s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7280 acc_val: 0.4133 loss_test: 1.1435 acc_test: 0.6790 time: 0.2916s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9027 acc_val: 0.4200 loss_test: 1.2245 acc_test: 0.6830 time: 0.2888s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0300 acc_val: 0.4400 loss_test: 1.3003 acc_test: 0.6850 time: 0.3135s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0614 acc_val: 0.4667 loss_test: 1.3424 acc_test: 0.6860 time: 0.2918s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0980 acc_val: 0.4733 loss_test: 1.3824 acc_test: 0.6890 time: 0.2846s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1173 acc_val: 0.4933 loss_test: 1.4106 acc_test: 0.6930 time: 0.3405s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1698 acc_val: 0.4967 loss_test: 1.4464 acc_test: 0.6950 time: 0.2925s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2016 acc_val: 0.5033 loss_test: 1.4766 acc_test: 0.6970 time: 0.2889s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2260 acc_val: 0.5067 loss_test: 1.4981 acc_test: 0.6970 time: 0.2951s
Optimization Finished!
Total time elapsed: 148.5544s, best testing performance  0.699000, minimun loss  0.961420
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7772 acc_train: 0.2667 loss_val: 1.8020 acc_val: 0.2033 loss_test: 1.6531 acc_test: 0.5510 time: 0.4013s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.6082 acc_val: 0.4333 loss_test: 1.0767 acc_test: 0.6900 time: 0.2862s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7625 acc_val: 0.4600 loss_test: 1.1515 acc_test: 0.6940 time: 0.3024s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9232 acc_val: 0.4733 loss_test: 1.2429 acc_test: 0.6950 time: 0.3236s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9714 acc_val: 0.4767 loss_test: 1.2918 acc_test: 0.6930 time: 0.2853s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0188 acc_val: 0.4833 loss_test: 1.3351 acc_test: 0.6950 time: 0.2915s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0823 acc_val: 0.4900 loss_test: 1.3874 acc_test: 0.6950 time: 0.3488s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1261 acc_val: 0.5100 loss_test: 1.4257 acc_test: 0.6980 time: 0.3070s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2075 acc_val: 0.5000 loss_test: 1.4749 acc_test: 0.6990 time: 0.3042s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2731 acc_val: 0.4967 loss_test: 1.5159 acc_test: 0.6990 time: 0.3378s
Optimization Finished!
Total time elapsed: 149.3913s, best testing performance  0.702000, minimun loss  0.936822
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8141 acc_train: 0.1000 loss_val: 1.8016 acc_val: 0.1800 loss_test: 1.6671 acc_test: 0.5150 time: 0.3548s
Epoch: 0051 loss_train: 0.0115 acc_train: 1.0000 loss_val: 1.6128 acc_val: 0.4100 loss_test: 1.0895 acc_test: 0.6730 time: 0.2889s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7481 acc_val: 0.4267 loss_test: 1.1552 acc_test: 0.6880 time: 0.2877s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9327 acc_val: 0.4367 loss_test: 1.2614 acc_test: 0.6840 time: 0.3001s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0023 acc_val: 0.4633 loss_test: 1.3109 acc_test: 0.6860 time: 0.2880s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0205 acc_val: 0.4700 loss_test: 1.3395 acc_test: 0.6890 time: 0.2872s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0564 acc_val: 0.4933 loss_test: 1.3773 acc_test: 0.6930 time: 0.2934s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1188 acc_val: 0.5033 loss_test: 1.4154 acc_test: 0.6920 time: 0.2938s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1162 acc_val: 0.5033 loss_test: 1.4377 acc_test: 0.6910 time: 0.3125s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1377 acc_val: 0.5033 loss_test: 1.4626 acc_test: 0.6910 time: 0.2966s
Optimization Finished!
Total time elapsed: 149.4741s, best testing performance  0.696000, minimun loss  0.952789
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7839 acc_train: 0.2167 loss_val: 1.8089 acc_val: 0.1367 loss_test: 1.6613 acc_test: 0.5300 time: 0.3612s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.6390 acc_val: 0.4067 loss_test: 1.1112 acc_test: 0.6810 time: 0.3003s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7246 acc_val: 0.4567 loss_test: 1.1576 acc_test: 0.6880 time: 0.2919s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9188 acc_val: 0.4633 loss_test: 1.2536 acc_test: 0.6870 time: 0.2874s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9993 acc_val: 0.4733 loss_test: 1.3015 acc_test: 0.6900 time: 0.2932s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0729 acc_val: 0.4833 loss_test: 1.3478 acc_test: 0.6930 time: 0.3020s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1272 acc_val: 0.4967 loss_test: 1.3871 acc_test: 0.6950 time: 0.2984s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1720 acc_val: 0.4967 loss_test: 1.4243 acc_test: 0.6950 time: 0.3084s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2097 acc_val: 0.5000 loss_test: 1.4553 acc_test: 0.6940 time: 0.2959s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2374 acc_val: 0.4967 loss_test: 1.4825 acc_test: 0.6930 time: 0.3003s
Optimization Finished!
Total time elapsed: 149.2497s, best testing performance  0.696000, minimun loss  0.938474
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1583 loss_val: 1.8164 acc_val: 0.1833 loss_test: 1.6476 acc_test: 0.5240 time: 0.3794s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.6599 acc_val: 0.4200 loss_test: 1.1134 acc_test: 0.6830 time: 0.2888s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8217 acc_val: 0.4400 loss_test: 1.1881 acc_test: 0.6890 time: 0.2858s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9452 acc_val: 0.4400 loss_test: 1.2595 acc_test: 0.6900 time: 0.2867s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0032 acc_val: 0.4733 loss_test: 1.3012 acc_test: 0.6880 time: 0.3103s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9970 acc_val: 0.4833 loss_test: 1.3289 acc_test: 0.6910 time: 0.2917s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0287 acc_val: 0.4933 loss_test: 1.3588 acc_test: 0.6930 time: 0.3029s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0634 acc_val: 0.5000 loss_test: 1.3890 acc_test: 0.6980 time: 0.2879s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0969 acc_val: 0.5000 loss_test: 1.4169 acc_test: 0.7000 time: 0.2893s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1075 acc_val: 0.5033 loss_test: 1.4385 acc_test: 0.7040 time: 0.2949s
Optimization Finished!
Total time elapsed: 148.0465s, best testing performance  0.705000, minimun loss  0.952092
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1750 loss_val: 1.8193 acc_val: 0.1333 loss_test: 1.6494 acc_test: 0.5050 time: 0.3585s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.9026 acc_val: 0.3700 loss_test: 1.2022 acc_test: 0.6590 time: 0.2944s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 2.0018 acc_val: 0.3967 loss_test: 1.2485 acc_test: 0.6640 time: 0.2732s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.1005 acc_val: 0.4433 loss_test: 1.3120 acc_test: 0.6810 time: 0.3112s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1071 acc_val: 0.4700 loss_test: 1.3415 acc_test: 0.6860 time: 0.2953s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1288 acc_val: 0.4767 loss_test: 1.3796 acc_test: 0.6910 time: 0.2864s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1416 acc_val: 0.4867 loss_test: 1.4118 acc_test: 0.6920 time: 0.2950s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1609 acc_val: 0.5067 loss_test: 1.4496 acc_test: 0.6980 time: 0.3638s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1679 acc_val: 0.5067 loss_test: 1.4770 acc_test: 0.7010 time: 0.3164s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2357 acc_val: 0.5033 loss_test: 1.5159 acc_test: 0.7010 time: 0.2925s
Optimization Finished!
Total time elapsed: 149.1225s, best testing performance  0.703000, minimun loss  0.956836
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7961 acc_train: 0.1417 loss_val: 1.8254 acc_val: 0.1300 loss_test: 1.6562 acc_test: 0.4820 time: 0.3463s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.9297 acc_val: 0.3800 loss_test: 1.2086 acc_test: 0.6540 time: 0.2976s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9732 acc_val: 0.4033 loss_test: 1.2427 acc_test: 0.6660 time: 0.3057s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0786 acc_val: 0.4367 loss_test: 1.3052 acc_test: 0.6790 time: 0.3148s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1495 acc_val: 0.4533 loss_test: 1.3482 acc_test: 0.6820 time: 0.3202s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1687 acc_val: 0.4700 loss_test: 1.3787 acc_test: 0.6850 time: 0.2777s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1698 acc_val: 0.4900 loss_test: 1.4097 acc_test: 0.6890 time: 0.3040s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1629 acc_val: 0.5033 loss_test: 1.4338 acc_test: 0.6910 time: 0.3363s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1682 acc_val: 0.5067 loss_test: 1.4591 acc_test: 0.6920 time: 0.3107s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2129 acc_val: 0.5000 loss_test: 1.4927 acc_test: 0.6930 time: 0.2872s
Optimization Finished!
Total time elapsed: 149.7456s, best testing performance  0.696000, minimun loss  0.938396
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7958 acc_train: 0.2250 loss_val: 1.8097 acc_val: 0.0633 loss_test: 1.6664 acc_test: 0.3600 time: 0.3541s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8470 acc_val: 0.3933 loss_test: 1.1900 acc_test: 0.6660 time: 0.2840s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8190 acc_val: 0.4267 loss_test: 1.1967 acc_test: 0.6840 time: 0.2980s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9329 acc_val: 0.4500 loss_test: 1.2680 acc_test: 0.6900 time: 0.2904s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0082 acc_val: 0.4633 loss_test: 1.3120 acc_test: 0.6960 time: 0.3123s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0676 acc_val: 0.4633 loss_test: 1.3541 acc_test: 0.6920 time: 0.2855s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1226 acc_val: 0.4733 loss_test: 1.3929 acc_test: 0.6970 time: 0.2821s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1305 acc_val: 0.4933 loss_test: 1.4146 acc_test: 0.6940 time: 0.3109s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1625 acc_val: 0.5033 loss_test: 1.4412 acc_test: 0.6980 time: 0.3067s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.5100 loss_test: 1.4601 acc_test: 0.7000 time: 0.2864s
Optimization Finished!
Total time elapsed: 149.2509s, best testing performance  0.700000, minimun loss  0.956770
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7807 acc_train: 0.2250 loss_val: 1.7985 acc_val: 0.1967 loss_test: 1.6435 acc_test: 0.5320 time: 0.3546s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7755 acc_val: 0.4200 loss_test: 1.1884 acc_test: 0.6740 time: 0.2924s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8693 acc_val: 0.4333 loss_test: 1.2246 acc_test: 0.6790 time: 0.2870s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.0264 acc_val: 0.4433 loss_test: 1.3071 acc_test: 0.6810 time: 0.2958s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0717 acc_val: 0.4700 loss_test: 1.3519 acc_test: 0.6850 time: 0.2757s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0775 acc_val: 0.4833 loss_test: 1.3837 acc_test: 0.6880 time: 0.2997s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0993 acc_val: 0.5033 loss_test: 1.4158 acc_test: 0.6960 time: 0.2820s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1139 acc_val: 0.5033 loss_test: 1.4426 acc_test: 0.6940 time: 0.3162s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1403 acc_val: 0.5067 loss_test: 1.4756 acc_test: 0.6950 time: 0.3102s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1703 acc_val: 0.5033 loss_test: 1.5011 acc_test: 0.6960 time: 0.2819s
Optimization Finished!
Total time elapsed: 149.6870s, best testing performance  0.699000, minimun loss  0.962765
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8206 acc_train: 0.0833 loss_val: 1.8462 acc_val: 0.0667 loss_test: 1.6828 acc_test: 0.3230 time: 0.3341s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8835 acc_val: 0.3767 loss_test: 1.2036 acc_test: 0.6610 time: 0.3039s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9815 acc_val: 0.4033 loss_test: 1.2536 acc_test: 0.6700 time: 0.2863s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0525 acc_val: 0.4367 loss_test: 1.3078 acc_test: 0.6830 time: 0.2971s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0635 acc_val: 0.4733 loss_test: 1.3364 acc_test: 0.6890 time: 0.2867s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0758 acc_val: 0.4900 loss_test: 1.3648 acc_test: 0.6910 time: 0.2962s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0915 acc_val: 0.5000 loss_test: 1.3945 acc_test: 0.6940 time: 0.2940s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1089 acc_val: 0.5200 loss_test: 1.4199 acc_test: 0.6980 time: 0.3244s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1565 acc_val: 0.5233 loss_test: 1.4556 acc_test: 0.7020 time: 0.3075s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1845 acc_val: 0.5267 loss_test: 1.4817 acc_test: 0.7010 time: 0.2931s
Optimization Finished!
Total time elapsed: 149.3428s, best testing performance  0.704000, minimun loss  0.985154
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7934 acc_train: 0.1083 loss_val: 1.7926 acc_val: 0.2100 loss_test: 1.6559 acc_test: 0.5100 time: 0.3606s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7306 acc_val: 0.3833 loss_test: 1.1421 acc_test: 0.6640 time: 0.3163s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7417 acc_val: 0.4333 loss_test: 1.1590 acc_test: 0.6890 time: 0.2909s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9172 acc_val: 0.4433 loss_test: 1.2463 acc_test: 0.6870 time: 0.2907s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0458 acc_val: 0.4567 loss_test: 1.3080 acc_test: 0.6840 time: 0.2900s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1094 acc_val: 0.4767 loss_test: 1.3580 acc_test: 0.6880 time: 0.3075s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.4900 loss_test: 1.3929 acc_test: 0.6910 time: 0.2977s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2418 acc_val: 0.4833 loss_test: 1.4424 acc_test: 0.6910 time: 0.3063s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2565 acc_val: 0.4933 loss_test: 1.4755 acc_test: 0.6890 time: 0.2871s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2786 acc_val: 0.5067 loss_test: 1.5015 acc_test: 0.6930 time: 0.2887s
Optimization Finished!
Total time elapsed: 150.2928s, best testing performance  0.697000, minimun loss  0.953368
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7812 acc_train: 0.1583 loss_val: 1.7973 acc_val: 0.2133 loss_test: 1.6455 acc_test: 0.5710 time: 0.3599s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.8235 acc_val: 0.4167 loss_test: 1.1558 acc_test: 0.6680 time: 0.2904s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9029 acc_val: 0.4267 loss_test: 1.1948 acc_test: 0.6840 time: 0.3120s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 2.0006 acc_val: 0.4367 loss_test: 1.2590 acc_test: 0.6840 time: 0.2814s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0406 acc_val: 0.4600 loss_test: 1.3015 acc_test: 0.6870 time: 0.2884s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0831 acc_val: 0.4867 loss_test: 1.3437 acc_test: 0.6900 time: 0.2849s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.4900 loss_test: 1.3762 acc_test: 0.6970 time: 0.3020s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0883 acc_val: 0.5000 loss_test: 1.4077 acc_test: 0.7040 time: 0.2980s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1468 acc_val: 0.5100 loss_test: 1.4518 acc_test: 0.7040 time: 0.2845s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2049 acc_val: 0.5067 loss_test: 1.4925 acc_test: 0.7060 time: 0.2999s
Optimization Finished!
Total time elapsed: 148.4269s, best testing performance  0.707000, minimun loss  0.939104
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7788 acc_train: 0.2000 loss_val: 1.7682 acc_val: 0.2333 loss_test: 1.6449 acc_test: 0.5410 time: 0.3537s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7563 acc_val: 0.4167 loss_test: 1.1451 acc_test: 0.6720 time: 0.2872s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7405 acc_val: 0.4333 loss_test: 1.1594 acc_test: 0.6830 time: 0.2923s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8663 acc_val: 0.4367 loss_test: 1.2331 acc_test: 0.6920 time: 0.2916s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9551 acc_val: 0.4533 loss_test: 1.2841 acc_test: 0.6900 time: 0.2932s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4733 loss_test: 1.3303 acc_test: 0.6920 time: 0.3161s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0776 acc_val: 0.4867 loss_test: 1.3661 acc_test: 0.6940 time: 0.3090s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1491 acc_val: 0.5033 loss_test: 1.4068 acc_test: 0.6960 time: 0.3089s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1822 acc_val: 0.5000 loss_test: 1.4348 acc_test: 0.6920 time: 0.2953s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2200 acc_val: 0.4967 loss_test: 1.4661 acc_test: 0.6950 time: 0.2776s
Optimization Finished!
Total time elapsed: 148.7335s, best testing performance  0.703000, minimun loss  0.931526
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7882 acc_train: 0.1667 loss_val: 1.8318 acc_val: 0.1700 loss_test: 1.6555 acc_test: 0.5290 time: 0.3706s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.8059 acc_val: 0.3667 loss_test: 1.1614 acc_test: 0.6670 time: 0.2954s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.8422 acc_val: 0.4067 loss_test: 1.1904 acc_test: 0.6810 time: 0.3046s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9396 acc_val: 0.4200 loss_test: 1.2530 acc_test: 0.6820 time: 0.2861s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0295 acc_val: 0.4567 loss_test: 1.3091 acc_test: 0.6840 time: 0.2884s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0578 acc_val: 0.4733 loss_test: 1.3427 acc_test: 0.6880 time: 0.2866s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1114 acc_val: 0.4767 loss_test: 1.3816 acc_test: 0.6900 time: 0.3008s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1452 acc_val: 0.4933 loss_test: 1.4151 acc_test: 0.6900 time: 0.3119s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1630 acc_val: 0.5033 loss_test: 1.4418 acc_test: 0.6870 time: 0.2993s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1627 acc_val: 0.5100 loss_test: 1.4587 acc_test: 0.6900 time: 0.3016s
Optimization Finished!
Total time elapsed: 148.8603s, best testing performance  0.697000, minimun loss  0.954940
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7913 acc_train: 0.1667 loss_val: 1.7831 acc_val: 0.1700 loss_test: 1.6693 acc_test: 0.5050 time: 0.3400s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.6381 acc_val: 0.4433 loss_test: 1.1399 acc_test: 0.6820 time: 0.3156s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7508 acc_val: 0.4400 loss_test: 1.1860 acc_test: 0.6860 time: 0.3044s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.8743 acc_val: 0.4633 loss_test: 1.2512 acc_test: 0.6890 time: 0.2783s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9614 acc_val: 0.4800 loss_test: 1.3010 acc_test: 0.6900 time: 0.2895s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 1.9664 acc_val: 0.4867 loss_test: 1.3282 acc_test: 0.6940 time: 0.2852s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0228 acc_val: 0.5067 loss_test: 1.3691 acc_test: 0.6910 time: 0.2977s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0807 acc_val: 0.5133 loss_test: 1.4064 acc_test: 0.6950 time: 0.2908s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0911 acc_val: 0.5167 loss_test: 1.4337 acc_test: 0.6960 time: 0.3057s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1375 acc_val: 0.5167 loss_test: 1.4661 acc_test: 0.6960 time: 0.3039s
Optimization Finished!
Total time elapsed: 148.8018s, best testing performance  0.699000, minimun loss  0.965442
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7746 acc_train: 0.2500 loss_val: 1.8159 acc_val: 0.2133 loss_test: 1.6359 acc_test: 0.5090 time: 0.3706s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.4945 acc_val: 0.4467 loss_test: 1.0804 acc_test: 0.6860 time: 0.2824s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.4970 acc_val: 0.4933 loss_test: 1.1049 acc_test: 0.7080 time: 0.2840s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.7596 acc_val: 0.4733 loss_test: 1.2439 acc_test: 0.6950 time: 0.3156s
Epoch: 0201 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0777 acc_val: 0.4467 loss_test: 1.3614 acc_test: 0.6830 time: 0.2979s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0930 acc_val: 0.4667 loss_test: 1.3832 acc_test: 0.6920 time: 0.2885s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0916 acc_val: 0.4967 loss_test: 1.4065 acc_test: 0.6940 time: 0.2890s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0846 acc_val: 0.5000 loss_test: 1.4276 acc_test: 0.6960 time: 0.3128s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1178 acc_val: 0.5100 loss_test: 1.4539 acc_test: 0.6970 time: 0.3139s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1639 acc_val: 0.5167 loss_test: 1.4816 acc_test: 0.6960 time: 0.2734s
Optimization Finished!
Total time elapsed: 148.5896s, best testing performance  0.712000, minimun loss  0.947421
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7873 acc_train: 0.1500 loss_val: 1.8284 acc_val: 0.1367 loss_test: 1.6369 acc_test: 0.4610 time: 0.3529s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6996 acc_val: 0.4267 loss_test: 1.1595 acc_test: 0.6780 time: 0.2832s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7722 acc_val: 0.4533 loss_test: 1.2015 acc_test: 0.6880 time: 0.2965s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0005 acc_val: 0.4367 loss_test: 1.3169 acc_test: 0.6810 time: 0.2976s
Epoch: 0201 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.1517 acc_val: 0.4467 loss_test: 1.3810 acc_test: 0.6810 time: 0.2921s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1938 acc_val: 0.4500 loss_test: 1.4052 acc_test: 0.6870 time: 0.3078s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.2259 acc_val: 0.4767 loss_test: 1.4303 acc_test: 0.6910 time: 0.2927s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2435 acc_val: 0.4933 loss_test: 1.4518 acc_test: 0.6950 time: 0.3032s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2421 acc_val: 0.4967 loss_test: 1.4718 acc_test: 0.6930 time: 0.3052s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2672 acc_val: 0.4967 loss_test: 1.4909 acc_test: 0.6970 time: 0.2943s
Optimization Finished!
Total time elapsed: 149.1862s, best testing performance  0.701000, minimun loss  0.960271
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8062 acc_train: 0.1250 loss_val: 1.8320 acc_val: 0.0467 loss_test: 1.6588 acc_test: 0.3740 time: 0.3509s
Epoch: 0051 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.5834 acc_val: 0.4400 loss_test: 1.1225 acc_test: 0.6780 time: 0.3030s
Epoch: 0101 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.6435 acc_val: 0.4700 loss_test: 1.1594 acc_test: 0.6910 time: 0.2920s
Epoch: 0151 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9080 acc_val: 0.4367 loss_test: 1.2823 acc_test: 0.6920 time: 0.2884s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0533 acc_val: 0.4400 loss_test: 1.3446 acc_test: 0.6850 time: 0.3179s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1080 acc_val: 0.4600 loss_test: 1.3837 acc_test: 0.6900 time: 0.2887s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1363 acc_val: 0.4767 loss_test: 1.4125 acc_test: 0.6900 time: 0.3003s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1273 acc_val: 0.4933 loss_test: 1.4334 acc_test: 0.6930 time: 0.3051s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1243 acc_val: 0.5067 loss_test: 1.4481 acc_test: 0.6970 time: 0.3073s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1558 acc_val: 0.4933 loss_test: 1.4719 acc_test: 0.6970 time: 0.2889s
Optimization Finished!
Total time elapsed: 149.6386s, best testing performance  0.705000, minimun loss  0.928549
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1667 loss_val: 1.8041 acc_val: 0.1967 loss_test: 1.6395 acc_test: 0.5550 time: 0.3590s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.5962 acc_val: 0.4500 loss_test: 1.1104 acc_test: 0.6820 time: 0.3181s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.6139 acc_val: 0.4900 loss_test: 1.1364 acc_test: 0.7000 time: 0.2875s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.7965 acc_val: 0.4900 loss_test: 1.2380 acc_test: 0.6980 time: 0.2833s
Epoch: 0201 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.1000 acc_val: 0.4567 loss_test: 1.3592 acc_test: 0.6910 time: 0.2953s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1950 acc_val: 0.4567 loss_test: 1.4057 acc_test: 0.6890 time: 0.3111s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.4800 loss_test: 1.4304 acc_test: 0.6920 time: 0.2915s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2395 acc_val: 0.4900 loss_test: 1.4558 acc_test: 0.6900 time: 0.3213s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2132 acc_val: 0.5067 loss_test: 1.4741 acc_test: 0.6900 time: 0.3087s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2686 acc_val: 0.5000 loss_test: 1.4986 acc_test: 0.6910 time: 0.3008s
Optimization Finished!
Total time elapsed: 149.4197s, best testing performance  0.705000, minimun loss  0.933859
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7994 acc_train: 0.0917 loss_val: 1.8256 acc_val: 0.1733 loss_test: 1.6505 acc_test: 0.5150 time: 0.3586s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7695 acc_val: 0.4333 loss_test: 1.1843 acc_test: 0.6730 time: 0.2817s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8503 acc_val: 0.4367 loss_test: 1.2334 acc_test: 0.6810 time: 0.3237s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0913 acc_val: 0.4167 loss_test: 1.3381 acc_test: 0.6760 time: 0.3002s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1054 acc_val: 0.4600 loss_test: 1.3620 acc_test: 0.6860 time: 0.3065s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1555 acc_val: 0.4733 loss_test: 1.3974 acc_test: 0.6890 time: 0.2869s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1663 acc_val: 0.4833 loss_test: 1.4203 acc_test: 0.6910 time: 0.2987s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2194 acc_val: 0.4933 loss_test: 1.4572 acc_test: 0.6910 time: 0.3075s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1955 acc_val: 0.5033 loss_test: 1.4730 acc_test: 0.6930 time: 0.3084s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2863 acc_val: 0.5000 loss_test: 1.5059 acc_test: 0.6920 time: 0.3056s
Optimization Finished!
Total time elapsed: 149.0307s, best testing performance  0.698000, minimun loss  0.962707
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7794 acc_train: 0.3083 loss_val: 1.8026 acc_val: 0.1367 loss_test: 1.6589 acc_test: 0.4430 time: 0.3511s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8348 acc_val: 0.3933 loss_test: 1.1941 acc_test: 0.6680 time: 0.3051s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7955 acc_val: 0.4467 loss_test: 1.1958 acc_test: 0.6840 time: 0.2879s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8598 acc_val: 0.4733 loss_test: 1.2515 acc_test: 0.6900 time: 0.2882s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9661 acc_val: 0.4700 loss_test: 1.3044 acc_test: 0.6880 time: 0.2940s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9916 acc_val: 0.4800 loss_test: 1.3385 acc_test: 0.6900 time: 0.2938s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0381 acc_val: 0.4900 loss_test: 1.3808 acc_test: 0.6920 time: 0.2946s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0384 acc_val: 0.5067 loss_test: 1.4060 acc_test: 0.6950 time: 0.3664s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0411 acc_val: 0.5133 loss_test: 1.4277 acc_test: 0.6950 time: 0.3265s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0747 acc_val: 0.5200 loss_test: 1.4587 acc_test: 0.6970 time: 0.3115s
Optimization Finished!
Total time elapsed: 149.4740s, best testing performance  0.700000, minimun loss  0.962758
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8224 acc_train: 0.0917 loss_val: 1.8591 acc_val: 0.0600 loss_test: 1.6777 acc_test: 0.3510 time: 0.3431s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6477 acc_val: 0.4233 loss_test: 1.1340 acc_test: 0.6700 time: 0.2844s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7333 acc_val: 0.4433 loss_test: 1.1772 acc_test: 0.6830 time: 0.2844s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9252 acc_val: 0.4500 loss_test: 1.2622 acc_test: 0.6880 time: 0.2830s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0691 acc_val: 0.4633 loss_test: 1.3211 acc_test: 0.6950 time: 0.3026s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1439 acc_val: 0.4733 loss_test: 1.3680 acc_test: 0.6880 time: 0.2872s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.2035 acc_val: 0.4867 loss_test: 1.4070 acc_test: 0.6910 time: 0.3195s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2380 acc_val: 0.4900 loss_test: 1.4394 acc_test: 0.6940 time: 0.3510s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2687 acc_val: 0.5033 loss_test: 1.4706 acc_test: 0.6940 time: 0.3200s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2879 acc_val: 0.5067 loss_test: 1.4921 acc_test: 0.6950 time: 0.2858s
Optimization Finished!
Total time elapsed: 149.6969s, best testing performance  0.699000, minimun loss  0.949909
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.1167 loss_val: 1.8270 acc_val: 0.1433 loss_test: 1.6853 acc_test: 0.4800 time: 0.3533s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6496 acc_val: 0.4200 loss_test: 1.1584 acc_test: 0.6730 time: 0.2960s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7799 acc_val: 0.4467 loss_test: 1.2008 acc_test: 0.6790 time: 0.2854s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9292 acc_val: 0.4667 loss_test: 1.2733 acc_test: 0.6870 time: 0.2834s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9929 acc_val: 0.4633 loss_test: 1.3083 acc_test: 0.6900 time: 0.2905s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0293 acc_val: 0.4900 loss_test: 1.3421 acc_test: 0.6910 time: 0.2870s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0502 acc_val: 0.5000 loss_test: 1.3705 acc_test: 0.6920 time: 0.2872s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1117 acc_val: 0.5067 loss_test: 1.4036 acc_test: 0.6920 time: 0.3068s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1286 acc_val: 0.5100 loss_test: 1.4286 acc_test: 0.6930 time: 0.3179s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1738 acc_val: 0.5033 loss_test: 1.4578 acc_test: 0.6930 time: 0.2951s
Optimization Finished!
Total time elapsed: 149.0968s, best testing performance  0.702000, minimun loss  0.955671
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7940 acc_train: 0.1167 loss_val: 1.8229 acc_val: 0.1133 loss_test: 1.6611 acc_test: 0.5010 time: 0.3445s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7040 acc_val: 0.4233 loss_test: 1.1667 acc_test: 0.6770 time: 0.2852s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8081 acc_val: 0.4400 loss_test: 1.2108 acc_test: 0.6870 time: 0.3027s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9636 acc_val: 0.4667 loss_test: 1.2856 acc_test: 0.6860 time: 0.2830s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0523 acc_val: 0.4667 loss_test: 1.3300 acc_test: 0.6860 time: 0.2863s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0836 acc_val: 0.4800 loss_test: 1.3635 acc_test: 0.6900 time: 0.2829s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1285 acc_val: 0.4933 loss_test: 1.3987 acc_test: 0.6930 time: 0.2894s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1423 acc_val: 0.5067 loss_test: 1.4212 acc_test: 0.6940 time: 0.3198s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2349 acc_val: 0.5000 loss_test: 1.4622 acc_test: 0.6910 time: 0.3296s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2162 acc_val: 0.5067 loss_test: 1.4795 acc_test: 0.6920 time: 0.2865s
Optimization Finished!
Total time elapsed: 148.6646s, best testing performance  0.698000, minimun loss  0.960304
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8114 acc_train: 0.1167 loss_val: 1.7976 acc_val: 0.1767 loss_test: 1.6666 acc_test: 0.5380 time: 0.3389s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7243 acc_val: 0.4233 loss_test: 1.1600 acc_test: 0.6720 time: 0.2972s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.7684 acc_val: 0.4600 loss_test: 1.1901 acc_test: 0.6860 time: 0.2909s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9017 acc_val: 0.4633 loss_test: 1.2688 acc_test: 0.6870 time: 0.3003s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9889 acc_val: 0.4733 loss_test: 1.3192 acc_test: 0.6880 time: 0.2838s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0357 acc_val: 0.4867 loss_test: 1.3567 acc_test: 0.6880 time: 0.2841s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0784 acc_val: 0.4900 loss_test: 1.3886 acc_test: 0.6930 time: 0.2851s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1153 acc_val: 0.5067 loss_test: 1.4228 acc_test: 0.6920 time: 0.3139s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1800 acc_val: 0.5100 loss_test: 1.4548 acc_test: 0.6910 time: 0.3041s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2024 acc_val: 0.5067 loss_test: 1.4766 acc_test: 0.6980 time: 0.2918s
Optimization Finished!
Total time elapsed: 149.2172s, best testing performance  0.701000, minimun loss  0.941290
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7941 acc_train: 0.1000 loss_val: 1.8354 acc_val: 0.1533 loss_test: 1.6533 acc_test: 0.5430 time: 0.3548s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 2.0373 acc_val: 0.3500 loss_test: 1.2634 acc_test: 0.6530 time: 0.2956s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9863 acc_val: 0.3967 loss_test: 1.2578 acc_test: 0.6680 time: 0.2986s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0377 acc_val: 0.4267 loss_test: 1.3044 acc_test: 0.6830 time: 0.2903s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0975 acc_val: 0.4433 loss_test: 1.3516 acc_test: 0.6890 time: 0.2861s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1500 acc_val: 0.4567 loss_test: 1.3917 acc_test: 0.6870 time: 0.2993s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1803 acc_val: 0.4700 loss_test: 1.4235 acc_test: 0.6880 time: 0.2894s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2442 acc_val: 0.4900 loss_test: 1.4631 acc_test: 0.6870 time: 0.3086s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2466 acc_val: 0.4933 loss_test: 1.4841 acc_test: 0.6900 time: 0.3160s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2964 acc_val: 0.4867 loss_test: 1.5150 acc_test: 0.6910 time: 0.3028s
Optimization Finished!
Total time elapsed: 149.6876s, best testing performance  0.693000, minimun loss  0.982651
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7791 acc_train: 0.1833 loss_val: 1.8078 acc_val: 0.1667 loss_test: 1.6442 acc_test: 0.5220 time: 0.3600s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8676 acc_val: 0.3800 loss_test: 1.2099 acc_test: 0.6580 time: 0.2904s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8953 acc_val: 0.4267 loss_test: 1.2200 acc_test: 0.6750 time: 0.2872s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9156 acc_val: 0.4567 loss_test: 1.2631 acc_test: 0.6870 time: 0.2752s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0167 acc_val: 0.4533 loss_test: 1.3259 acc_test: 0.6860 time: 0.3091s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0594 acc_val: 0.4700 loss_test: 1.3667 acc_test: 0.6910 time: 0.2846s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1060 acc_val: 0.4767 loss_test: 1.4098 acc_test: 0.6960 time: 0.2860s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1682 acc_val: 0.4967 loss_test: 1.4537 acc_test: 0.6980 time: 0.3069s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2049 acc_val: 0.5033 loss_test: 1.4896 acc_test: 0.7000 time: 0.3065s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2193 acc_val: 0.5100 loss_test: 1.5129 acc_test: 0.7060 time: 0.2969s
Optimization Finished!
Total time elapsed: 149.1571s, best testing performance  0.706000, minimun loss  0.995184
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7958 acc_train: 0.1750 loss_val: 1.8270 acc_val: 0.1767 loss_test: 1.6740 acc_test: 0.5010 time: 0.3858s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9397 acc_val: 0.4067 loss_test: 1.2471 acc_test: 0.6690 time: 0.3094s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9583 acc_val: 0.4433 loss_test: 1.2516 acc_test: 0.6800 time: 0.3071s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0154 acc_val: 0.4600 loss_test: 1.3000 acc_test: 0.6840 time: 0.2743s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.4600 loss_test: 1.3424 acc_test: 0.6880 time: 0.2920s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0897 acc_val: 0.4867 loss_test: 1.3730 acc_test: 0.6930 time: 0.2982s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1169 acc_val: 0.4967 loss_test: 1.4034 acc_test: 0.6950 time: 0.2851s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1442 acc_val: 0.4967 loss_test: 1.4335 acc_test: 0.6980 time: 0.3037s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1885 acc_val: 0.5000 loss_test: 1.4676 acc_test: 0.6980 time: 0.3100s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2451 acc_val: 0.5067 loss_test: 1.4988 acc_test: 0.7000 time: 0.2910s
Optimization Finished!
Total time elapsed: 149.3778s, best testing performance  0.701000, minimun loss  1.013813
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7881 acc_train: 0.2250 loss_val: 1.7958 acc_val: 0.1300 loss_test: 1.6629 acc_test: 0.4810 time: 0.3781s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8598 acc_val: 0.3833 loss_test: 1.2200 acc_test: 0.6600 time: 0.3016s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9700 acc_val: 0.4200 loss_test: 1.2710 acc_test: 0.6680 time: 0.3092s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9925 acc_val: 0.4367 loss_test: 1.3047 acc_test: 0.6800 time: 0.2903s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0613 acc_val: 0.4567 loss_test: 1.3436 acc_test: 0.6850 time: 0.2823s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1187 acc_val: 0.4733 loss_test: 1.3756 acc_test: 0.6880 time: 0.2972s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1639 acc_val: 0.4833 loss_test: 1.4071 acc_test: 0.6930 time: 0.2902s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1891 acc_val: 0.5000 loss_test: 1.4311 acc_test: 0.6910 time: 0.3169s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2475 acc_val: 0.5000 loss_test: 1.4611 acc_test: 0.6910 time: 0.3114s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2560 acc_val: 0.5033 loss_test: 1.4812 acc_test: 0.6920 time: 0.3208s
Optimization Finished!
Total time elapsed: 149.9460s, best testing performance  0.697000, minimun loss  1.000164
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7836 acc_train: 0.1833 loss_val: 1.8085 acc_val: 0.1200 loss_test: 1.6678 acc_test: 0.4940 time: 0.3486s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7425 acc_val: 0.3967 loss_test: 1.2007 acc_test: 0.6610 time: 0.2836s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7571 acc_val: 0.4333 loss_test: 1.2100 acc_test: 0.6760 time: 0.2766s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8339 acc_val: 0.4533 loss_test: 1.2618 acc_test: 0.6880 time: 0.2831s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9648 acc_val: 0.4500 loss_test: 1.3220 acc_test: 0.6880 time: 0.3160s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0118 acc_val: 0.4633 loss_test: 1.3584 acc_test: 0.6900 time: 0.2736s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0494 acc_val: 0.4867 loss_test: 1.3918 acc_test: 0.6930 time: 0.2805s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0520 acc_val: 0.5133 loss_test: 1.4196 acc_test: 0.6910 time: 0.3315s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1080 acc_val: 0.5167 loss_test: 1.4530 acc_test: 0.6920 time: 0.3294s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1236 acc_val: 0.5133 loss_test: 1.4729 acc_test: 0.6930 time: 0.2946s
Optimization Finished!
Total time elapsed: 150.0684s, best testing performance  0.698000, minimun loss  0.988604
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7944 acc_train: 0.2083 loss_val: 1.8318 acc_val: 0.0667 loss_test: 1.6798 acc_test: 0.4010 time: 0.3873s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7742 acc_val: 0.3967 loss_test: 1.1960 acc_test: 0.6680 time: 0.2828s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.7631 acc_val: 0.4433 loss_test: 1.2070 acc_test: 0.6770 time: 0.2928s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9189 acc_val: 0.4433 loss_test: 1.2811 acc_test: 0.6830 time: 0.2862s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0039 acc_val: 0.4633 loss_test: 1.3299 acc_test: 0.6880 time: 0.2832s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0896 acc_val: 0.4800 loss_test: 1.3779 acc_test: 0.6900 time: 0.2897s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1452 acc_val: 0.4800 loss_test: 1.4158 acc_test: 0.6910 time: 0.3142s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.5067 loss_test: 1.4468 acc_test: 0.6920 time: 0.3116s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2276 acc_val: 0.5100 loss_test: 1.4770 acc_test: 0.6940 time: 0.3151s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2694 acc_val: 0.5067 loss_test: 1.5021 acc_test: 0.6950 time: 0.2997s
Optimization Finished!
Total time elapsed: 150.2217s, best testing performance  0.701000, minimun loss  0.992590
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8058 acc_train: 0.0917 loss_val: 1.8257 acc_val: 0.1600 loss_test: 1.6899 acc_test: 0.5010 time: 0.3951s
Epoch: 0051 loss_train: 0.0112 acc_train: 1.0000 loss_val: 1.7568 acc_val: 0.3800 loss_test: 1.1632 acc_test: 0.6650 time: 0.3155s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8540 acc_val: 0.4167 loss_test: 1.2020 acc_test: 0.6740 time: 0.3236s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9914 acc_val: 0.4400 loss_test: 1.2690 acc_test: 0.6850 time: 0.2855s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 2.0174 acc_val: 0.4567 loss_test: 1.3038 acc_test: 0.6860 time: 0.2937s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0322 acc_val: 0.4667 loss_test: 1.3322 acc_test: 0.6910 time: 0.3007s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0297 acc_val: 0.4900 loss_test: 1.3600 acc_test: 0.6940 time: 0.3258s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0832 acc_val: 0.5000 loss_test: 1.3937 acc_test: 0.6940 time: 0.3090s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1038 acc_val: 0.5067 loss_test: 1.4222 acc_test: 0.6970 time: 0.2951s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1603 acc_val: 0.5033 loss_test: 1.4548 acc_test: 0.6960 time: 0.2919s
Optimization Finished!
Total time elapsed: 150.5645s, best testing performance  0.699000, minimun loss  0.982528
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8116 acc_train: 0.1167 loss_val: 1.8057 acc_val: 0.1667 loss_test: 1.7078 acc_test: 0.3930 time: 0.3808s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7089 acc_val: 0.4300 loss_test: 1.1388 acc_test: 0.6660 time: 0.2851s
Epoch: 0101 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7942 acc_val: 0.4400 loss_test: 1.1821 acc_test: 0.6830 time: 0.2929s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9303 acc_val: 0.4433 loss_test: 1.2495 acc_test: 0.6890 time: 0.2854s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9885 acc_val: 0.4567 loss_test: 1.2919 acc_test: 0.6920 time: 0.2940s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0627 acc_val: 0.4667 loss_test: 1.3428 acc_test: 0.6940 time: 0.2865s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.4800 loss_test: 1.3819 acc_test: 0.6940 time: 0.3072s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1413 acc_val: 0.4967 loss_test: 1.4294 acc_test: 0.6920 time: 0.3729s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1829 acc_val: 0.5000 loss_test: 1.4710 acc_test: 0.6990 time: 0.2841s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2689 acc_val: 0.5067 loss_test: 1.5175 acc_test: 0.7010 time: 0.3024s
Optimization Finished!
Total time elapsed: 149.0809s, best testing performance  0.705000, minimun loss  0.981393
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7999 acc_train: 0.1333 loss_val: 1.8168 acc_val: 0.1667 loss_test: 1.6725 acc_test: 0.5100 time: 0.3889s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7618 acc_val: 0.3800 loss_test: 1.1674 acc_test: 0.6680 time: 0.3355s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.8478 acc_val: 0.4233 loss_test: 1.2068 acc_test: 0.6730 time: 0.2982s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 1.9564 acc_val: 0.4500 loss_test: 1.2597 acc_test: 0.6860 time: 0.2867s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0238 acc_val: 0.4667 loss_test: 1.3016 acc_test: 0.6850 time: 0.2862s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0638 acc_val: 0.4800 loss_test: 1.3391 acc_test: 0.6890 time: 0.2890s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1185 acc_val: 0.5000 loss_test: 1.3778 acc_test: 0.6900 time: 0.3008s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1540 acc_val: 0.5033 loss_test: 1.4131 acc_test: 0.6940 time: 0.3109s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1893 acc_val: 0.5000 loss_test: 1.4453 acc_test: 0.6930 time: 0.2954s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2454 acc_val: 0.5000 loss_test: 1.4795 acc_test: 0.6940 time: 0.3147s
Optimization Finished!
Total time elapsed: 149.7971s, best testing performance  0.695000, minimun loss  0.979276
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 45, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7975 acc_train: 0.1250 loss_val: 1.8236 acc_val: 0.1400 loss_test: 1.6837 acc_test: 0.4550 time: 0.3628s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 1.7939 acc_val: 0.4033 loss_test: 1.1594 acc_test: 0.6710 time: 0.2845s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8113 acc_val: 0.4467 loss_test: 1.1698 acc_test: 0.6790 time: 0.2907s
Epoch: 0151 loss_train: 0.0065 acc_train: 1.0000 loss_val: 1.9200 acc_val: 0.4567 loss_test: 1.2338 acc_test: 0.6840 time: 0.2752s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9886 acc_val: 0.4633 loss_test: 1.2838 acc_test: 0.6880 time: 0.2842s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0293 acc_val: 0.4800 loss_test: 1.3230 acc_test: 0.6930 time: 0.2851s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0455 acc_val: 0.4967 loss_test: 1.3532 acc_test: 0.6940 time: 0.3008s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0916 acc_val: 0.4967 loss_test: 1.3892 acc_test: 0.6940 time: 0.3111s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1186 acc_val: 0.5000 loss_test: 1.4150 acc_test: 0.6970 time: 0.3625s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1323 acc_val: 0.5067 loss_test: 1.4350 acc_test: 0.6980 time: 0.3199s
Optimization Finished!
Total time elapsed: 148.6956s, best testing performance  0.699000, minimun loss  0.977991
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7894 acc_train: 0.1833 loss_val: 1.8443 acc_val: 0.0733 loss_test: 1.6486 acc_test: 0.4230 time: 0.4604s
Epoch: 0051 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9120 acc_val: 0.3800 loss_test: 1.1945 acc_test: 0.6710 time: 0.3124s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.9071 acc_val: 0.4000 loss_test: 1.2106 acc_test: 0.6790 time: 0.3461s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9995 acc_val: 0.4267 loss_test: 1.2795 acc_test: 0.6810 time: 0.3393s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1054 acc_val: 0.4500 loss_test: 1.3410 acc_test: 0.6810 time: 0.3444s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1375 acc_val: 0.4700 loss_test: 1.3767 acc_test: 0.6900 time: 0.3181s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1961 acc_val: 0.4767 loss_test: 1.4193 acc_test: 0.6860 time: 0.3391s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2311 acc_val: 0.4933 loss_test: 1.4514 acc_test: 0.6910 time: 0.3676s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2717 acc_val: 0.5033 loss_test: 1.4835 acc_test: 0.6930 time: 0.3554s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3075 acc_val: 0.5000 loss_test: 1.5128 acc_test: 0.6930 time: 0.3209s
Optimization Finished!
Total time elapsed: 165.5669s, best testing performance  0.696000, minimun loss  0.969068
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7754 acc_train: 0.2583 loss_val: 1.8090 acc_val: 0.1400 loss_test: 1.6409 acc_test: 0.5050 time: 0.3817s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.9165 acc_val: 0.3733 loss_test: 1.1906 acc_test: 0.6640 time: 0.3201s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9183 acc_val: 0.4100 loss_test: 1.2092 acc_test: 0.6780 time: 0.3250s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0062 acc_val: 0.4300 loss_test: 1.2804 acc_test: 0.6850 time: 0.3103s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0257 acc_val: 0.4733 loss_test: 1.3250 acc_test: 0.6860 time: 0.3201s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0534 acc_val: 0.4867 loss_test: 1.3598 acc_test: 0.6900 time: 0.3449s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0655 acc_val: 0.4900 loss_test: 1.3847 acc_test: 0.6940 time: 0.3259s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0982 acc_val: 0.4933 loss_test: 1.4189 acc_test: 0.6930 time: 0.3471s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0975 acc_val: 0.5033 loss_test: 1.4393 acc_test: 0.6990 time: 0.3436s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1315 acc_val: 0.5133 loss_test: 1.4707 acc_test: 0.6980 time: 0.3179s
Optimization Finished!
Total time elapsed: 165.5448s, best testing performance  0.704000, minimun loss  0.957715
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7903 acc_train: 0.1667 loss_val: 1.8068 acc_val: 0.1700 loss_test: 1.6556 acc_test: 0.5110 time: 0.3781s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8844 acc_val: 0.3800 loss_test: 1.1819 acc_test: 0.6630 time: 0.3283s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8521 acc_val: 0.4067 loss_test: 1.1869 acc_test: 0.6760 time: 0.3177s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9225 acc_val: 0.4400 loss_test: 1.2530 acc_test: 0.6840 time: 0.3165s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9920 acc_val: 0.4533 loss_test: 1.3061 acc_test: 0.6850 time: 0.3154s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0401 acc_val: 0.4800 loss_test: 1.3426 acc_test: 0.6890 time: 0.3327s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1166 acc_val: 0.4833 loss_test: 1.3882 acc_test: 0.6920 time: 0.3008s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1653 acc_val: 0.4933 loss_test: 1.4206 acc_test: 0.6940 time: 0.3448s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1980 acc_val: 0.5000 loss_test: 1.4461 acc_test: 0.6930 time: 0.3389s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2435 acc_val: 0.5033 loss_test: 1.4773 acc_test: 0.6960 time: 0.3407s
Optimization Finished!
Total time elapsed: 165.5366s, best testing performance  0.699000, minimun loss  0.955486
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8064 acc_train: 0.1167 loss_val: 1.8184 acc_val: 0.0900 loss_test: 1.6753 acc_test: 0.4730 time: 0.4059s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8013 acc_val: 0.3833 loss_test: 1.1574 acc_test: 0.6720 time: 0.3299s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8043 acc_val: 0.4367 loss_test: 1.1777 acc_test: 0.6860 time: 0.3211s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9711 acc_val: 0.4400 loss_test: 1.2713 acc_test: 0.6870 time: 0.3142s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0232 acc_val: 0.4667 loss_test: 1.3200 acc_test: 0.6880 time: 0.3216s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0691 acc_val: 0.4800 loss_test: 1.3572 acc_test: 0.6950 time: 0.3262s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1210 acc_val: 0.4967 loss_test: 1.3953 acc_test: 0.6890 time: 0.3184s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1473 acc_val: 0.5067 loss_test: 1.4226 acc_test: 0.6890 time: 0.3328s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1817 acc_val: 0.5067 loss_test: 1.4529 acc_test: 0.6910 time: 0.3528s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1836 acc_val: 0.5067 loss_test: 1.4695 acc_test: 0.6940 time: 0.3164s
Optimization Finished!
Total time elapsed: 164.8662s, best testing performance  0.696000, minimun loss  0.956379
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1917 loss_val: 1.8446 acc_val: 0.0767 loss_test: 1.6624 acc_test: 0.3740 time: 0.4235s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8920 acc_val: 0.3800 loss_test: 1.1857 acc_test: 0.6680 time: 0.3152s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9035 acc_val: 0.4267 loss_test: 1.2001 acc_test: 0.6870 time: 0.3209s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9928 acc_val: 0.4567 loss_test: 1.2720 acc_test: 0.6900 time: 0.3148s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0696 acc_val: 0.4600 loss_test: 1.3304 acc_test: 0.6910 time: 0.3039s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1049 acc_val: 0.4867 loss_test: 1.3725 acc_test: 0.6940 time: 0.3108s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1043 acc_val: 0.4967 loss_test: 1.4029 acc_test: 0.6940 time: 0.3240s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1659 acc_val: 0.4933 loss_test: 1.4415 acc_test: 0.6970 time: 0.3410s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2112 acc_val: 0.5000 loss_test: 1.4773 acc_test: 0.6940 time: 0.3534s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2257 acc_val: 0.5000 loss_test: 1.4967 acc_test: 0.6940 time: 0.3242s
Optimization Finished!
Total time elapsed: 164.9476s, best testing performance  0.698000, minimun loss  0.971320
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7950 acc_train: 0.1917 loss_val: 1.8382 acc_val: 0.1300 loss_test: 1.6745 acc_test: 0.4400 time: 0.3837s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.9873 acc_val: 0.3433 loss_test: 1.2283 acc_test: 0.6540 time: 0.3102s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9488 acc_val: 0.4000 loss_test: 1.2333 acc_test: 0.6600 time: 0.3121s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0024 acc_val: 0.4267 loss_test: 1.2846 acc_test: 0.6770 time: 0.3196s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0195 acc_val: 0.4700 loss_test: 1.3129 acc_test: 0.6840 time: 0.3240s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0408 acc_val: 0.4833 loss_test: 1.3434 acc_test: 0.6890 time: 0.3146s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0382 acc_val: 0.4967 loss_test: 1.3645 acc_test: 0.6930 time: 0.3212s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0421 acc_val: 0.5100 loss_test: 1.3880 acc_test: 0.7020 time: 0.3335s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0635 acc_val: 0.5100 loss_test: 1.4148 acc_test: 0.7060 time: 0.3442s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0777 acc_val: 0.5200 loss_test: 1.4387 acc_test: 0.7000 time: 0.3334s
Optimization Finished!
Total time elapsed: 164.2761s, best testing performance  0.707000, minimun loss  0.997850
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7995 acc_train: 0.1167 loss_val: 1.7996 acc_val: 0.1867 loss_test: 1.6742 acc_test: 0.4850 time: 0.4082s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9122 acc_val: 0.3633 loss_test: 1.1899 acc_test: 0.6620 time: 0.3325s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8602 acc_val: 0.4233 loss_test: 1.1953 acc_test: 0.6760 time: 0.3191s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9839 acc_val: 0.4433 loss_test: 1.2728 acc_test: 0.6810 time: 0.3253s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0806 acc_val: 0.4533 loss_test: 1.3308 acc_test: 0.6830 time: 0.3203s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1538 acc_val: 0.4700 loss_test: 1.3741 acc_test: 0.6920 time: 0.3150s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2149 acc_val: 0.4767 loss_test: 1.4132 acc_test: 0.6920 time: 0.3367s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2445 acc_val: 0.4767 loss_test: 1.4447 acc_test: 0.6940 time: 0.3461s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2717 acc_val: 0.4833 loss_test: 1.4731 acc_test: 0.6970 time: 0.3530s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2841 acc_val: 0.4767 loss_test: 1.4980 acc_test: 0.6960 time: 0.3356s
Optimization Finished!
Total time elapsed: 164.5182s, best testing performance  0.701000, minimun loss  0.966693
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7589 acc_train: 0.3833 loss_val: 1.8129 acc_val: 0.1800 loss_test: 1.6418 acc_test: 0.5450 time: 0.4047s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7044 acc_val: 0.4133 loss_test: 1.1474 acc_test: 0.6760 time: 0.3225s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7255 acc_val: 0.4600 loss_test: 1.1669 acc_test: 0.6840 time: 0.3236s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8983 acc_val: 0.4467 loss_test: 1.2571 acc_test: 0.6850 time: 0.3222s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9938 acc_val: 0.4633 loss_test: 1.3178 acc_test: 0.6860 time: 0.3238s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0490 acc_val: 0.4700 loss_test: 1.3587 acc_test: 0.6880 time: 0.3187s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0842 acc_val: 0.4833 loss_test: 1.3923 acc_test: 0.6880 time: 0.3540s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0953 acc_val: 0.4967 loss_test: 1.4158 acc_test: 0.6940 time: 0.3506s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1395 acc_val: 0.5100 loss_test: 1.4505 acc_test: 0.6940 time: 0.3407s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1430 acc_val: 0.5133 loss_test: 1.4694 acc_test: 0.6940 time: 0.3154s
Optimization Finished!
Total time elapsed: 165.6193s, best testing performance  0.699000, minimun loss  0.953363
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7935 acc_train: 0.1583 loss_val: 1.8225 acc_val: 0.0567 loss_test: 1.6631 acc_test: 0.3310 time: 0.4140s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8855 acc_val: 0.3733 loss_test: 1.2057 acc_test: 0.6590 time: 0.3152s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8854 acc_val: 0.4033 loss_test: 1.2216 acc_test: 0.6680 time: 0.3183s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0013 acc_val: 0.4133 loss_test: 1.2904 acc_test: 0.6750 time: 0.3120s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4467 loss_test: 1.3285 acc_test: 0.6850 time: 0.3229s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.4600 loss_test: 1.3669 acc_test: 0.6850 time: 0.3130s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1517 acc_val: 0.4767 loss_test: 1.3948 acc_test: 0.6880 time: 0.3204s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1646 acc_val: 0.4800 loss_test: 1.4177 acc_test: 0.6890 time: 0.3167s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2126 acc_val: 0.4867 loss_test: 1.4474 acc_test: 0.6920 time: 0.3365s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2158 acc_val: 0.5033 loss_test: 1.4650 acc_test: 0.6930 time: 0.3284s
Optimization Finished!
Total time elapsed: 164.1219s, best testing performance  0.695000, minimun loss  0.960654
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.2250 loss_val: 1.8181 acc_val: 0.1400 loss_test: 1.6503 acc_test: 0.5100 time: 0.3835s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.9293 acc_val: 0.3700 loss_test: 1.1950 acc_test: 0.6580 time: 0.3074s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9072 acc_val: 0.4067 loss_test: 1.1987 acc_test: 0.6710 time: 0.3308s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9955 acc_val: 0.4100 loss_test: 1.2609 acc_test: 0.6770 time: 0.3217s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0281 acc_val: 0.4467 loss_test: 1.3046 acc_test: 0.6870 time: 0.3155s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0385 acc_val: 0.4767 loss_test: 1.3401 acc_test: 0.6920 time: 0.3225s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0702 acc_val: 0.4967 loss_test: 1.3739 acc_test: 0.6910 time: 0.3228s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0942 acc_val: 0.5100 loss_test: 1.4048 acc_test: 0.6950 time: 0.3725s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1083 acc_val: 0.5067 loss_test: 1.4285 acc_test: 0.6970 time: 0.3416s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1356 acc_val: 0.5033 loss_test: 1.4551 acc_test: 0.6990 time: 0.3231s
Optimization Finished!
Total time elapsed: 165.9327s, best testing performance  0.702000, minimun loss  0.951843
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7942 acc_train: 0.1667 loss_val: 1.7895 acc_val: 0.1967 loss_test: 1.6899 acc_test: 0.5320 time: 0.3835s
Epoch: 0051 loss_train: 0.0119 acc_train: 1.0000 loss_val: 1.6660 acc_val: 0.4300 loss_test: 1.0910 acc_test: 0.6740 time: 0.3213s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7862 acc_val: 0.4333 loss_test: 1.1607 acc_test: 0.6720 time: 0.3219s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9411 acc_val: 0.4300 loss_test: 1.2392 acc_test: 0.6820 time: 0.3364s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0131 acc_val: 0.4433 loss_test: 1.2887 acc_test: 0.6830 time: 0.3127s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0380 acc_val: 0.4633 loss_test: 1.3268 acc_test: 0.6890 time: 0.3221s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0603 acc_val: 0.4667 loss_test: 1.3649 acc_test: 0.6920 time: 0.3308s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1048 acc_val: 0.4933 loss_test: 1.4028 acc_test: 0.6970 time: 0.3204s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1432 acc_val: 0.4933 loss_test: 1.4385 acc_test: 0.6970 time: 0.3532s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1545 acc_val: 0.5067 loss_test: 1.4635 acc_test: 0.6950 time: 0.3188s
Optimization Finished!
Total time elapsed: 165.2130s, best testing performance  0.700000, minimun loss  0.946156
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7865 acc_train: 0.1667 loss_val: 1.8169 acc_val: 0.1833 loss_test: 1.6897 acc_test: 0.4700 time: 0.3777s
Epoch: 0051 loss_train: 0.0122 acc_train: 1.0000 loss_val: 1.6414 acc_val: 0.4200 loss_test: 1.0712 acc_test: 0.6840 time: 0.3133s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7309 acc_val: 0.4567 loss_test: 1.1175 acc_test: 0.6910 time: 0.3422s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.8811 acc_val: 0.4567 loss_test: 1.2099 acc_test: 0.6910 time: 0.3347s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9894 acc_val: 0.4600 loss_test: 1.2740 acc_test: 0.6900 time: 0.3159s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0278 acc_val: 0.4800 loss_test: 1.3099 acc_test: 0.6900 time: 0.3254s
Epoch: 0301 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0626 acc_val: 0.4967 loss_test: 1.3442 acc_test: 0.6930 time: 0.3430s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1119 acc_val: 0.5067 loss_test: 1.3812 acc_test: 0.6960 time: 0.3548s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1321 acc_val: 0.4967 loss_test: 1.4085 acc_test: 0.6970 time: 0.3307s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.5033 loss_test: 1.4406 acc_test: 0.6960 time: 0.3442s
Optimization Finished!
Total time elapsed: 165.6799s, best testing performance  0.698000, minimun loss  0.970579
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7949 acc_train: 0.1667 loss_val: 1.8182 acc_val: 0.1433 loss_test: 1.6872 acc_test: 0.5270 time: 0.3879s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.5875 acc_val: 0.4267 loss_test: 1.0822 acc_test: 0.6820 time: 0.3389s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7029 acc_val: 0.4533 loss_test: 1.1507 acc_test: 0.6820 time: 0.3182s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8847 acc_val: 0.4600 loss_test: 1.2454 acc_test: 0.6850 time: 0.3169s
Epoch: 0201 loss_train: 0.0050 acc_train: 1.0000 loss_val: 1.9580 acc_val: 0.4767 loss_test: 1.2992 acc_test: 0.6900 time: 0.3293s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0033 acc_val: 0.4967 loss_test: 1.3460 acc_test: 0.6950 time: 0.3213s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0557 acc_val: 0.5000 loss_test: 1.3910 acc_test: 0.6900 time: 0.3398s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1110 acc_val: 0.5033 loss_test: 1.4363 acc_test: 0.6920 time: 0.3295s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1642 acc_val: 0.5133 loss_test: 1.4786 acc_test: 0.6970 time: 0.3340s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2228 acc_val: 0.5200 loss_test: 1.5185 acc_test: 0.6980 time: 0.3432s
Optimization Finished!
Total time elapsed: 165.3303s, best testing performance  0.702000, minimun loss  0.978526
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7905 acc_train: 0.1833 loss_val: 1.8099 acc_val: 0.1433 loss_test: 1.6893 acc_test: 0.4730 time: 0.3946s
Epoch: 0051 loss_train: 0.0116 acc_train: 1.0000 loss_val: 1.6295 acc_val: 0.4367 loss_test: 1.0848 acc_test: 0.6890 time: 0.3173s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.6582 acc_val: 0.4600 loss_test: 1.1160 acc_test: 0.6950 time: 0.3200s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8298 acc_val: 0.4733 loss_test: 1.2136 acc_test: 0.6890 time: 0.3111s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9599 acc_val: 0.4667 loss_test: 1.2818 acc_test: 0.6860 time: 0.3153s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9843 acc_val: 0.4800 loss_test: 1.3195 acc_test: 0.6930 time: 0.3441s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9969 acc_val: 0.5067 loss_test: 1.3525 acc_test: 0.6960 time: 0.3526s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0481 acc_val: 0.5100 loss_test: 1.3914 acc_test: 0.6990 time: 0.3415s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0651 acc_val: 0.5200 loss_test: 1.4156 acc_test: 0.7020 time: 0.3399s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1076 acc_val: 0.5200 loss_test: 1.4471 acc_test: 0.7030 time: 0.3444s
Optimization Finished!
Total time elapsed: 166.1843s, best testing performance  0.706000, minimun loss  0.972055
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7814 acc_train: 0.2750 loss_val: 1.8237 acc_val: 0.1033 loss_test: 1.6787 acc_test: 0.3950 time: 0.3721s
Epoch: 0051 loss_train: 0.0124 acc_train: 1.0000 loss_val: 1.6737 acc_val: 0.4333 loss_test: 1.0966 acc_test: 0.6860 time: 0.3523s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.6739 acc_val: 0.4700 loss_test: 1.1162 acc_test: 0.6960 time: 0.3364s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.8352 acc_val: 0.4833 loss_test: 1.2077 acc_test: 0.6910 time: 0.3058s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9309 acc_val: 0.4800 loss_test: 1.2669 acc_test: 0.6920 time: 0.3100s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9742 acc_val: 0.4800 loss_test: 1.3115 acc_test: 0.6910 time: 0.3168s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0428 acc_val: 0.4967 loss_test: 1.3570 acc_test: 0.6960 time: 0.3371s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0820 acc_val: 0.5067 loss_test: 1.3964 acc_test: 0.6960 time: 0.3383s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1494 acc_val: 0.5133 loss_test: 1.4389 acc_test: 0.6990 time: 0.3438s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2153 acc_val: 0.5100 loss_test: 1.4793 acc_test: 0.6950 time: 0.3349s
Optimization Finished!
Total time elapsed: 167.7598s, best testing performance  0.700000, minimun loss  0.979079
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8083 acc_train: 0.1833 loss_val: 1.8149 acc_val: 0.0833 loss_test: 1.6744 acc_test: 0.4440 time: 0.4392s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8208 acc_val: 0.3833 loss_test: 1.1714 acc_test: 0.6690 time: 0.3231s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8813 acc_val: 0.4167 loss_test: 1.2135 acc_test: 0.6790 time: 0.3180s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.9969 acc_val: 0.4333 loss_test: 1.2798 acc_test: 0.6800 time: 0.3495s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0181 acc_val: 0.4700 loss_test: 1.3193 acc_test: 0.6850 time: 0.3159s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0425 acc_val: 0.4767 loss_test: 1.3519 acc_test: 0.6900 time: 0.3398s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0405 acc_val: 0.4900 loss_test: 1.3833 acc_test: 0.6920 time: 0.3420s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0367 acc_val: 0.5200 loss_test: 1.4095 acc_test: 0.7010 time: 0.3138s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.0855 acc_val: 0.5233 loss_test: 1.4459 acc_test: 0.6990 time: 0.3155s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1130 acc_val: 0.5300 loss_test: 1.4749 acc_test: 0.6990 time: 0.3440s
Optimization Finished!
Total time elapsed: 162.9260s, best testing performance  0.701000, minimun loss  0.958781
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7919 acc_train: 0.2083 loss_val: 1.8158 acc_val: 0.1467 loss_test: 1.6637 acc_test: 0.5370 time: 0.4049s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8885 acc_val: 0.3967 loss_test: 1.1798 acc_test: 0.6680 time: 0.3078s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9533 acc_val: 0.4033 loss_test: 1.2208 acc_test: 0.6860 time: 0.3102s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0561 acc_val: 0.4400 loss_test: 1.2877 acc_test: 0.6830 time: 0.3123s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1009 acc_val: 0.4733 loss_test: 1.3297 acc_test: 0.6870 time: 0.3298s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1055 acc_val: 0.4800 loss_test: 1.3598 acc_test: 0.6930 time: 0.3195s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0961 acc_val: 0.4900 loss_test: 1.3857 acc_test: 0.6990 time: 0.3185s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1157 acc_val: 0.5067 loss_test: 1.4151 acc_test: 0.7010 time: 0.3437s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1490 acc_val: 0.5100 loss_test: 1.4483 acc_test: 0.7030 time: 0.3500s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.5033 loss_test: 1.4666 acc_test: 0.7030 time: 0.3469s
Optimization Finished!
Total time elapsed: 163.8931s, best testing performance  0.707000, minimun loss  0.962787
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1417 loss_val: 1.8239 acc_val: 0.1033 loss_test: 1.6928 acc_test: 0.4360 time: 0.4024s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.8621 acc_val: 0.3933 loss_test: 1.1727 acc_test: 0.6690 time: 0.3110s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8433 acc_val: 0.4400 loss_test: 1.1905 acc_test: 0.6920 time: 0.3178s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9271 acc_val: 0.4600 loss_test: 1.2553 acc_test: 0.6900 time: 0.3137s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0111 acc_val: 0.4767 loss_test: 1.3090 acc_test: 0.6880 time: 0.3072s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0868 acc_val: 0.4867 loss_test: 1.3551 acc_test: 0.6940 time: 0.3141s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1515 acc_val: 0.4933 loss_test: 1.3959 acc_test: 0.6940 time: 0.3119s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1883 acc_val: 0.4933 loss_test: 1.4319 acc_test: 0.6940 time: 0.3479s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2260 acc_val: 0.5033 loss_test: 1.4621 acc_test: 0.6970 time: 0.3381s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2479 acc_val: 0.5100 loss_test: 1.4898 acc_test: 0.6960 time: 0.3230s
Optimization Finished!
Total time elapsed: 164.7772s, best testing performance  0.701000, minimun loss  0.959279
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8091 acc_train: 0.1167 loss_val: 1.7820 acc_val: 0.1800 loss_test: 1.6646 acc_test: 0.5580 time: 0.4030s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8725 acc_val: 0.3933 loss_test: 1.1644 acc_test: 0.6680 time: 0.3319s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9558 acc_val: 0.3933 loss_test: 1.2138 acc_test: 0.6810 time: 0.3208s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0298 acc_val: 0.4200 loss_test: 1.2717 acc_test: 0.6840 time: 0.3334s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0752 acc_val: 0.4533 loss_test: 1.3158 acc_test: 0.6870 time: 0.3172s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0892 acc_val: 0.4600 loss_test: 1.3576 acc_test: 0.6940 time: 0.3038s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1532 acc_val: 0.4900 loss_test: 1.4053 acc_test: 0.6940 time: 0.3308s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1972 acc_val: 0.5033 loss_test: 1.4456 acc_test: 0.7030 time: 0.3353s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2183 acc_val: 0.5133 loss_test: 1.4780 acc_test: 0.7020 time: 0.3536s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2620 acc_val: 0.5100 loss_test: 1.5146 acc_test: 0.7010 time: 0.3159s
Optimization Finished!
Total time elapsed: 163.3509s, best testing performance  0.706000, minimun loss  0.939328
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7925 acc_train: 0.1833 loss_val: 1.7944 acc_val: 0.1667 loss_test: 1.6458 acc_test: 0.5650 time: 0.4164s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.9332 acc_val: 0.3833 loss_test: 1.1933 acc_test: 0.6630 time: 0.3178s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9290 acc_val: 0.4133 loss_test: 1.2115 acc_test: 0.6780 time: 0.3239s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0042 acc_val: 0.4333 loss_test: 1.2651 acc_test: 0.6840 time: 0.3145s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0623 acc_val: 0.4567 loss_test: 1.3088 acc_test: 0.6870 time: 0.3142s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0964 acc_val: 0.4700 loss_test: 1.3453 acc_test: 0.6860 time: 0.3273s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1290 acc_val: 0.4867 loss_test: 1.3818 acc_test: 0.6900 time: 0.3324s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1287 acc_val: 0.4900 loss_test: 1.4048 acc_test: 0.6950 time: 0.3505s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1086 acc_val: 0.5133 loss_test: 1.4246 acc_test: 0.6960 time: 0.3135s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1404 acc_val: 0.5200 loss_test: 1.4516 acc_test: 0.6960 time: 0.3316s
Optimization Finished!
Total time elapsed: 163.4560s, best testing performance  0.700000, minimun loss  0.937046
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8066 acc_train: 0.1000 loss_val: 1.8183 acc_val: 0.1200 loss_test: 1.6777 acc_test: 0.4500 time: 0.4267s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.6133 acc_val: 0.4500 loss_test: 1.0828 acc_test: 0.6880 time: 0.3177s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7470 acc_val: 0.4500 loss_test: 1.1533 acc_test: 0.6960 time: 0.3199s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9292 acc_val: 0.4633 loss_test: 1.2504 acc_test: 0.6910 time: 0.3309s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0259 acc_val: 0.4733 loss_test: 1.3044 acc_test: 0.6860 time: 0.3127s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0247 acc_val: 0.4767 loss_test: 1.3324 acc_test: 0.6940 time: 0.3150s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0848 acc_val: 0.4833 loss_test: 1.3743 acc_test: 0.6950 time: 0.3207s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0941 acc_val: 0.5033 loss_test: 1.4044 acc_test: 0.7000 time: 0.3687s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1134 acc_val: 0.5167 loss_test: 1.4332 acc_test: 0.7010 time: 0.3737s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1508 acc_val: 0.5133 loss_test: 1.4636 acc_test: 0.6980 time: 0.3154s
Optimization Finished!
Total time elapsed: 165.3355s, best testing performance  0.705000, minimun loss  0.938890
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7981 acc_train: 0.1500 loss_val: 1.8221 acc_val: 0.1933 loss_test: 1.6488 acc_test: 0.5420 time: 0.3957s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.9659 acc_val: 0.3600 loss_test: 1.2329 acc_test: 0.6640 time: 0.3225s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 2.0218 acc_val: 0.3967 loss_test: 1.2662 acc_test: 0.6690 time: 0.3259s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.1179 acc_val: 0.4300 loss_test: 1.3267 acc_test: 0.6790 time: 0.2982s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1857 acc_val: 0.4467 loss_test: 1.3680 acc_test: 0.6860 time: 0.3347s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1824 acc_val: 0.4600 loss_test: 1.3942 acc_test: 0.6880 time: 0.3144s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1982 acc_val: 0.4833 loss_test: 1.4238 acc_test: 0.6920 time: 0.3097s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2117 acc_val: 0.5067 loss_test: 1.4572 acc_test: 0.6960 time: 0.3781s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2151 acc_val: 0.5033 loss_test: 1.4790 acc_test: 0.6980 time: 0.3741s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2576 acc_val: 0.4967 loss_test: 1.5147 acc_test: 0.6960 time: 0.3221s
Optimization Finished!
Total time elapsed: 165.4760s, best testing performance  0.701000, minimun loss  0.968313
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7917 acc_train: 0.1583 loss_val: 1.8085 acc_val: 0.1433 loss_test: 1.6268 acc_test: 0.5370 time: 0.4082s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7653 acc_val: 0.3933 loss_test: 1.1583 acc_test: 0.6770 time: 0.3255s
Epoch: 0101 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.7441 acc_val: 0.4367 loss_test: 1.1726 acc_test: 0.6860 time: 0.3533s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8734 acc_val: 0.4567 loss_test: 1.2530 acc_test: 0.6930 time: 0.3124s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9690 acc_val: 0.4600 loss_test: 1.3086 acc_test: 0.6940 time: 0.3206s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0539 acc_val: 0.4667 loss_test: 1.3587 acc_test: 0.6920 time: 0.3263s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0649 acc_val: 0.5033 loss_test: 1.3866 acc_test: 0.6950 time: 0.3414s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1179 acc_val: 0.4933 loss_test: 1.4185 acc_test: 0.6950 time: 0.3702s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1106 acc_val: 0.5067 loss_test: 1.4372 acc_test: 0.6990 time: 0.3405s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1400 acc_val: 0.5033 loss_test: 1.4619 acc_test: 0.7010 time: 0.3266s
Optimization Finished!
Total time elapsed: 165.6415s, best testing performance  0.703000, minimun loss  0.944052
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7912 acc_train: 0.2750 loss_val: 1.8064 acc_val: 0.0933 loss_test: 1.6556 acc_test: 0.4590 time: 0.3844s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7420 acc_val: 0.4067 loss_test: 1.1501 acc_test: 0.6700 time: 0.3200s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.7396 acc_val: 0.4333 loss_test: 1.1711 acc_test: 0.6870 time: 0.3286s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8830 acc_val: 0.4533 loss_test: 1.2551 acc_test: 0.6910 time: 0.3187s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9708 acc_val: 0.4533 loss_test: 1.3072 acc_test: 0.6930 time: 0.3286s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0368 acc_val: 0.4833 loss_test: 1.3496 acc_test: 0.6910 time: 0.3216s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1123 acc_val: 0.4900 loss_test: 1.3910 acc_test: 0.6930 time: 0.3146s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1684 acc_val: 0.4967 loss_test: 1.4228 acc_test: 0.6970 time: 0.3636s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2225 acc_val: 0.5000 loss_test: 1.4547 acc_test: 0.6950 time: 0.3465s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2880 acc_val: 0.4967 loss_test: 1.4853 acc_test: 0.6960 time: 0.3274s
Optimization Finished!
Total time elapsed: 165.4963s, best testing performance  0.699000, minimun loss  0.935981
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7886 acc_train: 0.1917 loss_val: 1.8058 acc_val: 0.1667 loss_test: 1.6487 acc_test: 0.5160 time: 0.3638s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7656 acc_val: 0.4267 loss_test: 1.1546 acc_test: 0.6800 time: 0.3115s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7718 acc_val: 0.4700 loss_test: 1.1688 acc_test: 0.6990 time: 0.3199s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8913 acc_val: 0.4767 loss_test: 1.2416 acc_test: 0.6970 time: 0.3326s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9985 acc_val: 0.4633 loss_test: 1.3016 acc_test: 0.6960 time: 0.3167s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0787 acc_val: 0.4767 loss_test: 1.3495 acc_test: 0.6930 time: 0.3117s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1249 acc_val: 0.4800 loss_test: 1.3871 acc_test: 0.6930 time: 0.3179s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1477 acc_val: 0.4900 loss_test: 1.4197 acc_test: 0.6920 time: 0.3502s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1603 acc_val: 0.5067 loss_test: 1.4416 acc_test: 0.6970 time: 0.3508s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1983 acc_val: 0.5000 loss_test: 1.4690 acc_test: 0.6970 time: 0.3353s
Optimization Finished!
Total time elapsed: 165.3165s, best testing performance  0.700000, minimun loss  0.948525
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7985 acc_train: 0.1500 loss_val: 1.8159 acc_val: 0.1800 loss_test: 1.6606 acc_test: 0.4890 time: 0.4040s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7218 acc_val: 0.4033 loss_test: 1.1470 acc_test: 0.6670 time: 0.3181s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8806 acc_val: 0.4133 loss_test: 1.2116 acc_test: 0.6820 time: 0.3105s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.0360 acc_val: 0.4333 loss_test: 1.2926 acc_test: 0.6860 time: 0.3267s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0841 acc_val: 0.4667 loss_test: 1.3331 acc_test: 0.6880 time: 0.3278s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0775 acc_val: 0.4800 loss_test: 1.3593 acc_test: 0.6910 time: 0.3115s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1155 acc_val: 0.4933 loss_test: 1.4008 acc_test: 0.6960 time: 0.3501s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1381 acc_val: 0.5100 loss_test: 1.4323 acc_test: 0.6960 time: 0.4376s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1796 acc_val: 0.5133 loss_test: 1.4675 acc_test: 0.6920 time: 0.3308s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2146 acc_val: 0.5133 loss_test: 1.4957 acc_test: 0.6960 time: 0.3126s
Optimization Finished!
Total time elapsed: 166.2206s, best testing performance  0.699000, minimun loss  0.949164
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8124 acc_train: 0.0667 loss_val: 1.8451 acc_val: 0.1600 loss_test: 1.6749 acc_test: 0.4440 time: 0.4110s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7241 acc_val: 0.4200 loss_test: 1.1707 acc_test: 0.6800 time: 0.3138s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8422 acc_val: 0.4333 loss_test: 1.2346 acc_test: 0.6820 time: 0.3154s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9992 acc_val: 0.4500 loss_test: 1.3159 acc_test: 0.6900 time: 0.3201s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0326 acc_val: 0.4767 loss_test: 1.3555 acc_test: 0.6910 time: 0.3197s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0239 acc_val: 0.4800 loss_test: 1.3839 acc_test: 0.6970 time: 0.3314s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0095 acc_val: 0.4933 loss_test: 1.4138 acc_test: 0.7010 time: 0.3206s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0511 acc_val: 0.5200 loss_test: 1.4502 acc_test: 0.7030 time: 0.3398s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0560 acc_val: 0.5167 loss_test: 1.4785 acc_test: 0.7040 time: 0.3373s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.0526 acc_val: 0.5267 loss_test: 1.4983 acc_test: 0.6970 time: 0.3456s
Optimization Finished!
Total time elapsed: 165.4394s, best testing performance  0.705000, minimun loss  0.971407
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7947 acc_train: 0.1750 loss_val: 1.8562 acc_val: 0.1767 loss_test: 1.6585 acc_test: 0.4760 time: 0.3750s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.6646 acc_val: 0.4100 loss_test: 1.1216 acc_test: 0.6850 time: 0.3193s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7645 acc_val: 0.4500 loss_test: 1.1759 acc_test: 0.6900 time: 0.3013s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9578 acc_val: 0.4533 loss_test: 1.2776 acc_test: 0.6870 time: 0.3199s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0416 acc_val: 0.4733 loss_test: 1.3244 acc_test: 0.6890 time: 0.3414s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1093 acc_val: 0.4833 loss_test: 1.3625 acc_test: 0.6920 time: 0.3209s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1703 acc_val: 0.4800 loss_test: 1.4020 acc_test: 0.6910 time: 0.3291s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1856 acc_val: 0.4867 loss_test: 1.4266 acc_test: 0.6970 time: 0.3908s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2101 acc_val: 0.5000 loss_test: 1.4581 acc_test: 0.7010 time: 0.3465s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2294 acc_val: 0.5033 loss_test: 1.4793 acc_test: 0.7010 time: 0.3225s
Optimization Finished!
Total time elapsed: 166.0361s, best testing performance  0.704000, minimun loss  0.962245
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7865 acc_train: 0.2083 loss_val: 1.8253 acc_val: 0.0500 loss_test: 1.6797 acc_test: 0.3360 time: 0.3786s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6299 acc_val: 0.4200 loss_test: 1.0988 acc_test: 0.6800 time: 0.3117s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7568 acc_val: 0.4467 loss_test: 1.1632 acc_test: 0.6890 time: 0.3193s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9027 acc_val: 0.4533 loss_test: 1.2464 acc_test: 0.6890 time: 0.3179s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0065 acc_val: 0.4600 loss_test: 1.3047 acc_test: 0.6890 time: 0.3175s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0591 acc_val: 0.4800 loss_test: 1.3463 acc_test: 0.6880 time: 0.3220s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1033 acc_val: 0.4900 loss_test: 1.3903 acc_test: 0.6930 time: 0.3222s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1487 acc_val: 0.4967 loss_test: 1.4320 acc_test: 0.6970 time: 0.3468s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1911 acc_val: 0.5067 loss_test: 1.4667 acc_test: 0.7000 time: 0.3366s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2859 acc_val: 0.5100 loss_test: 1.5198 acc_test: 0.7000 time: 0.3345s
Optimization Finished!
Total time elapsed: 165.7637s, best testing performance  0.702000, minimun loss  0.938254
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7746 acc_train: 0.2167 loss_val: 1.8123 acc_val: 0.1933 loss_test: 1.6579 acc_test: 0.4650 time: 0.3838s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.6237 acc_val: 0.4500 loss_test: 1.1153 acc_test: 0.6810 time: 0.3129s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.8497 acc_val: 0.4500 loss_test: 1.2049 acc_test: 0.6860 time: 0.3111s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9768 acc_val: 0.4567 loss_test: 1.2803 acc_test: 0.6870 time: 0.3493s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9951 acc_val: 0.4667 loss_test: 1.3162 acc_test: 0.6890 time: 0.3131s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0345 acc_val: 0.4733 loss_test: 1.3566 acc_test: 0.6860 time: 0.3297s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0670 acc_val: 0.5133 loss_test: 1.3924 acc_test: 0.6920 time: 0.3389s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1129 acc_val: 0.5033 loss_test: 1.4240 acc_test: 0.6930 time: 0.3409s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1684 acc_val: 0.4967 loss_test: 1.4585 acc_test: 0.6910 time: 0.3331s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1963 acc_val: 0.5033 loss_test: 1.4874 acc_test: 0.6950 time: 0.3170s
Optimization Finished!
Total time elapsed: 165.2295s, best testing performance  0.697000, minimun loss  0.951460
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8024 acc_train: 0.1500 loss_val: 1.7835 acc_val: 0.1433 loss_test: 1.6872 acc_test: 0.4290 time: 0.4694s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.6938 acc_val: 0.4467 loss_test: 1.1348 acc_test: 0.6750 time: 0.3285s
Epoch: 0101 loss_train: 0.0070 acc_train: 1.0000 loss_val: 1.6901 acc_val: 0.4800 loss_test: 1.1659 acc_test: 0.6910 time: 0.3185s
Epoch: 0151 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9094 acc_val: 0.4733 loss_test: 1.2638 acc_test: 0.6900 time: 0.3312s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9800 acc_val: 0.4867 loss_test: 1.3102 acc_test: 0.6920 time: 0.3957s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0480 acc_val: 0.4800 loss_test: 1.3546 acc_test: 0.6920 time: 0.3251s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0552 acc_val: 0.4900 loss_test: 1.3868 acc_test: 0.6960 time: 0.3409s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1543 acc_val: 0.5100 loss_test: 1.4371 acc_test: 0.6970 time: 0.3407s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1855 acc_val: 0.5100 loss_test: 1.4685 acc_test: 0.6960 time: 0.3500s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2326 acc_val: 0.5067 loss_test: 1.5014 acc_test: 0.6980 time: 0.3307s
Optimization Finished!
Total time elapsed: 165.7186s, best testing performance  0.702000, minimun loss  0.941508
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8055 acc_train: 0.1000 loss_val: 1.8032 acc_val: 0.1600 loss_test: 1.7101 acc_test: 0.4820 time: 0.4205s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.6885 acc_val: 0.4567 loss_test: 1.1586 acc_test: 0.6780 time: 0.3213s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8220 acc_val: 0.4733 loss_test: 1.2148 acc_test: 0.6910 time: 0.3346s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9547 acc_val: 0.4733 loss_test: 1.2807 acc_test: 0.6920 time: 0.3034s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0190 acc_val: 0.4767 loss_test: 1.3244 acc_test: 0.6900 time: 0.3426s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0640 acc_val: 0.4867 loss_test: 1.3655 acc_test: 0.6930 time: 0.3268s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1001 acc_val: 0.5033 loss_test: 1.4013 acc_test: 0.6970 time: 0.3101s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1534 acc_val: 0.5133 loss_test: 1.4390 acc_test: 0.6960 time: 0.3412s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1763 acc_val: 0.5100 loss_test: 1.4723 acc_test: 0.6960 time: 0.3599s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2017 acc_val: 0.5067 loss_test: 1.4984 acc_test: 0.6990 time: 0.3296s
Optimization Finished!
Total time elapsed: 165.8639s, best testing performance  0.701000, minimun loss  0.948992
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8108 acc_train: 0.1000 loss_val: 1.8234 acc_val: 0.1333 loss_test: 1.7158 acc_test: 0.4080 time: 0.3806s
Epoch: 0051 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7886 acc_val: 0.4167 loss_test: 1.1924 acc_test: 0.6620 time: 0.3194s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.7880 acc_val: 0.4400 loss_test: 1.1995 acc_test: 0.6830 time: 0.3386s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8955 acc_val: 0.4633 loss_test: 1.2596 acc_test: 0.6940 time: 0.3100s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9797 acc_val: 0.4633 loss_test: 1.3086 acc_test: 0.6910 time: 0.3273s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0642 acc_val: 0.4767 loss_test: 1.3563 acc_test: 0.6930 time: 0.3156s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0949 acc_val: 0.4767 loss_test: 1.3891 acc_test: 0.6940 time: 0.3163s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1658 acc_val: 0.4933 loss_test: 1.4271 acc_test: 0.6960 time: 0.3371s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1882 acc_val: 0.5067 loss_test: 1.4509 acc_test: 0.6950 time: 0.3575s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2193 acc_val: 0.5133 loss_test: 1.4755 acc_test: 0.6940 time: 0.3298s
Optimization Finished!
Total time elapsed: 165.6773s, best testing performance  0.700000, minimun loss  0.965937
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7979 acc_train: 0.1333 loss_val: 1.8296 acc_val: 0.0600 loss_test: 1.6943 acc_test: 0.3480 time: 0.4630s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 2.0503 acc_val: 0.3633 loss_test: 1.2687 acc_test: 0.6530 time: 0.3234s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9270 acc_val: 0.4333 loss_test: 1.2430 acc_test: 0.6720 time: 0.3113s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9730 acc_val: 0.4467 loss_test: 1.2946 acc_test: 0.6830 time: 0.3273s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0407 acc_val: 0.4600 loss_test: 1.3454 acc_test: 0.6860 time: 0.3378s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0943 acc_val: 0.4700 loss_test: 1.3808 acc_test: 0.6890 time: 0.3198s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1397 acc_val: 0.4867 loss_test: 1.4123 acc_test: 0.6910 time: 0.3160s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1797 acc_val: 0.5067 loss_test: 1.4470 acc_test: 0.6920 time: 0.3340s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2174 acc_val: 0.5133 loss_test: 1.4752 acc_test: 0.6930 time: 0.3467s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2319 acc_val: 0.5033 loss_test: 1.5001 acc_test: 0.6940 time: 0.3127s
Optimization Finished!
Total time elapsed: 165.2374s, best testing performance  0.698000, minimun loss  1.009951
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8081 acc_train: 0.1167 loss_val: 1.8096 acc_val: 0.1600 loss_test: 1.6915 acc_test: 0.4460 time: 0.3961s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.7217 acc_val: 0.4167 loss_test: 1.1594 acc_test: 0.6760 time: 0.3843s
Epoch: 0101 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.8031 acc_val: 0.4167 loss_test: 1.2125 acc_test: 0.6820 time: 0.3343s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9188 acc_val: 0.4533 loss_test: 1.2749 acc_test: 0.6870 time: 0.3473s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9794 acc_val: 0.4633 loss_test: 1.3145 acc_test: 0.6900 time: 0.2997s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0236 acc_val: 0.4833 loss_test: 1.3500 acc_test: 0.6930 time: 0.3168s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0653 acc_val: 0.4933 loss_test: 1.3841 acc_test: 0.6900 time: 0.3243s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1274 acc_val: 0.4967 loss_test: 1.4272 acc_test: 0.6930 time: 0.3464s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1443 acc_val: 0.5033 loss_test: 1.4532 acc_test: 0.6970 time: 0.3776s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2313 acc_val: 0.5033 loss_test: 1.4900 acc_test: 0.6960 time: 0.3303s
Optimization Finished!
Total time elapsed: 166.0829s, best testing performance  0.699000, minimun loss  0.962099
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8011 acc_train: 0.1417 loss_val: 1.7895 acc_val: 0.1567 loss_test: 1.6985 acc_test: 0.5090 time: 0.4798s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8298 acc_val: 0.3867 loss_test: 1.1672 acc_test: 0.6620 time: 0.3147s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8089 acc_val: 0.4333 loss_test: 1.1716 acc_test: 0.6800 time: 0.3085s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8783 acc_val: 0.4500 loss_test: 1.2218 acc_test: 0.6840 time: 0.3199s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9363 acc_val: 0.4500 loss_test: 1.2637 acc_test: 0.6860 time: 0.3256s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9915 acc_val: 0.4667 loss_test: 1.3056 acc_test: 0.6940 time: 0.3159s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0160 acc_val: 0.4767 loss_test: 1.3370 acc_test: 0.6920 time: 0.3429s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0497 acc_val: 0.4967 loss_test: 1.3712 acc_test: 0.6920 time: 0.3577s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0698 acc_val: 0.4967 loss_test: 1.3976 acc_test: 0.6930 time: 0.3473s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0954 acc_val: 0.5000 loss_test: 1.4277 acc_test: 0.6940 time: 0.3490s
Optimization Finished!
Total time elapsed: 166.3240s, best testing performance  0.699000, minimun loss  0.987715
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7961 acc_train: 0.1833 loss_val: 1.7912 acc_val: 0.2033 loss_test: 1.6840 acc_test: 0.3850 time: 0.4210s
Epoch: 0051 loss_train: 0.0118 acc_train: 1.0000 loss_val: 1.7259 acc_val: 0.4033 loss_test: 1.1576 acc_test: 0.6690 time: 0.3089s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8570 acc_val: 0.4167 loss_test: 1.2007 acc_test: 0.6760 time: 0.3166s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9456 acc_val: 0.4400 loss_test: 1.2503 acc_test: 0.6780 time: 0.3156s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9758 acc_val: 0.4667 loss_test: 1.2869 acc_test: 0.6840 time: 0.3364s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0106 acc_val: 0.4667 loss_test: 1.3237 acc_test: 0.6880 time: 0.3281s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0638 acc_val: 0.4800 loss_test: 1.3660 acc_test: 0.6890 time: 0.3428s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1001 acc_val: 0.5000 loss_test: 1.4024 acc_test: 0.6880 time: 0.3189s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1413 acc_val: 0.4933 loss_test: 1.4341 acc_test: 0.6890 time: 0.3226s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1803 acc_val: 0.4933 loss_test: 1.4677 acc_test: 0.6880 time: 0.3483s
Optimization Finished!
Total time elapsed: 166.2956s, best testing performance  0.692000, minimun loss  0.993304
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7995 acc_train: 0.1000 loss_val: 1.8100 acc_val: 0.2100 loss_test: 1.7023 acc_test: 0.5140 time: 0.4026s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.9839 acc_val: 0.3600 loss_test: 1.2155 acc_test: 0.6490 time: 0.3047s
Epoch: 0101 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9632 acc_val: 0.4000 loss_test: 1.2219 acc_test: 0.6720 time: 0.3150s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 2.0048 acc_val: 0.4333 loss_test: 1.2623 acc_test: 0.6790 time: 0.3143s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 2.0431 acc_val: 0.4667 loss_test: 1.2990 acc_test: 0.6840 time: 0.3137s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0723 acc_val: 0.4800 loss_test: 1.3366 acc_test: 0.6850 time: 0.3252s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1053 acc_val: 0.4733 loss_test: 1.3707 acc_test: 0.6930 time: 0.3214s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1362 acc_val: 0.4800 loss_test: 1.4034 acc_test: 0.6970 time: 0.3235s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1649 acc_val: 0.4967 loss_test: 1.4330 acc_test: 0.7020 time: 0.3419s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2166 acc_val: 0.5067 loss_test: 1.4647 acc_test: 0.6990 time: 0.3075s
Optimization Finished!
Total time elapsed: 163.0229s, best testing performance  0.704000, minimun loss  0.986322
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7844 acc_train: 0.1833 loss_val: 1.8182 acc_val: 0.1000 loss_test: 1.6840 acc_test: 0.4320 time: 0.4262s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.8967 acc_val: 0.3667 loss_test: 1.1978 acc_test: 0.6630 time: 0.3205s
Epoch: 0101 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8837 acc_val: 0.4100 loss_test: 1.2016 acc_test: 0.6670 time: 0.3706s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9286 acc_val: 0.4433 loss_test: 1.2457 acc_test: 0.6810 time: 0.3186s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9956 acc_val: 0.4567 loss_test: 1.2907 acc_test: 0.6860 time: 0.3018s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0388 acc_val: 0.4800 loss_test: 1.3314 acc_test: 0.6920 time: 0.3202s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0697 acc_val: 0.4867 loss_test: 1.3666 acc_test: 0.6930 time: 0.3212s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1028 acc_val: 0.5133 loss_test: 1.4021 acc_test: 0.6980 time: 0.3325s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1177 acc_val: 0.5167 loss_test: 1.4313 acc_test: 0.6990 time: 0.3220s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1614 acc_val: 0.5067 loss_test: 1.4654 acc_test: 0.6990 time: 0.3283s
Optimization Finished!
Total time elapsed: 162.8693s, best testing performance  0.703000, minimun loss  0.979658
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7938 acc_train: 0.1583 loss_val: 1.8076 acc_val: 0.1867 loss_test: 1.6778 acc_test: 0.5160 time: 0.3908s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7874 acc_val: 0.3933 loss_test: 1.1711 acc_test: 0.6710 time: 0.3208s
Epoch: 0101 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7934 acc_val: 0.4333 loss_test: 1.1830 acc_test: 0.6850 time: 0.3498s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.8767 acc_val: 0.4567 loss_test: 1.2400 acc_test: 0.6860 time: 0.3387s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9177 acc_val: 0.4733 loss_test: 1.2818 acc_test: 0.6880 time: 0.3252s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 1.9702 acc_val: 0.4867 loss_test: 1.3243 acc_test: 0.6940 time: 0.3071s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 1.9921 acc_val: 0.5000 loss_test: 1.3569 acc_test: 0.6950 time: 0.3202s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0224 acc_val: 0.5033 loss_test: 1.3900 acc_test: 0.6970 time: 0.3192s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0373 acc_val: 0.5067 loss_test: 1.4191 acc_test: 0.6980 time: 0.3332s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0767 acc_val: 0.5067 loss_test: 1.4509 acc_test: 0.6980 time: 0.3259s
Optimization Finished!
Total time elapsed: 163.1972s, best testing performance  0.701000, minimun loss  0.980856
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7889 acc_train: 0.1917 loss_val: 1.8343 acc_val: 0.0767 loss_test: 1.6645 acc_test: 0.3660 time: 0.3962s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8601 acc_val: 0.3867 loss_test: 1.2021 acc_test: 0.6630 time: 0.3408s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9855 acc_val: 0.4167 loss_test: 1.2596 acc_test: 0.6670 time: 0.3263s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4300 loss_test: 1.2943 acc_test: 0.6800 time: 0.3404s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0231 acc_val: 0.4633 loss_test: 1.3193 acc_test: 0.6850 time: 0.3204s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0462 acc_val: 0.4900 loss_test: 1.3502 acc_test: 0.6900 time: 0.3549s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0759 acc_val: 0.5000 loss_test: 1.3796 acc_test: 0.6920 time: 0.3389s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1334 acc_val: 0.5067 loss_test: 1.4176 acc_test: 0.6920 time: 0.3407s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1707 acc_val: 0.5033 loss_test: 1.4469 acc_test: 0.6930 time: 0.3492s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1799 acc_val: 0.5100 loss_test: 1.4669 acc_test: 0.6960 time: 0.3261s
Optimization Finished!
Total time elapsed: 166.4016s, best testing performance  0.696000, minimun loss  0.959149
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8002 acc_train: 0.1500 loss_val: 1.7991 acc_val: 0.1900 loss_test: 1.6856 acc_test: 0.3910 time: 0.3768s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7795 acc_val: 0.4100 loss_test: 1.1742 acc_test: 0.6740 time: 0.3344s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9143 acc_val: 0.4267 loss_test: 1.2234 acc_test: 0.6750 time: 0.3181s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9770 acc_val: 0.4600 loss_test: 1.2660 acc_test: 0.6860 time: 0.3396s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9881 acc_val: 0.4700 loss_test: 1.2988 acc_test: 0.6900 time: 0.3204s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0006 acc_val: 0.4933 loss_test: 1.3348 acc_test: 0.6920 time: 0.3189s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0295 acc_val: 0.5100 loss_test: 1.3690 acc_test: 0.6970 time: 0.3551s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.5100 loss_test: 1.3989 acc_test: 0.7010 time: 0.3490s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1025 acc_val: 0.5100 loss_test: 1.4327 acc_test: 0.7020 time: 0.3855s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1260 acc_val: 0.5000 loss_test: 1.4626 acc_test: 0.6990 time: 0.3383s
Optimization Finished!
Total time elapsed: 166.9746s, best testing performance  0.705000, minimun loss  0.968830
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8008 acc_train: 0.1167 loss_val: 1.8191 acc_val: 0.1100 loss_test: 1.6629 acc_test: 0.4930 time: 0.3871s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.9097 acc_val: 0.3733 loss_test: 1.2098 acc_test: 0.6510 time: 0.3308s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9389 acc_val: 0.4267 loss_test: 1.2336 acc_test: 0.6740 time: 0.3190s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0211 acc_val: 0.4433 loss_test: 1.2892 acc_test: 0.6810 time: 0.3132s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0271 acc_val: 0.4667 loss_test: 1.3155 acc_test: 0.6880 time: 0.3074s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0555 acc_val: 0.4767 loss_test: 1.3474 acc_test: 0.6870 time: 0.3346s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0880 acc_val: 0.4933 loss_test: 1.3804 acc_test: 0.6920 time: 0.3301s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1405 acc_val: 0.5067 loss_test: 1.4145 acc_test: 0.6950 time: 0.3420s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1686 acc_val: 0.5067 loss_test: 1.4413 acc_test: 0.6980 time: 0.3469s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2122 acc_val: 0.5067 loss_test: 1.4738 acc_test: 0.6940 time: 0.3294s
Optimization Finished!
Total time elapsed: 165.4833s, best testing performance  0.700000, minimun loss  0.954625
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8010 acc_train: 0.1500 loss_val: 1.8249 acc_val: 0.0933 loss_test: 1.6802 acc_test: 0.3970 time: 0.4017s
Epoch: 0051 loss_train: 0.0114 acc_train: 1.0000 loss_val: 1.8035 acc_val: 0.3800 loss_test: 1.1772 acc_test: 0.6590 time: 0.3127s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.9559 acc_val: 0.4000 loss_test: 1.2402 acc_test: 0.6720 time: 0.3225s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0651 acc_val: 0.4167 loss_test: 1.2909 acc_test: 0.6800 time: 0.3317s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0779 acc_val: 0.4433 loss_test: 1.3151 acc_test: 0.6830 time: 0.3206s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0765 acc_val: 0.4733 loss_test: 1.3416 acc_test: 0.6880 time: 0.3512s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0863 acc_val: 0.4900 loss_test: 1.3690 acc_test: 0.6900 time: 0.3512s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1033 acc_val: 0.4933 loss_test: 1.3978 acc_test: 0.6990 time: 0.3485s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1042 acc_val: 0.5100 loss_test: 1.4245 acc_test: 0.6990 time: 0.3589s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1770 acc_val: 0.5000 loss_test: 1.4582 acc_test: 0.6980 time: 0.3340s
Optimization Finished!
Total time elapsed: 166.9520s, best testing performance  0.703000, minimun loss  0.977427
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7853 acc_train: 0.2833 loss_val: 1.8092 acc_val: 0.1567 loss_test: 1.6854 acc_test: 0.4660 time: 0.4574s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.8664 acc_val: 0.3733 loss_test: 1.2019 acc_test: 0.6570 time: 0.3162s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8021 acc_val: 0.4300 loss_test: 1.1873 acc_test: 0.6820 time: 0.3401s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9000 acc_val: 0.4633 loss_test: 1.2512 acc_test: 0.6840 time: 0.3172s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9422 acc_val: 0.4700 loss_test: 1.2843 acc_test: 0.6900 time: 0.3523s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9813 acc_val: 0.4767 loss_test: 1.3218 acc_test: 0.6910 time: 0.3190s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 1.9792 acc_val: 0.4967 loss_test: 1.3489 acc_test: 0.6960 time: 0.3281s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0156 acc_val: 0.5000 loss_test: 1.3814 acc_test: 0.6970 time: 0.3537s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0473 acc_val: 0.5100 loss_test: 1.4123 acc_test: 0.6990 time: 0.3476s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0793 acc_val: 0.5067 loss_test: 1.4353 acc_test: 0.7020 time: 0.3242s
Optimization Finished!
Total time elapsed: 165.9760s, best testing performance  0.705000, minimun loss  0.968329
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7999 acc_train: 0.2083 loss_val: 1.8142 acc_val: 0.1767 loss_test: 1.6999 acc_test: 0.4680 time: 0.3846s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.6964 acc_val: 0.4133 loss_test: 1.1515 acc_test: 0.6700 time: 0.3270s
Epoch: 0101 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.7741 acc_val: 0.4533 loss_test: 1.1850 acc_test: 0.6880 time: 0.3229s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8897 acc_val: 0.4533 loss_test: 1.2581 acc_test: 0.6900 time: 0.3388s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9998 acc_val: 0.4567 loss_test: 1.3149 acc_test: 0.6900 time: 0.3180s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0578 acc_val: 0.4800 loss_test: 1.3520 acc_test: 0.6890 time: 0.3227s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0913 acc_val: 0.4933 loss_test: 1.3858 acc_test: 0.6930 time: 0.3184s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1174 acc_val: 0.5000 loss_test: 1.4185 acc_test: 0.6950 time: 0.3396s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1444 acc_val: 0.5167 loss_test: 1.4456 acc_test: 0.6970 time: 0.3456s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1656 acc_val: 0.5033 loss_test: 1.4716 acc_test: 0.6920 time: 0.3246s
Optimization Finished!
Total time elapsed: 166.8235s, best testing performance  0.699000, minimun loss  0.971576
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7934 acc_train: 0.1417 loss_val: 1.8308 acc_val: 0.0533 loss_test: 1.6563 acc_test: 0.3630 time: 0.3989s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.7554 acc_val: 0.4367 loss_test: 1.1739 acc_test: 0.6690 time: 0.3243s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.6338 acc_val: 0.4867 loss_test: 1.1613 acc_test: 0.6940 time: 0.3367s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8078 acc_val: 0.4800 loss_test: 1.2464 acc_test: 0.6890 time: 0.3157s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9027 acc_val: 0.4667 loss_test: 1.2975 acc_test: 0.6910 time: 0.3134s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9713 acc_val: 0.4767 loss_test: 1.3411 acc_test: 0.6920 time: 0.3283s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0479 acc_val: 0.5067 loss_test: 1.3816 acc_test: 0.6940 time: 0.3189s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1180 acc_val: 0.5100 loss_test: 1.4264 acc_test: 0.6930 time: 0.3478s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1437 acc_val: 0.5133 loss_test: 1.4488 acc_test: 0.6920 time: 0.3400s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1810 acc_val: 0.5133 loss_test: 1.4810 acc_test: 0.6950 time: 0.3214s
Optimization Finished!
Total time elapsed: 166.3908s, best testing performance  0.698000, minimun loss  0.950351
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7755 acc_train: 0.2667 loss_val: 1.7896 acc_val: 0.2067 loss_test: 1.6497 acc_test: 0.5430 time: 0.4091s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8317 acc_val: 0.4100 loss_test: 1.1963 acc_test: 0.6670 time: 0.3377s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8035 acc_val: 0.4667 loss_test: 1.2086 acc_test: 0.6830 time: 0.3277s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8868 acc_val: 0.4467 loss_test: 1.2704 acc_test: 0.6930 time: 0.3159s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0098 acc_val: 0.4633 loss_test: 1.3280 acc_test: 0.6900 time: 0.3135s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0675 acc_val: 0.4700 loss_test: 1.3728 acc_test: 0.6950 time: 0.3335s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1009 acc_val: 0.4833 loss_test: 1.4074 acc_test: 0.6940 time: 0.3577s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1238 acc_val: 0.5000 loss_test: 1.4388 acc_test: 0.6980 time: 0.3429s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1878 acc_val: 0.5100 loss_test: 1.4779 acc_test: 0.7020 time: 0.3443s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2216 acc_val: 0.5133 loss_test: 1.5034 acc_test: 0.7010 time: 0.3239s
Optimization Finished!
Total time elapsed: 165.3442s, best testing performance  0.703000, minimun loss  0.962827
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7797 acc_train: 0.2333 loss_val: 1.8248 acc_val: 0.1000 loss_test: 1.6745 acc_test: 0.4610 time: 0.4122s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6746 acc_val: 0.4033 loss_test: 1.1571 acc_test: 0.6690 time: 0.3323s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7241 acc_val: 0.4500 loss_test: 1.1956 acc_test: 0.6880 time: 0.3271s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9085 acc_val: 0.4733 loss_test: 1.2763 acc_test: 0.6890 time: 0.3288s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9968 acc_val: 0.4767 loss_test: 1.3237 acc_test: 0.6950 time: 0.3761s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0277 acc_val: 0.4967 loss_test: 1.3548 acc_test: 0.6950 time: 0.3178s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0589 acc_val: 0.5133 loss_test: 1.3809 acc_test: 0.7000 time: 0.3224s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0967 acc_val: 0.5000 loss_test: 1.4141 acc_test: 0.7040 time: 0.3633s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1634 acc_val: 0.5033 loss_test: 1.4435 acc_test: 0.7040 time: 0.3361s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1923 acc_val: 0.5033 loss_test: 1.4716 acc_test: 0.7030 time: 0.3125s
Optimization Finished!
Total time elapsed: 168.8097s, best testing performance  0.709000, minimun loss  0.967083
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7891 acc_train: 0.1833 loss_val: 1.8311 acc_val: 0.1600 loss_test: 1.6581 acc_test: 0.5080 time: 0.4642s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9536 acc_val: 0.3767 loss_test: 1.2359 acc_test: 0.6450 time: 0.3449s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8040 acc_val: 0.4200 loss_test: 1.2046 acc_test: 0.6820 time: 0.3132s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9160 acc_val: 0.4367 loss_test: 1.2768 acc_test: 0.6860 time: 0.3145s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9994 acc_val: 0.4567 loss_test: 1.3204 acc_test: 0.6850 time: 0.3438s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0558 acc_val: 0.4600 loss_test: 1.3571 acc_test: 0.6850 time: 0.3172s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0850 acc_val: 0.4733 loss_test: 1.3832 acc_test: 0.6920 time: 0.3163s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1185 acc_val: 0.5000 loss_test: 1.4125 acc_test: 0.6890 time: 0.3526s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1416 acc_val: 0.5033 loss_test: 1.4355 acc_test: 0.6910 time: 0.4098s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1695 acc_val: 0.5033 loss_test: 1.4600 acc_test: 0.6910 time: 0.3184s
Optimization Finished!
Total time elapsed: 166.5882s, best testing performance  0.698000, minimun loss  0.957345
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7733 acc_train: 0.2750 loss_val: 1.8092 acc_val: 0.2067 loss_test: 1.6356 acc_test: 0.4220 time: 0.3849s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.8077 acc_val: 0.4167 loss_test: 1.1835 acc_test: 0.6790 time: 0.3520s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9072 acc_val: 0.4333 loss_test: 1.2311 acc_test: 0.6880 time: 0.3110s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0595 acc_val: 0.4467 loss_test: 1.3134 acc_test: 0.6930 time: 0.3102s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.1084 acc_val: 0.4533 loss_test: 1.3532 acc_test: 0.6890 time: 0.3313s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1466 acc_val: 0.4567 loss_test: 1.3945 acc_test: 0.6880 time: 0.3208s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1836 acc_val: 0.4767 loss_test: 1.4298 acc_test: 0.6910 time: 0.3186s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2081 acc_val: 0.4933 loss_test: 1.4611 acc_test: 0.6930 time: 0.3418s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2699 acc_val: 0.5000 loss_test: 1.4952 acc_test: 0.6930 time: 0.3346s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.3152 acc_val: 0.5033 loss_test: 1.5252 acc_test: 0.6960 time: 0.3144s
Optimization Finished!
Total time elapsed: 165.8732s, best testing performance  0.700000, minimun loss  0.953390
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7804 acc_train: 0.2167 loss_val: 1.8604 acc_val: 0.0500 loss_test: 1.6601 acc_test: 0.3370 time: 0.4226s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7438 acc_val: 0.4067 loss_test: 1.1889 acc_test: 0.6660 time: 0.3262s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.7700 acc_val: 0.4433 loss_test: 1.2108 acc_test: 0.6810 time: 0.3149s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8862 acc_val: 0.4533 loss_test: 1.2785 acc_test: 0.6850 time: 0.3214s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9823 acc_val: 0.4600 loss_test: 1.3270 acc_test: 0.6820 time: 0.3206s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0198 acc_val: 0.4767 loss_test: 1.3587 acc_test: 0.6930 time: 0.3432s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0764 acc_val: 0.4833 loss_test: 1.3931 acc_test: 0.6920 time: 0.3320s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1174 acc_val: 0.5033 loss_test: 1.4214 acc_test: 0.6900 time: 0.3557s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1468 acc_val: 0.5033 loss_test: 1.4476 acc_test: 0.6940 time: 0.3410s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1574 acc_val: 0.4933 loss_test: 1.4675 acc_test: 0.6930 time: 0.3175s
Optimization Finished!
Total time elapsed: 166.4778s, best testing performance  0.698000, minimun loss  0.972512
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8045 acc_train: 0.1333 loss_val: 1.7914 acc_val: 0.2133 loss_test: 1.6621 acc_test: 0.5060 time: 0.4273s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.6222 acc_val: 0.4333 loss_test: 1.1370 acc_test: 0.6860 time: 0.3112s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8043 acc_val: 0.4400 loss_test: 1.2034 acc_test: 0.6920 time: 0.3437s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0320 acc_val: 0.4300 loss_test: 1.3116 acc_test: 0.6920 time: 0.3297s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0578 acc_val: 0.4567 loss_test: 1.3471 acc_test: 0.6930 time: 0.3135s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0748 acc_val: 0.4767 loss_test: 1.3796 acc_test: 0.6920 time: 0.3278s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1025 acc_val: 0.5067 loss_test: 1.4123 acc_test: 0.6910 time: 0.3329s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1206 acc_val: 0.5100 loss_test: 1.4393 acc_test: 0.6920 time: 0.3511s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1867 acc_val: 0.5133 loss_test: 1.4733 acc_test: 0.6970 time: 0.3414s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1677 acc_val: 0.5167 loss_test: 1.4820 acc_test: 0.6940 time: 0.3135s
Optimization Finished!
Total time elapsed: 165.7266s, best testing performance  0.701000, minimun loss  0.953064
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7925 acc_train: 0.2250 loss_val: 1.8159 acc_val: 0.1267 loss_test: 1.6594 acc_test: 0.4780 time: 0.4144s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8134 acc_val: 0.3900 loss_test: 1.1885 acc_test: 0.6720 time: 0.3116s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9139 acc_val: 0.4233 loss_test: 1.2374 acc_test: 0.6880 time: 0.3316s
Epoch: 0151 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0503 acc_val: 0.4367 loss_test: 1.3174 acc_test: 0.6900 time: 0.3155s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0746 acc_val: 0.4467 loss_test: 1.3544 acc_test: 0.6900 time: 0.3548s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0582 acc_val: 0.4767 loss_test: 1.3746 acc_test: 0.6940 time: 0.3412s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0723 acc_val: 0.5000 loss_test: 1.4012 acc_test: 0.6910 time: 0.3337s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0693 acc_val: 0.5033 loss_test: 1.4213 acc_test: 0.6910 time: 0.3527s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1197 acc_val: 0.5067 loss_test: 1.4496 acc_test: 0.6890 time: 0.3514s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1560 acc_val: 0.5000 loss_test: 1.4670 acc_test: 0.6950 time: 0.3450s
Optimization Finished!
Total time elapsed: 165.6624s, best testing performance  0.697000, minimun loss  0.958386
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 50, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7914 acc_train: 0.2000 loss_val: 1.7940 acc_val: 0.1000 loss_test: 1.6471 acc_test: 0.4720 time: 0.3767s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.6460 acc_val: 0.4367 loss_test: 1.1534 acc_test: 0.6730 time: 0.3122s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8022 acc_val: 0.4433 loss_test: 1.2156 acc_test: 0.6830 time: 0.3034s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9788 acc_val: 0.4300 loss_test: 1.2974 acc_test: 0.6900 time: 0.3179s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0235 acc_val: 0.4633 loss_test: 1.3335 acc_test: 0.6890 time: 0.3213s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0055 acc_val: 0.4667 loss_test: 1.3537 acc_test: 0.6950 time: 0.3412s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0621 acc_val: 0.4900 loss_test: 1.3911 acc_test: 0.6960 time: 0.3297s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0750 acc_val: 0.4867 loss_test: 1.4173 acc_test: 0.6980 time: 0.3410s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1010 acc_val: 0.5033 loss_test: 1.4404 acc_test: 0.6990 time: 0.3821s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1381 acc_val: 0.5033 loss_test: 1.4654 acc_test: 0.6990 time: 0.3068s
Optimization Finished!
Total time elapsed: 166.0884s, best testing performance  0.701000, minimun loss  0.963881
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8156 acc_train: 0.0917 loss_val: 1.8024 acc_val: 0.1567 loss_test: 1.6619 acc_test: 0.4710 time: 1.8730s
Epoch: 0051 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.8157 acc_val: 0.4067 loss_test: 1.1585 acc_test: 0.6790 time: 0.4143s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8144 acc_val: 0.4233 loss_test: 1.1846 acc_test: 0.6860 time: 0.4466s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9072 acc_val: 0.4667 loss_test: 1.2708 acc_test: 0.6910 time: 0.3847s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0021 acc_val: 0.4733 loss_test: 1.3303 acc_test: 0.6920 time: 0.3760s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0629 acc_val: 0.4867 loss_test: 1.3703 acc_test: 0.6890 time: 0.4056s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1089 acc_val: 0.4933 loss_test: 1.4027 acc_test: 0.6910 time: 0.4039s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1328 acc_val: 0.5133 loss_test: 1.4315 acc_test: 0.6880 time: 0.4473s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.5100 loss_test: 1.4619 acc_test: 0.6900 time: 0.4200s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1951 acc_val: 0.5133 loss_test: 1.4840 acc_test: 0.6910 time: 0.3911s
Optimization Finished!
Total time elapsed: 201.0687s, best testing performance  0.694000, minimun loss  0.969076
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7848 acc_train: 0.1667 loss_val: 1.8386 acc_val: 0.1500 loss_test: 1.6468 acc_test: 0.4720 time: 14.4420s
Epoch: 0051 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.9649 acc_val: 0.3533 loss_test: 1.2090 acc_test: 0.6580 time: 0.3874s
Epoch: 0101 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9687 acc_val: 0.3967 loss_test: 1.2232 acc_test: 0.6710 time: 0.3926s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0710 acc_val: 0.4167 loss_test: 1.2976 acc_test: 0.6780 time: 0.3745s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1384 acc_val: 0.4500 loss_test: 1.3472 acc_test: 0.6780 time: 0.3658s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1525 acc_val: 0.4700 loss_test: 1.3782 acc_test: 0.6880 time: 0.3840s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2051 acc_val: 0.4800 loss_test: 1.4177 acc_test: 0.6880 time: 0.4005s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2224 acc_val: 0.4967 loss_test: 1.4432 acc_test: 0.6910 time: 0.4485s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2257 acc_val: 0.5000 loss_test: 1.4642 acc_test: 0.6880 time: 0.4271s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2541 acc_val: 0.5000 loss_test: 1.4894 acc_test: 0.6910 time: 0.4471s
Optimization Finished!
Total time elapsed: 214.4612s, best testing performance  0.695000, minimun loss  0.967985
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7754 acc_train: 0.2750 loss_val: 1.8553 acc_val: 0.0900 loss_test: 1.6578 acc_test: 0.4250 time: 1.2969s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.8420 acc_val: 0.4067 loss_test: 1.1778 acc_test: 0.6800 time: 0.4128s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8754 acc_val: 0.4333 loss_test: 1.2105 acc_test: 0.6780 time: 0.3959s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9648 acc_val: 0.4533 loss_test: 1.2923 acc_test: 0.6860 time: 0.3886s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0228 acc_val: 0.4800 loss_test: 1.3368 acc_test: 0.6900 time: 0.3831s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0892 acc_val: 0.4767 loss_test: 1.3776 acc_test: 0.6900 time: 0.4047s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1575 acc_val: 0.4733 loss_test: 1.4165 acc_test: 0.6900 time: 0.3951s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1831 acc_val: 0.4900 loss_test: 1.4418 acc_test: 0.6930 time: 0.4159s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1406 acc_val: 0.5067 loss_test: 1.4513 acc_test: 0.6980 time: 0.4587s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1749 acc_val: 0.5033 loss_test: 1.4737 acc_test: 0.7000 time: 0.3886s
Optimization Finished!
Total time elapsed: 200.2642s, best testing performance  0.706000, minimun loss  0.982688
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7841 acc_train: 0.1917 loss_val: 1.8668 acc_val: 0.1167 loss_test: 1.6485 acc_test: 0.4850 time: 26.7848s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8713 acc_val: 0.4033 loss_test: 1.1778 acc_test: 0.6720 time: 0.3852s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8989 acc_val: 0.4300 loss_test: 1.2001 acc_test: 0.6810 time: 0.3874s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0128 acc_val: 0.4467 loss_test: 1.2799 acc_test: 0.6870 time: 0.3676s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1061 acc_val: 0.4700 loss_test: 1.3386 acc_test: 0.6830 time: 0.3840s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1574 acc_val: 0.4833 loss_test: 1.3779 acc_test: 0.6880 time: 0.4253s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2130 acc_val: 0.4767 loss_test: 1.4156 acc_test: 0.6900 time: 0.3960s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2496 acc_val: 0.4900 loss_test: 1.4478 acc_test: 0.6940 time: 0.4146s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2470 acc_val: 0.4967 loss_test: 1.4673 acc_test: 0.6960 time: 0.4560s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2469 acc_val: 0.4967 loss_test: 1.4842 acc_test: 0.6940 time: 0.3740s
Optimization Finished!
Total time elapsed: 227.4047s, best testing performance  0.699000, minimun loss  0.983776
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7797 acc_train: 0.1833 loss_val: 1.8046 acc_val: 0.2267 loss_test: 1.6546 acc_test: 0.5520 time: 3.0850s
Epoch: 0051 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.7480 acc_val: 0.4067 loss_test: 1.1399 acc_test: 0.6780 time: 0.3766s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7798 acc_val: 0.4367 loss_test: 1.1692 acc_test: 0.6880 time: 0.3892s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8648 acc_val: 0.4567 loss_test: 1.2391 acc_test: 0.6850 time: 0.4092s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9591 acc_val: 0.4600 loss_test: 1.2986 acc_test: 0.6880 time: 0.3778s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9961 acc_val: 0.4867 loss_test: 1.3389 acc_test: 0.6870 time: 0.3745s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0681 acc_val: 0.4833 loss_test: 1.3827 acc_test: 0.6910 time: 0.3770s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1002 acc_val: 0.5067 loss_test: 1.4214 acc_test: 0.6940 time: 0.4123s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1099 acc_val: 0.5167 loss_test: 1.4538 acc_test: 0.6930 time: 0.4340s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1156 acc_val: 0.5133 loss_test: 1.4838 acc_test: 0.6960 time: 0.3962s
Optimization Finished!
Total time elapsed: 202.7070s, best testing performance  0.697000, minimun loss  0.956333
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7969 acc_train: 0.1917 loss_val: 1.7900 acc_val: 0.1200 loss_test: 1.6767 acc_test: 0.4730 time: 27.2080s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.8300 acc_val: 0.3867 loss_test: 1.1627 acc_test: 0.6720 time: 0.3843s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8626 acc_val: 0.4100 loss_test: 1.1897 acc_test: 0.6800 time: 0.4066s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0367 acc_val: 0.4133 loss_test: 1.2827 acc_test: 0.6810 time: 0.3888s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1122 acc_val: 0.4400 loss_test: 1.3341 acc_test: 0.6820 time: 0.3898s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1022 acc_val: 0.4700 loss_test: 1.3589 acc_test: 0.6900 time: 0.3771s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1275 acc_val: 0.4800 loss_test: 1.3870 acc_test: 0.6940 time: 0.3982s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1333 acc_val: 0.5000 loss_test: 1.4100 acc_test: 0.6930 time: 0.3904s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1504 acc_val: 0.5100 loss_test: 1.4333 acc_test: 0.6930 time: 0.4025s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1566 acc_val: 0.5067 loss_test: 1.4517 acc_test: 0.7000 time: 0.4119s
Optimization Finished!
Total time elapsed: 225.3639s, best testing performance  0.703000, minimun loss  0.975005
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7733 acc_train: 0.2833 loss_val: 1.7962 acc_val: 0.1567 loss_test: 1.6559 acc_test: 0.4900 time: 1.2969s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7598 acc_val: 0.4033 loss_test: 1.1426 acc_test: 0.6780 time: 0.3555s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8290 acc_val: 0.4100 loss_test: 1.1868 acc_test: 0.6800 time: 0.3852s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9774 acc_val: 0.4133 loss_test: 1.2727 acc_test: 0.6770 time: 0.3686s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0370 acc_val: 0.4567 loss_test: 1.3241 acc_test: 0.6840 time: 0.3787s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0870 acc_val: 0.4767 loss_test: 1.3618 acc_test: 0.6880 time: 0.4122s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1310 acc_val: 0.4833 loss_test: 1.3928 acc_test: 0.6930 time: 0.3993s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1153 acc_val: 0.5100 loss_test: 1.4089 acc_test: 0.6960 time: 0.4103s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1595 acc_val: 0.5067 loss_test: 1.4391 acc_test: 0.7000 time: 0.3913s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1846 acc_val: 0.5100 loss_test: 1.4657 acc_test: 0.6980 time: 0.4131s
Optimization Finished!
Total time elapsed: 201.9724s, best testing performance  0.702000, minimun loss  0.948598
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7920 acc_train: 0.1667 loss_val: 1.8159 acc_val: 0.1467 loss_test: 1.6652 acc_test: 0.5190 time: 19.2552s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.8841 acc_val: 0.4000 loss_test: 1.1609 acc_test: 0.6760 time: 0.3985s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8782 acc_val: 0.4267 loss_test: 1.1871 acc_test: 0.6900 time: 0.3885s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9722 acc_val: 0.4333 loss_test: 1.2651 acc_test: 0.6920 time: 0.3707s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0605 acc_val: 0.4567 loss_test: 1.3299 acc_test: 0.6890 time: 0.3902s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0702 acc_val: 0.4733 loss_test: 1.3631 acc_test: 0.6920 time: 0.3854s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1096 acc_val: 0.4867 loss_test: 1.4027 acc_test: 0.6940 time: 0.4046s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1022 acc_val: 0.5033 loss_test: 1.4267 acc_test: 0.6940 time: 0.4823s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1455 acc_val: 0.5067 loss_test: 1.4626 acc_test: 0.6970 time: 0.3853s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1375 acc_val: 0.5200 loss_test: 1.4813 acc_test: 0.6970 time: 0.4184s
Optimization Finished!
Total time elapsed: 220.0174s, best testing performance  0.700000, minimun loss  0.949461
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7895 acc_train: 0.2167 loss_val: 1.8074 acc_val: 0.1500 loss_test: 1.6486 acc_test: 0.5230 time: 1.3827s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8505 acc_val: 0.3933 loss_test: 1.1639 acc_test: 0.6690 time: 0.3549s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8077 acc_val: 0.4167 loss_test: 1.1733 acc_test: 0.6800 time: 0.4059s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9367 acc_val: 0.4267 loss_test: 1.2580 acc_test: 0.6800 time: 0.3803s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9804 acc_val: 0.4600 loss_test: 1.3095 acc_test: 0.6890 time: 0.3915s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0747 acc_val: 0.4767 loss_test: 1.3568 acc_test: 0.6890 time: 0.4017s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1154 acc_val: 0.5000 loss_test: 1.3892 acc_test: 0.6900 time: 0.4044s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1825 acc_val: 0.5000 loss_test: 1.4260 acc_test: 0.6920 time: 0.4512s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2085 acc_val: 0.5033 loss_test: 1.4530 acc_test: 0.6940 time: 0.4057s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2532 acc_val: 0.5033 loss_test: 1.4849 acc_test: 0.6920 time: 0.4058s
Optimization Finished!
Total time elapsed: 200.4307s, best testing performance  0.696000, minimun loss  0.968514
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7958 acc_train: 0.1583 loss_val: 1.8342 acc_val: 0.1433 loss_test: 1.6775 acc_test: 0.4800 time: 28.7912s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.9106 acc_val: 0.3667 loss_test: 1.1930 acc_test: 0.6620 time: 0.4087s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8077 acc_val: 0.4367 loss_test: 1.1750 acc_test: 0.6850 time: 0.4108s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8674 acc_val: 0.4467 loss_test: 1.2371 acc_test: 0.6890 time: 0.3919s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9651 acc_val: 0.4700 loss_test: 1.3071 acc_test: 0.6920 time: 0.3873s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0251 acc_val: 0.4900 loss_test: 1.3538 acc_test: 0.6970 time: 0.3531s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0829 acc_val: 0.5000 loss_test: 1.3953 acc_test: 0.6960 time: 0.3862s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1301 acc_val: 0.5133 loss_test: 1.4316 acc_test: 0.6960 time: 0.4212s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1763 acc_val: 0.5200 loss_test: 1.4623 acc_test: 0.6960 time: 0.4435s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2209 acc_val: 0.5167 loss_test: 1.4869 acc_test: 0.6970 time: 0.4590s
Optimization Finished!
Total time elapsed: 228.7075s, best testing performance  0.701000, minimun loss  0.968983
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8019 acc_train: 0.1667 loss_val: 1.8173 acc_val: 0.1967 loss_test: 1.6885 acc_test: 0.5310 time: 1.7811s
Epoch: 0051 loss_train: 0.0129 acc_train: 1.0000 loss_val: 1.8050 acc_val: 0.3767 loss_test: 1.1325 acc_test: 0.6630 time: 0.3822s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.8404 acc_val: 0.4133 loss_test: 1.1638 acc_test: 0.6780 time: 0.4004s
Epoch: 0151 loss_train: 0.0067 acc_train: 1.0000 loss_val: 1.9324 acc_val: 0.4367 loss_test: 1.2281 acc_test: 0.6850 time: 0.3881s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9744 acc_val: 0.4533 loss_test: 1.2694 acc_test: 0.6880 time: 0.3859s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0174 acc_val: 0.4733 loss_test: 1.3117 acc_test: 0.6890 time: 0.3770s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0683 acc_val: 0.4900 loss_test: 1.3557 acc_test: 0.6900 time: 0.4692s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1030 acc_val: 0.5033 loss_test: 1.3962 acc_test: 0.6870 time: 0.4201s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1389 acc_val: 0.5033 loss_test: 1.4344 acc_test: 0.6890 time: 0.3784s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1586 acc_val: 0.5067 loss_test: 1.4676 acc_test: 0.6880 time: 0.4038s
Optimization Finished!
Total time elapsed: 198.9399s, best testing performance  0.693000, minimun loss  0.958929
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8097 acc_train: 0.1167 loss_val: 1.7951 acc_val: 0.2067 loss_test: 1.6963 acc_test: 0.5440 time: 14.4384s
Epoch: 0051 loss_train: 0.0113 acc_train: 1.0000 loss_val: 1.7535 acc_val: 0.3867 loss_test: 1.1304 acc_test: 0.6730 time: 0.3841s
Epoch: 0101 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7352 acc_val: 0.4467 loss_test: 1.1435 acc_test: 0.6860 time: 0.3820s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8553 acc_val: 0.4600 loss_test: 1.2194 acc_test: 0.6850 time: 0.4005s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9285 acc_val: 0.4667 loss_test: 1.2696 acc_test: 0.6900 time: 0.3763s
Epoch: 0251 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.0207 acc_val: 0.4700 loss_test: 1.3258 acc_test: 0.6940 time: 0.3825s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0607 acc_val: 0.5000 loss_test: 1.3683 acc_test: 0.6980 time: 0.4208s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0981 acc_val: 0.5133 loss_test: 1.4095 acc_test: 0.7010 time: 0.4138s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1346 acc_val: 0.5100 loss_test: 1.4478 acc_test: 0.7020 time: 0.4010s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1707 acc_val: 0.5133 loss_test: 1.4802 acc_test: 0.7000 time: 0.4678s
Optimization Finished!
Total time elapsed: 214.4579s, best testing performance  0.703000, minimun loss  0.970601
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7973 acc_train: 0.1667 loss_val: 1.8017 acc_val: 0.2033 loss_test: 1.6874 acc_test: 0.5220 time: 2.1845s
Epoch: 0051 loss_train: 0.0111 acc_train: 1.0000 loss_val: 1.6444 acc_val: 0.4233 loss_test: 1.0899 acc_test: 0.6840 time: 0.4602s
Epoch: 0101 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.6756 acc_val: 0.4567 loss_test: 1.1223 acc_test: 0.6930 time: 0.4431s
Epoch: 0151 loss_train: 0.0066 acc_train: 1.0000 loss_val: 1.9167 acc_val: 0.4367 loss_test: 1.2353 acc_test: 0.6890 time: 0.3772s
Epoch: 0201 loss_train: 0.0051 acc_train: 1.0000 loss_val: 1.9643 acc_val: 0.4700 loss_test: 1.2800 acc_test: 0.6880 time: 0.3983s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0095 acc_val: 0.4833 loss_test: 1.3205 acc_test: 0.6950 time: 0.3888s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0533 acc_val: 0.4933 loss_test: 1.3571 acc_test: 0.6930 time: 0.4187s
Epoch: 0351 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1089 acc_val: 0.5033 loss_test: 1.3940 acc_test: 0.6920 time: 0.4157s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1421 acc_val: 0.5067 loss_test: 1.4230 acc_test: 0.6890 time: 0.4058s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1827 acc_val: 0.5067 loss_test: 1.4534 acc_test: 0.6910 time: 0.4007s
Optimization Finished!
Total time elapsed: 202.1979s, best testing performance  0.696000, minimun loss  0.976549
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.1750 loss_val: 1.7746 acc_val: 0.1833 loss_test: 1.6882 acc_test: 0.5040 time: 13.7023s
Epoch: 0051 loss_train: 0.0127 acc_train: 1.0000 loss_val: 1.6226 acc_val: 0.4200 loss_test: 1.0726 acc_test: 0.6850 time: 0.3820s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.6894 acc_val: 0.4633 loss_test: 1.1179 acc_test: 0.6920 time: 0.3847s
Epoch: 0151 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.8532 acc_val: 0.4533 loss_test: 1.2107 acc_test: 0.6900 time: 0.3904s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9271 acc_val: 0.4667 loss_test: 1.2625 acc_test: 0.6890 time: 0.3807s
Epoch: 0251 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9754 acc_val: 0.4933 loss_test: 1.3043 acc_test: 0.6920 time: 0.3787s
Epoch: 0301 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0292 acc_val: 0.5033 loss_test: 1.3475 acc_test: 0.6960 time: 0.3674s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0610 acc_val: 0.5033 loss_test: 1.3820 acc_test: 0.6980 time: 0.3894s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1029 acc_val: 0.5067 loss_test: 1.4168 acc_test: 0.7000 time: 0.4002s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1179 acc_val: 0.5100 loss_test: 1.4424 acc_test: 0.7020 time: 0.3935s
Optimization Finished!
Total time elapsed: 212.1325s, best testing performance  0.705000, minimun loss  0.984373
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7812 acc_train: 0.2000 loss_val: 1.7814 acc_val: 0.2367 loss_test: 1.6758 acc_test: 0.5570 time: 2.1942s
Epoch: 0051 loss_train: 0.0120 acc_train: 1.0000 loss_val: 1.7009 acc_val: 0.4067 loss_test: 1.1007 acc_test: 0.6800 time: 0.3726s
Epoch: 0101 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7437 acc_val: 0.4533 loss_test: 1.1311 acc_test: 0.6850 time: 0.3726s
Epoch: 0151 loss_train: 0.0069 acc_train: 1.0000 loss_val: 1.9215 acc_val: 0.4267 loss_test: 1.2316 acc_test: 0.6790 time: 0.4657s
Epoch: 0201 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0009 acc_val: 0.4567 loss_test: 1.2814 acc_test: 0.6850 time: 0.3581s
Epoch: 0251 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0378 acc_val: 0.4767 loss_test: 1.3141 acc_test: 0.6910 time: 0.3773s
Epoch: 0301 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0719 acc_val: 0.4900 loss_test: 1.3481 acc_test: 0.6930 time: 0.4161s
Epoch: 0351 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0833 acc_val: 0.4967 loss_test: 1.3764 acc_test: 0.6940 time: 0.4343s
Epoch: 0401 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1356 acc_val: 0.4967 loss_test: 1.4105 acc_test: 0.6910 time: 0.3970s
Epoch: 0451 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.5067 loss_test: 1.4291 acc_test: 0.6940 time: 0.4642s
Optimization Finished!
Total time elapsed: 201.5864s, best testing performance  0.698000, minimun loss  0.971326
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7977 acc_train: 0.1667 loss_val: 1.8475 acc_val: 0.0767 loss_test: 1.6654 acc_test: 0.3580 time: 10.2084s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.9221 acc_val: 0.3600 loss_test: 1.1973 acc_test: 0.6690 time: 0.3727s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9642 acc_val: 0.3933 loss_test: 1.2313 acc_test: 0.6750 time: 0.3726s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.0484 acc_val: 0.4333 loss_test: 1.2956 acc_test: 0.6870 time: 0.3751s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0794 acc_val: 0.4700 loss_test: 1.3306 acc_test: 0.6890 time: 0.3734s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.4833 loss_test: 1.3570 acc_test: 0.6940 time: 0.3903s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0753 acc_val: 0.5000 loss_test: 1.3841 acc_test: 0.6970 time: 0.3809s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1385 acc_val: 0.5100 loss_test: 1.4181 acc_test: 0.6950 time: 0.4142s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1018 acc_val: 0.5033 loss_test: 1.4277 acc_test: 0.7000 time: 0.4465s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1732 acc_val: 0.5033 loss_test: 1.4602 acc_test: 0.6960 time: 0.3945s
Optimization Finished!
Total time elapsed: 207.9099s, best testing performance  0.701000, minimun loss  0.979505
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7804 acc_train: 0.2583 loss_val: 1.8256 acc_val: 0.1000 loss_test: 1.6311 acc_test: 0.4840 time: 2.9211s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.8610 acc_val: 0.4000 loss_test: 1.1584 acc_test: 0.6750 time: 0.3908s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8983 acc_val: 0.4267 loss_test: 1.1923 acc_test: 0.6890 time: 0.3737s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.0445 acc_val: 0.4400 loss_test: 1.2853 acc_test: 0.6880 time: 0.3878s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.1158 acc_val: 0.4633 loss_test: 1.3410 acc_test: 0.6900 time: 0.3866s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.1707 acc_val: 0.4767 loss_test: 1.3920 acc_test: 0.6920 time: 0.3853s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1504 acc_val: 0.4967 loss_test: 1.4243 acc_test: 0.6970 time: 0.3920s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1977 acc_val: 0.5133 loss_test: 1.4709 acc_test: 0.7010 time: 0.4184s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1813 acc_val: 0.5167 loss_test: 1.4978 acc_test: 0.7020 time: 0.4085s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1948 acc_val: 0.5167 loss_test: 1.5307 acc_test: 0.6990 time: 0.3869s
Optimization Finished!
Total time elapsed: 201.8042s, best testing performance  0.703000, minimun loss  0.936430
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1500 loss_val: 1.8015 acc_val: 0.1333 loss_test: 1.6632 acc_test: 0.4660 time: 3.5740s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7683 acc_val: 0.4067 loss_test: 1.1463 acc_test: 0.6800 time: 0.3620s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8116 acc_val: 0.4467 loss_test: 1.1771 acc_test: 0.6880 time: 0.3807s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9428 acc_val: 0.4767 loss_test: 1.2660 acc_test: 0.6890 time: 0.3828s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0477 acc_val: 0.4700 loss_test: 1.3218 acc_test: 0.6900 time: 0.3606s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0922 acc_val: 0.4867 loss_test: 1.3598 acc_test: 0.6930 time: 0.3803s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1081 acc_val: 0.4933 loss_test: 1.3914 acc_test: 0.6910 time: 0.3786s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1327 acc_val: 0.5133 loss_test: 1.4184 acc_test: 0.6910 time: 0.4244s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1505 acc_val: 0.5167 loss_test: 1.4352 acc_test: 0.6910 time: 0.4069s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1636 acc_val: 0.5133 loss_test: 1.4561 acc_test: 0.6910 time: 0.4034s
Optimization Finished!
Total time elapsed: 201.4998s, best testing performance  0.697000, minimun loss  0.953385
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7948 acc_train: 0.2250 loss_val: 1.8342 acc_val: 0.0767 loss_test: 1.6594 acc_test: 0.3920 time: 2.3701s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6647 acc_val: 0.4233 loss_test: 1.0966 acc_test: 0.6840 time: 0.3936s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8298 acc_val: 0.4467 loss_test: 1.1868 acc_test: 0.6890 time: 0.3862s
Epoch: 0151 loss_train: 0.0052 acc_train: 1.0000 loss_val: 2.0225 acc_val: 0.4467 loss_test: 1.3046 acc_test: 0.6860 time: 0.3779s
Epoch: 0201 loss_train: 0.0040 acc_train: 1.0000 loss_val: 2.1017 acc_val: 0.4633 loss_test: 1.3594 acc_test: 0.6860 time: 0.3715s
Epoch: 0251 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1529 acc_val: 0.4733 loss_test: 1.4067 acc_test: 0.6920 time: 0.3935s
Epoch: 0301 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1753 acc_val: 0.4933 loss_test: 1.4457 acc_test: 0.6920 time: 0.3881s
Epoch: 0351 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2138 acc_val: 0.4967 loss_test: 1.4822 acc_test: 0.6950 time: 0.4288s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2211 acc_val: 0.5100 loss_test: 1.5118 acc_test: 0.6970 time: 0.3945s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2747 acc_val: 0.5033 loss_test: 1.5469 acc_test: 0.6960 time: 0.4180s
Optimization Finished!
Total time elapsed: 200.0999s, best testing performance  0.702000, minimun loss  0.965236
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8050 acc_train: 0.1333 loss_val: 1.8378 acc_val: 0.1333 loss_test: 1.6609 acc_test: 0.4910 time: 11.3533s
Epoch: 0051 loss_train: 0.0088 acc_train: 1.0000 loss_val: 1.7622 acc_val: 0.3967 loss_test: 1.1798 acc_test: 0.6740 time: 0.3790s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.8684 acc_val: 0.4333 loss_test: 1.2330 acc_test: 0.6810 time: 0.3772s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0424 acc_val: 0.4367 loss_test: 1.3254 acc_test: 0.6820 time: 0.3896s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.4667 loss_test: 1.3520 acc_test: 0.6900 time: 0.3654s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0585 acc_val: 0.4933 loss_test: 1.3763 acc_test: 0.6940 time: 0.3772s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0705 acc_val: 0.5033 loss_test: 1.4031 acc_test: 0.6970 time: 0.3761s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0576 acc_val: 0.5233 loss_test: 1.4188 acc_test: 0.7000 time: 0.4151s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0751 acc_val: 0.5200 loss_test: 1.4397 acc_test: 0.7020 time: 0.4103s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1088 acc_val: 0.5167 loss_test: 1.4622 acc_test: 0.7040 time: 0.3698s
Optimization Finished!
Total time elapsed: 208.3690s, best testing performance  0.707000, minimun loss  0.970981
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7984 acc_train: 0.1333 loss_val: 1.8261 acc_val: 0.0800 loss_test: 1.6754 acc_test: 0.3720 time: 1.9172s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6742 acc_val: 0.4233 loss_test: 1.1055 acc_test: 0.6820 time: 0.3844s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7307 acc_val: 0.4600 loss_test: 1.1427 acc_test: 0.6950 time: 0.3939s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.8904 acc_val: 0.4600 loss_test: 1.2297 acc_test: 0.6930 time: 0.3701s
Epoch: 0201 loss_train: 0.0048 acc_train: 1.0000 loss_val: 1.9569 acc_val: 0.4700 loss_test: 1.2751 acc_test: 0.6920 time: 0.3780s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0198 acc_val: 0.4733 loss_test: 1.3212 acc_test: 0.6890 time: 0.4071s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0555 acc_val: 0.4900 loss_test: 1.3586 acc_test: 0.6930 time: 0.3993s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.5000 loss_test: 1.3958 acc_test: 0.6930 time: 0.4240s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1167 acc_val: 0.5033 loss_test: 1.4239 acc_test: 0.6960 time: 0.4444s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1431 acc_val: 0.5133 loss_test: 1.4530 acc_test: 0.6950 time: 0.4320s
Optimization Finished!
Total time elapsed: 201.3229s, best testing performance  0.699000, minimun loss  0.950866
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1167 loss_val: 1.8010 acc_val: 0.1967 loss_test: 1.6853 acc_test: 0.3530 time: 8.7752s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7022 acc_val: 0.4133 loss_test: 1.1329 acc_test: 0.6800 time: 0.3870s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.7804 acc_val: 0.4333 loss_test: 1.1794 acc_test: 0.6820 time: 0.3798s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9229 acc_val: 0.4333 loss_test: 1.2602 acc_test: 0.6860 time: 0.3844s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9979 acc_val: 0.4733 loss_test: 1.3099 acc_test: 0.6880 time: 0.4100s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0229 acc_val: 0.4833 loss_test: 1.3447 acc_test: 0.6870 time: 0.3917s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0383 acc_val: 0.5067 loss_test: 1.3758 acc_test: 0.6900 time: 0.4071s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0305 acc_val: 0.5167 loss_test: 1.3976 acc_test: 0.6940 time: 0.4118s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0714 acc_val: 0.5200 loss_test: 1.4282 acc_test: 0.6970 time: 0.4061s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1071 acc_val: 0.5200 loss_test: 1.4527 acc_test: 0.6930 time: 0.3887s
Optimization Finished!
Total time elapsed: 208.7633s, best testing performance  0.698000, minimun loss  0.965930
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7954 acc_train: 0.1083 loss_val: 1.8071 acc_val: 0.1433 loss_test: 1.6649 acc_test: 0.4730 time: 2.4581s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7159 acc_val: 0.3867 loss_test: 1.1352 acc_test: 0.6750 time: 0.3767s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7327 acc_val: 0.4367 loss_test: 1.1547 acc_test: 0.6870 time: 0.3751s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.8719 acc_val: 0.4433 loss_test: 1.2367 acc_test: 0.6930 time: 0.3919s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9715 acc_val: 0.4567 loss_test: 1.2952 acc_test: 0.6910 time: 0.3854s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0655 acc_val: 0.4667 loss_test: 1.3461 acc_test: 0.6910 time: 0.3745s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1145 acc_val: 0.4900 loss_test: 1.3811 acc_test: 0.6960 time: 0.4043s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1852 acc_val: 0.4933 loss_test: 1.4244 acc_test: 0.6970 time: 0.4533s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2353 acc_val: 0.4933 loss_test: 1.4562 acc_test: 0.6970 time: 0.3953s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2845 acc_val: 0.5033 loss_test: 1.4860 acc_test: 0.6970 time: 0.3860s
Optimization Finished!
Total time elapsed: 199.2179s, best testing performance  0.702000, minimun loss  0.936691
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7900 acc_train: 0.2250 loss_val: 1.8120 acc_val: 0.0900 loss_test: 1.6712 acc_test: 0.3950 time: 5.2298s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.6432 acc_val: 0.4000 loss_test: 1.1045 acc_test: 0.6830 time: 0.3738s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.6650 acc_val: 0.4533 loss_test: 1.1384 acc_test: 0.6940 time: 0.3961s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8485 acc_val: 0.4467 loss_test: 1.2407 acc_test: 0.6930 time: 0.3789s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9692 acc_val: 0.4667 loss_test: 1.3020 acc_test: 0.6890 time: 0.3884s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0518 acc_val: 0.4733 loss_test: 1.3550 acc_test: 0.6920 time: 0.3871s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0946 acc_val: 0.4867 loss_test: 1.3966 acc_test: 0.6910 time: 0.4262s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1321 acc_val: 0.5033 loss_test: 1.4353 acc_test: 0.6950 time: 0.4103s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1928 acc_val: 0.5100 loss_test: 1.4751 acc_test: 0.6970 time: 0.4360s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2669 acc_val: 0.5100 loss_test: 1.5169 acc_test: 0.6940 time: 0.3962s
Optimization Finished!
Total time elapsed: 204.1584s, best testing performance  0.698000, minimun loss  0.939551
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7991 acc_train: 0.1083 loss_val: 1.8379 acc_val: 0.0867 loss_test: 1.6628 acc_test: 0.4040 time: 2.2450s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6340 acc_val: 0.4133 loss_test: 1.1246 acc_test: 0.6830 time: 0.3849s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8595 acc_val: 0.4300 loss_test: 1.2200 acc_test: 0.6820 time: 0.3797s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0175 acc_val: 0.4400 loss_test: 1.3053 acc_test: 0.6810 time: 0.3945s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0680 acc_val: 0.4733 loss_test: 1.3472 acc_test: 0.6870 time: 0.3858s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1303 acc_val: 0.4733 loss_test: 1.3880 acc_test: 0.6900 time: 0.3969s
Epoch: 0301 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1721 acc_val: 0.4933 loss_test: 1.4252 acc_test: 0.6950 time: 0.3939s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2327 acc_val: 0.5067 loss_test: 1.4656 acc_test: 0.6970 time: 0.4221s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2496 acc_val: 0.5067 loss_test: 1.4927 acc_test: 0.6960 time: 0.4223s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2954 acc_val: 0.5033 loss_test: 1.5243 acc_test: 0.6940 time: 0.3901s
Optimization Finished!
Total time elapsed: 201.4075s, best testing performance  0.700000, minimun loss  0.963476
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8020 acc_train: 0.1000 loss_val: 1.8352 acc_val: 0.1600 loss_test: 1.6713 acc_test: 0.5440 time: 15.7875s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.5521 acc_val: 0.4567 loss_test: 1.0928 acc_test: 0.6820 time: 0.3866s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.6268 acc_val: 0.4500 loss_test: 1.1491 acc_test: 0.6940 time: 0.3748s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9008 acc_val: 0.4633 loss_test: 1.2796 acc_test: 0.6900 time: 0.4027s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0136 acc_val: 0.4700 loss_test: 1.3471 acc_test: 0.6890 time: 0.3693s
Epoch: 0251 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0866 acc_val: 0.4767 loss_test: 1.4015 acc_test: 0.6960 time: 0.3701s
Epoch: 0301 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1138 acc_val: 0.4833 loss_test: 1.4434 acc_test: 0.6930 time: 0.4000s
Epoch: 0351 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.5133 loss_test: 1.4794 acc_test: 0.6980 time: 0.4239s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1635 acc_val: 0.5067 loss_test: 1.5070 acc_test: 0.6990 time: 0.4119s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2024 acc_val: 0.5067 loss_test: 1.5376 acc_test: 0.6990 time: 0.3920s
Optimization Finished!
Total time elapsed: 214.6989s, best testing performance  0.704000, minimun loss  0.927885
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8120 acc_train: 0.1083 loss_val: 1.8713 acc_val: 0.1133 loss_test: 1.6845 acc_test: 0.4210 time: 2.2610s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.5637 acc_val: 0.4300 loss_test: 1.0790 acc_test: 0.6850 time: 0.3552s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7076 acc_val: 0.4633 loss_test: 1.1520 acc_test: 0.6970 time: 0.3857s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8841 acc_val: 0.4667 loss_test: 1.2593 acc_test: 0.6910 time: 0.3763s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9895 acc_val: 0.4700 loss_test: 1.3095 acc_test: 0.6940 time: 0.3871s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1041 acc_val: 0.4833 loss_test: 1.3620 acc_test: 0.6900 time: 0.4221s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1448 acc_val: 0.4867 loss_test: 1.3938 acc_test: 0.6920 time: 0.3753s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1721 acc_val: 0.4867 loss_test: 1.4231 acc_test: 0.6950 time: 0.4427s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2084 acc_val: 0.4900 loss_test: 1.4538 acc_test: 0.6920 time: 0.4185s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2205 acc_val: 0.5067 loss_test: 1.4713 acc_test: 0.6990 time: 0.4486s
Optimization Finished!
Total time elapsed: 200.6407s, best testing performance  0.706000, minimun loss  0.933869
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7927 acc_train: 0.1583 loss_val: 1.8184 acc_val: 0.1500 loss_test: 1.6443 acc_test: 0.5070 time: 14.2152s
Epoch: 0051 loss_train: 0.0090 acc_train: 1.0000 loss_val: 1.6319 acc_val: 0.4167 loss_test: 1.1266 acc_test: 0.6810 time: 0.4032s
Epoch: 0101 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.6248 acc_val: 0.4633 loss_test: 1.1476 acc_test: 0.6960 time: 0.3758s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8520 acc_val: 0.4500 loss_test: 1.2590 acc_test: 0.6890 time: 0.4124s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9741 acc_val: 0.4700 loss_test: 1.3134 acc_test: 0.6880 time: 0.3778s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0391 acc_val: 0.4767 loss_test: 1.3567 acc_test: 0.6900 time: 0.3759s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1180 acc_val: 0.4833 loss_test: 1.4012 acc_test: 0.6870 time: 0.4115s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1650 acc_val: 0.4933 loss_test: 1.4299 acc_test: 0.6940 time: 0.4243s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2034 acc_val: 0.4967 loss_test: 1.4556 acc_test: 0.6940 time: 0.4361s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2079 acc_val: 0.5067 loss_test: 1.4692 acc_test: 0.6940 time: 0.3786s
Optimization Finished!
Total time elapsed: 219.0222s, best testing performance  0.699000, minimun loss  0.928166
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7959 acc_train: 0.1833 loss_val: 1.8679 acc_val: 0.0500 loss_test: 1.6577 acc_test: 0.3290 time: 1.8250s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7086 acc_val: 0.4133 loss_test: 1.1480 acc_test: 0.6730 time: 0.3728s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.8154 acc_val: 0.4200 loss_test: 1.1995 acc_test: 0.6850 time: 0.3740s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9883 acc_val: 0.4500 loss_test: 1.2941 acc_test: 0.6870 time: 0.3755s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0355 acc_val: 0.4700 loss_test: 1.3308 acc_test: 0.6920 time: 0.3768s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0584 acc_val: 0.4800 loss_test: 1.3619 acc_test: 0.6900 time: 0.3903s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0962 acc_val: 0.4867 loss_test: 1.3945 acc_test: 0.6920 time: 0.3799s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0838 acc_val: 0.5000 loss_test: 1.4146 acc_test: 0.6980 time: 0.4378s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0691 acc_val: 0.5067 loss_test: 1.4296 acc_test: 0.6980 time: 0.4226s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0612 acc_val: 0.5067 loss_test: 1.4450 acc_test: 0.6990 time: 0.3841s
Optimization Finished!
Total time elapsed: 199.8282s, best testing performance  0.702000, minimun loss  0.941391
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7955 acc_train: 0.1500 loss_val: 1.8341 acc_val: 0.0600 loss_test: 1.6546 acc_test: 0.3330 time: 17.8310s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.5492 acc_val: 0.4267 loss_test: 1.1130 acc_test: 0.6810 time: 0.4007s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8517 acc_val: 0.4333 loss_test: 1.2180 acc_test: 0.6780 time: 0.3568s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0287 acc_val: 0.4367 loss_test: 1.3115 acc_test: 0.6900 time: 0.3784s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0914 acc_val: 0.4600 loss_test: 1.3546 acc_test: 0.6850 time: 0.3582s
Epoch: 0251 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1235 acc_val: 0.4833 loss_test: 1.3861 acc_test: 0.6910 time: 0.3758s
Epoch: 0301 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1394 acc_val: 0.4900 loss_test: 1.4158 acc_test: 0.6940 time: 0.3889s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1973 acc_val: 0.4967 loss_test: 1.4535 acc_test: 0.6970 time: 0.4240s
Epoch: 0401 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2180 acc_val: 0.4933 loss_test: 1.4853 acc_test: 0.6970 time: 0.4143s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2426 acc_val: 0.4967 loss_test: 1.5153 acc_test: 0.6990 time: 0.4223s
Optimization Finished!
Total time elapsed: 216.2658s, best testing performance  0.708000, minimun loss  0.935555
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7906 acc_train: 0.1750 loss_val: 1.7882 acc_val: 0.2033 loss_test: 1.7025 acc_test: 0.3940 time: 1.4410s
Epoch: 0051 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.9077 acc_val: 0.3800 loss_test: 1.2160 acc_test: 0.6580 time: 0.4181s
Epoch: 0101 loss_train: 0.0068 acc_train: 1.0000 loss_val: 1.9050 acc_val: 0.4333 loss_test: 1.2331 acc_test: 0.6740 time: 0.3773s
Epoch: 0151 loss_train: 0.0052 acc_train: 1.0000 loss_val: 1.9944 acc_val: 0.4500 loss_test: 1.2894 acc_test: 0.6800 time: 0.3602s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0588 acc_val: 0.4667 loss_test: 1.3341 acc_test: 0.6830 time: 0.4234s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0871 acc_val: 0.4733 loss_test: 1.3711 acc_test: 0.6900 time: 0.3835s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1410 acc_val: 0.4933 loss_test: 1.4078 acc_test: 0.6980 time: 0.4077s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1620 acc_val: 0.5000 loss_test: 1.4398 acc_test: 0.6970 time: 0.4761s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1951 acc_val: 0.5067 loss_test: 1.4683 acc_test: 0.6980 time: 0.4094s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2001 acc_val: 0.5100 loss_test: 1.4901 acc_test: 0.6980 time: 0.3921s
Optimization Finished!
Total time elapsed: 200.2590s, best testing performance  0.700000, minimun loss  0.967958
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8040 acc_train: 0.1000 loss_val: 1.8048 acc_val: 0.0833 loss_test: 1.6916 acc_test: 0.3740 time: 6.8168s
Epoch: 0051 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9246 acc_val: 0.3633 loss_test: 1.2398 acc_test: 0.6550 time: 0.3880s
Epoch: 0101 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9052 acc_val: 0.4033 loss_test: 1.2290 acc_test: 0.6690 time: 0.3648s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0062 acc_val: 0.4267 loss_test: 1.2872 acc_test: 0.6810 time: 0.3700s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1005 acc_val: 0.4400 loss_test: 1.3393 acc_test: 0.6840 time: 0.3946s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1958 acc_val: 0.4600 loss_test: 1.3933 acc_test: 0.6870 time: 0.3907s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2526 acc_val: 0.4733 loss_test: 1.4295 acc_test: 0.6930 time: 0.3728s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.3162 acc_val: 0.4733 loss_test: 1.4651 acc_test: 0.6940 time: 0.4322s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.3701 acc_val: 0.4833 loss_test: 1.4972 acc_test: 0.6960 time: 0.4321s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.4158 acc_val: 0.4833 loss_test: 1.5262 acc_test: 0.6960 time: 0.3861s
Optimization Finished!
Total time elapsed: 204.7262s, best testing performance  0.698000, minimun loss  0.962918
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7825 acc_train: 0.2250 loss_val: 1.8319 acc_val: 0.0467 loss_test: 1.6991 acc_test: 0.3260 time: 3.7222s
Epoch: 0051 loss_train: 0.0084 acc_train: 1.0000 loss_val: 2.1134 acc_val: 0.3633 loss_test: 1.3329 acc_test: 0.6410 time: 0.3732s
Epoch: 0101 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.9766 acc_val: 0.4267 loss_test: 1.2848 acc_test: 0.6620 time: 0.4508s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.9979 acc_val: 0.4433 loss_test: 1.3160 acc_test: 0.6750 time: 0.3910s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0322 acc_val: 0.4667 loss_test: 1.3512 acc_test: 0.6830 time: 0.3747s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0640 acc_val: 0.4800 loss_test: 1.3810 acc_test: 0.6860 time: 0.3970s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4800 loss_test: 1.4070 acc_test: 0.6920 time: 0.3706s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0976 acc_val: 0.4933 loss_test: 1.4279 acc_test: 0.6940 time: 0.4194s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1120 acc_val: 0.4967 loss_test: 1.4493 acc_test: 0.6950 time: 0.4187s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1133 acc_val: 0.5067 loss_test: 1.4666 acc_test: 0.6950 time: 0.3999s
Optimization Finished!
Total time elapsed: 201.0646s, best testing performance  0.699000, minimun loss  1.032776
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8088 acc_train: 0.0833 loss_val: 1.8084 acc_val: 0.0833 loss_test: 1.7278 acc_test: 0.3510 time: 8.7869s
Epoch: 0051 loss_train: 0.0086 acc_train: 1.0000 loss_val: 1.9517 acc_val: 0.4000 loss_test: 1.2560 acc_test: 0.6640 time: 0.3828s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8464 acc_val: 0.4433 loss_test: 1.2202 acc_test: 0.6750 time: 0.3710s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9236 acc_val: 0.4633 loss_test: 1.2758 acc_test: 0.6850 time: 0.3887s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0187 acc_val: 0.4767 loss_test: 1.3302 acc_test: 0.6870 time: 0.3942s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1096 acc_val: 0.4767 loss_test: 1.3770 acc_test: 0.6870 time: 0.3880s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1388 acc_val: 0.4767 loss_test: 1.4049 acc_test: 0.6890 time: 0.4365s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1706 acc_val: 0.4767 loss_test: 1.4337 acc_test: 0.6910 time: 0.4281s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2034 acc_val: 0.4800 loss_test: 1.4610 acc_test: 0.6920 time: 0.4358s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2129 acc_val: 0.4800 loss_test: 1.4808 acc_test: 0.6940 time: 0.3874s
Optimization Finished!
Total time elapsed: 206.7670s, best testing performance  0.695000, minimun loss  0.969935
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7861 acc_train: 0.2083 loss_val: 1.7974 acc_val: 0.2133 loss_test: 1.7117 acc_test: 0.5020 time: 1.9690s
Epoch: 0051 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7344 acc_val: 0.4200 loss_test: 1.1829 acc_test: 0.6660 time: 0.3860s
Epoch: 0101 loss_train: 0.0072 acc_train: 1.0000 loss_val: 1.7010 acc_val: 0.4467 loss_test: 1.1782 acc_test: 0.6840 time: 0.3995s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8074 acc_val: 0.4700 loss_test: 1.2442 acc_test: 0.6870 time: 0.3864s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9288 acc_val: 0.4733 loss_test: 1.3057 acc_test: 0.6900 time: 0.3812s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0001 acc_val: 0.4867 loss_test: 1.3527 acc_test: 0.6910 time: 0.3842s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0284 acc_val: 0.5000 loss_test: 1.3856 acc_test: 0.6950 time: 0.3915s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0804 acc_val: 0.5033 loss_test: 1.4217 acc_test: 0.6980 time: 0.4695s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1227 acc_val: 0.5067 loss_test: 1.4525 acc_test: 0.6980 time: 0.5080s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1415 acc_val: 0.5033 loss_test: 1.4754 acc_test: 0.6950 time: 0.4109s
Optimization Finished!
Total time elapsed: 200.8175s, best testing performance  0.701000, minimun loss  0.978022
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7973 acc_train: 0.1417 loss_val: 1.8015 acc_val: 0.1467 loss_test: 1.6942 acc_test: 0.4390 time: 14.5655s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6236 acc_val: 0.4400 loss_test: 1.1179 acc_test: 0.6840 time: 0.3630s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7051 acc_val: 0.4500 loss_test: 1.1666 acc_test: 0.6970 time: 0.3853s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9762 acc_val: 0.4300 loss_test: 1.2834 acc_test: 0.6860 time: 0.3779s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0520 acc_val: 0.4533 loss_test: 1.3295 acc_test: 0.6910 time: 0.3839s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.1233 acc_val: 0.4767 loss_test: 1.3731 acc_test: 0.6890 time: 0.3882s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1629 acc_val: 0.4733 loss_test: 1.4096 acc_test: 0.6920 time: 0.4196s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.2112 acc_val: 0.4900 loss_test: 1.4441 acc_test: 0.6960 time: 0.4342s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2353 acc_val: 0.4967 loss_test: 1.4730 acc_test: 0.6960 time: 0.4279s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2791 acc_val: 0.5000 loss_test: 1.5033 acc_test: 0.6970 time: 0.3983s
Optimization Finished!
Total time elapsed: 213.6029s, best testing performance  0.706000, minimun loss  0.945992
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8186 acc_train: 0.1167 loss_val: 1.8434 acc_val: 0.0700 loss_test: 1.6867 acc_test: 0.3420 time: 2.4051s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7692 acc_val: 0.3800 loss_test: 1.1639 acc_test: 0.6730 time: 0.3825s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8172 acc_val: 0.4167 loss_test: 1.2034 acc_test: 0.6730 time: 0.3882s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9417 acc_val: 0.4300 loss_test: 1.2695 acc_test: 0.6790 time: 0.3985s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9967 acc_val: 0.4500 loss_test: 1.3053 acc_test: 0.6870 time: 0.4096s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0208 acc_val: 0.4733 loss_test: 1.3317 acc_test: 0.6890 time: 0.3924s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0283 acc_val: 0.4767 loss_test: 1.3565 acc_test: 0.6890 time: 0.3763s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0272 acc_val: 0.4967 loss_test: 1.3764 acc_test: 0.6950 time: 0.4858s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0833 acc_val: 0.5067 loss_test: 1.4100 acc_test: 0.6950 time: 0.4135s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0924 acc_val: 0.5167 loss_test: 1.4322 acc_test: 0.7000 time: 0.3889s
Optimization Finished!
Total time elapsed: 202.0715s, best testing performance  0.701000, minimun loss  0.941753
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8009 acc_train: 0.1417 loss_val: 1.8123 acc_val: 0.1533 loss_test: 1.6662 acc_test: 0.5040 time: 6.7349s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7799 acc_val: 0.3933 loss_test: 1.1703 acc_test: 0.6650 time: 0.4049s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.6905 acc_val: 0.4567 loss_test: 1.1641 acc_test: 0.6900 time: 0.4419s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8799 acc_val: 0.4333 loss_test: 1.2531 acc_test: 0.6890 time: 0.3924s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9654 acc_val: 0.4600 loss_test: 1.3069 acc_test: 0.6920 time: 0.3951s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0430 acc_val: 0.4733 loss_test: 1.3571 acc_test: 0.6900 time: 0.3980s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0895 acc_val: 0.4967 loss_test: 1.3981 acc_test: 0.6930 time: 0.4016s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1501 acc_val: 0.5000 loss_test: 1.4389 acc_test: 0.6950 time: 0.4165s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1884 acc_val: 0.5067 loss_test: 1.4668 acc_test: 0.6990 time: 0.3996s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2079 acc_val: 0.5100 loss_test: 1.4929 acc_test: 0.7000 time: 0.4062s
Optimization Finished!
Total time elapsed: 207.7248s, best testing performance  0.703000, minimun loss  0.954769
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7710 acc_train: 0.2500 loss_val: 1.8085 acc_val: 0.1967 loss_test: 1.6556 acc_test: 0.5540 time: 2.4422s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7182 acc_val: 0.4000 loss_test: 1.1501 acc_test: 0.6720 time: 0.4036s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8657 acc_val: 0.4033 loss_test: 1.2106 acc_test: 0.6790 time: 0.3607s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9593 acc_val: 0.4333 loss_test: 1.2749 acc_test: 0.6870 time: 0.4078s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0135 acc_val: 0.4467 loss_test: 1.3199 acc_test: 0.6860 time: 0.3876s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0206 acc_val: 0.4633 loss_test: 1.3501 acc_test: 0.6910 time: 0.3763s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0664 acc_val: 0.4833 loss_test: 1.3839 acc_test: 0.6950 time: 0.3815s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1284 acc_val: 0.4933 loss_test: 1.4250 acc_test: 0.6990 time: 0.4037s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1625 acc_val: 0.4933 loss_test: 1.4566 acc_test: 0.7010 time: 0.4356s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1787 acc_val: 0.4967 loss_test: 1.4759 acc_test: 0.7020 time: 0.3878s
Optimization Finished!
Total time elapsed: 200.8067s, best testing performance  0.704000, minimun loss  0.957666
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7860 acc_train: 0.2083 loss_val: 1.7899 acc_val: 0.2133 loss_test: 1.6723 acc_test: 0.5490 time: 12.5445s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.7853 acc_val: 0.4133 loss_test: 1.1842 acc_test: 0.6790 time: 0.3845s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8084 acc_val: 0.4300 loss_test: 1.2023 acc_test: 0.6850 time: 0.3944s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9777 acc_val: 0.4467 loss_test: 1.2791 acc_test: 0.6830 time: 0.3784s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0502 acc_val: 0.4567 loss_test: 1.3234 acc_test: 0.6870 time: 0.3692s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1016 acc_val: 0.4733 loss_test: 1.3605 acc_test: 0.6920 time: 0.3991s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1434 acc_val: 0.4867 loss_test: 1.3999 acc_test: 0.6950 time: 0.3899s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1654 acc_val: 0.4967 loss_test: 1.4342 acc_test: 0.6950 time: 0.4648s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2126 acc_val: 0.5100 loss_test: 1.4658 acc_test: 0.6950 time: 0.4369s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.2313 acc_val: 0.5100 loss_test: 1.4961 acc_test: 0.6950 time: 0.3859s
Optimization Finished!
Total time elapsed: 212.9944s, best testing performance  0.702000, minimun loss  0.968640
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7884 acc_train: 0.1583 loss_val: 1.8138 acc_val: 0.0700 loss_test: 1.6481 acc_test: 0.3660 time: 2.0785s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.7511 acc_val: 0.4300 loss_test: 1.1805 acc_test: 0.6750 time: 0.3801s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7970 acc_val: 0.4600 loss_test: 1.1995 acc_test: 0.6870 time: 0.3779s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9078 acc_val: 0.4633 loss_test: 1.2670 acc_test: 0.6920 time: 0.3761s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0055 acc_val: 0.4667 loss_test: 1.3199 acc_test: 0.6860 time: 0.3926s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0826 acc_val: 0.4767 loss_test: 1.3628 acc_test: 0.6880 time: 0.4155s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1228 acc_val: 0.4867 loss_test: 1.3970 acc_test: 0.6900 time: 0.3705s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1529 acc_val: 0.4867 loss_test: 1.4280 acc_test: 0.6890 time: 0.4233s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1860 acc_val: 0.4833 loss_test: 1.4576 acc_test: 0.6880 time: 0.4251s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2114 acc_val: 0.4900 loss_test: 1.4830 acc_test: 0.6900 time: 0.4115s
Optimization Finished!
Total time elapsed: 202.0201s, best testing performance  0.696000, minimun loss  0.967275
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1000 loss_val: 1.8353 acc_val: 0.1333 loss_test: 1.6638 acc_test: 0.4870 time: 5.6269s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8280 acc_val: 0.3867 loss_test: 1.2163 acc_test: 0.6560 time: 0.3790s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8114 acc_val: 0.4367 loss_test: 1.2164 acc_test: 0.6760 time: 0.3945s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8735 acc_val: 0.4467 loss_test: 1.2677 acc_test: 0.6840 time: 0.4010s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9665 acc_val: 0.4633 loss_test: 1.3219 acc_test: 0.6840 time: 0.3788s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0138 acc_val: 0.4733 loss_test: 1.3600 acc_test: 0.6830 time: 0.3582s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0685 acc_val: 0.4933 loss_test: 1.3959 acc_test: 0.6890 time: 0.3984s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0965 acc_val: 0.4900 loss_test: 1.4246 acc_test: 0.6870 time: 0.4687s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1490 acc_val: 0.4867 loss_test: 1.4572 acc_test: 0.6860 time: 0.4256s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1852 acc_val: 0.4900 loss_test: 1.4819 acc_test: 0.6880 time: 0.4257s
Optimization Finished!
Total time elapsed: 204.9384s, best testing performance  0.692000, minimun loss  0.992286
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7850 acc_train: 0.2000 loss_val: 1.8452 acc_val: 0.1100 loss_test: 1.6635 acc_test: 0.5010 time: 1.9503s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8528 acc_val: 0.3833 loss_test: 1.1922 acc_test: 0.6710 time: 0.3740s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8411 acc_val: 0.4500 loss_test: 1.1931 acc_test: 0.6860 time: 0.4009s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9012 acc_val: 0.4567 loss_test: 1.2478 acc_test: 0.6890 time: 0.3994s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9812 acc_val: 0.4600 loss_test: 1.2995 acc_test: 0.6920 time: 0.3787s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 1.9861 acc_val: 0.4800 loss_test: 1.3313 acc_test: 0.6910 time: 0.3847s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0023 acc_val: 0.5000 loss_test: 1.3592 acc_test: 0.6950 time: 0.3798s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 1.9745 acc_val: 0.5100 loss_test: 1.3778 acc_test: 0.6990 time: 0.4463s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0028 acc_val: 0.5100 loss_test: 1.4066 acc_test: 0.7000 time: 0.4272s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0097 acc_val: 0.5033 loss_test: 1.4262 acc_test: 0.7010 time: 0.4220s
Optimization Finished!
Total time elapsed: 201.7638s, best testing performance  0.703000, minimun loss  0.968714
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7756 acc_train: 0.2833 loss_val: 1.8111 acc_val: 0.1867 loss_test: 1.6363 acc_test: 0.5150 time: 5.7761s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.7691 acc_val: 0.4100 loss_test: 1.1945 acc_test: 0.6710 time: 0.3705s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9668 acc_val: 0.4200 loss_test: 1.2533 acc_test: 0.6750 time: 0.3791s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.0725 acc_val: 0.4267 loss_test: 1.3113 acc_test: 0.6820 time: 0.4083s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1040 acc_val: 0.4433 loss_test: 1.3448 acc_test: 0.6850 time: 0.3639s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1044 acc_val: 0.4700 loss_test: 1.3707 acc_test: 0.6860 time: 0.3887s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0769 acc_val: 0.4967 loss_test: 1.3866 acc_test: 0.6920 time: 0.3865s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0873 acc_val: 0.5000 loss_test: 1.4121 acc_test: 0.6940 time: 0.4159s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0883 acc_val: 0.5067 loss_test: 1.4315 acc_test: 0.6960 time: 0.4086s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1159 acc_val: 0.5000 loss_test: 1.4551 acc_test: 0.6950 time: 0.4133s
Optimization Finished!
Total time elapsed: 204.7655s, best testing performance  0.700000, minimun loss  0.960198
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8048 acc_train: 0.1333 loss_val: 1.8272 acc_val: 0.1500 loss_test: 1.6449 acc_test: 0.4700 time: 3.6024s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.9054 acc_val: 0.4000 loss_test: 1.2081 acc_test: 0.6640 time: 0.4003s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.9020 acc_val: 0.4367 loss_test: 1.2164 acc_test: 0.6760 time: 0.3993s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9838 acc_val: 0.4400 loss_test: 1.2746 acc_test: 0.6850 time: 0.3990s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0764 acc_val: 0.4633 loss_test: 1.3289 acc_test: 0.6870 time: 0.4188s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1625 acc_val: 0.4733 loss_test: 1.3808 acc_test: 0.6890 time: 0.3873s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.2124 acc_val: 0.4767 loss_test: 1.4203 acc_test: 0.6910 time: 0.4144s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2652 acc_val: 0.4800 loss_test: 1.4550 acc_test: 0.6930 time: 0.4353s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2966 acc_val: 0.4800 loss_test: 1.4831 acc_test: 0.6940 time: 0.4380s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.3488 acc_val: 0.4867 loss_test: 1.5149 acc_test: 0.6950 time: 0.3621s
Optimization Finished!
Total time elapsed: 204.5535s, best testing performance  0.697000, minimun loss  0.954019
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7888 acc_train: 0.1750 loss_val: 1.8405 acc_val: 0.1500 loss_test: 1.6723 acc_test: 0.4860 time: 5.9949s
Epoch: 0051 loss_train: 0.0094 acc_train: 1.0000 loss_val: 1.7438 acc_val: 0.3767 loss_test: 1.1882 acc_test: 0.6610 time: 0.3895s
Epoch: 0101 loss_train: 0.0073 acc_train: 1.0000 loss_val: 1.7786 acc_val: 0.4300 loss_test: 1.2101 acc_test: 0.6830 time: 0.3993s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9405 acc_val: 0.4533 loss_test: 1.2801 acc_test: 0.6880 time: 0.4005s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9860 acc_val: 0.4733 loss_test: 1.3166 acc_test: 0.6920 time: 0.4500s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0255 acc_val: 0.4833 loss_test: 1.3530 acc_test: 0.6960 time: 0.3992s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0720 acc_val: 0.4933 loss_test: 1.3934 acc_test: 0.6940 time: 0.3931s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1122 acc_val: 0.4967 loss_test: 1.4274 acc_test: 0.6960 time: 0.4474s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1551 acc_val: 0.5133 loss_test: 1.4575 acc_test: 0.6950 time: 0.4250s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1487 acc_val: 0.5167 loss_test: 1.4762 acc_test: 0.7000 time: 0.4112s
Optimization Finished!
Total time elapsed: 208.7299s, best testing performance  0.703000, minimun loss  0.986575
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8088 acc_train: 0.1417 loss_val: 1.8116 acc_val: 0.0867 loss_test: 1.6900 acc_test: 0.3700 time: 2.5872s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.6018 acc_val: 0.4333 loss_test: 1.1231 acc_test: 0.6670 time: 0.3880s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7368 acc_val: 0.4433 loss_test: 1.1754 acc_test: 0.6790 time: 0.3828s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8744 acc_val: 0.4633 loss_test: 1.2423 acc_test: 0.6800 time: 0.3871s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9788 acc_val: 0.4600 loss_test: 1.3012 acc_test: 0.6780 time: 0.3970s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0385 acc_val: 0.4700 loss_test: 1.3441 acc_test: 0.6850 time: 0.3864s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0951 acc_val: 0.4800 loss_test: 1.3834 acc_test: 0.6880 time: 0.4282s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1212 acc_val: 0.5033 loss_test: 1.4094 acc_test: 0.6890 time: 0.4721s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1719 acc_val: 0.5067 loss_test: 1.4432 acc_test: 0.6860 time: 0.4468s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2303 acc_val: 0.5100 loss_test: 1.4744 acc_test: 0.6860 time: 0.3898s
Optimization Finished!
Total time elapsed: 203.3781s, best testing performance  0.692000, minimun loss  0.965018
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8176 acc_train: 0.0833 loss_val: 1.8056 acc_val: 0.1933 loss_test: 1.6908 acc_test: 0.3060 time: 12.5891s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.6008 acc_val: 0.4600 loss_test: 1.1306 acc_test: 0.6760 time: 0.3904s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.6589 acc_val: 0.4767 loss_test: 1.1586 acc_test: 0.6890 time: 0.4034s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8542 acc_val: 0.4700 loss_test: 1.2490 acc_test: 0.6910 time: 0.3801s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9728 acc_val: 0.4633 loss_test: 1.3080 acc_test: 0.6920 time: 0.4012s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0550 acc_val: 0.4600 loss_test: 1.3565 acc_test: 0.6910 time: 0.3788s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1014 acc_val: 0.4733 loss_test: 1.3949 acc_test: 0.6910 time: 0.4026s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1467 acc_val: 0.4933 loss_test: 1.4293 acc_test: 0.6970 time: 0.4076s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1867 acc_val: 0.5000 loss_test: 1.4587 acc_test: 0.7030 time: 0.4413s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1773 acc_val: 0.5000 loss_test: 1.4710 acc_test: 0.7010 time: 0.4208s
Optimization Finished!
Total time elapsed: 212.7362s, best testing performance  0.705000, minimun loss  0.955883
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7937 acc_train: 0.1333 loss_val: 1.8325 acc_val: 0.0600 loss_test: 1.6699 acc_test: 0.3700 time: 2.9688s
Epoch: 0051 loss_train: 0.0091 acc_train: 1.0000 loss_val: 1.6313 acc_val: 0.4433 loss_test: 1.1594 acc_test: 0.6800 time: 0.3600s
Epoch: 0101 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.7301 acc_val: 0.4700 loss_test: 1.2005 acc_test: 0.6850 time: 0.3906s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9124 acc_val: 0.4567 loss_test: 1.2802 acc_test: 0.6930 time: 0.3794s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0010 acc_val: 0.4533 loss_test: 1.3288 acc_test: 0.6910 time: 0.3827s
Epoch: 0251 loss_train: 0.0033 acc_train: 1.0000 loss_val: 2.0405 acc_val: 0.4800 loss_test: 1.3662 acc_test: 0.6950 time: 0.4510s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0760 acc_val: 0.4900 loss_test: 1.3983 acc_test: 0.6910 time: 0.3675s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1213 acc_val: 0.5000 loss_test: 1.4338 acc_test: 0.6940 time: 0.4184s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1265 acc_val: 0.5033 loss_test: 1.4534 acc_test: 0.6970 time: 0.4319s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1573 acc_val: 0.5100 loss_test: 1.4749 acc_test: 0.6970 time: 0.4561s
Optimization Finished!
Total time elapsed: 202.9059s, best testing performance  0.698000, minimun loss  0.974753
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8079 acc_train: 0.1333 loss_val: 1.8491 acc_val: 0.0500 loss_test: 1.6808 acc_test: 0.3270 time: 5.0342s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.6257 acc_val: 0.4267 loss_test: 1.1455 acc_test: 0.6750 time: 0.3816s
Epoch: 0101 loss_train: 0.0074 acc_train: 1.0000 loss_val: 1.6968 acc_val: 0.4567 loss_test: 1.1680 acc_test: 0.6870 time: 0.3920s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.9043 acc_val: 0.4700 loss_test: 1.2587 acc_test: 0.6910 time: 0.3807s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9969 acc_val: 0.4800 loss_test: 1.3126 acc_test: 0.6900 time: 0.3788s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0409 acc_val: 0.4667 loss_test: 1.3590 acc_test: 0.6940 time: 0.3839s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1109 acc_val: 0.4867 loss_test: 1.4005 acc_test: 0.6930 time: 0.4422s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1750 acc_val: 0.4900 loss_test: 1.4429 acc_test: 0.6940 time: 0.4468s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2054 acc_val: 0.4867 loss_test: 1.4674 acc_test: 0.6950 time: 0.4196s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2611 acc_val: 0.4900 loss_test: 1.4989 acc_test: 0.6970 time: 0.3881s
Optimization Finished!
Total time elapsed: 206.5473s, best testing performance  0.701000, minimun loss  0.970134
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1750 loss_val: 1.8358 acc_val: 0.0967 loss_test: 1.6399 acc_test: 0.4340 time: 3.4371s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.7345 acc_val: 0.4167 loss_test: 1.1506 acc_test: 0.6800 time: 0.3929s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.7086 acc_val: 0.4667 loss_test: 1.1625 acc_test: 0.6950 time: 0.3562s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8315 acc_val: 0.4667 loss_test: 1.2455 acc_test: 0.6950 time: 0.3846s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9150 acc_val: 0.4733 loss_test: 1.2992 acc_test: 0.6920 time: 0.3891s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9839 acc_val: 0.4767 loss_test: 1.3420 acc_test: 0.6920 time: 0.3750s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0496 acc_val: 0.4767 loss_test: 1.3844 acc_test: 0.6910 time: 0.3824s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0802 acc_val: 0.4933 loss_test: 1.4144 acc_test: 0.6990 time: 0.4350s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1118 acc_val: 0.5067 loss_test: 1.4437 acc_test: 0.6970 time: 0.4177s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1292 acc_val: 0.5167 loss_test: 1.4652 acc_test: 0.6980 time: 0.4200s
Optimization Finished!
Total time elapsed: 204.1063s, best testing performance  0.701000, minimun loss  0.960921
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7942 acc_train: 0.1250 loss_val: 1.8250 acc_val: 0.0700 loss_test: 1.6620 acc_test: 0.3740 time: 7.4283s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.9362 acc_val: 0.3767 loss_test: 1.2107 acc_test: 0.6630 time: 0.3693s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8955 acc_val: 0.4300 loss_test: 1.2166 acc_test: 0.6840 time: 0.3880s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9615 acc_val: 0.4567 loss_test: 1.2701 acc_test: 0.6900 time: 0.3635s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0080 acc_val: 0.4667 loss_test: 1.3086 acc_test: 0.6960 time: 0.3614s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0361 acc_val: 0.4800 loss_test: 1.3463 acc_test: 0.6940 time: 0.3769s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0759 acc_val: 0.4967 loss_test: 1.3802 acc_test: 0.6950 time: 0.3950s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1101 acc_val: 0.4900 loss_test: 1.4135 acc_test: 0.6980 time: 0.4102s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1485 acc_val: 0.4900 loss_test: 1.4426 acc_test: 0.6970 time: 0.4250s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1997 acc_val: 0.4967 loss_test: 1.4721 acc_test: 0.6990 time: 0.4047s
Optimization Finished!
Total time elapsed: 207.9177s, best testing performance  0.702000, minimun loss  0.971121
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7843 acc_train: 0.2250 loss_val: 1.8362 acc_val: 0.1167 loss_test: 1.6452 acc_test: 0.4340 time: 3.9011s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8929 acc_val: 0.3967 loss_test: 1.2159 acc_test: 0.6700 time: 0.3690s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9715 acc_val: 0.4333 loss_test: 1.2451 acc_test: 0.6790 time: 0.4334s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 2.0884 acc_val: 0.4267 loss_test: 1.3155 acc_test: 0.6810 time: 0.3740s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.1108 acc_val: 0.4600 loss_test: 1.3547 acc_test: 0.6880 time: 0.3635s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1271 acc_val: 0.4733 loss_test: 1.3901 acc_test: 0.6890 time: 0.3835s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1500 acc_val: 0.4800 loss_test: 1.4249 acc_test: 0.6930 time: 0.4141s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1964 acc_val: 0.5000 loss_test: 1.4654 acc_test: 0.6940 time: 0.4229s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2107 acc_val: 0.5167 loss_test: 1.4948 acc_test: 0.6990 time: 0.4667s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2477 acc_val: 0.5100 loss_test: 1.5243 acc_test: 0.6950 time: 0.3944s
Optimization Finished!
Total time elapsed: 205.6612s, best testing performance  0.700000, minimun loss  0.997983
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7876 acc_train: 0.2250 loss_val: 1.8414 acc_val: 0.1300 loss_test: 1.6624 acc_test: 0.4980 time: 4.6549s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 1.8419 acc_val: 0.4033 loss_test: 1.1876 acc_test: 0.6730 time: 0.3907s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8794 acc_val: 0.4233 loss_test: 1.2179 acc_test: 0.6800 time: 0.3903s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9305 acc_val: 0.4633 loss_test: 1.2727 acc_test: 0.6860 time: 0.3906s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9427 acc_val: 0.4833 loss_test: 1.3084 acc_test: 0.6900 time: 0.3803s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9937 acc_val: 0.4867 loss_test: 1.3492 acc_test: 0.6940 time: 0.3859s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 1.9989 acc_val: 0.5067 loss_test: 1.3773 acc_test: 0.6990 time: 0.4122s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0733 acc_val: 0.5067 loss_test: 1.4192 acc_test: 0.6980 time: 0.4368s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1124 acc_val: 0.5167 loss_test: 1.4518 acc_test: 0.6990 time: 0.4052s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1504 acc_val: 0.5233 loss_test: 1.4779 acc_test: 0.7000 time: 0.3924s
Optimization Finished!
Total time elapsed: 205.4080s, best testing performance  0.705000, minimun loss  0.992056
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 60, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7868 acc_train: 0.1917 loss_val: 1.8048 acc_val: 0.1800 loss_test: 1.6486 acc_test: 0.5460 time: 2.8823s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8287 acc_val: 0.4200 loss_test: 1.1742 acc_test: 0.6720 time: 0.3897s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.8831 acc_val: 0.4400 loss_test: 1.2161 acc_test: 0.6860 time: 0.4007s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9656 acc_val: 0.4500 loss_test: 1.2793 acc_test: 0.6960 time: 0.3828s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0214 acc_val: 0.4667 loss_test: 1.3305 acc_test: 0.6910 time: 0.4499s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0351 acc_val: 0.4800 loss_test: 1.3693 acc_test: 0.6880 time: 0.3759s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1081 acc_val: 0.5067 loss_test: 1.4155 acc_test: 0.6940 time: 0.4261s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1695 acc_val: 0.5100 loss_test: 1.4539 acc_test: 0.6950 time: 0.4188s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1926 acc_val: 0.5133 loss_test: 1.4734 acc_test: 0.6950 time: 0.4337s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2287 acc_val: 0.5067 loss_test: 1.4993 acc_test: 0.6950 time: 0.3950s
Optimization Finished!
Total time elapsed: 206.2095s, best testing performance  0.700000, minimun loss  0.973673
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8065 acc_train: 0.0750 loss_val: 1.8327 acc_val: 0.1567 loss_test: 1.6685 acc_test: 0.5050 time: 36.2912s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 2.0432 acc_val: 0.3667 loss_test: 1.2297 acc_test: 0.6550 time: 0.4287s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 2.0783 acc_val: 0.3933 loss_test: 1.2547 acc_test: 0.6720 time: 0.4542s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 2.1236 acc_val: 0.4133 loss_test: 1.3112 acc_test: 0.6790 time: 0.4453s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1432 acc_val: 0.4667 loss_test: 1.3512 acc_test: 0.6860 time: 0.4547s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1402 acc_val: 0.4767 loss_test: 1.3768 acc_test: 0.6870 time: 0.4764s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1554 acc_val: 0.4800 loss_test: 1.4059 acc_test: 0.6890 time: 0.5425s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1709 acc_val: 0.5000 loss_test: 1.4289 acc_test: 0.6910 time: 0.5037s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1581 acc_val: 0.5067 loss_test: 1.4463 acc_test: 0.6900 time: 0.4687s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1609 acc_val: 0.5067 loss_test: 1.4626 acc_test: 0.6930 time: 0.4333s
Optimization Finished!
Total time elapsed: 270.7828s, best testing performance  0.697000, minimun loss  1.012688
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7789 acc_train: 0.1917 loss_val: 1.8164 acc_val: 0.2133 loss_test: 1.6380 acc_test: 0.5540 time: 38.9386s
Epoch: 0051 loss_train: 0.0093 acc_train: 1.0000 loss_val: 2.0209 acc_val: 0.3400 loss_test: 1.1977 acc_test: 0.6570 time: 0.4655s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9913 acc_val: 0.3900 loss_test: 1.2139 acc_test: 0.6660 time: 0.4598s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 2.1238 acc_val: 0.4000 loss_test: 1.3065 acc_test: 0.6670 time: 0.4186s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.1886 acc_val: 0.4367 loss_test: 1.3539 acc_test: 0.6810 time: 0.4126s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1868 acc_val: 0.4633 loss_test: 1.3785 acc_test: 0.6860 time: 0.4904s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1619 acc_val: 0.4800 loss_test: 1.4001 acc_test: 0.6900 time: 0.4576s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1933 acc_val: 0.4967 loss_test: 1.4293 acc_test: 0.6940 time: 0.4977s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1904 acc_val: 0.5067 loss_test: 1.4471 acc_test: 0.6970 time: 0.5016s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2727 acc_val: 0.5067 loss_test: 1.4829 acc_test: 0.6990 time: 0.4576s
Optimization Finished!
Total time elapsed: 275.2269s, best testing performance  0.701000, minimun loss  0.962362
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7989 acc_train: 0.0917 loss_val: 1.8375 acc_val: 0.1000 loss_test: 1.6592 acc_test: 0.4470 time: 36.9077s
Epoch: 0051 loss_train: 0.0105 acc_train: 1.0000 loss_val: 2.0100 acc_val: 0.3500 loss_test: 1.1971 acc_test: 0.6510 time: 0.4746s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.9730 acc_val: 0.3933 loss_test: 1.2109 acc_test: 0.6680 time: 0.4265s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 2.0389 acc_val: 0.4100 loss_test: 1.2789 acc_test: 0.6760 time: 0.4543s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0618 acc_val: 0.4300 loss_test: 1.3171 acc_test: 0.6840 time: 0.4485s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0727 acc_val: 0.4600 loss_test: 1.3455 acc_test: 0.6870 time: 0.4688s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1030 acc_val: 0.4767 loss_test: 1.3824 acc_test: 0.6900 time: 0.4317s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1256 acc_val: 0.4900 loss_test: 1.4112 acc_test: 0.6930 time: 0.5094s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1779 acc_val: 0.4933 loss_test: 1.4486 acc_test: 0.6960 time: 0.5477s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1912 acc_val: 0.5067 loss_test: 1.4700 acc_test: 0.6960 time: 0.4574s
Optimization Finished!
Total time elapsed: 272.4964s, best testing performance  0.701000, minimun loss  0.952026
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7973 acc_train: 0.1750 loss_val: 1.8344 acc_val: 0.0433 loss_test: 1.6648 acc_test: 0.3290 time: 40.8792s
Epoch: 0051 loss_train: 0.0089 acc_train: 1.0000 loss_val: 1.9310 acc_val: 0.3667 loss_test: 1.1895 acc_test: 0.6690 time: 0.4164s
Epoch: 0101 loss_train: 0.0075 acc_train: 1.0000 loss_val: 1.9564 acc_val: 0.4100 loss_test: 1.2252 acc_test: 0.6770 time: 0.4216s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 2.0812 acc_val: 0.4233 loss_test: 1.3034 acc_test: 0.6780 time: 0.4485s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.1157 acc_val: 0.4467 loss_test: 1.3383 acc_test: 0.6840 time: 0.5035s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1260 acc_val: 0.4667 loss_test: 1.3639 acc_test: 0.6860 time: 0.4512s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1468 acc_val: 0.4867 loss_test: 1.3919 acc_test: 0.6900 time: 0.5018s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1252 acc_val: 0.5067 loss_test: 1.4060 acc_test: 0.6950 time: 0.4689s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1447 acc_val: 0.5133 loss_test: 1.4279 acc_test: 0.6970 time: 0.4922s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1801 acc_val: 0.5100 loss_test: 1.4549 acc_test: 0.6990 time: 0.4703s
Optimization Finished!
Total time elapsed: 277.2776s, best testing performance  0.702000, minimun loss  0.971142
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7960 acc_train: 0.1250 loss_val: 1.8315 acc_val: 0.0500 loss_test: 1.6641 acc_test: 0.3250 time: 38.4544s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.8740 acc_val: 0.3800 loss_test: 1.1674 acc_test: 0.6650 time: 0.4677s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.8861 acc_val: 0.4200 loss_test: 1.1917 acc_test: 0.6740 time: 0.4501s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.9401 acc_val: 0.4467 loss_test: 1.2515 acc_test: 0.6860 time: 0.4471s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 2.0237 acc_val: 0.4567 loss_test: 1.3174 acc_test: 0.6850 time: 0.4129s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0588 acc_val: 0.4733 loss_test: 1.3585 acc_test: 0.6900 time: 0.4440s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0791 acc_val: 0.4867 loss_test: 1.3884 acc_test: 0.6920 time: 0.4763s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1064 acc_val: 0.4900 loss_test: 1.4194 acc_test: 0.6940 time: 0.5011s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1103 acc_val: 0.5133 loss_test: 1.4438 acc_test: 0.6990 time: 0.5294s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1470 acc_val: 0.5100 loss_test: 1.4711 acc_test: 0.6970 time: 0.5049s
Optimization Finished!
Total time elapsed: 273.2802s, best testing performance  0.701000, minimun loss  0.944376
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7995 acc_train: 0.1083 loss_val: 1.8542 acc_val: 0.1667 loss_test: 1.6693 acc_test: 0.5030 time: 19.4726s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 2.0143 acc_val: 0.3533 loss_test: 1.2292 acc_test: 0.6510 time: 0.5428s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.9471 acc_val: 0.3867 loss_test: 1.2213 acc_test: 0.6680 time: 0.5029s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0487 acc_val: 0.4233 loss_test: 1.2869 acc_test: 0.6790 time: 0.5069s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1005 acc_val: 0.4500 loss_test: 1.3320 acc_test: 0.6810 time: 0.4198s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1258 acc_val: 0.4800 loss_test: 1.3733 acc_test: 0.6870 time: 0.5244s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1435 acc_val: 0.4933 loss_test: 1.4097 acc_test: 0.6940 time: 0.4962s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1648 acc_val: 0.5067 loss_test: 1.4468 acc_test: 0.6930 time: 0.5130s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1672 acc_val: 0.5100 loss_test: 1.4777 acc_test: 0.6940 time: 0.5290s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1905 acc_val: 0.5133 loss_test: 1.5128 acc_test: 0.6910 time: 0.4259s
Optimization Finished!
Total time elapsed: 254.9070s, best testing performance  0.697000, minimun loss  0.993737
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7762 acc_train: 0.2250 loss_val: 1.8196 acc_val: 0.1333 loss_test: 1.6313 acc_test: 0.4980 time: 28.1044s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.8463 acc_val: 0.4067 loss_test: 1.1767 acc_test: 0.6760 time: 0.4716s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8648 acc_val: 0.4233 loss_test: 1.2029 acc_test: 0.6840 time: 0.4562s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9754 acc_val: 0.4533 loss_test: 1.2843 acc_test: 0.6830 time: 0.4744s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0626 acc_val: 0.4633 loss_test: 1.3427 acc_test: 0.6830 time: 0.4287s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.1069 acc_val: 0.4800 loss_test: 1.3806 acc_test: 0.6870 time: 0.4666s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1350 acc_val: 0.4800 loss_test: 1.4129 acc_test: 0.6970 time: 0.4691s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1381 acc_val: 0.4933 loss_test: 1.4360 acc_test: 0.6960 time: 0.4713s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1544 acc_val: 0.5067 loss_test: 1.4590 acc_test: 0.6970 time: 0.5159s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1528 acc_val: 0.5067 loss_test: 1.4813 acc_test: 0.6950 time: 0.4510s
Optimization Finished!
Total time elapsed: 263.5921s, best testing performance  0.699000, minimun loss  0.970151
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1667 loss_val: 1.8281 acc_val: 0.1667 loss_test: 1.6670 acc_test: 0.4650 time: 26.6227s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.9534 acc_val: 0.3767 loss_test: 1.2146 acc_test: 0.6570 time: 0.4165s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9505 acc_val: 0.4033 loss_test: 1.2238 acc_test: 0.6700 time: 0.4726s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0279 acc_val: 0.4400 loss_test: 1.2836 acc_test: 0.6830 time: 0.4519s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0479 acc_val: 0.4600 loss_test: 1.3197 acc_test: 0.6860 time: 0.4668s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1024 acc_val: 0.4767 loss_test: 1.3648 acc_test: 0.6910 time: 0.4217s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1534 acc_val: 0.4800 loss_test: 1.4026 acc_test: 0.6950 time: 0.4904s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1694 acc_val: 0.4900 loss_test: 1.4296 acc_test: 0.6950 time: 0.5061s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1898 acc_val: 0.4967 loss_test: 1.4555 acc_test: 0.6950 time: 0.5059s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2187 acc_val: 0.5000 loss_test: 1.4808 acc_test: 0.6960 time: 0.4340s
Optimization Finished!
Total time elapsed: 260.4888s, best testing performance  0.700000, minimun loss  0.985447
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7938 acc_train: 0.2083 loss_val: 1.8440 acc_val: 0.1267 loss_test: 1.6753 acc_test: 0.4570 time: 40.0386s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 2.0061 acc_val: 0.3667 loss_test: 1.2376 acc_test: 0.6610 time: 0.4473s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9559 acc_val: 0.4033 loss_test: 1.2381 acc_test: 0.6680 time: 0.4518s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9717 acc_val: 0.4400 loss_test: 1.2798 acc_test: 0.6800 time: 0.4219s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0054 acc_val: 0.4567 loss_test: 1.3208 acc_test: 0.6840 time: 0.4648s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4767 loss_test: 1.3572 acc_test: 0.6890 time: 0.4529s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0587 acc_val: 0.5000 loss_test: 1.3922 acc_test: 0.6950 time: 0.4166s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0824 acc_val: 0.5033 loss_test: 1.4211 acc_test: 0.6950 time: 0.4768s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1146 acc_val: 0.5100 loss_test: 1.4461 acc_test: 0.6950 time: 0.5312s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1255 acc_val: 0.5133 loss_test: 1.4690 acc_test: 0.6980 time: 0.4260s
Optimization Finished!
Total time elapsed: 274.8932s, best testing performance  0.699000, minimun loss  0.971693
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7875 acc_train: 0.1250 loss_val: 1.8231 acc_val: 0.1400 loss_test: 1.6562 acc_test: 0.5380 time: 18.3151s
Epoch: 0051 loss_train: 0.0092 acc_train: 1.0000 loss_val: 1.7406 acc_val: 0.3833 loss_test: 1.1183 acc_test: 0.6770 time: 0.4460s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.7848 acc_val: 0.4433 loss_test: 1.1576 acc_test: 0.6840 time: 0.4971s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9297 acc_val: 0.4433 loss_test: 1.2412 acc_test: 0.6830 time: 0.4160s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9964 acc_val: 0.4700 loss_test: 1.2900 acc_test: 0.6910 time: 0.4541s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0576 acc_val: 0.4767 loss_test: 1.3374 acc_test: 0.6910 time: 0.4788s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0773 acc_val: 0.4900 loss_test: 1.3711 acc_test: 0.6930 time: 0.4841s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1253 acc_val: 0.4933 loss_test: 1.4093 acc_test: 0.6960 time: 0.4981s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1790 acc_val: 0.4933 loss_test: 1.4469 acc_test: 0.6950 time: 0.4799s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1798 acc_val: 0.4933 loss_test: 1.4661 acc_test: 0.6960 time: 0.4639s
Optimization Finished!
Total time elapsed: 252.4444s, best testing performance  0.699000, minimun loss  0.938215
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8055 acc_train: 0.1167 loss_val: 1.8242 acc_val: 0.1733 loss_test: 1.6737 acc_test: 0.4890 time: 24.3179s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 2.0407 acc_val: 0.3567 loss_test: 1.2657 acc_test: 0.6600 time: 0.4519s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9966 acc_val: 0.4067 loss_test: 1.2468 acc_test: 0.6670 time: 0.4802s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0577 acc_val: 0.4267 loss_test: 1.2925 acc_test: 0.6780 time: 0.4176s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1012 acc_val: 0.4567 loss_test: 1.3307 acc_test: 0.6860 time: 0.4490s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.1038 acc_val: 0.4767 loss_test: 1.3631 acc_test: 0.6940 time: 0.4544s
Epoch: 0301 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1115 acc_val: 0.5033 loss_test: 1.3967 acc_test: 0.6940 time: 0.4716s
Epoch: 0351 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1164 acc_val: 0.5033 loss_test: 1.4323 acc_test: 0.7040 time: 0.5030s
Epoch: 0401 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1351 acc_val: 0.5067 loss_test: 1.4763 acc_test: 0.6940 time: 0.5123s
Epoch: 0451 loss_train: 0.0015 acc_train: 1.0000 loss_val: 2.1435 acc_val: 0.5033 loss_test: 1.5128 acc_test: 0.6900 time: 0.4550s
Optimization Finished!
Total time elapsed: 260.0092s, best testing performance  0.704000, minimun loss  1.016604
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8006 acc_train: 0.0917 loss_val: 1.7754 acc_val: 0.2433 loss_test: 1.6536 acc_test: 0.5310 time: 3.1143s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.9416 acc_val: 0.3900 loss_test: 1.1962 acc_test: 0.6620 time: 0.4641s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9005 acc_val: 0.4167 loss_test: 1.2070 acc_test: 0.6750 time: 0.4514s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0017 acc_val: 0.4267 loss_test: 1.2718 acc_test: 0.6850 time: 0.4675s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0462 acc_val: 0.4600 loss_test: 1.3140 acc_test: 0.6910 time: 0.4533s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0704 acc_val: 0.4833 loss_test: 1.3511 acc_test: 0.6950 time: 0.4143s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1033 acc_val: 0.4933 loss_test: 1.3884 acc_test: 0.6960 time: 0.4797s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1308 acc_val: 0.4967 loss_test: 1.4217 acc_test: 0.6990 time: 0.4885s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1568 acc_val: 0.5100 loss_test: 1.4504 acc_test: 0.6970 time: 0.4832s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1753 acc_val: 0.5067 loss_test: 1.4723 acc_test: 0.6990 time: 0.4639s
Optimization Finished!
Total time elapsed: 235.7361s, best testing performance  0.701000, minimun loss  0.959705
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7987 acc_train: 0.1750 loss_val: 1.8041 acc_val: 0.1867 loss_test: 1.6757 acc_test: 0.3610 time: 13.8671s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.9499 acc_val: 0.3600 loss_test: 1.2156 acc_test: 0.6640 time: 0.4759s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.9008 acc_val: 0.4133 loss_test: 1.2071 acc_test: 0.6740 time: 0.4521s
Epoch: 0151 loss_train: 0.0062 acc_train: 1.0000 loss_val: 1.9853 acc_val: 0.4533 loss_test: 1.2657 acc_test: 0.6860 time: 0.4472s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0276 acc_val: 0.4800 loss_test: 1.3143 acc_test: 0.6880 time: 0.4659s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0391 acc_val: 0.4967 loss_test: 1.3526 acc_test: 0.6900 time: 0.4496s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0735 acc_val: 0.5033 loss_test: 1.3930 acc_test: 0.6910 time: 0.4729s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1095 acc_val: 0.5033 loss_test: 1.4258 acc_test: 0.6960 time: 0.4913s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1317 acc_val: 0.5100 loss_test: 1.4561 acc_test: 0.6950 time: 0.4816s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1625 acc_val: 0.5133 loss_test: 1.4837 acc_test: 0.7010 time: 0.4335s
Optimization Finished!
Total time elapsed: 247.0727s, best testing performance  0.703000, minimun loss  0.994363
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8124 acc_train: 0.1083 loss_val: 1.8330 acc_val: 0.0900 loss_test: 1.6801 acc_test: 0.3980 time: 3.8464s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.9980 acc_val: 0.3500 loss_test: 1.2265 acc_test: 0.6580 time: 0.4181s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.9844 acc_val: 0.3933 loss_test: 1.2343 acc_test: 0.6660 time: 0.4119s
Epoch: 0151 loss_train: 0.0064 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4333 loss_test: 1.2791 acc_test: 0.6790 time: 0.4791s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 2.0616 acc_val: 0.4600 loss_test: 1.3226 acc_test: 0.6820 time: 0.4541s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0874 acc_val: 0.4700 loss_test: 1.3612 acc_test: 0.6880 time: 0.4549s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1020 acc_val: 0.4867 loss_test: 1.3895 acc_test: 0.6890 time: 0.5079s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1132 acc_val: 0.5100 loss_test: 1.4166 acc_test: 0.6920 time: 0.5276s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1456 acc_val: 0.5167 loss_test: 1.4410 acc_test: 0.6950 time: 0.4529s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1798 acc_val: 0.5133 loss_test: 1.4687 acc_test: 0.6930 time: 0.4203s
Optimization Finished!
Total time elapsed: 237.0951s, best testing performance  0.696000, minimun loss  0.984548
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.2, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8051 acc_train: 0.1333 loss_val: 1.7973 acc_val: 0.1567 loss_test: 1.6583 acc_test: 0.4990 time: 11.7046s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.9394 acc_val: 0.3567 loss_test: 1.2177 acc_test: 0.6570 time: 0.4188s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8977 acc_val: 0.4100 loss_test: 1.2152 acc_test: 0.6730 time: 0.4602s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9831 acc_val: 0.4367 loss_test: 1.2756 acc_test: 0.6860 time: 0.4690s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0428 acc_val: 0.4567 loss_test: 1.3212 acc_test: 0.6860 time: 0.4725s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0880 acc_val: 0.4767 loss_test: 1.3604 acc_test: 0.6900 time: 0.4554s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1509 acc_val: 0.4933 loss_test: 1.4023 acc_test: 0.6900 time: 0.4843s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1774 acc_val: 0.4967 loss_test: 1.4310 acc_test: 0.6930 time: 0.4939s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2155 acc_val: 0.5033 loss_test: 1.4617 acc_test: 0.6950 time: 0.4846s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2564 acc_val: 0.5100 loss_test: 1.4888 acc_test: 0.6950 time: 0.4866s
Optimization Finished!
Total time elapsed: 246.5388s, best testing performance  0.699000, minimun loss  0.985057
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8012 acc_train: 0.1333 loss_val: 1.8151 acc_val: 0.1733 loss_test: 1.6848 acc_test: 0.3920 time: 4.7024s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6278 acc_val: 0.4433 loss_test: 1.0907 acc_test: 0.6840 time: 0.4484s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7723 acc_val: 0.4533 loss_test: 1.1617 acc_test: 0.6920 time: 0.4202s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9620 acc_val: 0.4433 loss_test: 1.2696 acc_test: 0.6750 time: 0.4109s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0509 acc_val: 0.4533 loss_test: 1.3236 acc_test: 0.6790 time: 0.4464s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0853 acc_val: 0.4633 loss_test: 1.3585 acc_test: 0.6850 time: 0.4525s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1191 acc_val: 0.4767 loss_test: 1.3903 acc_test: 0.6890 time: 0.4489s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1574 acc_val: 0.4900 loss_test: 1.4197 acc_test: 0.6900 time: 0.5181s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1610 acc_val: 0.4967 loss_test: 1.4390 acc_test: 0.6890 time: 0.5318s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1875 acc_val: 0.4867 loss_test: 1.4606 acc_test: 0.6920 time: 0.4626s
Optimization Finished!
Total time elapsed: 238.7453s, best testing performance  0.698000, minimun loss  0.939661
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7974 acc_train: 0.1167 loss_val: 1.8293 acc_val: 0.1233 loss_test: 1.6858 acc_test: 0.4070 time: 9.7590s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.7518 acc_val: 0.4067 loss_test: 1.1379 acc_test: 0.6780 time: 0.4528s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.8665 acc_val: 0.4167 loss_test: 1.2037 acc_test: 0.6740 time: 0.4442s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0041 acc_val: 0.4267 loss_test: 1.2885 acc_test: 0.6790 time: 0.4520s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0437 acc_val: 0.4567 loss_test: 1.3267 acc_test: 0.6860 time: 0.4467s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0741 acc_val: 0.4667 loss_test: 1.3621 acc_test: 0.6850 time: 0.4815s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1095 acc_val: 0.4833 loss_test: 1.3958 acc_test: 0.6890 time: 0.4551s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1478 acc_val: 0.4933 loss_test: 1.4311 acc_test: 0.6870 time: 0.5082s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1369 acc_val: 0.4900 loss_test: 1.4513 acc_test: 0.6870 time: 0.5196s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1940 acc_val: 0.4933 loss_test: 1.4849 acc_test: 0.6900 time: 0.5378s
Optimization Finished!
Total time elapsed: 242.4049s, best testing performance  0.697000, minimun loss  0.945194
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7820 acc_train: 0.1833 loss_val: 1.8398 acc_val: 0.1900 loss_test: 1.6779 acc_test: 0.3970 time: 5.0344s
Epoch: 0051 loss_train: 0.0108 acc_train: 1.0000 loss_val: 1.6243 acc_val: 0.4300 loss_test: 1.1292 acc_test: 0.6810 time: 0.4608s
Epoch: 0101 loss_train: 0.0087 acc_train: 1.0000 loss_val: 1.6576 acc_val: 0.4867 loss_test: 1.1587 acc_test: 0.6880 time: 0.5139s
Epoch: 0151 loss_train: 0.0063 acc_train: 1.0000 loss_val: 1.8526 acc_val: 0.4633 loss_test: 1.2494 acc_test: 0.6880 time: 0.4657s
Epoch: 0201 loss_train: 0.0049 acc_train: 1.0000 loss_val: 1.9745 acc_val: 0.4800 loss_test: 1.3119 acc_test: 0.6850 time: 0.4123s
Epoch: 0251 loss_train: 0.0039 acc_train: 1.0000 loss_val: 2.0063 acc_val: 0.4867 loss_test: 1.3476 acc_test: 0.6900 time: 0.4496s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0536 acc_val: 0.4900 loss_test: 1.3810 acc_test: 0.6910 time: 0.4118s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1017 acc_val: 0.4967 loss_test: 1.4128 acc_test: 0.6940 time: 0.4695s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1450 acc_val: 0.4933 loss_test: 1.4394 acc_test: 0.6930 time: 0.5067s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1798 acc_val: 0.4900 loss_test: 1.4678 acc_test: 0.6920 time: 0.4791s
Optimization Finished!
Total time elapsed: 238.7420s, best testing performance  0.700000, minimun loss  0.973072
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7883 acc_train: 0.2250 loss_val: 1.8294 acc_val: 0.0633 loss_test: 1.6762 acc_test: 0.3810 time: 5.9874s
Epoch: 0051 loss_train: 0.0104 acc_train: 1.0000 loss_val: 1.7762 acc_val: 0.3667 loss_test: 1.1595 acc_test: 0.6610 time: 0.4715s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7492 acc_val: 0.4100 loss_test: 1.1671 acc_test: 0.6740 time: 0.4442s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8859 acc_val: 0.4433 loss_test: 1.2481 acc_test: 0.6830 time: 0.4611s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9885 acc_val: 0.4700 loss_test: 1.3086 acc_test: 0.6850 time: 0.4518s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0499 acc_val: 0.4833 loss_test: 1.3530 acc_test: 0.6880 time: 0.4149s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1032 acc_val: 0.4900 loss_test: 1.3935 acc_test: 0.6930 time: 0.4528s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1687 acc_val: 0.5033 loss_test: 1.4341 acc_test: 0.6940 time: 0.4768s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2105 acc_val: 0.5000 loss_test: 1.4659 acc_test: 0.6960 time: 0.5015s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2423 acc_val: 0.5033 loss_test: 1.5023 acc_test: 0.6930 time: 0.4297s
Optimization Finished!
Total time elapsed: 239.2563s, best testing performance  0.701000, minimun loss  0.946672
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.3, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7917 acc_train: 0.1417 loss_val: 1.8415 acc_val: 0.0667 loss_test: 1.6809 acc_test: 0.4070 time: 7.5745s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8209 acc_val: 0.3633 loss_test: 1.1693 acc_test: 0.6680 time: 0.4491s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9182 acc_val: 0.4233 loss_test: 1.2206 acc_test: 0.6780 time: 0.4246s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 2.0752 acc_val: 0.4300 loss_test: 1.3091 acc_test: 0.6780 time: 0.4724s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.1114 acc_val: 0.4667 loss_test: 1.3521 acc_test: 0.6860 time: 0.4545s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1357 acc_val: 0.4733 loss_test: 1.3857 acc_test: 0.6910 time: 0.4762s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1778 acc_val: 0.4933 loss_test: 1.4242 acc_test: 0.6930 time: 0.4485s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.2017 acc_val: 0.4933 loss_test: 1.4504 acc_test: 0.6940 time: 0.5035s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2331 acc_val: 0.4933 loss_test: 1.4776 acc_test: 0.6950 time: 0.5402s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2520 acc_val: 0.5033 loss_test: 1.4978 acc_test: 0.6990 time: 0.4218s
Optimization Finished!
Total time elapsed: 240.5280s, best testing performance  0.699000, minimun loss  0.968916
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7903 acc_train: 0.1667 loss_val: 1.8355 acc_val: 0.0833 loss_test: 1.6686 acc_test: 0.4290 time: 5.9156s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.6864 acc_val: 0.4267 loss_test: 1.1332 acc_test: 0.6860 time: 0.4480s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7259 acc_val: 0.4633 loss_test: 1.1611 acc_test: 0.6910 time: 0.4245s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8608 acc_val: 0.4600 loss_test: 1.2473 acc_test: 0.6840 time: 0.4793s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9482 acc_val: 0.4833 loss_test: 1.3065 acc_test: 0.6870 time: 0.4490s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9865 acc_val: 0.5000 loss_test: 1.3471 acc_test: 0.6910 time: 0.4487s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0509 acc_val: 0.5067 loss_test: 1.3925 acc_test: 0.6950 time: 0.4662s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1082 acc_val: 0.5100 loss_test: 1.4313 acc_test: 0.6950 time: 0.4723s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1512 acc_val: 0.5133 loss_test: 1.4633 acc_test: 0.6940 time: 0.4873s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1753 acc_val: 0.5133 loss_test: 1.4933 acc_test: 0.6950 time: 0.4507s
Optimization Finished!
Total time elapsed: 238.8498s, best testing performance  0.700000, minimun loss  0.940969
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8153 acc_train: 0.0833 loss_val: 1.8223 acc_val: 0.0633 loss_test: 1.6751 acc_test: 0.3670 time: 10.7985s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7372 acc_val: 0.4267 loss_test: 1.1416 acc_test: 0.6820 time: 0.4528s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.7628 acc_val: 0.4600 loss_test: 1.1838 acc_test: 0.6860 time: 0.4479s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9049 acc_val: 0.4733 loss_test: 1.2691 acc_test: 0.6850 time: 0.4562s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9758 acc_val: 0.4633 loss_test: 1.3178 acc_test: 0.6880 time: 0.4199s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0196 acc_val: 0.4767 loss_test: 1.3564 acc_test: 0.6920 time: 0.4322s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0499 acc_val: 0.4833 loss_test: 1.3900 acc_test: 0.6910 time: 0.4500s
Epoch: 0351 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0714 acc_val: 0.4933 loss_test: 1.4196 acc_test: 0.6900 time: 0.5023s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0948 acc_val: 0.5033 loss_test: 1.4486 acc_test: 0.6930 time: 0.4855s
Epoch: 0451 loss_train: 0.0017 acc_train: 1.0000 loss_val: 2.1017 acc_val: 0.4967 loss_test: 1.4681 acc_test: 0.6980 time: 0.4320s
Optimization Finished!
Total time elapsed: 244.0107s, best testing performance  0.702000, minimun loss  0.941151
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7940 acc_train: 0.1500 loss_val: 1.7820 acc_val: 0.1800 loss_test: 1.6584 acc_test: 0.5110 time: 9.3826s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7084 acc_val: 0.4067 loss_test: 1.1666 acc_test: 0.6770 time: 0.4450s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7302 acc_val: 0.4500 loss_test: 1.1897 acc_test: 0.6880 time: 0.4518s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8950 acc_val: 0.4633 loss_test: 1.2780 acc_test: 0.6870 time: 0.4561s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9938 acc_val: 0.4800 loss_test: 1.3281 acc_test: 0.6900 time: 0.4718s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9994 acc_val: 0.5067 loss_test: 1.3514 acc_test: 0.6970 time: 0.4522s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0432 acc_val: 0.5067 loss_test: 1.3839 acc_test: 0.6960 time: 0.4519s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0408 acc_val: 0.5100 loss_test: 1.4012 acc_test: 0.6980 time: 0.5177s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0498 acc_val: 0.5133 loss_test: 1.4191 acc_test: 0.6950 time: 0.4547s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0592 acc_val: 0.5100 loss_test: 1.4376 acc_test: 0.6960 time: 0.4751s
Optimization Finished!
Total time elapsed: 243.6128s, best testing performance  0.699000, minimun loss  0.978998
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7852 acc_train: 0.1833 loss_val: 1.8406 acc_val: 0.0767 loss_test: 1.6646 acc_test: 0.3790 time: 4.0504s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6990 acc_val: 0.4033 loss_test: 1.1283 acc_test: 0.6730 time: 0.4758s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7734 acc_val: 0.4333 loss_test: 1.1715 acc_test: 0.6840 time: 0.4702s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9081 acc_val: 0.4567 loss_test: 1.2455 acc_test: 0.6880 time: 0.4494s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9983 acc_val: 0.4600 loss_test: 1.2998 acc_test: 0.6870 time: 0.4747s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0533 acc_val: 0.4733 loss_test: 1.3460 acc_test: 0.6920 time: 0.4466s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0941 acc_val: 0.4900 loss_test: 1.3830 acc_test: 0.6920 time: 0.4658s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0980 acc_val: 0.5033 loss_test: 1.4068 acc_test: 0.6960 time: 0.4845s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0949 acc_val: 0.5033 loss_test: 1.4256 acc_test: 0.6960 time: 0.5001s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1609 acc_val: 0.4933 loss_test: 1.4670 acc_test: 0.6910 time: 0.4257s
Optimization Finished!
Total time elapsed: 238.7736s, best testing performance  0.698000, minimun loss  0.955716
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.4, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8029 acc_train: 0.1583 loss_val: 1.8297 acc_val: 0.0933 loss_test: 1.6644 acc_test: 0.4130 time: 7.5986s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7504 acc_val: 0.4200 loss_test: 1.1544 acc_test: 0.6760 time: 0.4815s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7497 acc_val: 0.4467 loss_test: 1.1759 acc_test: 0.6880 time: 0.4205s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8782 acc_val: 0.4533 loss_test: 1.2579 acc_test: 0.6880 time: 0.4426s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0034 acc_val: 0.4633 loss_test: 1.3215 acc_test: 0.6840 time: 0.4750s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0890 acc_val: 0.4700 loss_test: 1.3727 acc_test: 0.6890 time: 0.4127s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1613 acc_val: 0.4733 loss_test: 1.4201 acc_test: 0.6920 time: 0.4928s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2284 acc_val: 0.4867 loss_test: 1.4620 acc_test: 0.6930 time: 0.5253s
Epoch: 0401 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2705 acc_val: 0.4933 loss_test: 1.4979 acc_test: 0.6940 time: 0.4814s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.3332 acc_val: 0.5000 loss_test: 1.5352 acc_test: 0.6950 time: 0.4501s
Optimization Finished!
Total time elapsed: 240.6099s, best testing performance  0.696000, minimun loss  0.952799
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7767 acc_train: 0.1917 loss_val: 1.7912 acc_val: 0.1933 loss_test: 1.6543 acc_test: 0.5390 time: 7.4262s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7275 acc_val: 0.4100 loss_test: 1.1280 acc_test: 0.6850 time: 0.4537s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.8127 acc_val: 0.4333 loss_test: 1.1852 acc_test: 0.6880 time: 0.4739s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9500 acc_val: 0.4433 loss_test: 1.2634 acc_test: 0.6900 time: 0.4512s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0345 acc_val: 0.4600 loss_test: 1.3118 acc_test: 0.6900 time: 0.4111s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1070 acc_val: 0.4800 loss_test: 1.3603 acc_test: 0.6920 time: 0.4131s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1622 acc_val: 0.4800 loss_test: 1.4029 acc_test: 0.6890 time: 0.4707s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1797 acc_val: 0.5000 loss_test: 1.4322 acc_test: 0.6870 time: 0.5279s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.2014 acc_val: 0.4967 loss_test: 1.4638 acc_test: 0.6870 time: 0.4818s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2249 acc_val: 0.4967 loss_test: 1.4914 acc_test: 0.6900 time: 0.4588s
Optimization Finished!
Total time elapsed: 242.0408s, best testing performance  0.695000, minimun loss  0.954612
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7986 acc_train: 0.1250 loss_val: 1.7784 acc_val: 0.2067 loss_test: 1.6583 acc_test: 0.4010 time: 7.8273s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.6494 acc_val: 0.4167 loss_test: 1.1323 acc_test: 0.6830 time: 0.4652s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.6810 acc_val: 0.4667 loss_test: 1.1653 acc_test: 0.6940 time: 0.4480s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.8507 acc_val: 0.4700 loss_test: 1.2574 acc_test: 0.6910 time: 0.4887s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 1.9159 acc_val: 0.4833 loss_test: 1.3000 acc_test: 0.6870 time: 0.4469s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9678 acc_val: 0.4967 loss_test: 1.3319 acc_test: 0.6910 time: 0.4443s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 1.9884 acc_val: 0.5133 loss_test: 1.3620 acc_test: 0.6920 time: 0.4680s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0242 acc_val: 0.5100 loss_test: 1.3939 acc_test: 0.6960 time: 0.5448s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0759 acc_val: 0.5133 loss_test: 1.4277 acc_test: 0.7000 time: 0.4968s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.0835 acc_val: 0.5067 loss_test: 1.4472 acc_test: 0.6990 time: 0.4669s
Optimization Finished!
Total time elapsed: 243.3489s, best testing performance  0.703000, minimun loss  0.932911
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7945 acc_train: 0.1833 loss_val: 1.8080 acc_val: 0.1800 loss_test: 1.6385 acc_test: 0.5470 time: 8.9624s
Epoch: 0051 loss_train: 0.0110 acc_train: 1.0000 loss_val: 1.6545 acc_val: 0.4233 loss_test: 1.1026 acc_test: 0.6800 time: 0.4542s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7841 acc_val: 0.4200 loss_test: 1.1668 acc_test: 0.6920 time: 0.4447s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9687 acc_val: 0.4300 loss_test: 1.2558 acc_test: 0.6890 time: 0.4454s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0336 acc_val: 0.4500 loss_test: 1.3045 acc_test: 0.6890 time: 0.4411s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0724 acc_val: 0.4733 loss_test: 1.3457 acc_test: 0.6930 time: 0.4522s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0846 acc_val: 0.5000 loss_test: 1.3794 acc_test: 0.6930 time: 0.5080s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0778 acc_val: 0.5000 loss_test: 1.4053 acc_test: 0.6980 time: 0.4996s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0829 acc_val: 0.5100 loss_test: 1.4277 acc_test: 0.6980 time: 0.4560s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1221 acc_val: 0.5167 loss_test: 1.4579 acc_test: 0.6990 time: 0.4695s
Optimization Finished!
Total time elapsed: 243.1940s, best testing performance  0.701000, minimun loss  0.931155
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7711 acc_train: 0.2917 loss_val: 1.8338 acc_val: 0.1133 loss_test: 1.6623 acc_test: 0.4400 time: 5.9688s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.7191 acc_val: 0.3800 loss_test: 1.1398 acc_test: 0.6680 time: 0.4157s
Epoch: 0101 loss_train: 0.0085 acc_train: 1.0000 loss_val: 1.8124 acc_val: 0.4200 loss_test: 1.1788 acc_test: 0.6840 time: 0.4419s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9721 acc_val: 0.4267 loss_test: 1.2597 acc_test: 0.6800 time: 0.4241s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0221 acc_val: 0.4467 loss_test: 1.3030 acc_test: 0.6850 time: 0.5535s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0409 acc_val: 0.4733 loss_test: 1.3360 acc_test: 0.6910 time: 0.4176s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0790 acc_val: 0.4800 loss_test: 1.3686 acc_test: 0.6920 time: 0.4798s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0791 acc_val: 0.5000 loss_test: 1.3911 acc_test: 0.6900 time: 0.5023s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0510 acc_val: 0.5133 loss_test: 1.4045 acc_test: 0.6900 time: 0.5111s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0820 acc_val: 0.5033 loss_test: 1.4302 acc_test: 0.6910 time: 0.4445s
Optimization Finished!
Total time elapsed: 240.9359s, best testing performance  0.693000, minimun loss  0.959441
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.5, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7805 acc_train: 0.2667 loss_val: 1.8293 acc_val: 0.1633 loss_test: 1.6611 acc_test: 0.5180 time: 9.0105s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.8242 acc_val: 0.3900 loss_test: 1.1498 acc_test: 0.6650 time: 0.4485s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.8448 acc_val: 0.4167 loss_test: 1.1798 acc_test: 0.6790 time: 0.4516s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.9509 acc_val: 0.4333 loss_test: 1.2609 acc_test: 0.6840 time: 0.4671s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0383 acc_val: 0.4600 loss_test: 1.3163 acc_test: 0.6830 time: 0.4496s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.1147 acc_val: 0.4800 loss_test: 1.3640 acc_test: 0.6840 time: 0.4675s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1454 acc_val: 0.4900 loss_test: 1.3989 acc_test: 0.6860 time: 0.4653s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1693 acc_val: 0.4933 loss_test: 1.4310 acc_test: 0.6870 time: 0.5095s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1962 acc_val: 0.4867 loss_test: 1.4606 acc_test: 0.6860 time: 0.4529s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1814 acc_val: 0.4900 loss_test: 1.4770 acc_test: 0.6880 time: 0.4897s
Optimization Finished!
Total time elapsed: 242.9336s, best testing performance  0.691000, minimun loss  0.937365
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7886 acc_train: 0.1833 loss_val: 1.8049 acc_val: 0.1300 loss_test: 1.6603 acc_test: 0.4660 time: 4.6754s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.4055 acc_val: 0.4933 loss_test: 1.0602 acc_test: 0.7020 time: 0.4972s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.5438 acc_val: 0.4867 loss_test: 1.1347 acc_test: 0.7040 time: 0.4474s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.7791 acc_val: 0.4733 loss_test: 1.2462 acc_test: 0.6910 time: 0.4907s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.8963 acc_val: 0.4733 loss_test: 1.3026 acc_test: 0.6880 time: 0.4265s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 1.9692 acc_val: 0.4967 loss_test: 1.3455 acc_test: 0.6900 time: 0.4202s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0385 acc_val: 0.5067 loss_test: 1.3858 acc_test: 0.6900 time: 0.4604s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0826 acc_val: 0.5067 loss_test: 1.4211 acc_test: 0.6980 time: 0.5664s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1246 acc_val: 0.5100 loss_test: 1.4539 acc_test: 0.6970 time: 0.4865s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1620 acc_val: 0.5100 loss_test: 1.4801 acc_test: 0.6980 time: 0.4666s
Optimization Finished!
Total time elapsed: 237.5712s, best testing performance  0.710000, minimun loss  0.922690
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8064 acc_train: 0.1417 loss_val: 1.8244 acc_val: 0.0467 loss_test: 1.6676 acc_test: 0.3320 time: 9.6979s
Epoch: 0051 loss_train: 0.0096 acc_train: 1.0000 loss_val: 1.5202 acc_val: 0.4700 loss_test: 1.0827 acc_test: 0.6960 time: 0.4539s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.6785 acc_val: 0.4567 loss_test: 1.1561 acc_test: 0.6960 time: 0.4210s
Epoch: 0151 loss_train: 0.0054 acc_train: 1.0000 loss_val: 1.8720 acc_val: 0.4700 loss_test: 1.2636 acc_test: 0.6930 time: 0.4841s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 2.0147 acc_val: 0.4633 loss_test: 1.3282 acc_test: 0.6880 time: 0.4683s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0566 acc_val: 0.4833 loss_test: 1.3622 acc_test: 0.6890 time: 0.4156s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0809 acc_val: 0.4900 loss_test: 1.3935 acc_test: 0.6950 time: 0.4460s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1405 acc_val: 0.4933 loss_test: 1.4307 acc_test: 0.6980 time: 0.5020s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2281 acc_val: 0.5000 loss_test: 1.4700 acc_test: 0.6980 time: 0.5582s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2278 acc_val: 0.5033 loss_test: 1.4838 acc_test: 0.6980 time: 0.5025s
Optimization Finished!
Total time elapsed: 243.4763s, best testing performance  0.705000, minimun loss  0.919258
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7932 acc_train: 0.1500 loss_val: 1.8056 acc_val: 0.1633 loss_test: 1.6733 acc_test: 0.4680 time: 11.2618s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.6071 acc_val: 0.4367 loss_test: 1.0994 acc_test: 0.6800 time: 0.4650s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.6318 acc_val: 0.4600 loss_test: 1.1362 acc_test: 0.6910 time: 0.4497s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8217 acc_val: 0.4633 loss_test: 1.2499 acc_test: 0.6940 time: 0.4845s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.9903 acc_val: 0.4700 loss_test: 1.3228 acc_test: 0.6930 time: 0.4718s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0581 acc_val: 0.4800 loss_test: 1.3664 acc_test: 0.6870 time: 0.4508s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0896 acc_val: 0.5033 loss_test: 1.3991 acc_test: 0.6930 time: 0.4468s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1010 acc_val: 0.5000 loss_test: 1.4287 acc_test: 0.6960 time: 0.5096s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1282 acc_val: 0.5133 loss_test: 1.4541 acc_test: 0.6950 time: 0.4849s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1230 acc_val: 0.5033 loss_test: 1.4718 acc_test: 0.6980 time: 0.4767s
Optimization Finished!
Total time elapsed: 244.2220s, best testing performance  0.702000, minimun loss  0.926919
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7813 acc_train: 0.2500 loss_val: 1.8457 acc_val: 0.2033 loss_test: 1.6394 acc_test: 0.5310 time: 13.0105s
Epoch: 0051 loss_train: 0.0106 acc_train: 1.0000 loss_val: 1.6716 acc_val: 0.4333 loss_test: 1.1162 acc_test: 0.6760 time: 0.4866s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.6797 acc_val: 0.4567 loss_test: 1.1438 acc_test: 0.6910 time: 0.4503s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.8198 acc_val: 0.4633 loss_test: 1.2392 acc_test: 0.7020 time: 0.4516s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9704 acc_val: 0.4733 loss_test: 1.3118 acc_test: 0.6950 time: 0.4662s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0279 acc_val: 0.4833 loss_test: 1.3544 acc_test: 0.6920 time: 0.5057s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0861 acc_val: 0.5067 loss_test: 1.3906 acc_test: 0.6920 time: 0.4566s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0867 acc_val: 0.5133 loss_test: 1.4146 acc_test: 0.6990 time: 0.5041s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1506 acc_val: 0.5133 loss_test: 1.4499 acc_test: 0.6980 time: 0.4691s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1953 acc_val: 0.5100 loss_test: 1.4790 acc_test: 0.7010 time: 0.4900s
Optimization Finished!
Total time elapsed: 246.4572s, best testing performance  0.704000, minimun loss  0.930327
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.6, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8015 acc_train: 0.1250 loss_val: 1.8236 acc_val: 0.1033 loss_test: 1.6865 acc_test: 0.4000 time: 4.4823s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.5704 acc_val: 0.4400 loss_test: 1.0994 acc_test: 0.6830 time: 0.4533s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.6684 acc_val: 0.4467 loss_test: 1.1541 acc_test: 0.6880 time: 0.4520s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8865 acc_val: 0.4567 loss_test: 1.2697 acc_test: 0.6880 time: 0.5062s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9549 acc_val: 0.4600 loss_test: 1.3189 acc_test: 0.6880 time: 0.5008s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9612 acc_val: 0.4767 loss_test: 1.3451 acc_test: 0.6930 time: 0.4837s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0184 acc_val: 0.4967 loss_test: 1.3795 acc_test: 0.6930 time: 0.4362s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0488 acc_val: 0.5067 loss_test: 1.4106 acc_test: 0.6950 time: 0.5269s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1152 acc_val: 0.5167 loss_test: 1.4465 acc_test: 0.6960 time: 0.5913s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.1287 acc_val: 0.5233 loss_test: 1.4667 acc_test: 0.6950 time: 0.4532s
Optimization Finished!
Total time elapsed: 238.3351s, best testing performance  0.701000, minimun loss  0.937086
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7962 acc_train: 0.1417 loss_val: 1.8019 acc_val: 0.1267 loss_test: 1.6610 acc_test: 0.4550 time: 10.4865s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.7347 acc_val: 0.4100 loss_test: 1.1737 acc_test: 0.6690 time: 0.4638s
Epoch: 0101 loss_train: 0.0083 acc_train: 1.0000 loss_val: 1.7390 acc_val: 0.4500 loss_test: 1.1880 acc_test: 0.6840 time: 0.4551s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.8780 acc_val: 0.4567 loss_test: 1.2635 acc_test: 0.6870 time: 0.4447s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 1.9423 acc_val: 0.4767 loss_test: 1.3072 acc_test: 0.6870 time: 0.4495s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 1.9937 acc_val: 0.4900 loss_test: 1.3443 acc_test: 0.6880 time: 0.4716s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.0419 acc_val: 0.4967 loss_test: 1.3795 acc_test: 0.6920 time: 0.4963s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.0688 acc_val: 0.5100 loss_test: 1.4060 acc_test: 0.6920 time: 0.5055s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1058 acc_val: 0.5067 loss_test: 1.4338 acc_test: 0.6960 time: 0.5415s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1253 acc_val: 0.5100 loss_test: 1.4564 acc_test: 0.6980 time: 0.4692s
Optimization Finished!
Total time elapsed: 244.8770s, best testing performance  0.701000, minimun loss  0.946470
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8047 acc_train: 0.1250 loss_val: 1.7848 acc_val: 0.2267 loss_test: 1.6686 acc_test: 0.5170 time: 4.0474s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.9571 acc_val: 0.3833 loss_test: 1.2326 acc_test: 0.6610 time: 0.4687s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.9387 acc_val: 0.4200 loss_test: 1.2332 acc_test: 0.6750 time: 0.4680s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 2.0676 acc_val: 0.4333 loss_test: 1.3000 acc_test: 0.6830 time: 0.4481s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.1324 acc_val: 0.4500 loss_test: 1.3457 acc_test: 0.6890 time: 0.4496s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.1432 acc_val: 0.4700 loss_test: 1.3734 acc_test: 0.6910 time: 0.4233s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1612 acc_val: 0.4867 loss_test: 1.4001 acc_test: 0.6930 time: 0.4341s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.2006 acc_val: 0.4933 loss_test: 1.4320 acc_test: 0.6940 time: 0.5185s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.2251 acc_val: 0.5000 loss_test: 1.4550 acc_test: 0.6960 time: 0.4897s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2552 acc_val: 0.5033 loss_test: 1.4764 acc_test: 0.6980 time: 0.4828s
Optimization Finished!
Total time elapsed: 238.9847s, best testing performance  0.698000, minimun loss  0.978670
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8098 acc_train: 0.0917 loss_val: 1.8030 acc_val: 0.1900 loss_test: 1.6805 acc_test: 0.4990 time: 7.7985s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.7425 acc_val: 0.4133 loss_test: 1.1579 acc_test: 0.6740 time: 0.4191s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7375 acc_val: 0.4300 loss_test: 1.1738 acc_test: 0.6850 time: 0.4226s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9111 acc_val: 0.4333 loss_test: 1.2611 acc_test: 0.6870 time: 0.4610s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0126 acc_val: 0.4567 loss_test: 1.3144 acc_test: 0.6840 time: 0.4181s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0885 acc_val: 0.4800 loss_test: 1.3582 acc_test: 0.6890 time: 0.4809s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1215 acc_val: 0.4867 loss_test: 1.3922 acc_test: 0.6960 time: 0.4536s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1509 acc_val: 0.5033 loss_test: 1.4205 acc_test: 0.7000 time: 0.5082s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1698 acc_val: 0.5000 loss_test: 1.4453 acc_test: 0.7010 time: 0.4879s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2042 acc_val: 0.5067 loss_test: 1.4732 acc_test: 0.7040 time: 0.4516s
Optimization Finished!
Total time elapsed: 242.1033s, best testing performance  0.705000, minimun loss  0.955108
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7761 acc_train: 0.3167 loss_val: 1.7892 acc_val: 0.1667 loss_test: 1.6352 acc_test: 0.5520 time: 4.0672s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.7196 acc_val: 0.4033 loss_test: 1.1476 acc_test: 0.6760 time: 0.5007s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.8030 acc_val: 0.4533 loss_test: 1.2020 acc_test: 0.6910 time: 0.4133s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9753 acc_val: 0.4467 loss_test: 1.2870 acc_test: 0.6810 time: 0.4713s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0143 acc_val: 0.4700 loss_test: 1.3316 acc_test: 0.6880 time: 0.4518s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0670 acc_val: 0.4833 loss_test: 1.3724 acc_test: 0.6900 time: 0.4930s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0816 acc_val: 0.4800 loss_test: 1.4069 acc_test: 0.6930 time: 0.4864s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.1122 acc_val: 0.4933 loss_test: 1.4396 acc_test: 0.6980 time: 0.5468s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1423 acc_val: 0.5133 loss_test: 1.4620 acc_test: 0.6970 time: 0.4353s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1865 acc_val: 0.5033 loss_test: 1.4934 acc_test: 0.6970 time: 0.4845s
Optimization Finished!
Total time elapsed: 238.6528s, best testing performance  0.700000, minimun loss  0.961054
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.7, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8069 acc_train: 0.0917 loss_val: 1.8129 acc_val: 0.0633 loss_test: 1.6564 acc_test: 0.3670 time: 8.5625s
Epoch: 0051 loss_train: 0.0102 acc_train: 1.0000 loss_val: 1.8571 acc_val: 0.3800 loss_test: 1.1883 acc_test: 0.6610 time: 0.4729s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8605 acc_val: 0.4233 loss_test: 1.2035 acc_test: 0.6740 time: 0.4495s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 1.9647 acc_val: 0.4467 loss_test: 1.2681 acc_test: 0.6840 time: 0.4551s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0002 acc_val: 0.4667 loss_test: 1.3057 acc_test: 0.6890 time: 0.4511s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0389 acc_val: 0.4767 loss_test: 1.3434 acc_test: 0.6880 time: 0.4618s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.0836 acc_val: 0.4967 loss_test: 1.3831 acc_test: 0.6890 time: 0.4662s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1226 acc_val: 0.5033 loss_test: 1.4111 acc_test: 0.6930 time: 0.4432s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1399 acc_val: 0.5000 loss_test: 1.4339 acc_test: 0.6950 time: 0.5023s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1610 acc_val: 0.5000 loss_test: 1.4556 acc_test: 0.6970 time: 0.4225s
Optimization Finished!
Total time elapsed: 242.1667s, best testing performance  0.699000, minimun loss  0.953521
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8076 acc_train: 0.1333 loss_val: 1.8256 acc_val: 0.0700 loss_test: 1.7007 acc_test: 0.3870 time: 4.9233s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.6691 acc_val: 0.4367 loss_test: 1.1521 acc_test: 0.6810 time: 0.5721s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.7079 acc_val: 0.4500 loss_test: 1.1805 acc_test: 0.6900 time: 0.4494s
Epoch: 0151 loss_train: 0.0060 acc_train: 1.0000 loss_val: 1.9028 acc_val: 0.4500 loss_test: 1.2789 acc_test: 0.6850 time: 0.4646s
Epoch: 0201 loss_train: 0.0047 acc_train: 1.0000 loss_val: 2.0289 acc_val: 0.4633 loss_test: 1.3326 acc_test: 0.6870 time: 0.4210s
Epoch: 0251 loss_train: 0.0038 acc_train: 1.0000 loss_val: 2.0928 acc_val: 0.4733 loss_test: 1.3693 acc_test: 0.6850 time: 0.4429s
Epoch: 0301 loss_train: 0.0032 acc_train: 1.0000 loss_val: 2.1433 acc_val: 0.4833 loss_test: 1.4007 acc_test: 0.6920 time: 0.4787s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1893 acc_val: 0.5000 loss_test: 1.4291 acc_test: 0.6970 time: 0.4897s
Epoch: 0401 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.2126 acc_val: 0.5033 loss_test: 1.4531 acc_test: 0.6980 time: 0.4844s
Epoch: 0451 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2407 acc_val: 0.5067 loss_test: 1.4759 acc_test: 0.6950 time: 0.4400s
Optimization Finished!
Total time elapsed: 239.5053s, best testing performance  0.699000, minimun loss  0.957052
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8127 acc_train: 0.1083 loss_val: 1.8427 acc_val: 0.0667 loss_test: 1.6841 acc_test: 0.3870 time: 9.7465s
Epoch: 0051 loss_train: 0.0109 acc_train: 1.0000 loss_val: 1.6319 acc_val: 0.4267 loss_test: 1.1188 acc_test: 0.6750 time: 0.4829s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7396 acc_val: 0.4600 loss_test: 1.1664 acc_test: 0.6870 time: 0.4505s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8920 acc_val: 0.4667 loss_test: 1.2564 acc_test: 0.6870 time: 0.4522s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 1.9774 acc_val: 0.4733 loss_test: 1.3085 acc_test: 0.6910 time: 0.4602s
Epoch: 0251 loss_train: 0.0036 acc_train: 1.0000 loss_val: 2.0410 acc_val: 0.4867 loss_test: 1.3536 acc_test: 0.6870 time: 0.4483s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.1044 acc_val: 0.4867 loss_test: 1.3957 acc_test: 0.6880 time: 0.4596s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1697 acc_val: 0.4967 loss_test: 1.4399 acc_test: 0.6900 time: 0.5012s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1972 acc_val: 0.4967 loss_test: 1.4699 acc_test: 0.6960 time: 0.4683s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2677 acc_val: 0.5033 loss_test: 1.5103 acc_test: 0.6910 time: 0.4667s
Optimization Finished!
Total time elapsed: 243.6606s, best testing performance  0.699000, minimun loss  0.949469
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7797 acc_train: 0.2167 loss_val: 1.7952 acc_val: 0.1433 loss_test: 1.6701 acc_test: 0.5030 time: 13.6322s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.6489 acc_val: 0.4333 loss_test: 1.1363 acc_test: 0.6760 time: 0.4544s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.8300 acc_val: 0.4333 loss_test: 1.2061 acc_test: 0.6850 time: 0.4816s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.9981 acc_val: 0.4400 loss_test: 1.2878 acc_test: 0.6870 time: 0.4695s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 2.0615 acc_val: 0.4567 loss_test: 1.3325 acc_test: 0.6870 time: 0.4798s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0831 acc_val: 0.4900 loss_test: 1.3660 acc_test: 0.6910 time: 0.4253s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.1308 acc_val: 0.4967 loss_test: 1.4076 acc_test: 0.6890 time: 0.4673s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1632 acc_val: 0.5100 loss_test: 1.4399 acc_test: 0.6960 time: 0.5093s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2089 acc_val: 0.5133 loss_test: 1.4733 acc_test: 0.6980 time: 0.4839s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2429 acc_val: 0.5067 loss_test: 1.4965 acc_test: 0.6980 time: 0.4623s
Optimization Finished!
Total time elapsed: 248.8683s, best testing performance  0.704000, minimun loss  0.946981
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7870 acc_train: 0.2500 loss_val: 1.8126 acc_val: 0.1600 loss_test: 1.6694 acc_test: 0.5270 time: 7.9145s
Epoch: 0051 loss_train: 0.0103 acc_train: 1.0000 loss_val: 1.5981 acc_val: 0.4400 loss_test: 1.1328 acc_test: 0.6760 time: 0.4542s
Epoch: 0101 loss_train: 0.0082 acc_train: 1.0000 loss_val: 1.7112 acc_val: 0.4600 loss_test: 1.1817 acc_test: 0.6890 time: 0.4808s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8708 acc_val: 0.4633 loss_test: 1.2653 acc_test: 0.6910 time: 0.4507s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9711 acc_val: 0.4500 loss_test: 1.3169 acc_test: 0.6890 time: 0.4502s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0310 acc_val: 0.4833 loss_test: 1.3578 acc_test: 0.6890 time: 0.4210s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0669 acc_val: 0.5000 loss_test: 1.3895 acc_test: 0.6970 time: 0.4739s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0909 acc_val: 0.5133 loss_test: 1.4155 acc_test: 0.6990 time: 0.5139s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1570 acc_val: 0.5133 loss_test: 1.4493 acc_test: 0.7010 time: 0.4852s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1955 acc_val: 0.5100 loss_test: 1.4745 acc_test: 0.7010 time: 0.5162s
Optimization Finished!
Total time elapsed: 242.9726s, best testing performance  0.704000, minimun loss  0.941347
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.8, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7921 acc_train: 0.1500 loss_val: 1.8227 acc_val: 0.1633 loss_test: 1.6690 acc_test: 0.5140 time: 11.4688s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7653 acc_val: 0.4200 loss_test: 1.1661 acc_test: 0.6840 time: 0.4474s
Epoch: 0101 loss_train: 0.0079 acc_train: 1.0000 loss_val: 1.7339 acc_val: 0.4633 loss_test: 1.1678 acc_test: 0.6950 time: 0.4194s
Epoch: 0151 loss_train: 0.0056 acc_train: 1.0000 loss_val: 1.8607 acc_val: 0.4767 loss_test: 1.2467 acc_test: 0.6960 time: 0.4482s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.9511 acc_val: 0.4633 loss_test: 1.3027 acc_test: 0.6960 time: 0.4635s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 1.9978 acc_val: 0.4767 loss_test: 1.3427 acc_test: 0.6940 time: 0.4261s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0570 acc_val: 0.4900 loss_test: 1.3847 acc_test: 0.6980 time: 0.4656s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.0989 acc_val: 0.5000 loss_test: 1.4144 acc_test: 0.7000 time: 0.5002s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1314 acc_val: 0.5167 loss_test: 1.4442 acc_test: 0.7010 time: 0.5001s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1761 acc_val: 0.5133 loss_test: 1.4714 acc_test: 0.7010 time: 0.4605s
Optimization Finished!
Total time elapsed: 245.6729s, best testing performance  0.705000, minimun loss  0.944580
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7870 acc_train: 0.1750 loss_val: 1.8071 acc_val: 0.1567 loss_test: 1.6612 acc_test: 0.4560 time: 4.0552s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.4762 acc_val: 0.4867 loss_test: 1.0919 acc_test: 0.6980 time: 0.4511s
Epoch: 0101 loss_train: 0.0077 acc_train: 1.0000 loss_val: 1.5626 acc_val: 0.5000 loss_test: 1.1431 acc_test: 0.7040 time: 0.4531s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.7791 acc_val: 0.4767 loss_test: 1.2464 acc_test: 0.6970 time: 0.4558s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9204 acc_val: 0.4700 loss_test: 1.3111 acc_test: 0.6950 time: 0.4457s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9900 acc_val: 0.4833 loss_test: 1.3566 acc_test: 0.6980 time: 0.4161s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.0923 acc_val: 0.4967 loss_test: 1.4141 acc_test: 0.6900 time: 0.4474s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1681 acc_val: 0.5033 loss_test: 1.4553 acc_test: 0.6960 time: 0.5058s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.2188 acc_val: 0.5167 loss_test: 1.4852 acc_test: 0.6980 time: 0.5079s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.2428 acc_val: 0.5033 loss_test: 1.5113 acc_test: 0.6970 time: 0.4417s
Optimization Finished!
Total time elapsed: 238.2285s, best testing performance  0.709000, minimun loss  0.929116
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8095 acc_train: 0.1583 loss_val: 1.7970 acc_val: 0.1400 loss_test: 1.6350 acc_test: 0.4720 time: 9.9462s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.5453 acc_val: 0.4700 loss_test: 1.1236 acc_test: 0.6900 time: 0.4543s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.6721 acc_val: 0.4633 loss_test: 1.1772 acc_test: 0.6920 time: 0.6000s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.9640 acc_val: 0.4400 loss_test: 1.2944 acc_test: 0.6920 time: 0.4618s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 2.0408 acc_val: 0.4533 loss_test: 1.3361 acc_test: 0.6950 time: 0.4142s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0899 acc_val: 0.4733 loss_test: 1.3748 acc_test: 0.6960 time: 0.4219s
Epoch: 0301 loss_train: 0.0028 acc_train: 1.0000 loss_val: 2.1108 acc_val: 0.4933 loss_test: 1.4052 acc_test: 0.6960 time: 0.4699s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1727 acc_val: 0.4900 loss_test: 1.4432 acc_test: 0.6960 time: 0.5093s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1975 acc_val: 0.5033 loss_test: 1.4739 acc_test: 0.6960 time: 0.5479s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2108 acc_val: 0.5100 loss_test: 1.4965 acc_test: 0.6990 time: 0.4680s
Optimization Finished!
Total time elapsed: 243.4632s, best testing performance  0.704000, minimun loss  0.937943
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7858 acc_train: 0.2250 loss_val: 1.8132 acc_val: 0.1267 loss_test: 1.6351 acc_test: 0.4850 time: 5.6024s
Epoch: 0051 loss_train: 0.0095 acc_train: 1.0000 loss_val: 1.7636 acc_val: 0.4033 loss_test: 1.2155 acc_test: 0.6710 time: 0.4681s
Epoch: 0101 loss_train: 0.0076 acc_train: 1.0000 loss_val: 1.6335 acc_val: 0.4667 loss_test: 1.1824 acc_test: 0.6970 time: 0.4511s
Epoch: 0151 loss_train: 0.0053 acc_train: 1.0000 loss_val: 1.7261 acc_val: 0.4933 loss_test: 1.2470 acc_test: 0.6990 time: 0.4540s
Epoch: 0201 loss_train: 0.0041 acc_train: 1.0000 loss_val: 1.9234 acc_val: 0.4867 loss_test: 1.3286 acc_test: 0.6950 time: 0.4523s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 2.0271 acc_val: 0.4833 loss_test: 1.3792 acc_test: 0.6880 time: 0.4508s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0621 acc_val: 0.5000 loss_test: 1.4121 acc_test: 0.6900 time: 0.5251s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.1332 acc_val: 0.4933 loss_test: 1.4439 acc_test: 0.6920 time: 0.4922s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.1938 acc_val: 0.5033 loss_test: 1.4722 acc_test: 0.6970 time: 0.4762s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2008 acc_val: 0.5033 loss_test: 1.4909 acc_test: 0.6940 time: 0.4675s
Optimization Finished!
Total time elapsed: 240.1181s, best testing performance  0.709000, minimun loss  0.945850
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7874 acc_train: 0.2083 loss_val: 1.8410 acc_val: 0.0700 loss_test: 1.6481 acc_test: 0.3860 time: 13.8407s
Epoch: 0051 loss_train: 0.0098 acc_train: 1.0000 loss_val: 1.7146 acc_val: 0.4333 loss_test: 1.1600 acc_test: 0.6760 time: 0.4683s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.6691 acc_val: 0.4900 loss_test: 1.1554 acc_test: 0.6980 time: 0.4522s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.7001 acc_val: 0.4933 loss_test: 1.2098 acc_test: 0.7050 time: 0.4199s
Epoch: 0201 loss_train: 0.0042 acc_train: 1.0000 loss_val: 1.8837 acc_val: 0.4700 loss_test: 1.2914 acc_test: 0.6970 time: 0.4587s
Epoch: 0251 loss_train: 0.0034 acc_train: 1.0000 loss_val: 1.9690 acc_val: 0.4933 loss_test: 1.3407 acc_test: 0.6960 time: 0.4502s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 1.9986 acc_val: 0.5100 loss_test: 1.3690 acc_test: 0.6940 time: 0.4542s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0452 acc_val: 0.5033 loss_test: 1.4017 acc_test: 0.6930 time: 0.4950s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.0612 acc_val: 0.5100 loss_test: 1.4250 acc_test: 0.6970 time: 0.5983s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.0968 acc_val: 0.5100 loss_test: 1.4468 acc_test: 0.6970 time: 0.4783s
Optimization Finished!
Total time elapsed: 249.3119s, best testing performance  0.708000, minimun loss  0.940562
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 0.9, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8024 acc_train: 0.1500 loss_val: 1.7909 acc_val: 0.1667 loss_test: 1.6579 acc_test: 0.4740 time: 4.9024s
Epoch: 0051 loss_train: 0.0099 acc_train: 1.0000 loss_val: 1.4334 acc_val: 0.5200 loss_test: 1.1110 acc_test: 0.7060 time: 0.4531s
Epoch: 0101 loss_train: 0.0078 acc_train: 1.0000 loss_val: 1.4701 acc_val: 0.5233 loss_test: 1.1331 acc_test: 0.7120 time: 0.4966s
Epoch: 0151 loss_train: 0.0055 acc_train: 1.0000 loss_val: 1.7391 acc_val: 0.4767 loss_test: 1.2457 acc_test: 0.7000 time: 0.4494s
Epoch: 0201 loss_train: 0.0043 acc_train: 1.0000 loss_val: 1.8858 acc_val: 0.4767 loss_test: 1.3011 acc_test: 0.6970 time: 0.4265s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0024 acc_val: 0.4833 loss_test: 1.3502 acc_test: 0.6950 time: 0.4512s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0461 acc_val: 0.5033 loss_test: 1.3896 acc_test: 0.6940 time: 0.4639s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1153 acc_val: 0.5000 loss_test: 1.4265 acc_test: 0.6950 time: 0.4987s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1581 acc_val: 0.5033 loss_test: 1.4497 acc_test: 0.6960 time: 0.4971s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.2275 acc_val: 0.5033 loss_test: 1.4784 acc_test: 0.6950 time: 0.4668s
Optimization Finished!
Total time elapsed: 240.0262s, best testing performance  0.716000, minimun loss  0.940271
************ Finish ************
0
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.8096 acc_train: 0.1250 loss_val: 1.7940 acc_val: 0.1800 loss_test: 1.6765 acc_test: 0.5440 time: 10.9223s
Epoch: 0051 loss_train: 0.0097 acc_train: 1.0000 loss_val: 1.9695 acc_val: 0.3700 loss_test: 1.2177 acc_test: 0.6570 time: 0.4596s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.9198 acc_val: 0.4067 loss_test: 1.2159 acc_test: 0.6760 time: 0.4228s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 1.9810 acc_val: 0.4233 loss_test: 1.2701 acc_test: 0.6830 time: 0.5161s
Epoch: 0201 loss_train: 0.0045 acc_train: 1.0000 loss_val: 2.0528 acc_val: 0.4400 loss_test: 1.3260 acc_test: 0.6810 time: 0.4205s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0968 acc_val: 0.4467 loss_test: 1.3658 acc_test: 0.6840 time: 0.4494s
Epoch: 0301 loss_train: 0.0031 acc_train: 1.0000 loss_val: 2.1323 acc_val: 0.4767 loss_test: 1.4002 acc_test: 0.6850 time: 0.4698s
Epoch: 0351 loss_train: 0.0027 acc_train: 1.0000 loss_val: 2.1674 acc_val: 0.4833 loss_test: 1.4324 acc_test: 0.6880 time: 0.4826s
Epoch: 0401 loss_train: 0.0023 acc_train: 1.0000 loss_val: 2.1837 acc_val: 0.5000 loss_test: 1.4558 acc_test: 0.6930 time: 0.5225s
Epoch: 0451 loss_train: 0.0020 acc_train: 1.0000 loss_val: 2.2258 acc_val: 0.5000 loss_test: 1.4809 acc_test: 0.6960 time: 0.5304s
Optimization Finished!
Total time elapsed: 248.4285s, best testing performance  0.696000, minimun loss  0.964420
************ Finish ************
1
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7747 acc_train: 0.3000 loss_val: 1.8066 acc_val: 0.1633 loss_test: 1.6634 acc_test: 0.4980 time: 10.8619s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8404 acc_val: 0.3800 loss_test: 1.2051 acc_test: 0.6590 time: 0.4577s
Epoch: 0101 loss_train: 0.0080 acc_train: 1.0000 loss_val: 1.7427 acc_val: 0.4233 loss_test: 1.1857 acc_test: 0.6880 time: 0.4564s
Epoch: 0151 loss_train: 0.0057 acc_train: 1.0000 loss_val: 1.8547 acc_val: 0.4467 loss_test: 1.2563 acc_test: 0.6860 time: 0.4694s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9480 acc_val: 0.4767 loss_test: 1.3062 acc_test: 0.6890 time: 0.4920s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0068 acc_val: 0.4833 loss_test: 1.3481 acc_test: 0.6910 time: 0.4556s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0396 acc_val: 0.4833 loss_test: 1.3830 acc_test: 0.6940 time: 0.4700s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0807 acc_val: 0.5033 loss_test: 1.4198 acc_test: 0.7000 time: 0.4982s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1060 acc_val: 0.5033 loss_test: 1.4503 acc_test: 0.6980 time: 0.6218s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1295 acc_val: 0.5100 loss_test: 1.4803 acc_test: 0.6950 time: 0.4300s
Optimization Finished!
Total time elapsed: 247.8531s, best testing performance  0.701000, minimun loss  0.956842
************ Finish ************
2
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7970 acc_train: 0.1083 loss_val: 1.7965 acc_val: 0.2167 loss_test: 1.6816 acc_test: 0.5240 time: 7.1353s
Epoch: 0051 loss_train: 0.0101 acc_train: 1.0000 loss_val: 1.8938 acc_val: 0.3733 loss_test: 1.2150 acc_test: 0.6570 time: 0.5029s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9539 acc_val: 0.4233 loss_test: 1.2419 acc_test: 0.6710 time: 0.4540s
Epoch: 0151 loss_train: 0.0061 acc_train: 1.0000 loss_val: 2.0379 acc_val: 0.4333 loss_test: 1.2988 acc_test: 0.6790 time: 0.4636s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0690 acc_val: 0.4633 loss_test: 1.3382 acc_test: 0.6830 time: 0.4528s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0892 acc_val: 0.4767 loss_test: 1.3701 acc_test: 0.6920 time: 0.4710s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0848 acc_val: 0.4800 loss_test: 1.3956 acc_test: 0.6940 time: 0.4800s
Epoch: 0351 loss_train: 0.0026 acc_train: 1.0000 loss_val: 2.0834 acc_val: 0.4967 loss_test: 1.4177 acc_test: 0.7020 time: 0.4985s
Epoch: 0401 loss_train: 0.0022 acc_train: 1.0000 loss_val: 2.0876 acc_val: 0.5033 loss_test: 1.4408 acc_test: 0.7010 time: 0.5026s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1050 acc_val: 0.5033 loss_test: 1.4679 acc_test: 0.6980 time: 0.4630s
Optimization Finished!
Total time elapsed: 239.6602s, best testing performance  0.704000, minimun loss  0.983994
************ Finish ************
3
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7967 acc_train: 0.1500 loss_val: 1.7649 acc_val: 0.2267 loss_test: 1.6877 acc_test: 0.4890 time: 13.7145s
Epoch: 0051 loss_train: 0.0107 acc_train: 1.0000 loss_val: 1.9301 acc_val: 0.3633 loss_test: 1.2385 acc_test: 0.6560 time: 0.4560s
Epoch: 0101 loss_train: 0.0084 acc_train: 1.0000 loss_val: 1.8465 acc_val: 0.4300 loss_test: 1.2151 acc_test: 0.6830 time: 0.5443s
Epoch: 0151 loss_train: 0.0058 acc_train: 1.0000 loss_val: 1.8932 acc_val: 0.4533 loss_test: 1.2725 acc_test: 0.6880 time: 0.4486s
Epoch: 0201 loss_train: 0.0044 acc_train: 1.0000 loss_val: 1.9646 acc_val: 0.4667 loss_test: 1.3184 acc_test: 0.6910 time: 0.4541s
Epoch: 0251 loss_train: 0.0035 acc_train: 1.0000 loss_val: 2.0065 acc_val: 0.4733 loss_test: 1.3584 acc_test: 0.6940 time: 0.4240s
Epoch: 0301 loss_train: 0.0029 acc_train: 1.0000 loss_val: 2.0529 acc_val: 0.4933 loss_test: 1.3953 acc_test: 0.6960 time: 0.4682s
Epoch: 0351 loss_train: 0.0024 acc_train: 1.0000 loss_val: 2.0873 acc_val: 0.4933 loss_test: 1.4269 acc_test: 0.6930 time: 0.5432s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1329 acc_val: 0.5000 loss_test: 1.4558 acc_test: 0.6970 time: 0.4345s
Epoch: 0451 loss_train: 0.0018 acc_train: 1.0000 loss_val: 2.1748 acc_val: 0.4933 loss_test: 1.4845 acc_test: 0.6960 time: 0.4487s
Optimization Finished!
Total time elapsed: 245.4475s, best testing performance  0.699000, minimun loss  0.992981
************ Finish ************
4
************ Start ************
GrapBert, dataset: citeseer, residual: graph_raw, k: 70, alpha: 1, hidden dimension: 32, hidden layer: 2, attention head: 2
Loading citeseer dataset...
Load WL Dictionary
Load Hop Distance Dictionary
Load Subgraph Batches
Epoch: 0001 loss_train: 1.7889 acc_train: 0.2000 loss_val: 1.8092 acc_val: 0.1667 loss_test: 1.6705 acc_test: 0.4850 time: 6.9259s
Epoch: 0051 loss_train: 0.0100 acc_train: 1.0000 loss_val: 1.8017 acc_val: 0.3933 loss_test: 1.1777 acc_test: 0.6750 time: 0.4481s
Epoch: 0101 loss_train: 0.0081 acc_train: 1.0000 loss_val: 1.9273 acc_val: 0.4100 loss_test: 1.2227 acc_test: 0.6800 time: 0.4799s
Epoch: 0151 loss_train: 0.0059 acc_train: 1.0000 loss_val: 2.0066 acc_val: 0.4167 loss_test: 1.2808 acc_test: 0.6910 time: 0.4232s
Epoch: 0201 loss_train: 0.0046 acc_train: 1.0000 loss_val: 2.0483 acc_val: 0.4667 loss_test: 1.3206 acc_test: 0.6880 time: 0.4487s
Epoch: 0251 loss_train: 0.0037 acc_train: 1.0000 loss_val: 2.0728 acc_val: 0.4833 loss_test: 1.3545 acc_test: 0.6880 time: 0.4697s
Epoch: 0301 loss_train: 0.0030 acc_train: 1.0000 loss_val: 2.0853 acc_val: 0.4933 loss_test: 1.3881 acc_test: 0.6890 time: 0.4610s
Epoch: 0351 loss_train: 0.0025 acc_train: 1.0000 loss_val: 2.1272 acc_val: 0.5067 loss_test: 1.4207 acc_test: 0.6940 time: 0.4812s
Epoch: 0401 loss_train: 0.0021 acc_train: 1.0000 loss_val: 2.1613 acc_val: 0.5133 loss_test: 1.4552 acc_test: 0.6980 time: 0.4711s
Epoch: 0451 loss_train: 0.0019 acc_train: 1.0000 loss_val: 2.1885 acc_val: 0.5167 loss_test: 1.4820 acc_test: 0.7000 time: 0.4831s
Optimization Finished!
Total time elapsed: 239.3554s, best testing performance  0.701000, minimun loss  0.974362
************ Finish ************
